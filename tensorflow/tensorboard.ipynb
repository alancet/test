{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_datab/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_datab/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_datab/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_datab/t10k-labels-idx1-ubyte.gz\n",
      "Step: 0, Accuracy: 0.407700\n",
      "Step: 10, Accuracy: 0.677900\n",
      "Step: 20, Accuracy: 0.772800\n",
      "Step: 30, Accuracy: 0.773700\n",
      "Step: 40, Accuracy: 0.794500\n",
      "Step: 50, Accuracy: 0.810900\n",
      "Step: 60, Accuracy: 0.822900\n",
      "Step: 70, Accuracy: 0.828300\n",
      "Step: 80, Accuracy: 0.829400\n",
      "Step: 90, Accuracy: 0.839200\n",
      "Step: 100, Accuracy: 0.842700\n",
      "Step: 110, Accuracy: 0.846000\n",
      "Step: 120, Accuracy: 0.851000\n",
      "Step: 130, Accuracy: 0.859600\n",
      "Step: 140, Accuracy: 0.864200\n",
      "Step: 150, Accuracy: 0.866000\n",
      "Step: 160, Accuracy: 0.866800\n",
      "Step: 170, Accuracy: 0.871000\n",
      "Step: 180, Accuracy: 0.872500\n",
      "Step: 190, Accuracy: 0.874600\n",
      "Step: 200, Accuracy: 0.878400\n",
      "Step: 210, Accuracy: 0.875900\n",
      "Step: 220, Accuracy: 0.880600\n",
      "Step: 230, Accuracy: 0.883900\n",
      "Step: 240, Accuracy: 0.886300\n",
      "Step: 250, Accuracy: 0.886300\n",
      "Step: 260, Accuracy: 0.888500\n",
      "Step: 270, Accuracy: 0.890900\n",
      "Step: 280, Accuracy: 0.890500\n",
      "Step: 290, Accuracy: 0.889900\n",
      "Step: 300, Accuracy: 0.894800\n",
      "Step: 310, Accuracy: 0.893300\n",
      "Step: 320, Accuracy: 0.893900\n",
      "Step: 330, Accuracy: 0.893600\n",
      "Step: 340, Accuracy: 0.894500\n",
      "Step: 350, Accuracy: 0.896100\n",
      "Step: 360, Accuracy: 0.896400\n",
      "Step: 370, Accuracy: 0.895900\n",
      "Step: 380, Accuracy: 0.897500\n",
      "Step: 390, Accuracy: 0.898400\n",
      "Step: 400, Accuracy: 0.897800\n",
      "Step: 410, Accuracy: 0.897600\n",
      "Step: 420, Accuracy: 0.899300\n",
      "Step: 430, Accuracy: 0.902500\n",
      "Step: 440, Accuracy: 0.901200\n",
      "Step: 450, Accuracy: 0.901600\n",
      "Step: 460, Accuracy: 0.901200\n",
      "Step: 470, Accuracy: 0.900500\n",
      "Step: 480, Accuracy: 0.903700\n",
      "Step: 490, Accuracy: 0.903400\n",
      "Step: 500, Accuracy: 0.902400\n",
      "Step: 510, Accuracy: 0.903400\n",
      "Step: 520, Accuracy: 0.904500\n",
      "Step: 530, Accuracy: 0.905200\n",
      "Step: 540, Accuracy: 0.904600\n",
      "Step: 550, Accuracy: 0.904900\n",
      "Step: 560, Accuracy: 0.906700\n",
      "Step: 570, Accuracy: 0.906000\n",
      "Step: 580, Accuracy: 0.905100\n",
      "Step: 590, Accuracy: 0.905700\n",
      "Step: 600, Accuracy: 0.906400\n",
      "Step: 610, Accuracy: 0.906100\n",
      "Step: 620, Accuracy: 0.906400\n",
      "Step: 630, Accuracy: 0.909000\n",
      "Step: 640, Accuracy: 0.909000\n",
      "Step: 650, Accuracy: 0.908800\n",
      "Step: 660, Accuracy: 0.908700\n",
      "Step: 670, Accuracy: 0.908600\n",
      "Step: 680, Accuracy: 0.909000\n",
      "Step: 690, Accuracy: 0.909400\n",
      "Step: 700, Accuracy: 0.909000\n",
      "Step: 710, Accuracy: 0.909700\n",
      "Step: 720, Accuracy: 0.908800\n",
      "Step: 730, Accuracy: 0.909200\n",
      "Step: 740, Accuracy: 0.910400\n",
      "Step: 750, Accuracy: 0.911700\n",
      "Step: 760, Accuracy: 0.911400\n",
      "Step: 770, Accuracy: 0.909800\n",
      "Step: 780, Accuracy: 0.909600\n",
      "Step: 790, Accuracy: 0.910700\n",
      "Step: 800, Accuracy: 0.910600\n",
      "Step: 810, Accuracy: 0.911600\n",
      "Step: 820, Accuracy: 0.911800\n",
      "Step: 830, Accuracy: 0.911800\n",
      "Step: 840, Accuracy: 0.911700\n",
      "Step: 850, Accuracy: 0.911600\n",
      "Step: 860, Accuracy: 0.911400\n",
      "Step: 870, Accuracy: 0.912100\n",
      "Step: 880, Accuracy: 0.913700\n",
      "Step: 890, Accuracy: 0.911700\n",
      "Step: 900, Accuracy: 0.913200\n",
      "Step: 910, Accuracy: 0.912500\n",
      "Step: 920, Accuracy: 0.912500\n",
      "Step: 930, Accuracy: 0.913100\n",
      "Step: 940, Accuracy: 0.914900\n",
      "Step: 950, Accuracy: 0.914200\n",
      "Step: 960, Accuracy: 0.913300\n",
      "Step: 970, Accuracy: 0.913500\n",
      "Step: 980, Accuracy: 0.913900\n",
      "Step: 990, Accuracy: 0.914100\n",
      "Step: 1000, Accuracy: 0.915200\n",
      "Step: 1010, Accuracy: 0.915200\n",
      "Step: 1020, Accuracy: 0.915800\n",
      "Step: 1030, Accuracy: 0.915900\n",
      "Step: 1040, Accuracy: 0.916000\n",
      "Step: 1050, Accuracy: 0.914800\n",
      "Step: 1060, Accuracy: 0.914600\n",
      "Step: 1070, Accuracy: 0.916100\n",
      "Step: 1080, Accuracy: 0.913900\n",
      "Step: 1090, Accuracy: 0.912600\n",
      "Step: 1100, Accuracy: 0.914200\n",
      "Step: 1110, Accuracy: 0.914300\n",
      "Step: 1120, Accuracy: 0.914400\n",
      "Step: 1130, Accuracy: 0.914300\n",
      "Step: 1140, Accuracy: 0.914200\n",
      "Step: 1150, Accuracy: 0.914400\n",
      "Step: 1160, Accuracy: 0.915100\n",
      "Step: 1170, Accuracy: 0.915000\n",
      "Step: 1180, Accuracy: 0.916300\n",
      "Step: 1190, Accuracy: 0.915000\n",
      "Step: 1200, Accuracy: 0.914400\n",
      "Step: 1210, Accuracy: 0.915800\n",
      "Step: 1220, Accuracy: 0.915900\n",
      "Step: 1230, Accuracy: 0.916000\n",
      "Step: 1240, Accuracy: 0.915800\n",
      "Step: 1250, Accuracy: 0.915200\n",
      "Step: 1260, Accuracy: 0.913200\n",
      "Step: 1270, Accuracy: 0.916100\n",
      "Step: 1280, Accuracy: 0.917100\n",
      "Step: 1290, Accuracy: 0.916500\n",
      "Step: 1300, Accuracy: 0.915400\n",
      "Step: 1310, Accuracy: 0.915200\n",
      "Step: 1320, Accuracy: 0.915700\n",
      "Step: 1330, Accuracy: 0.916000\n",
      "Step: 1340, Accuracy: 0.915700\n",
      "Step: 1350, Accuracy: 0.916700\n",
      "Step: 1360, Accuracy: 0.917600\n",
      "Step: 1370, Accuracy: 0.917500\n",
      "Step: 1380, Accuracy: 0.916900\n",
      "Step: 1390, Accuracy: 0.917200\n",
      "Step: 1400, Accuracy: 0.916800\n",
      "Step: 1410, Accuracy: 0.916200\n",
      "Step: 1420, Accuracy: 0.916500\n",
      "Step: 1430, Accuracy: 0.918000\n",
      "Step: 1440, Accuracy: 0.918500\n",
      "Step: 1450, Accuracy: 0.917400\n",
      "Step: 1460, Accuracy: 0.918200\n",
      "Step: 1470, Accuracy: 0.918200\n",
      "Step: 1480, Accuracy: 0.918900\n",
      "Step: 1490, Accuracy: 0.919700\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('MNIST_datab', one_hot=True)\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "w = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "y = tf.nn.softmax(tf.matmul(x, w) + b)\n",
    "t = tf.placeholder(tf.float32, [None, 10])\n",
    "loss = -tf.reduce_sum(t * tf.log(tf.clip_by_value(y, 1e-10, 1.0)))\n",
    "train_step = tf.train.AdamOptimizer().minimize(loss)\n",
    "correct = tf.equal(tf.argmax(y, 1), tf.argmax(t, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "tf.summary.scalar('accuracy', accuracy)\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "with tf.Session() as sess:    \n",
    "    writer = tf.summary.FileWriter('logs', sess.graph)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(1500):\n",
    "        batch = mnist.train.next_batch(100)\n",
    "        sess.run(train_step, feed_dict={x:batch[0], t:batch[1]})\n",
    "        if not i % 10:\n",
    "            summary, acc = sess.run([merged, accuracy], feed_dict={x:mnist.test.images, t:mnist.test.labels})\n",
    "            writer.add_summary(summary, i)\n",
    "            print('Step: %d, Accuracy: %f' % (i, acc))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_datab/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_datab/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_datab/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_datab/t10k-labels-idx1-ubyte.gz\n",
      "Step: 0, Accuracy: 0.326000\n",
      "Step: 100, Accuracy: 0.846900\n",
      "Step: 200, Accuracy: 0.879400\n",
      "Step: 300, Accuracy: 0.890200\n",
      "Step: 400, Accuracy: 0.898800\n",
      "Step: 500, Accuracy: 0.904500\n",
      "Step: 600, Accuracy: 0.907800\n",
      "Step: 700, Accuracy: 0.909000\n",
      "Step: 800, Accuracy: 0.911600\n",
      "Step: 900, Accuracy: 0.911000\n",
      "Step: 1000, Accuracy: 0.913300\n",
      "Step: 1100, Accuracy: 0.914700\n",
      "Step: 1200, Accuracy: 0.914300\n",
      "Step: 1300, Accuracy: 0.915700\n",
      "Step: 1400, Accuracy: 0.919200\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('MNIST_datab', one_hot=True)\n",
    "\n",
    "with tf.name_scope('input'):\n",
    "    x = tf.placeholder(tf.float32, [None, 784])\n",
    "    w = tf.Variable(tf.zeros([784, 10]))\n",
    "    b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "with tf.name_scope('output'):\n",
    "    y = tf.nn.softmax(tf.matmul(x, w) + b)\n",
    "\n",
    "with tf.name_scope('loss'):\n",
    "    t = tf.placeholder(tf.float32, [None, 10])\n",
    "    loss = -tf.reduce_sum(t * tf.log(tf.clip_by_value(y, 1e-10, 1.0)))\n",
    "\n",
    "with tf.name_scope('train'):\n",
    "    train_step = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "with tf.name_scope('accuracy'):\n",
    "    correct = tf.equal(tf.argmax(y, 1), tf.argmax(t, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "tf.summary.scalar('accuracy', accuracy)\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "with tf.Session() as sess:    \n",
    "    writer = tf.summary.FileWriter('logs2', sess.graph)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(1500):\n",
    "        batch = mnist.train.next_batch(100)\n",
    "        sess.run(train_step, feed_dict={x:batch[0], t:batch[1]})\n",
    "        if not i % 100:\n",
    "            summary, acc = sess.run([merged, accuracy], feed_dict={x:mnist.test.images, t:mnist.test.labels})\n",
    "            writer.add_summary(summary, i)\n",
    "            print('Step: %d, Accuracy: %f' % (i, acc))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 定数で1 + 2\n",
    "x = tf.constant(1, name='x')\n",
    "y = tf.constant(2, name='y')\n",
    "z = x + y\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(z)\n",
    "    # SummaryWriterでグラフを書く\n",
    "    summary_writer = tf.summary.FileWriter('data', graph=sess.graph)\n",
    "    tf.summary.scalar('z', z)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
