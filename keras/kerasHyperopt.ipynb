{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://qiita.com/cvusk/items/1f3b178f34c39beb29ff#_reference-3c5df6e5237c0c705690\n",
    "https://github.com/shibuiwilliam/keras_opt/blob/master/tpe_nn.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import hp, tpe, Trials, fmin\n",
    "import numpy as np\n",
    "import pandas as pds\n",
    "import random\n",
    "from keras.layers import Activation, Dropout, BatchNormalization, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.datasets import mnist\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST class\n",
    "class MNIST():\n",
    "    def __init__(self,\n",
    "                 l1_out=512, \n",
    "                 l2_out=512, \n",
    "                 l1_drop=0.2, \n",
    "                 l2_drop=0.2, \n",
    "                 bn1=0,\n",
    "                 bn2=0,\n",
    "                 batch_size=100, \n",
    "                 epochs=10, \n",
    "                 validation_split=0.1):\n",
    "        self.l1_out = l1_out\n",
    "        self.l2_out = l2_out\n",
    "        self.l1_drop = l1_drop\n",
    "        self.l2_drop = l2_drop\n",
    "        self.bn1 = bn1\n",
    "        self.bn2 = bn2\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.validation_split = validation_split\n",
    "        self.__x_train, self.__x_test, self.__y_train, self.__y_test = self.mnist_data()\n",
    "        self.__model = self.mnist_model()\n",
    "        params = \"\"\"\n",
    "        validation_split:\\t{0}\n",
    "        l1_drop:\\t{1}\n",
    "        l2_drop:\\t{2}\n",
    "        l1_out:\\t{3}\n",
    "        l2_out:\\t{4}\n",
    "        bn1:\\t{5}\n",
    "        bn2:\\t{6}\n",
    "        batch_size:\\t{7}\n",
    "        epochs:\\t{8}\n",
    "        \"\"\".format(self.validation_split,\n",
    "                   self.l1_drop, self.l2_drop,\n",
    "                   self.l1_out, self.l2_out,\n",
    "                   self.bn1, self.bn2,\n",
    "                   self.batch_size, self.epochs)\n",
    "        print(params)\n",
    "        \n",
    "    # load mnist data from keras dataset\n",
    "    def mnist_data(self):\n",
    "        (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "        X_train = X_train.reshape(60000, 784)\n",
    "        X_test = X_test.reshape(10000, 784)\n",
    "\n",
    "        X_train = X_train.astype('float32')\n",
    "        X_test = X_test.astype('float32')\n",
    "        X_train /= 255\n",
    "        X_test /= 255\n",
    "\n",
    "        Y_train = np_utils.to_categorical(y_train, 10)\n",
    "        Y_test = np_utils.to_categorical(y_test, 10)\n",
    "        return X_train, X_test, Y_train, Y_test\n",
    "    \n",
    "    # mnist model\n",
    "    def mnist_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(self.l1_out, input_shape=(784,)))\n",
    "        if self.bn1 == 0:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(self.l1_drop))\n",
    "        model.add(Dense(self.l2_out))\n",
    "        if self.bn2 == 0:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(self.l2_drop))\n",
    "        model.add(Dense(10))\n",
    "        model.add(Activation('softmax'))\n",
    "        model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer=Adam(),\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        return model\n",
    "    \n",
    "    # fit mnist model\n",
    "    def mnist_fit(self):\n",
    "        early_stopping = EarlyStopping(patience=0, verbose=1)\n",
    "        \n",
    "        self.__model.fit(self.__x_train, self.__y_train,\n",
    "                       batch_size=self.batch_size,\n",
    "                       epochs=self.epochs,\n",
    "                       verbose=0,\n",
    "                       validation_split=self.validation_split,\n",
    "                       callbacks=[early_stopping])\n",
    "    \n",
    "    # evaluate mnist model\n",
    "    def mnist_evaluate(self):\n",
    "        self.mnist_fit()\n",
    "        \n",
    "        evaluation = self.__model.evaluate(self.__x_test, self.__y_test, batch_size=self.batch_size, verbose=0)\n",
    "        return evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to run mnist class\n",
    "def run_mnist(args):\n",
    "    _mnist = MNIST(**args)\n",
    "    mnist_evaluation = _mnist.mnist_evaluate()\n",
    "    print(\"loss:{0} \\t\\t accuracy:{1}\".format(mnist_evaluation[0], mnist_evaluation[1]))\n",
    "    return mnist_evaluation[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperopt_parameters = {\n",
    "    'validation_split': hp.uniform('validation_split', 0.0, 0.3),\n",
    "    'l1_drop': hp.uniform('l1_drop', 0.0, 0.3),\n",
    "    'l2_drop': hp.uniform('l2_drop', 0.0, 0.3),\n",
    "    'l1_out': hp.choice('l1_out', [64, 128, 256, 512, 1024]),\n",
    "    'l2_out': hp.choice('l2_out', [64, 128, 256, 512, 1024]),\n",
    "    'bn1': hp.choice('bn1', [0, 1]),\n",
    "    'bn2': hp.choice('bn2', [0, 1]),\n",
    "    'batch_size': hp.choice('batch_size', [10, 100, 500]),\n",
    "    'epochs': hp.choice('epochs', [5, 10, 20]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        validation_split:\t0.25210183207450515\n",
      "        l1_drop:\t0.04078296978658915\n",
      "        l2_drop:\t0.12967533990443414\n",
      "        l1_out:\t256\n",
      "        l2_out:\t1024\n",
      "        bn1:\t0\n",
      "        bn2:\t0\n",
      "        batch_size:\t10\n",
      "        epochs:\t10\n",
      "        \n",
      "Epoch 00006: early stopping\n",
      "loss:0.0849205720221359 \t\t accuracy:0.9756999960541726\n",
      "\n",
      "        validation_split:\t0.06766876800843981\n",
      "        l1_drop:\t0.15831282640415287\n",
      "        l2_drop:\t0.2712976414226083\n",
      "        l1_out:\t64\n",
      "        l2_out:\t256\n",
      "        bn1:\t0\n",
      "        bn2:\t0\n",
      "        batch_size:\t100\n",
      "        epochs:\t20\n",
      "        \n",
      "Epoch 00006: early stopping\n",
      "loss:0.08202886960702017 \t\t accuracy:0.9737000060081482\n",
      "\n",
      "        validation_split:\t0.15686753908968556\n",
      "        l1_drop:\t0.08310994380234824\n",
      "        l2_drop:\t0.17774936069553876\n",
      "        l1_out:\t1024\n",
      "        l2_out:\t256\n",
      "        bn1:\t0\n",
      "        bn2:\t1\n",
      "        batch_size:\t10\n",
      "        epochs:\t20\n",
      "        \n",
      "Epoch 00003: early stopping\n",
      "loss:0.09641656795304857 \t\t accuracy:0.970799995303154\n",
      "\n",
      "        validation_split:\t0.27593699588753307\n",
      "        l1_drop:\t0.2694958470268064\n",
      "        l2_drop:\t0.05437416757485166\n",
      "        l1_out:\t64\n",
      "        l2_out:\t128\n",
      "        bn1:\t0\n",
      "        bn2:\t1\n",
      "        batch_size:\t10\n",
      "        epochs:\t20\n",
      "        \n",
      "Epoch 00006: early stopping\n",
      "loss:0.11814980891566665 \t\t accuracy:0.9641999947428703\n",
      "\n",
      "        validation_split:\t0.02518961603074906\n",
      "        l1_drop:\t0.005409662554518779\n",
      "        l2_drop:\t0.2452174369138502\n",
      "        l1_out:\t64\n",
      "        l2_out:\t512\n",
      "        bn1:\t0\n",
      "        bn2:\t0\n",
      "        batch_size:\t10\n",
      "        epochs:\t20\n",
      "        \n",
      "Epoch 00004: early stopping\n",
      "loss:0.07950071955936437 \t\t accuracy:0.9737999957203866\n",
      "\n",
      "        validation_split:\t0.28598326721795136\n",
      "        l1_drop:\t0.13621247127634953\n",
      "        l2_drop:\t0.19972481379574133\n",
      "        l1_out:\t64\n",
      "        l2_out:\t512\n",
      "        bn1:\t1\n",
      "        bn2:\t0\n",
      "        batch_size:\t100\n",
      "        epochs:\t5\n",
      "        \n",
      "Epoch 00004: early stopping\n",
      "loss:0.09821990272786935 \t\t accuracy:0.9695000034570694\n",
      "\n",
      "        validation_split:\t0.20435745044865122\n",
      "        l1_drop:\t0.26516063422860503\n",
      "        l2_drop:\t0.02809066365822341\n",
      "        l1_out:\t128\n",
      "        l2_out:\t1024\n",
      "        bn1:\t1\n",
      "        bn2:\t0\n",
      "        batch_size:\t500\n",
      "        epochs:\t5\n",
      "        \n",
      "loss:0.0807685375213623 \t\t accuracy:0.9750999987125397\n",
      "\n",
      "        validation_split:\t0.01504138131868634\n",
      "        l1_drop:\t0.1734010487352102\n",
      "        l2_drop:\t0.10450278110570312\n",
      "        l1_out:\t1024\n",
      "        l2_out:\t512\n",
      "        bn1:\t0\n",
      "        bn2:\t0\n",
      "        batch_size:\t10\n",
      "        epochs:\t20\n",
      "        \n",
      "Epoch 00004: early stopping\n",
      "loss:0.06884805611037564 \t\t accuracy:0.979499996304512\n",
      "\n",
      "        validation_split:\t0.23957643588095556\n",
      "        l1_drop:\t0.14961053551686163\n",
      "        l2_drop:\t0.17798670502663363\n",
      "        l1_out:\t128\n",
      "        l2_out:\t64\n",
      "        bn1:\t0\n",
      "        bn2:\t1\n",
      "        batch_size:\t100\n",
      "        epochs:\t5\n",
      "        \n",
      "loss:0.08873753791500348 \t\t accuracy:0.974100005030632\n",
      "\n",
      "        validation_split:\t0.2611648514544326\n",
      "        l1_drop:\t0.19593191204036478\n",
      "        l2_drop:\t0.10285900450080485\n",
      "        l1_out:\t1024\n",
      "        l2_out:\t256\n",
      "        bn1:\t1\n",
      "        bn2:\t0\n",
      "        batch_size:\t10\n",
      "        epochs:\t5\n",
      "        \n",
      "Epoch 00003: early stopping\n",
      "loss:0.0834480235249066 \t\t accuracy:0.9731999952197075\n",
      "\n",
      "        validation_split:\t0.14001610534222517\n",
      "        l1_drop:\t0.2837577859483468\n",
      "        l2_drop:\t0.18060019874238803\n",
      "        l1_out:\t1024\n",
      "        l2_out:\t256\n",
      "        bn1:\t0\n",
      "        bn2:\t1\n",
      "        batch_size:\t10\n",
      "        epochs:\t20\n",
      "        \n",
      "Epoch 00008: early stopping\n",
      "loss:0.06844664397383304 \t\t accuracy:0.9812999964356423\n",
      "\n",
      "        validation_split:\t0.2813467913520218\n",
      "        l1_drop:\t0.18145033328150262\n",
      "        l2_drop:\t0.0639739002708495\n",
      "        l1_out:\t512\n",
      "        l2_out:\t128\n",
      "        bn1:\t1\n",
      "        bn2:\t1\n",
      "        batch_size:\t10\n",
      "        epochs:\t10\n",
      "        \n",
      "Epoch 00005: early stopping\n",
      "loss:0.08645215958907229 \t\t accuracy:0.9772999957799912\n",
      "\n",
      "        validation_split:\t0.002893977570911854\n",
      "        l1_drop:\t0.020519645143870457\n",
      "        l2_drop:\t0.1093653971096225\n",
      "        l1_out:\t256\n",
      "        l2_out:\t128\n",
      "        bn1:\t1\n",
      "        bn2:\t1\n",
      "        batch_size:\t500\n",
      "        epochs:\t5\n",
      "        \n",
      "Epoch 00005: early stopping\n",
      "loss:0.07440370726399123 \t\t accuracy:0.9757999986410141\n",
      "\n",
      "        validation_split:\t0.13494520795524698\n",
      "        l1_drop:\t0.1204459549710683\n",
      "        l2_drop:\t0.14361538967649456\n",
      "        l1_out:\t128\n",
      "        l2_out:\t64\n",
      "        bn1:\t1\n",
      "        bn2:\t0\n",
      "        batch_size:\t500\n",
      "        epochs:\t5\n",
      "        \n",
      "loss:0.08824477214366197 \t\t accuracy:0.9748999983072281\n",
      "\n",
      "        validation_split:\t0.2488963511741761\n",
      "        l1_drop:\t0.0289680657963038\n",
      "        l2_drop:\t0.27908710417841787\n",
      "        l1_out:\t1024\n",
      "        l2_out:\t128\n",
      "        bn1:\t0\n",
      "        bn2:\t0\n",
      "        batch_size:\t10\n",
      "        epochs:\t5\n",
      "        \n",
      "Epoch 00005: early stopping\n",
      "loss:0.07112955600782288 \t\t accuracy:0.9790999960899353\n",
      "\n",
      "        validation_split:\t0.008593150268823223\n",
      "        l1_drop:\t0.22362658798969945\n",
      "        l2_drop:\t0.21120439478984113\n",
      "        l1_out:\t1024\n",
      "        l2_out:\t1024\n",
      "        bn1:\t1\n",
      "        bn2:\t1\n",
      "        batch_size:\t10\n",
      "        epochs:\t5\n",
      "        \n",
      "Epoch 00002: early stopping\n",
      "loss:0.11808726796884036 \t\t accuracy:0.968099995136261\n",
      "\n",
      "        validation_split:\t0.017501815419015552\n",
      "        l1_drop:\t0.08552098668935329\n",
      "        l2_drop:\t0.04220288595692059\n",
      "        l1_out:\t64\n",
      "        l2_out:\t512\n",
      "        bn1:\t1\n",
      "        bn2:\t0\n",
      "        batch_size:\t500\n",
      "        epochs:\t20\n",
      "        \n",
      "Epoch 00004: early stopping\n",
      "loss:0.09323564684018493 \t\t accuracy:0.9720999956130981\n",
      "\n",
      "        validation_split:\t0.2591778023049591\n",
      "        l1_drop:\t0.04212552597835123\n",
      "        l2_drop:\t0.23692733383868106\n",
      "        l1_out:\t1024\n",
      "        l2_out:\t64\n",
      "        bn1:\t1\n",
      "        bn2:\t1\n",
      "        batch_size:\t100\n",
      "        epochs:\t5\n",
      "        \n",
      "Epoch 00005: early stopping\n",
      "loss:0.07000078457960626 \t\t accuracy:0.9797000056505203\n",
      "\n",
      "        validation_split:\t0.13049768558180427\n",
      "        l1_drop:\t0.1017633700971969\n",
      "        l2_drop:\t0.1458698801031853\n",
      "        l1_out:\t512\n",
      "        l2_out:\t256\n",
      "        bn1:\t0\n",
      "        bn2:\t1\n",
      "        batch_size:\t100\n",
      "        epochs:\t20\n",
      "        \n",
      "Epoch 00004: early stopping\n",
      "loss:0.08477146790071856 \t\t accuracy:0.9743000048398972\n",
      "\n",
      "        validation_split:\t0.06803998741086877\n",
      "        l1_drop:\t0.2883831565598951\n",
      "        l2_drop:\t0.05162875661944679\n",
      "        l1_out:\t128\n",
      "        l2_out:\t512\n",
      "        bn1:\t1\n",
      "        bn2:\t1\n",
      "        batch_size:\t500\n",
      "        epochs:\t5\n",
      "        \n",
      "loss:0.0935300731100142 \t\t accuracy:0.9712000012397766\n"
     ]
    }
   ],
   "source": [
    "max_evals = 20\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "best = fmin(run_mnist, hyperopt_parameters, \n",
    "            algo=tpe.suggest, max_evals=max_evals,\n",
    "           trials=trials, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 0, 'bn1': 0, 'bn2': 1, 'epochs': 2, 'l1_drop': 0.2837577859483468, 'l1_out': 4, 'l2_drop': 0.18060019874238803, 'l2_out': 2, 'validation_split': 0.14001610534222517}\n"
     ]
    }
   ],
   "source": [
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
