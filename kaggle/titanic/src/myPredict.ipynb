{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# data analysis and wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# train, test, validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "\n",
    "\n",
    "# scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "# decomposition\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "# feature engineering\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# feature selection\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../input/train.csv')\n",
    "test_df = pd.read_csv('../input/test.csv')\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# modify features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make ticket length feature\n",
    "https://www.kaggle.com/yuanxuan/titanic-random-forest-82-78/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Ticket_Len'] = train_df['Ticket'].apply(lambda x: len(x))\n",
    "test_df['Ticket_Len'] = test_df['Ticket'].apply(lambda x: len(x))\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.barplot(data=train_df, x=\"Ticket_Len\", y=\"Survived\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df['Ticket_Len'].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_df['Ticket_Len'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make Cabin First character feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Cabin_Letter\"] = train_df[\"Cabin\"].fillna('0').apply(lambda x: x[0])\n",
    "test_df[\"Cabin_Letter\"] = test_df[\"Cabin\"].fillna('0').apply(lambda x: x[0])\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.barplot(data=train_df, x=\"Cabin_Letter\", y=\"Survived\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.groupby(\"Cabin_Letter\").Survived.value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df[\"Cabin_Letter\"].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.barplot(data=train_df, x=\"Cabin_Letter\", y=\"Survived\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_df[\"Cabin_Letter\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make dummy variable for Cabin_Letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1309, 14)\n",
      "(891, 22) (418, 21)\n"
     ]
    }
   ],
   "source": [
    "train_test_df = pd.concat((train_df, test_df))\n",
    "\n",
    "print(train_test_df.shape)\n",
    "\n",
    "# apply get_dummies for Cabin_Letter\n",
    "train_test_df = pd.get_dummies(train_test_df, columns=[\"Cabin_Letter\"])\n",
    "\n",
    "#train_test_df.head()\n",
    "train_df = train_test_df.iloc[:train_df.shape[0]]\n",
    "test_df = train_test_df.iloc[train_df.shape[0]:]\n",
    "\n",
    "# drop added Survived column from test_df\n",
    "test_df = test_df.drop(\"Survived\", axis=1)\n",
    "print(train_df.shape, test_df.shape)\n",
    "\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make CabinBool feature\n",
    "**I think the idea here is that people with recorded cabin numbers are of higher socioeconomic class, and thus more likely to survive. **\n",
    "https://www.kaggle.com/nadintamer/titanic-survival-predictions-beginner\n",
    "\n",
    "- I tried it\n",
    "  - but gradient boosting result became worse. from 0.79904 to 0.77990\n",
    "  - more than cabinbool is necessary? should i use first letter of cabin name?\n",
    "\n",
    "**CabinBool is inclueded in Cabin letter and cabin number**\n",
    "**no need to use**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df[\"CabinBool\"] = (train_df[\"Cabin\"].notnull().astype('int'))\n",
    "test_df[\"CabinBool\"] = (test_df[\"Cabin\"].notnull().astype('int'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make Cabin number feature\n",
    "https://www.kaggle.com/yuanxuan/titanic-random-forest-82-78/notebook"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df['Cabin'].apply(lambda x: str(x).split(' ')[-1][1:]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/yuki/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:4619: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "for i in [train_df, test_df]:\n",
    "    i['Cabin_num1'] = i['Cabin'].apply(lambda x: str(x).split(' ')[-1][1:])\n",
    "    i['Cabin_num1'].replace('an', np.NaN, inplace = True)\n",
    "    i['Cabin_num1'] = i['Cabin_num1'].apply(lambda x: int(x) if not pd.isnull(x) and x != '' else np.NaN)\n",
    "    i['Cabin_num'] = pd.qcut(train_df['Cabin_num1'], 3)\n",
    "    i['Cabin_num'] = i['Cabin_num'].cat.add_categories([\"nan_category\"])\n",
    "    i['Cabin_num'] = i['Cabin_num'].fillna(\"nan_category\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat((train_df, pd.get_dummies(train_df['Cabin_num'], prefix='Cabin_num')), axis = 1)\n",
    "test_df = pd.concat((test_df, pd.get_dummies(test_df['Cabin_num'], prefix='Cabin_num')), axis = 1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.barplot(data=train_df, x=\"Cabin_num\", y=\"Survived\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.groupby([\"Cabin_num\"])[\"Survived\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_df['Cabin_num']\n",
    "del test_df['Cabin_num']\n",
    "del train_df['Cabin_num1']\n",
    "del test_df['Cabin_num1']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df[['Cabin_num_(1.999, 28.667]', \n",
    "          'Cabin_num_(28.667, 65.667]',\n",
    "          'Cabin_num_(65.667, 148.0]']].head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df[[\"Cabin_Letter_0\", \"Cabin_num_nan_category\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**duplicate feature. delete one of these**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(\"Cabin_Letter_0\", axis=1)\n",
    "test_df.drop(\"Cabin_Letter_0\", axis=1)\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## del Ticket, Cabin columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del Ticket, Cabin columns\n",
    "train_df = train_df.drop(['Ticket', 'Cabin'], axis=1)\n",
    "test_df = test_df.drop(['Ticket', 'Cabin'], axis=1)\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add title\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.barplot(data=train_df, x=\"Title\", y=\"Survived\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.Title.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make name length feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Name_Len'] = train_df['Name'].apply(lambda x: len(x))\n",
    "test_df['Name_Len'] = test_df['Name'].apply(lambda x: len(x))\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df[\"Name_Len\"].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.barplot(data=train_df, x=\"Name_Len\", y=\"Survived\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.groupby(\"Name_Len\").Survived.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## map value to Sex "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in combine:\n",
    "    dataset[\"Sex\"] = dataset[\"Sex\"].map({'female':1, 'male':0}).astype(int)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make Age_Null_Flag if the Age is nulll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Age_Null_Flag'] = train_df['Age'].apply(lambda x: 1 if pd.isnull(x) else 0)\n",
    "test_df['Age_Null_Flag'] = test_df['Age'].apply(lambda x: 1 if pd.isnull(x) else 0)\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.barplot(data=train_df, x=\"Age_Null_Flag\", y=\"Survived\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df[\"Age_Null_Flag\"].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_df[\"Age_Null_Flag\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fill na of Age\n",
    "\n",
    "options\n",
    "\n",
    "- by Sex and Pclass\n",
    "- by Title and Pclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### by Sex and Pclass"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "guess_ages = np.zeros((2,3))\n",
    "\n",
    "for dataset in combine:\n",
    "    for i in range(0, 2):\n",
    "        for j in range(0, 3):\n",
    "            guess_df = dataset[(dataset['Sex'] == i) & \\\n",
    "                                  (dataset['Pclass'] == j+1)]['Age'].dropna()\n",
    "\n",
    "            # age_mean = guess_df.mean()\n",
    "            # age_std = guess_df.std()\n",
    "            # age_guess = rnd.uniform(age_mean - age_std, age_mean + age_std)\n",
    "\n",
    "            age_guess = guess_df.median()\n",
    "\n",
    "            # Convert random age float to nearest .5 age\n",
    "            guess_ages[i,j] = int( age_guess/0.5 + 0.5 ) * 0.5\n",
    "            \n",
    "    for i in range(0, 2):\n",
    "        for j in range(0, 3):\n",
    "            dataset.loc[ (dataset.Age.isnull()) & (dataset.Sex == i) & (dataset.Pclass == j+1),\\\n",
    "                    'Age'] = guess_ages[i,j]\n",
    "\n",
    "    dataset['Age'] = dataset['Age'].astype(int)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.barplot(data=train_df, x=\"Age\", y=\"Survived\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fill nan of Age by Title and Pclass\n",
    "https://www.kaggle.com/yuanxuan/titanic-random-forest-82-78/notebook\n",
    "\n",
    "There is mistake in the original notebook.\n",
    "test_df was filled by train_df.\n",
    "So I modified."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "groupedAge_train = train_df.groupby(['Title', 'Pclass'])['Age']\n",
    "groupedAge_train.mean()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_test_df = pd.concat((train_df, test_df))\n",
    "groupedAge_train_test = train_test_df.groupby(['Title', 'Pclass'])['Age']\n",
    "filledAge = groupedAge_train_test.transform(lambda x:x.fillna(x.mean()))\n",
    "train_test_df[filledAge.isna()]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "groupedByTitleOnly_Age_train_test = train_test_df.groupby(['Title'])['Age']\n",
    "groupedByTitleOnly_Age_train_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_df = pd.concat((train_df, test_df))\n",
    "groupedAge_train_test = train_test_df.groupby(['Title', 'Pclass'])['Age']\n",
    "train_test_df.Age = groupedAge_train_test.transform(lambda x:x.fillna(x.mean()))\n",
    "\n",
    "groupedByTitleOnly_Age_train_test = train_test_df.groupby(['Title'])['Age']\n",
    "train_test_df.Age = groupedByTitleOnly_Age_train_test.transform(lambda x:x.fillna(x.mean()))\n",
    "\n",
    "train_df = train_test_df.iloc[:train_df.shape[0]]\n",
    "test_df = train_test_df.iloc[train_df.shape[0]:]\n",
    "\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "groupedAge_train_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_df.Age.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((891, 27), (418, 27))"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head(30)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_df.head(30)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.isna().any()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_df.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tried keep Age feature and don't add AgeBand numerical feature\n",
    "if both are there, it is duplicate information\n",
    "\n",
    "#### 2018/03/17 tried Age instead of Age band. But AgeBand is better score for almost all models.\n",
    "svc score was same of little bit better.\n",
    "random forest score became worse.\n",
    "so AgeBand is better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add age band\n",
    "\n",
    "- 5 age band by pd.cut\n",
    "- 10 age band by pd.cut: this is better score.\n",
    "\n",
    "if i use pd.qcut, band become too short for young adult around 25."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pd.cut(train_df['Age'], 10).value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df['AgeBand'] = pd.cut(train_df['Age'], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "train_df['AgeBand'] = pd.cut(train_df['Age'], 10)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.barplot(x=\"AgeBand\", data=train_df, y=\"Survived\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overwrite AgeBand number on Age. means, drop Age and AgeBand text column"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 5 age band\n",
    "for dataset in combine:\n",
    "    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n",
    "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
    "    dataset.loc[ dataset['Age'] > 64, 'Age'] = 4\n",
    "train_df = train_df.drop(['AgeBand'], axis=1)\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuki/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n(24.0, 32.0]    275\\n(16.0, 24.0]    220\\n(32.0, 40.0]    148\\n(40.0, 48.0]     68\\n(-0.08, 8.0]     54\\n(8.0, 16.0]      46\\n(48.0, 56.0]     45\\n(56.0, 64.0]     24\\n(64.0, 72.0]      9\\n(72.0, 80.0]      2\\n'"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10 age band\n",
    "for dataset in combine:\n",
    "    dataset.loc[ dataset['Age'] <= 8, 'Age'] = 0\n",
    "    dataset.loc[(dataset['Age'] > 8) & (dataset['Age'] <= 16), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 24), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 24) & (dataset['Age'] <= 32), 'Age'] = 3\n",
    "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 40), 'Age'] = 4\n",
    "    dataset.loc[(dataset['Age'] > 40) & (dataset['Age'] <= 48), 'Age'] = 5\n",
    "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 56), 'Age'] = 6\n",
    "    dataset.loc[(dataset['Age'] > 56) & (dataset['Age'] <= 64), 'Age'] = 7\n",
    "    dataset.loc[(dataset['Age'] > 64) & (dataset['Age'] <= 72), 'Age'] = 8\n",
    "    dataset.loc[ dataset['Age'] > 72, 'Age'] = 9\n",
    "train_df = train_df.drop(['AgeBand'], axis=1)\n",
    "combine = [train_df, test_df]\n",
    "\n",
    "\"\"\"\n",
    "(24.0, 32.0]    275\n",
    "(16.0, 24.0]    220\n",
    "(32.0, 40.0]    148\n",
    "(40.0, 48.0]     68\n",
    "(-0.08, 8.0]     54\n",
    "(8.0, 16.0]      46\n",
    "(48.0, 56.0]     45\n",
    "(56.0, 64.0]     24\n",
    "(64.0, 72.0]      9\n",
    "(72.0, 80.0]      2\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.barplot(data=train_df, x=\"Age\", y=\"Survived\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert Title to numerical or one hot encoding\n",
    "\n",
    "- one hot encoding, no deleting rare title\n",
    "- OR change rare title to \"Rare\" and map value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one hot encoding, no deleteing rare title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 27) (418, 27)\n",
      "(1309, 27)\n",
      "(891, 44) (418, 43)\n"
     ]
    }
   ],
   "source": [
    "# try one hote encoding without delete rare title\n",
    "#\n",
    "# concat train and test data. and apply get_dummies for Title. \n",
    "# then split to original size. also drop Survived column from test_df\n",
    "print(train_df.shape, test_df.shape)\n",
    "\n",
    "# concat train and test data\n",
    "#   test_df's Survived column is filled with NaN\n",
    "train_test_df = pd.concat((train_df, test_df))\n",
    "\n",
    "print(train_test_df.shape)\n",
    "\n",
    "# apply get_dummies for Title\n",
    "train_test_df = pd.get_dummies(train_test_df, columns=[\"Title\"])\n",
    "\n",
    "#train_test_df.head()\n",
    "train_df = train_test_df.iloc[:train_df.shape[0]]\n",
    "test_df = train_test_df.iloc[train_df.shape[0]:]\n",
    "\n",
    "# drop added Survived column from test_df\n",
    "test_df = test_df.drop(\"Survived\", axis=1)\n",
    "print(train_df.shape, test_df.shape)\n",
    "\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OR change rare title to \"Rare\" and map value"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# del rare title and map value\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\n",
    "                                                 'Don', 'Dr', 'Major', 'Rev', 'Sir',\n",
    "                                                 'Jonkheer', 'Dona'], 'Rare')\n",
    "\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "    \n",
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset['Title'].map(title_mapping)\n",
    "    dataset['Title'] = dataset['Title'].fillna(0)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.countplot(data=train_df, x=\"Title\", hue=\"Survived\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new feature \"FamilySize\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/home/yuki/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "for dataset in combine:\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset['IsAlone'] = 0\n",
    "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset['Age*Class'] = dataset.Age * dataset.Pclass"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.barplot(data=train_df, x=\"FamilySize\", y=\"Survived\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.barplot(data=train_df, x=\"IsAlone\", y=\"Survived\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.countplot(data=train_df, x=\"Age*Class\", hue=\"Survived\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### select family related feature\n",
    "Parch, SibSp, FaimilySize, IsAlone\n",
    "\n",
    "2018/03/18 Parch and SibSp only was best for almost all models"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# keep all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep Parch, SibSp only. this was best amoung familly related features\n",
    "\n",
    "train_df = train_df.drop(['FamilySize', 'IsAlone'], axis=1)\n",
    "test_df = test_df.drop(['FamilySize', 'IsAlone'], axis=1)\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# keep FamilySize only\n",
    "\n",
    "train_df = train_df.drop(['Parch', 'SibSp', 'IsAlone'], axis=1)\n",
    "test_df = test_df.drop(['Parch', 'SibSp', 'IsAlone'], axis=1)\n",
    "combine = [train_df, test_df]\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# keep IsAlone only (drop Parch, SibSp, FaimilySize)\n",
    "\n",
    "train_df = train_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\n",
    "test_df = test_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\n",
    "combine = [train_df, test_df]\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fill missing Embarked "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_port = train_df.Embarked.dropna().mode()[0]\n",
    "for dataset in combine:\n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna(freq_port)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Embarked categorical feature to numeric"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for dataset in combine:\n",
    "    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## try one hot encoding for Embarked categorical feature\n",
    "2018/03/18 this is better than using converting categorical to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 45) (418, 44)\n",
      "(1309, 45)\n",
      "(891, 47) (418, 46)\n"
     ]
    }
   ],
   "source": [
    "# try one hote encoding for Embarked\n",
    "#\n",
    "# concat train and test data. and apply get_dummies for Title. \n",
    "# then split to original size. also drop Survived column from test_df\n",
    "print(train_df.shape, test_df.shape)\n",
    "\n",
    "# concat train and test data\n",
    "#   test_df's Survived column is filled with NaN\n",
    "train_test_df = pd.concat((train_df, test_df))\n",
    "\n",
    "print(train_test_df.shape)\n",
    "\n",
    "# apply get_dummies for Title\n",
    "train_test_df = pd.get_dummies(train_test_df, columns=[\"Embarked\"])\n",
    "\n",
    "#train_test_df.head()\n",
    "train_df = train_test_df.iloc[:train_df.shape[0]]\n",
    "test_df = train_test_df.iloc[train_df.shape[0]:]\n",
    "\n",
    "# drop added Survived column from test_df\n",
    "test_df = test_df.drop(\"Survived\", axis=1)\n",
    "print(train_df.shape, test_df.shape)\n",
    "\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fill na of test data Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Fare'].fillna(test_df['Fare'].dropna().median(), inplace=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make Fareband feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/yuki/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train_df['FareBand'] = pd.qcut(train_df['Fare'], 4)\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
    "    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "\n",
    "train_df = train_df.drop(['FareBand'], axis=1)\n",
    "\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try more fare band number\n",
    "\n",
    "- no difference\n",
    "\n",
    "### keep Fare feature and add FareBand numerical feature¶\n",
    "\n",
    "- not good result"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fareband = pd.qcut(train_df['Fare'], 6)\n",
    "fareband.unique()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df['FareBand'] = pd.qcut(train_df['Fare'], 6)\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset.loc[ dataset['Fare'] <= 7.775, 'Fare'] = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.775) & (dataset['Fare'] <= 8.662), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 8.662) & (dataset['Fare'] <= 14.454), 'Fare']   = 2\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 26.0), 'Fare']   = 3\n",
    "    dataset.loc[(dataset['Fare'] > 26.0) & (dataset['Fare'] <= 52.369), 'Fare']   = 4\n",
    "    \n",
    "    dataset.loc[ dataset['Fare'] > 52.369, 'Fare'] = 5\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "\n",
    "train_df = train_df.drop(['FareBand'], axis=1)\n",
    "\n",
    "combine = [train_df, test_df]\n",
    "    \n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## drop Name, PassengerId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(['Name', 'PassengerId'], axis=1)\n",
    "test_df = test_df.drop(['Name'], axis=1)\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## final check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Age*Class</th>\n",
       "      <th>Age_Null_Flag</th>\n",
       "      <th>Cabin_Letter_0</th>\n",
       "      <th>Cabin_Letter_A</th>\n",
       "      <th>Cabin_Letter_B</th>\n",
       "      <th>Cabin_Letter_C</th>\n",
       "      <th>Cabin_Letter_D</th>\n",
       "      <th>Cabin_Letter_E</th>\n",
       "      <th>Cabin_Letter_F</th>\n",
       "      <th>...</th>\n",
       "      <th>Title_Mlle</th>\n",
       "      <th>Title_Mme</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Ms</th>\n",
       "      <th>Title_Rev</th>\n",
       "      <th>Title_Sir</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Age*Class  Age_Null_Flag  Cabin_Letter_0  Cabin_Letter_A  \\\n",
       "0  2.0        6.0              0               1               0   \n",
       "1  4.0        4.0              0               0               0   \n",
       "2  3.0        9.0              0               1               0   \n",
       "3  4.0        4.0              0               0               0   \n",
       "4  4.0       12.0              0               1               0   \n",
       "\n",
       "   Cabin_Letter_B  Cabin_Letter_C  Cabin_Letter_D  Cabin_Letter_E  \\\n",
       "0               0               0               0               0   \n",
       "1               0               1               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               1               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   Cabin_Letter_F     ...      Title_Mlle  Title_Mme  Title_Mr  Title_Mrs  \\\n",
       "0               0     ...               0          0         1          0   \n",
       "1               0     ...               0          0         0          1   \n",
       "2               0     ...               0          0         0          0   \n",
       "3               0     ...               0          0         0          1   \n",
       "4               0     ...               0          0         1          0   \n",
       "\n",
       "   Title_Ms  Title_Rev  Title_Sir  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0         0          0          0           0           0           1  \n",
       "1         0          0          0           1           0           0  \n",
       "2         0          0          0           0           0           1  \n",
       "3         0          0          0           0           0           1  \n",
       "4         0          0          0           0           0           1  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Age*Class</th>\n",
       "      <th>Age_Null_Flag</th>\n",
       "      <th>Cabin_Letter_0</th>\n",
       "      <th>Cabin_Letter_A</th>\n",
       "      <th>Cabin_Letter_B</th>\n",
       "      <th>Cabin_Letter_C</th>\n",
       "      <th>Cabin_Letter_D</th>\n",
       "      <th>Cabin_Letter_E</th>\n",
       "      <th>Cabin_Letter_F</th>\n",
       "      <th>...</th>\n",
       "      <th>Title_Mlle</th>\n",
       "      <th>Title_Mme</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Ms</th>\n",
       "      <th>Title_Rev</th>\n",
       "      <th>Title_Sir</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Age*Class  Age_Null_Flag  Cabin_Letter_0  Cabin_Letter_A  \\\n",
       "0  4.0       12.0              0               1               0   \n",
       "1  5.0       15.0              0               1               0   \n",
       "2  7.0       14.0              0               1               0   \n",
       "3  3.0        9.0              0               1               0   \n",
       "4  2.0        6.0              0               1               0   \n",
       "\n",
       "   Cabin_Letter_B  Cabin_Letter_C  Cabin_Letter_D  Cabin_Letter_E  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   Cabin_Letter_F     ...      Title_Mlle  Title_Mme  Title_Mr  Title_Mrs  \\\n",
       "0               0     ...               0          0         1          0   \n",
       "1               0     ...               0          0         0          1   \n",
       "2               0     ...               0          0         1          0   \n",
       "3               0     ...               0          0         1          0   \n",
       "4               0     ...               0          0         0          1   \n",
       "\n",
       "   Title_Ms  Title_Rev  Title_Sir  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0         0          0          0           0           1           0  \n",
       "1         0          0          0           0           0           1  \n",
       "2         0          0          0           0           1           0  \n",
       "3         0          0          0           0           0           1  \n",
       "4         0          0          0           0           0           1  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "colormap = plt.cm.viridis\n",
    "plt.figure(figsize=(30,30))\n",
    "plt.title('Pearson Correlation of Features', y=1.05, size=15)\n",
    "sns.heatmap(train_df.astype(float).corr(), \n",
    "            linewidths=0.1,vmax=1.0,\n",
    "            square=True, cmap=colormap, \n",
    "            linecolor='white', annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# try to delete some features\n",
    "\n",
    "- Age*Class is duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(['Age*Class'], axis=1)\n",
    "test_df = test_df.drop(['Age*Class'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 44) (418, 44)\n",
      "Index(['Age', 'Age_Null_Flag', 'Cabin_Letter_0', 'Cabin_Letter_A',\n",
      "       'Cabin_Letter_B', 'Cabin_Letter_C', 'Cabin_Letter_D', 'Cabin_Letter_E',\n",
      "       'Cabin_Letter_F', 'Cabin_Letter_G', 'Cabin_Letter_T',\n",
      "       'Cabin_num_(1.999, 28.667]', 'Cabin_num_(28.667, 65.667]',\n",
      "       'Cabin_num_(65.667, 148.0]', 'Cabin_num_nan_category', 'Fare',\n",
      "       'Name_Len', 'Parch', 'Pclass', 'Sex', 'SibSp', 'Survived', 'Ticket_Len',\n",
      "       'Title_Capt', 'Title_Col', 'Title_Countess', 'Title_Don', 'Title_Dona',\n",
      "       'Title_Dr', 'Title_Jonkheer', 'Title_Lady', 'Title_Major',\n",
      "       'Title_Master', 'Title_Miss', 'Title_Mlle', 'Title_Mme', 'Title_Mr',\n",
      "       'Title_Mrs', 'Title_Ms', 'Title_Rev', 'Title_Sir', 'Embarked_C',\n",
      "       'Embarked_Q', 'Embarked_S'],\n",
      "      dtype='object') Index(['Age', 'Age_Null_Flag', 'Cabin_Letter_0', 'Cabin_Letter_A',\n",
      "       'Cabin_Letter_B', 'Cabin_Letter_C', 'Cabin_Letter_D', 'Cabin_Letter_E',\n",
      "       'Cabin_Letter_F', 'Cabin_Letter_G', 'Cabin_Letter_T',\n",
      "       'Cabin_num_(1.999, 28.667]', 'Cabin_num_(28.667, 65.667]',\n",
      "       'Cabin_num_(65.667, 148.0]', 'Cabin_num_nan_category', 'Fare',\n",
      "       'Name_Len', 'Parch', 'PassengerId', 'Pclass', 'Sex', 'SibSp',\n",
      "       'Ticket_Len', 'Title_Capt', 'Title_Col', 'Title_Countess', 'Title_Don',\n",
      "       'Title_Dona', 'Title_Dr', 'Title_Jonkheer', 'Title_Lady', 'Title_Major',\n",
      "       'Title_Master', 'Title_Miss', 'Title_Mlle', 'Title_Mme', 'Title_Mr',\n",
      "       'Title_Mrs', 'Title_Ms', 'Title_Rev', 'Title_Sir', 'Embarked_C',\n",
      "       'Embarked_Q', 'Embarked_S'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape, test_df.shape)\n",
    "print(train_df.columns, test_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Age_Null_Flag</th>\n",
       "      <th>Cabin_Letter_0</th>\n",
       "      <th>Cabin_Letter_A</th>\n",
       "      <th>Cabin_Letter_B</th>\n",
       "      <th>Cabin_Letter_C</th>\n",
       "      <th>Cabin_Letter_D</th>\n",
       "      <th>Cabin_Letter_E</th>\n",
       "      <th>Cabin_Letter_F</th>\n",
       "      <th>Cabin_Letter_G</th>\n",
       "      <th>...</th>\n",
       "      <th>Title_Mlle</th>\n",
       "      <th>Title_Mme</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Ms</th>\n",
       "      <th>Title_Rev</th>\n",
       "      <th>Title_Sir</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Age_Null_Flag  Cabin_Letter_0  Cabin_Letter_A  Cabin_Letter_B  \\\n",
       "0  2.0              0               1               0               0   \n",
       "1  4.0              0               0               0               0   \n",
       "2  3.0              0               1               0               0   \n",
       "3  4.0              0               0               0               0   \n",
       "4  4.0              0               1               0               0   \n",
       "\n",
       "   Cabin_Letter_C  Cabin_Letter_D  Cabin_Letter_E  Cabin_Letter_F  \\\n",
       "0               0               0               0               0   \n",
       "1               1               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               1               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   Cabin_Letter_G     ...      Title_Mlle  Title_Mme  Title_Mr  Title_Mrs  \\\n",
       "0               0     ...               0          0         1          0   \n",
       "1               0     ...               0          0         0          1   \n",
       "2               0     ...               0          0         0          0   \n",
       "3               0     ...               0          0         0          1   \n",
       "4               0     ...               0          0         1          0   \n",
       "\n",
       "   Title_Ms  Title_Rev  Title_Sir  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0         0          0          0           0           0           1  \n",
       "1         0          0          0           1           0           0  \n",
       "2         0          0          0           0           0           1  \n",
       "3         0          0          0           0           0           1  \n",
       "4         0          0          0           0           0           1  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Age_Null_Flag</th>\n",
       "      <th>Cabin_Letter_0</th>\n",
       "      <th>Cabin_Letter_A</th>\n",
       "      <th>Cabin_Letter_B</th>\n",
       "      <th>Cabin_Letter_C</th>\n",
       "      <th>Cabin_Letter_D</th>\n",
       "      <th>Cabin_Letter_E</th>\n",
       "      <th>Cabin_Letter_F</th>\n",
       "      <th>Cabin_Letter_G</th>\n",
       "      <th>...</th>\n",
       "      <th>Title_Mlle</th>\n",
       "      <th>Title_Mme</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Ms</th>\n",
       "      <th>Title_Rev</th>\n",
       "      <th>Title_Sir</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Age_Null_Flag  Cabin_Letter_0  Cabin_Letter_A  Cabin_Letter_B  \\\n",
       "0  4.0              0               1               0               0   \n",
       "1  5.0              0               1               0               0   \n",
       "2  7.0              0               1               0               0   \n",
       "3  3.0              0               1               0               0   \n",
       "4  2.0              0               1               0               0   \n",
       "\n",
       "   Cabin_Letter_C  Cabin_Letter_D  Cabin_Letter_E  Cabin_Letter_F  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   Cabin_Letter_G     ...      Title_Mlle  Title_Mme  Title_Mr  Title_Mrs  \\\n",
       "0               0     ...               0          0         1          0   \n",
       "1               0     ...               0          0         0          1   \n",
       "2               0     ...               0          0         1          0   \n",
       "3               0     ...               0          0         1          0   \n",
       "4               0     ...               0          0         0          1   \n",
       "\n",
       "   Title_Ms  Title_Rev  Title_Sir  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0         0          0          0           0           1           0  \n",
       "1         0          0          0           0           0           1  \n",
       "2         0          0          0           0           1           0  \n",
       "3         0          0          0           0           0           1  \n",
       "4         0          0          0           0           0           1  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model and estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = train_df.drop(\"Survived\", axis=1)\n",
    "y_train_df = train_df[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/test data shape (596, 43) (295, 43)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train_df, y_train_df, test_size=0.33, random_state=42)\n",
    "print(\"train/test data shape\", X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done  82 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=3)]: Done 320 out of 320 | elapsed:   14.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'C': 100, 'gamma': 0.001}\n",
      "Mean cross-validated score of the best_estimator:  0.8154362416107382\n",
      "test:  0.8406779661016949\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASIAAAD3CAYAAAC5OlmeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAGTRJREFUeJzt3Xu0XGV5x/HvL4EQDLeQyMVwtVLbGKliEJa6KFSFoBaook1sFZSaRQVtq7aF5QWKy7UA1xK1UDViymUtbtKLsQ1GBC+1BUxQBBILCYgQSI0hAbmG5Jynf+w9Yc7knJl3cvY+e8/M77PWXmdmz55n3jlJnuz9vu9+H0UEZmZVmlR1A8zMnIjMrHJORGZWOSciM6ucE5GZVc6JyMwq50RkZpVzIjKzyjkRmVnlnIjMrHI7Vd0AMyvXCcdNi8c3DiUde+fdm5dFxLx2x0iaB3wJmAxcHhEXtrx+EHAlsFd+zDkRsbRdTCcisz63YeMQdyw7IOnYnfd/YGa71yVNBi4D3gqsBZZLWhIRq5oO+xRwQ0R8RdJsYClwSLu4TkRmfS8YiuGigr0eWBMRDwJIug44GWhORAHskT/eE3isU1AnIrM+F8Awha2yMQt4pOn5WuColmPOB74r6SPANOAtnYK6s9qszwXBlhhK2oCZklY0bQtbwmnUjxhpAXBFRBwAvA24WlLbXNPXiUjSPEn3SVoj6ZxRXt9F0vX563dIOqTptXPz/fdJOmGsmE3PfyNpg6SQNHOcn7FY0npJ9473u0iaIen7kp6WdOk4f1/HSPqppK2STm0Xq5PRvmORsSTtLelmSavzn9OLjqXMl/Pf192SjigrnqTT8uNXSzqt29/RMJG0ARsiYm7Ttqgl1FrgwKbnB7D9pdcZwA0AEXEbMBVo2/dERPTlRtZb/wDwcmAK8HNgdssxHwa+mj+eD1yfP56dH78LcGgeZ/IYMR/Onx9Jdp38KDBzRz8jf+0Y4Ajg3gK+yzTgTcCZwKXj/H0dAhwOXAWcOs4/nxHfsehYwMVkozUA5wAXFR2L7H/7m8jOEo4G7igjHrA38GD+c3r+eHrq7+cPDt85Njw6K2kDVnT4/eyUf/6hTX9PXtVyzE3A6fnj3ydLVGoXt5/PiLZ1qkXEC0CjU63ZyWTDjAA3Am+WpHz/dRGxOSJ+CazJ47XG/B/g+fz5cuBq4CXj/Awi4kfAxiK+S0Q8ExE/Bp4f7+8rIh6KiLuBcfd8jvIdi47V/Pu4EjilhFgnA1dF5nZgL0n7lxDvBODmiNgYEZuAm4G2Q+ytujgjaisitgJnA8uAX5CNjq2UdIGkk/LDPg58SNLPgWvJklLb4P3cWZ3SqbbtmIjYKulJYEa+//aW987KHzfH3JJvzcdNLuAzivwuG8aIuSOf0Uv2jYh1ABGxTtI+JcQa7Xc2C1hXcLyx9icJYKh9HuhKZHOClrbs+0zT41XAG7uJ2c+JKKVTbaxjxtrfegY52nGp7UhpX6cY3R7TznjfP4iK/p0V8XdlVIUN3pekny/NUjrVth0jaSeyOQ8b27y3df9OwM4tx7VOYe32M4r+Lqm6aU8v+HXjMin/ub6EWDv6O+s23rj+bIJgKHGrSj8nouXAYZIOlTSFrAN3ScsxS4DGCMSpwK35tewSYH4+EnUocBjwk1FivgHYteUznh3nZxT9XVKlfEYvaf59nAZ8q4RYS4D356NdRwNPNi65Co63DDhe0vR8hO34fF+SCNiSuFVmvCMWdd7IRiHuJxsN+mS+7wLgpPzxVOCbZB3FPwFe3vTeT+bvuw84cayYTc83AE8CW4GngO+O4zOuJetn2EL2v+EZ4/wuD5GdHT2dx5u9g7+vI/P3PwM8Dqwcx5/Ndt+xyFhk/WO3AKvzn3sXHYvskumy/Pd1DzC3rHjAB/M/2zXAB7r5/cx59c5x/yP7J210GDUra1P+Jc2sT805fEr8y3+2n8bT8HsHrbszIuaW3KTt9HNntZnlhpLGVarjRGTW5wInIjOrgeFwIjKzCvmMyMwqF4gt0Trhv176eR7RuGn7JRAGMm6ZsXstbpmxy4rbOCNK2ariRNReWX+Zey1umbF7LW6ZsUuKK4ZiUtJWFV+amfW5bIXGep9zDFwi2nWvqbH7y6YlHbvbfi9hn9kzCp/x2Wtxy4zda3HLjN1N3Kcee4bnnng++VrKndU1s/vLpnHq1SdW3QyzcbnxfTclHxuhSi+7UgxcIjIbRMM+IzKzKgXihaj3P/V6t87Mxq0XOqvr3TozK8RQKGlLkVDt5RJJd+Xb/ZKe6BTTZ0RmfS4QQwWdcyih5HRE/E3T8R8BXtsp7oSdESVk0ULqf5nZ9oZjUtKWIKWiTLMFZIvDtTUhiagpi55IVs9rgaTZLYedAWyKiFcAlwAX5e+dTbZs6avISqj8Ux4P4Aq6LKtiNmiyWzwmJW0JkiuKSDqYrP7ZrZ2CTtQZURk1xogCa2OZ9avGTa8pG8WUnG6YD9wYEa0FJbYzUX1EZdUYM7MOIuhmQuOGDkvFdlNRZD5wVsqHTtQZURk1xtI/XFrYyPDPbepU8NSs34jhxC1BUrUXSa8kK499W0rQiUpEZdQYSxYRiyJibkTM3XX61C6bbtbbskqvxdx9H2klpyHrpL4uEqtzTNSl2bYsCjxKlkXf23JMo9bTbTTV5ZK0BLhG0heAl9G+/peZjaKo4XvoXHI6f35+NzEnJBHlfT6NLDoZWNzIomR1lJYA3wCulrSG7Exofv7elZJuAFaR1Qw7q9H5Jela4FiyDra1wHkR8Y2J+E5mvSKQ16xu6JRFI+J54N1jvPdzwOdG2b+g4Gaa9aUiz4jK4JnVZn2uF9asdiIy63MBqbOmK+NEZDYAvEKjmVUqQj4jMrPqealYM6tUtjCaL83MrFJePN/MKhbg4Xszq5ZnVptZLdR98XwnIrM+l61H5DMiM6uYL83MrFJZH1G9L80qb92OVveQNEPS9yU9LenSiW63WS8ZQklbVSo9I0qpkURTdQ9J88mqe/wp8DzwaWBOvpnZKAKxdbjew/dVnxHtcHWPiHgmIn5MlpDMrI0C16wuRdWJKKVG0ojqHkCjuoeZJWiMmhVVcroMVSei8VT3SP8QV/GwAVdgpdeO/br5Me+RtErSSknXdIpZ9ahZN9U91rZU90gWEYuARQD7zJ7RVRIz63VFzqxO6deVdBhwLvDGiNgkaZ9Ocas+I0qpkdSo7gFN1T0msI1mPa/APqKUft0PAZdFxCaAiFjfKWilZ0Tjqe4BIOkhYA9giqRTgONbRtzMBl62VGxh/T8pVZt/F0DSf5P9uz4/Ir7TLmjVl2bjre5xSKmNM+sH0dXw/UxJK5qeL8q7NhpS+mx3Iqs/eCxZd8t/SZoTEU+M9aGVJyIzK1eXC6NtiIi5bV5P7de9PSK2AL+UdB9ZYlo+VtCq+4jMbAIMh5K2BCn9uv8OHAcgaSbZpdqD7YL6jMiszxXZR5TYr7sMOF7SKmAI+NuIeLxdXCciswFQ5N33Cf26AXws35I4EZn1Oa/QaGbVC9ha82VAnIjM+lzB84hK4URkNgCciMysUu4jMrNaCCciM6uaS06bWaUi3EdkZpUTQ8MevjezitW9j6i2aTKhzNAxkn4qaaukU6too1kvaMwjKuim11LUMhE1LUd5IjAbWCBpdsthDwOnAx3XwzUbaJH1E6VsVanrpdm25SgBJDWWo9y2+mJEPJS/NlxFA816Sd1HzWp5RkRamSEzSxBkfUQpW1XqekY07hJCI4JJC4GFALvt95IdDWPWozyzekelLEeZzOWEbNAND9c7EdX10ixlOUozS5B1RNf70qyWiSgvLd1YjvIXwA2N5SglnQQg6UhJa8kqfHxN0srqWmxWb3Ufvq/rpVnKcpTLyS7ZzKyDIofmJc0DvkS2ZvXlEXFhy+unA58HHs13XRoRl7eLWdtEZGbFKeqyK6XkdO76iDg7NW4tL83MrDhBWv9QYrJKKTndNSciswEQiVuC1Dl+75J0t6QbJR04yusjOBGZ9buAGFbSRl5yumlb2BItZY7ft4FDIuJw4HvAlZ2a6D4iswHQRR/RuEtOtxRT/DpwUacPHbhENEVbOXDqxsLjTirxlrdfPTeztNg2GAocNds2x49sVGw+8N7mAyTtHxHr8qcnkU3BaWvgEpHZoGnca1ZIrLSS0x/N5/ttBTaSrZLRlhORWb8LYGJLTp8LnNtNTCciswFQ5VpDKZyIzAaBE5GZVWvb0HxtORGZ9bvok8XzJR0tabmkpyW9IGlI0m/LbpyZFaTAqdVlSJ1ZfSmwAFgN7Ar8BfCPZTUqlaTFktZLurfqtpjVmxK3aiTf4hERa4DJETEUEf8MHFdes5JdAcyruhFmtVfzM6LUPqJn85US75J0MbAOmFZes9JExI8kHVJ1O8xqr+ajZqlnRO8jm0V5NvAM2b0m7yqrUWZWoO5ueq1E0hlRRPwqf/gc8A/lNacczVU89tp/asWtMatAP5wRSXqHpJ9J2ijpt5Ke6qVRs4hYFBFzI2LutOlTqm6O2cQLpW0VSe0j+iLwTuCeiLpPFjezVqr5v9rUPqJHgHvrloQkXQvcBrxS0lpJZ1TdJrPaSR0x64FRs78Dlkr6IbC5sTMivlBKqxJFxIIqP9+sN1R72ZUiNRF9DngamAq4k8Ws19TqWmZ7qYlo74g4vtSWmFl5yltAtBCpfUTfk+REZNaLGguj1XjULDURnQV8R9JzvTh8bzboFGlbVZISUUTsHhGTImLXiNgjf75H2Y0zs4IUOGomaZ6k+yStkXROm+NOlRSS2lUFAbpYj0jS4cAhze+JiH9NfX9dTFKw2+TnC4/7zt06FirYYVtKSvkX//rNpcTdPOxlrso2XNFlVGrJaUm7Ax8F7kiJm/Q3RtJi4HBgJS92ewXQc4nIbBAVeNm1reQ0gKRGyelVLcd9FrgY+ERK0NT/uo6OiNmJx5pZ3RR3BjVayemjmg+Q9FrgwIj4D0lJiSi1s/o2SU5EZr0oyK5jUrZxlpyWNAm4BPh4N01MPSO6kiwZ/R/ZzGoBkde2NrOa6+LSbLwlp3cH5gA/kASwH7BE0kkRsWKsoKmJaDHZmkT3UPupUWa2nQkqOR0RTwLbaqRL+gHwiXZJCNIT0cN5KVkz60UFJaLEktNdS01E/yvpGuDbjLzp1aNmZjVX9GTFTiWnW/YfmxIzNRHtSpaAmm/zmLDh+3z6wDuA9RExJ9+3N3A92dymh4D3RMSmiWiPWc/ph7vvI+IDZTekgyvIShpd1bTvHOCWiLgwn915DvD3FbTNrP764e57SVOBM4BXkS0FAkBEfLCkdo0wRrWOk4Fj88dXAj/AichsVKr5EFPqPKKryYbhTgB+SDZk91RZjUq0b0SsA8h/7lNxe8zqKfGG19rf9Aq8IiI+DTwTEVcCbwdeXV6ziiVpYWOC1tObXqi6OWYTr+ZLxaYmoi35zyckzQH2JOskrtKvJe0PkP9cP9aBzVU8dnMVDxtEfZKIFkmaDnwKWEJ2g9tFpbUqzRLgtPzxacC3KmyLWa3V/dIsdfh+T6AxcnZZ/nOrpNdExF3FN2ukvFrHsWT3wawFzgMuBG7IK3c8DLy77HaYWTlSE9HrgLlkExoh6yNaDpwp6ZsRcXEZjWtoU62jnAV1zPpNPwzfAzOAIyLiaQBJ5wE3AscAd5KtO2JmdRT1H75PTUQHAc3DTVuAgyPiOUmbx3iPmdVFn5wRXQPcLqnRIfzHwLWSprH9ymxmViOi/iWnU2/x+KykpcCbyL7XmU239f9ZWY0zs4L0QyICiIg7yfqDzKyXVDw0n8LlFswGgRNRvcyY/Dyn7bG68LiTKG/G9s9eKOePyWV/Bke/jJqZWS/zGZGZVari+8hSOBGZDYC6d1an3vRqZr2swLvvJc2TdJ+kNfnqqK2vnynpHkl3SfpxSk1EJyKzAVDU3feSJpPd+H4iMBtYMEqiuSYiXh0RryG7/esLneI6EZkNguLOiF4PrImIByPiBeA6smWbX/yoiN82PZ2WEtl9RGZ9ruC1hmYBjzQ9Xwsctd1nSmcBHwOmAH/UKWitzogkLZa0XtK9Tfv2lnSzpNX5z+n5fkn6cn6derekI6pruVnNpZ8RzWyqe79C0sKWSKPVJdouzUXEZRHxO2QFLT7VqXm1SkRkZYPmtexrlA06DLglfw7ZNeph+bYQ+MoEtdGs53TRR7Shsaxyvi1qCbUWOLDp+QHAY20++jrglE7tq1UiiogfARtbdp9MVi6I/OcpTfuvisztwF6NNazNrEVxfUTLgcMkHSppCjCfbNnmbSQd1vT07UDHWxl6oY9oRNkgSY2yQaNdq84C1k1w+8zqr6A+oojYKulsYBkwGVgcESslXQCsiIglwNmS3kK2btkmXlxbfky9kIjGknStClk5IbLLNw6cNbnMNpnVT8F330fEUmBpy77PND3+q25j1urSbAxjlQ1KvlZtLic0Y0YvfGWzgvVJOaEqjVU2aAnw/nz07GjgycYlnJmNpOG0rSq1ujTrsmzQUuBtwBrgWV4sd2RmLep+r1mtElE3ZYMiIoCzym2RWR/w3fdmVgtORGZWpb6p4mFmPc6JyMyqpqh3JnIiMut3fVRyum9MZhK7TZpaeNzNsaXwmA1bYuD+mKxo9T4hGrxEZDaI3FltZtVzIjKzSrnktJnVghORmVXJExrNrBY0XO9M5ERk1u964KbXStYjKqpah6TT8uNXS+q4HKXZoKr7ekRVLYx2BeOs1iFpb7L1io4iK/p2XiN5mVmLiS05/TFJq/ITh1skHdwpZiWJqKBqHScAN0fExojYBNzM9snNzJjwktM/A+ZGxOHAjWRlp9uq01KxI6p1AJ2qdYy138yaBRCRtnWWUnL6+xHxbP70drL15NuqUyIay1jVOrqq4tGoXPmbx4cKbZxZLyiwj6jbE4AzgJs6Ba1TIuq2WscOVfF46QyXE7LB0phHlHhpVkjJaQBJfw7MBT7fqY11SkTdVutYBhwvaXreSX18vs/MmqVelmWXZoWUnM4LLH4SOCkiNndqYiXziIqo1hERGyV9lqwELsAFEdHaAW5mFDqzelvJaeBRspLT7x3xWdJrga8B8yJi/fYhtldJIiqqWkdELAYWF9g0s/40sSWnPw/sBnxTEsDDEXFSu7ieWW02ACa45PRbuo3pRGTW7wLwvWZmVjWvWW1m1XMVDzOrmtcjMrNq9cAyIE5EBXlwS3nlhGCXEmNbv8tmVtc7EzkRmQ0Cd1abWdV8RmRm1YrwPCIzq55Hzcyser40M7NKRf1nVpe2HlHZlTokvU7SPfl7vqz8Nl8zG0VxS8WWosyF0a6g3EodX8mPbbzPC+ebjaXAKh5lKC0RlVmpI39tj4i4LV+v6KqmWGbWQhFJW1Umuo9oRKUOSTtaqWNW/rh1v5m1CmDIndUpuq3UkbyAN2RVPMgu4zhoVl2+stnEENWe7aSY6MXzi6rUsZaRtZLGrOABruJhNsid1aMppFJH/tpTko7OR8ve3xTLzFoNaiLKK3XcBrxS0tq8OseFwFslrQbemj+HbP3bB8kqdXwd+DBklTqARqWO5Yys1PGXwOX5ex4goYib2UAKspteU7YEkuZJui+fOnPOKK8fI+mnkrZKOjUlZmkdJmVX6oiIFcCc8bTRbFAU1UckaTJwGdmJxFpguaQlEbGq6bCHgdOBT6TGdc+t2SAo7rLr9cCaiHgQQNJ1ZNNvtiWiiHgofy15PrcTkVm/i4Dh5JwwU9KKpueLWqq9jjal5qhxttCJyGwgpN9rtiEi5rZ5vaupM6mciMwGQIHziMaaUjMuEz18b2ZVKG74fjlwmKRDJU0B5pNNvxkXJyKzfteo9JqydQoVsRU4m2yO3y+AGyJipaQLJJ0EIOlISWuBdwNfk7SyU9yBuzS78+7NGybvv+ZXiYfPBDaU0IyaxL2/xNh9G7fM2N3EPTg9bLGTFSNiKdncv+Z9n2l6vJyRdz50NHCJKCJemnqspBUdOu52SK/FLTN2r8UtM3aZbfYKjWZWrQCG6r1EoxORWd8LCCeiXrao8yEDEbfM2L0Wt8zY5bW55pdmipo30HqHpP2ALwJHApuBh4C/joiuesWtWHtO2TfesN9Yt36O9J1HvnRnaf1UbfiMyAqRL8fyb8CVETE/3/caYF+6HJ6zEtT8hMOJyIpyHLAlIr7a2BERd1XYHmvmRGQDYg5wZ9WNsFFEwNBQ1a1oy4nIbBDU/IzIt3hYUVYCr6u6ETaGQV0q1gbOrcAukj7U2JHfc/SHFbbJAEi8zyzhXrOyOBFZIfLlfv+EbE3yB/IbHc+ngCUibJwCIoaTtqq4j8gKExGPAe+puh02igrPdlI4EZkNgpp3VjsRmfU7D9+bWR1E+uL5lXAiMut71Q7Np3AiMut3jaVia8zD92aDIIbTtgQJJad3kXR9/vodkg7pFNOJyKzPBRDDkbR10lRy+kRgNrBA0uyWw84ANkXEK4BLgIs6xXUiMut3EUWeEW0rOR0RLwCNktPNTgauzB/fCLw5XyZmTO4jMhsAUdzwfUrJ6W3HRMRWSU8CM2hTocSJyKzPPcWmZd+LG2cmHj5V0oqm54sionkJ25SS012XpXYiMutzETGvwHApJacbx6yVtBOwJ7CxXVD3EZlZN1JKTi8BTssfnwrcGh0Wx/cZkZkly/t8GiWnJwOLGyWngRURsQT4BnC1pDVkZ0LzO8V1FQ8zq5wvzcysck5EZlY5JyIzq5wTkZlVzonIzCrnRGRmlXMiMrPKORGZWeX+H57u7fpgboYVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb4eb742e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make wide the ranges\n",
    "\n",
    "param_grid = {'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "              'gamma': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]}\n",
    "\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5, n_jobs=3, verbose=1)\n",
    "\n",
    "# no meaning to use cross_val for grid_search model because it is incluced in grid search\n",
    "#scores = cross_val_score(grid_search, X_train, y_train, cv=5, n_jobs=6)\n",
    "#print(\"mean of train scores\", scores.mean())\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "plt.matshow(grid_search.cv_results_['mean_test_score'].reshape(8, -1),\n",
    "            vmin=0, cmap=\"viridis\")\n",
    "plt.xlabel(\"C\")\n",
    "plt.ylabel(\"gamma\")\n",
    "plt.xticks(range(len(param_grid['C'])), param_grid['C'])\n",
    "plt.yticks(range(len(param_grid['gamma'])), param_grid['gamma'])\n",
    "plt.colorbar()\n",
    "\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# if age band is 5\n",
    "Mean cross-validated score of the best_estimator:  0.8154362416107382\n",
    "best parameters: {'C': 100, 'gamma': 0.001}\n",
    "test:  0.8338983050847457\n",
    "\n",
    "\n",
    "# if age band is 10\n",
    "Mean cross-validated score of the best_estimator:  0.8137583892617449\n",
    "best parameters: {'C': 100, 'gamma': 0.001}\n",
    "test:  0.8372881355932204\n",
    "\n",
    "\n",
    "# OR change rare title to \"Rare\" and map value\n",
    "Mean cross-validated score of the best_estimator:  0.8070469798657718\n",
    "best parameters: {'C': 10, 'gamma': 0.01}\n",
    "test:  0.8135593220338984\n",
    "\n",
    "# 5 age band and filled age by mean of group(title, pclass)\n",
    "Mean cross-validated score of the best_estimator:  0.8120805369127517\n",
    "best parameters: {'C': 100, 'gamma': 0.001}\n",
    "test:  0.8305084745762712\n",
    "\n",
    "# 10 age band, parch, sibsp\n",
    "best parameters: {'C': 100, 'gamma': 0.001}\n",
    "Mean cross-validated score of the best_estimator:  0.8154362416107382\n",
    "test:  0.8406779661016949\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "grid_search.best_estimator_.support_vectors_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "grid_search.best_estimator_.dual_coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done  50 out of  55 | elapsed:    1.5s remaining:    0.2s\n",
      "[Parallel(n_jobs=3)]: Done  55 out of  55 | elapsed:    1.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'kneighborsclassifier__n_neighbors': 8}\n",
      "Mean cross-validated score of the best_estimator:  0.8338926174496645\n",
      "test:  0.8271186440677966\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'kneighborsclassifier__n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20]}\n",
    "\n",
    "pipe = make_pipeline(MinMaxScaler(), KNeighborsClassifier())\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv=5, n_jobs=3, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 5 age band\n",
    "Mean cross-validated score of the best_estimator:  0.837248322147651\n",
    "best parameters: {'kneighborsclassifier__n_neighbors': 8}\n",
    "test:  0.823728813559322\n",
    "\n",
    "# if age band is 10\n",
    "Mean cross-validated score of the best_estimator:  0.8355704697986577\n",
    "best parameters: {'kneighborsclassifier__n_neighbors': 8}\n",
    "test:  0.8271186440677966\n",
    "\n",
    "# OR change rare title to \"Rare\" and map value\n",
    "Mean cross-validated score of the best_estimator:  0.8087248322147651\n",
    "best parameters: {'kneighborsclassifier__n_neighbors': 10}\n",
    "test:  0.7830508474576271\n",
    "\n",
    "\n",
    "# 5 age band and filled age by mean of group(title, pclass)\n",
    "Mean cross-validated score of the best_estimator:  0.837248322147651\n",
    "best parameters: {'kneighborsclassifier__n_neighbors': 8}\n",
    "test:  0.823728813559322\n",
    "\n",
    "# 10 age band, parch, sibsp\n",
    "best parameters: {'kneighborsclassifier__n_neighbors': 8}\n",
    "Mean cross-validated score of the best_estimator:  0.8338926174496645\n",
    "test:  0.8271186440677966\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## try several SVC, KNeighborsClassifier models and preprocessing conbinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 42 candidates, totalling 210 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done  82 tasks      | elapsed:    5.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'clf': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=8, p=2,\n",
      "           weights='uniform'), 'reduce_dim': PCA(copy=True, iterated_power='auto', n_components=15, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), 'scaling': MinMaxScaler(copy=True, feature_range=(0, 1))}\n",
      "Mean cross-validated score of the best_estimator:  0.8439597315436241\n",
      "test:  0.8067796610169492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done 210 out of 210 | elapsed:   14.0s finished\n"
     ]
    }
   ],
   "source": [
    "param_grid = dict(scaling=[None, MinMaxScaler(), RobustScaler()],\n",
    "                  reduce_dim=[None, PCA(), PCA(5), PCA(10), PCA(15), PCA(20), PCA(25)],\n",
    "                  clf=[SVC(C=100, gamma=0.001), KNeighborsClassifier(n_neighbors=8)]\n",
    "                 )\n",
    "pipe = Pipeline([('scaling', StandardScaler()), ('reduce_dim', PCA()), ('clf', SVC())]) \n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=3, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 5 age band\n",
    "\n",
    "Mean cross-validated score of the best_estimator:  0.8422818791946308\n",
    "best parameters: {'clf': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "           metric_params=None, n_jobs=1, n_neighbors=8, p=2,\n",
    "           weights='uniform'), 'reduce_dim': PCA(copy=True, iterated_power='auto', n_components=15, random_state=None,\n",
    "  svd_solver='auto', tol=0.0, whiten=False), 'scaling': MinMaxScaler(copy=True, feature_range=(0, 1))}\n",
    "test:  0.8101694915254237\n",
    "\n",
    "# 10 age band\n",
    "\n",
    "Mean cross-validated score of the best_estimator:  0.8422818791946308\n",
    "best parameters: {'clf': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "           metric_params=None, n_jobs=1, n_neighbors=8, p=2,\n",
    "           weights='uniform'), 'reduce_dim': PCA(copy=True, iterated_power='auto', n_components=15, random_state=None,\n",
    "  svd_solver='auto', tol=0.0, whiten=False), 'scaling': MinMaxScaler(copy=True, feature_range=(0, 1))}\n",
    "test:  0.8101694915254237\n",
    "\n",
    "# OR change rare title to \"Rare\" and map value\n",
    "Mean cross-validated score of the best_estimator:  0.8154362416107382\n",
    "best parameters: {'clf': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "           metric_params=None, n_jobs=1, n_neighbors=8, p=2,\n",
    "           weights='uniform'), 'reduce_dim': PCA(copy=True, iterated_power='auto', n_components=15, random_state=None,\n",
    "  svd_solver='auto', tol=0.0, whiten=False), 'scaling': MinMaxScaler(copy=True, feature_range=(0, 1))}\n",
    "test:  0.7898305084745763\n",
    "\n",
    "\n",
    "\n",
    "# 5 age band and filled age by mean of group(title, pclass)\n",
    "Mean cross-validated score of the best_estimator:  0.8439597315436241\n",
    "best parameters: {'clf': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "           metric_params=None, n_jobs=1, n_neighbors=8, p=2,\n",
    "           weights='uniform'), 'reduce_dim': PCA(copy=True, iterated_power='auto', n_components=15, random_state=None,\n",
    "  svd_solver='auto', tol=0.0, whiten=False), 'scaling': MinMaxScaler(copy=True, feature_range=(0, 1))}\n",
    "test:  0.8067796610169492\n",
    "\n",
    "\n",
    "# 10 age band, parch, sibsp\n",
    "best parameters: {'clf': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "           metric_params=None, n_jobs=1, n_neighbors=8, p=2,\n",
    "           weights='uniform'), 'reduce_dim': PCA(copy=True, iterated_power='auto', n_components=15, random_state=None,\n",
    "  svd_solver='auto', tol=0.0, whiten=False), 'scaling': MinMaxScaler(copy=True, feature_range=(0, 1))}\n",
    "Mean cross-validated score of the best_estimator:  0.8439597315436241\n",
    "test:  0.8067796610169492\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random forest result for compare"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "param_grid = {'randomforestclassifier__n_estimators': [10, 50, 100, 300, 500, 1000],\n",
    "              'randomforestclassifier__max_features': [1, 'auto', None],\n",
    "             'randomforestclassifier__max_depth':[1, 3, 5, 7, 9, None],\n",
    "             'randomforestclassifier__min_samples_leaf': [1,2,4],\n",
    "             \"randomforestclassifier__min_samples_split\" : [2, 3, 4]}\n",
    "\"\"\"\n",
    "# very narrow range\n",
    "param_grid = {'randomforestclassifier__n_estimators': [10,  100,  500, 1000],\n",
    "              'randomforestclassifier__max_features': [1, 'auto', None],\n",
    "             'randomforestclassifier__max_depth':[1, 3, 5, 7, None],\n",
    "             'randomforestclassifier__min_samples_leaf': [1,2,4],\n",
    "             \"randomforestclassifier__min_samples_split\" : [2, 3, 4]}\n",
    "\n",
    "pipe = make_pipeline(RandomForestClassifier())\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=3, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "output of upper code\n",
    "\n",
    "# 5 age band\n",
    "Mean cross-validated score of the best_estimator:  0.8406040268456376\n",
    "best parameters: {'randomforestclassifier__max_depth': 7, 'randomforestclassifier__max_features': 'auto', 'randomforestclassifier__min_samples_leaf': 1, 'randomforestclassifier__min_samples_split': 2, 'randomforestclassifier__n_estimators': 100}\n",
    "test:  0.8203389830508474\n",
    "\n",
    "# if age band is 10\n",
    "Mean cross-validated score of the best_estimator:  0.8406040268456376\n",
    "best parameters: {'randomforestclassifier__max_depth': 7, 'randomforestclassifier__max_features': 'auto', 'randomforestclassifier__min_samples_leaf': 1, 'randomforestclassifier__min_samples_split': 3, 'randomforestclassifier__n_estimators': 100}\n",
    "test:  0.8271186440677966\n",
    "\n",
    "\n",
    "# OR change rare title to \"Rare\" and map value\n",
    "\n",
    "Mean cross-validated score of the best_estimator:  0.8305369127516778\n",
    "best parameters: {'randomforestclassifier__max_depth': 7, 'randomforestclassifier__max_features': 'auto', 'randomforestclassifier__min_samples_leaf': 1, 'randomforestclassifier__min_samples_split': 3, 'randomforestclassifier__n_estimators': 10}\n",
    "test:  0.8440677966101695\n",
    "\n",
    "test score was not bad score. but best estimager score is lower. it is better to not use Rare title\n",
    "\n",
    "\n",
    "# 5 age band and filled age by mean of group(title, pclass)\n",
    "?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test:  0.8372881355932204\n",
      "mean of cross val score:  0.8282828282828283\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(RandomForestClassifier(max_depth=7, \n",
    "                                            max_features=\"auto\",\n",
    "                                            min_samples_leaf=1, \n",
    "                                            min_samples_split=3, \n",
    "                                            n_estimators=100))\n",
    "pipe.fit(X_train, y_train)\n",
    "print(\"test: \", pipe.score(X_test, y_test))\n",
    "\n",
    "scores = cross_val_score(pipe, X_train_df, y_train_df, n_jobs=3)\n",
    "print(\"mean of cross val score: \", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Sex</td>\n",
       "      <td>0.180336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Title_Mr</td>\n",
       "      <td>0.140401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Name_Len</td>\n",
       "      <td>0.093664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Pclass</td>\n",
       "      <td>0.083183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Ticket_Len</td>\n",
       "      <td>0.049638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.049052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Title_Mrs</td>\n",
       "      <td>0.046030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Title_Miss</td>\n",
       "      <td>0.042904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Fare</td>\n",
       "      <td>0.038416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Cabin_num_nan_category</td>\n",
       "      <td>0.035760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SibSp</td>\n",
       "      <td>0.035031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cabin_Letter_0</td>\n",
       "      <td>0.031568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Parch</td>\n",
       "      <td>0.031024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Embarked_S</td>\n",
       "      <td>0.020378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Embarked_C</td>\n",
       "      <td>0.016800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Cabin_num_(28.667, 65.667]</td>\n",
       "      <td>0.011522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cabin_Letter_E</td>\n",
       "      <td>0.010071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Age_Null_Flag</td>\n",
       "      <td>0.010023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cabin_Letter_B</td>\n",
       "      <td>0.009831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Title_Master</td>\n",
       "      <td>0.009547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Cabin_num_(65.667, 148.0]</td>\n",
       "      <td>0.009329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Embarked_Q</td>\n",
       "      <td>0.008048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Cabin_num_(1.999, 28.667]</td>\n",
       "      <td>0.007891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cabin_Letter_C</td>\n",
       "      <td>0.007741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cabin_Letter_D</td>\n",
       "      <td>0.006317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cabin_Letter_A</td>\n",
       "      <td>0.002786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Title_Rev</td>\n",
       "      <td>0.002778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cabin_Letter_F</td>\n",
       "      <td>0.002735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Title_Dr</td>\n",
       "      <td>0.001763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cabin_Letter_G</td>\n",
       "      <td>0.001719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Title_Col</td>\n",
       "      <td>0.001216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Title_Capt</td>\n",
       "      <td>0.001169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Title_Ms</td>\n",
       "      <td>0.000755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Title_Mlle</td>\n",
       "      <td>0.000433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cabin_Letter_T</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Title_Lady</td>\n",
       "      <td>0.000043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Title_Don</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Title_Sir</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Title_Mme</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Title_Dona</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Title_Major</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Title_Jonkheer</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Title_Countess</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      variable  importance\n",
       "19                         Sex    0.180336\n",
       "35                    Title_Mr    0.140401\n",
       "16                    Name_Len    0.093664\n",
       "18                      Pclass    0.083183\n",
       "21                  Ticket_Len    0.049638\n",
       "0                          Age    0.049052\n",
       "36                   Title_Mrs    0.046030\n",
       "32                  Title_Miss    0.042904\n",
       "15                        Fare    0.038416\n",
       "14      Cabin_num_nan_category    0.035760\n",
       "20                       SibSp    0.035031\n",
       "2               Cabin_Letter_0    0.031568\n",
       "17                       Parch    0.031024\n",
       "42                  Embarked_S    0.020378\n",
       "40                  Embarked_C    0.016800\n",
       "12  Cabin_num_(28.667, 65.667]    0.011522\n",
       "7               Cabin_Letter_E    0.010071\n",
       "1                Age_Null_Flag    0.010023\n",
       "4               Cabin_Letter_B    0.009831\n",
       "31                Title_Master    0.009547\n",
       "13   Cabin_num_(65.667, 148.0]    0.009329\n",
       "41                  Embarked_Q    0.008048\n",
       "11   Cabin_num_(1.999, 28.667]    0.007891\n",
       "5               Cabin_Letter_C    0.007741\n",
       "6               Cabin_Letter_D    0.006317\n",
       "3               Cabin_Letter_A    0.002786\n",
       "38                   Title_Rev    0.002778\n",
       "8               Cabin_Letter_F    0.002735\n",
       "27                    Title_Dr    0.001763\n",
       "9               Cabin_Letter_G    0.001719\n",
       "23                   Title_Col    0.001216\n",
       "22                  Title_Capt    0.001169\n",
       "37                    Title_Ms    0.000755\n",
       "33                  Title_Mlle    0.000433\n",
       "10              Cabin_Letter_T    0.000100\n",
       "29                  Title_Lady    0.000043\n",
       "25                   Title_Don    0.000000\n",
       "39                   Title_Sir    0.000000\n",
       "34                   Title_Mme    0.000000\n",
       "26                  Title_Dona    0.000000\n",
       "30                 Title_Major    0.000000\n",
       "28              Title_Jonkheer    0.000000\n",
       "24              Title_Countess    0.000000"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat((pd.DataFrame(X_train.columns, columns = ['variable']), \n",
    "           pd.DataFrame(pipe.named_steps[\"randomforestclassifier\"].feature_importances_, columns = ['importance'])), \n",
    "          axis = 1).sort_values(by='importance', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try several scaling and feature selections for random forest"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "param_grid = dict(scaling=[None, MinMaxScaler(), RobustScaler()],\n",
    "                  reduce_dim=[None, PCA(), PCA(5), PCA(10), PCA(15), PCA(20), PCA(25)],\n",
    "                  clf=[RandomForestClassifier(max_depth=7, \n",
    "                                            max_features=\"auto\",\n",
    "                                            min_samples_leaf=1, \n",
    "                                            min_samples_split=3, \n",
    "                                            n_estimators=100)]\n",
    "                 )\n",
    "pipe = Pipeline([('scaling', StandardScaler()), ('reduce_dim', PCA()), ('clf', RandomForestClassifier())]) \n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=3, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**try scaling for random forest**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# RobustScaler(), \n",
    "pipe = make_pipeline(RobustScaler(), RandomForestClassifier(max_depth=10, \n",
    "                                            max_features=1,\n",
    "                                            min_samples_leaf=1, \n",
    "                                            min_samples_split=13, \n",
    "                                            n_estimators=300))\n",
    "pipe.fit(X_train, y_train)\n",
    "print(\"test: \", pipe.score(X_test, y_test))\n",
    "\n",
    "scores = cross_val_score(pipe, X_train_df, y_train_df, n_jobs=3)\n",
    "print(\"mean of cross val score: \", scores.mean())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# MinMaxScaler(), \n",
    "pipe = make_pipeline(MinMaxScaler(), RandomForestClassifier(max_depth=10, \n",
    "                                            max_features=1,\n",
    "                                            min_samples_leaf=1, \n",
    "                                            min_samples_split=13, \n",
    "                                            n_estimators=300))\n",
    "pipe.fit(X_train, y_train)\n",
    "print(\"test: \", pipe.score(X_test, y_test))\n",
    "\n",
    "scores = cross_val_score(pipe, X_train_df, y_train_df, n_jobs=3)\n",
    "print(\"mean of cross val score: \", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**try feature selection**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#pca\n",
    "param_grid = {'pca__n_components':[5, 10, 15, 20, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 40]}\n",
    "\n",
    "pipe = make_pipeline(PCA(n_components=30), RandomForestClassifier(max_depth=10, \n",
    "                                            max_features=1,\n",
    "                                            min_samples_leaf=1, \n",
    "                                            min_samples_split=13, \n",
    "                                            n_estimators=300))\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=6)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pipe = make_pipeline(PCA(n_components=15), RandomForestClassifier(max_depth=10, \n",
    "                                            max_features=1,\n",
    "                                            min_samples_leaf=1, \n",
    "                                            min_samples_split=13, \n",
    "                                            n_estimators=300))\n",
    "pipe.fit(X_train, y_train)\n",
    "print(\"test: \", pipe.score(X_test, y_test))\n",
    "\n",
    "scores = cross_val_score(pipe, X_train_df, y_train_df, n_jobs=3)\n",
    "print(\"mean of cross val score: \", scores.mean())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test:  0.840677966102\n",
    "mean of cross val score:  0.82379349046"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "AdaBoostClassifier(base_estimator=None, n_estimators=50,\n",
    "                   learning_rate=1.0, algorithm='SAMME.R',\n",
    "                   random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "param_grid = {'learning_rate': [0.001, 0.005, 0.01, 0.05, 0.1],\n",
    "              'n_estimators': [3, 5, 10, 50, 100, 200, 500, 700, 1000],\n",
    "              'min_samples_split':[2, 3, 4, 5],\n",
    "              'min_samples_leaf': [1, 2, 3, 5],\n",
    "              'max_depth':[1,2,3,4,5],\n",
    "              'max_features': ['auto', 'sqrt', 'log2'],}\n",
    "\n",
    "grid_search = GridSearchCV(GradientBoostingClassifier(), param_grid, cv=5, n_jobs=3, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "plt.matshow(grid_search.cv_results_['mean_test_score'].reshape(6, -1),\n",
    "            vmin=0, cmap=\"viridis\")\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.ylabel(\"learning_rate\")\n",
    "plt.xticks(range(len(param_grid['n_estimators'])), param_grid['n_estimators'])\n",
    "plt.yticks(range(len(param_grid['learning_rate'])), param_grid['learning_rate'])\n",
    "plt.colorbar()\n",
    "\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# output of upper code\n",
    "\n",
    "Mean cross-validated score of the best_estimator:  0.843959731544\n",
    "best parameters: {'learning_rate': 0.01, 'max_depth': 6, 'max_features': 'sqrt', 'min_samples_leaf': 3, 'min_samples_split': 3, 'n_estimators': 200}\n",
    "test:  0.830508474576\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test:  0.8305084745762712\n",
      "mean of cross val score for X_train_df:  0.8260381593714928\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(GradientBoostingClassifier(learning_rate=0.01,\n",
    "                                                max_depth=6,\n",
    "                                                max_features=\"sqrt\",\n",
    "                                                min_samples_leaf=3,\n",
    "                                                min_samples_split=3,\n",
    "                                                n_estimators=200))\n",
    "pipe.fit(X_train, y_train)\n",
    "print(\"test: \", pipe.score(X_test, y_test))\n",
    "\n",
    "scores = cross_val_score(pipe, X_train_df, y_train_df, n_jobs=3)\n",
    "print(\"mean of cross val score for X_train_df: \", scores.mean())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 5 age band\n",
    "test:  0.823728813559322\n",
    "mean of cross val score for X_train_df:  0.8237934904601572\n",
    "    \n",
    "# 10 age band\n",
    "test:  0.823728813559322\n",
    "mean of cross val score for X_train_df:  0.8282828282828283\n",
    "\n",
    "# 10 age band, keep all family features\n",
    "test:  0.8338983050847457\n",
    "mean of cross val score for X_train_df:  0.8260381593714926\n",
    "\n",
    "# 10 age band, parch, siblib, use embarked column\n",
    "test:  0.8338983050847457\n",
    "mean of cross val score for X_train_df:  0.8271604938271605\n",
    "\n",
    "# 10 age band, parch, sibsp\n",
    "test:  0.8305084745762712\n",
    "mean of cross val score for X_train_df:  0.8260381593714928\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Sex</td>\n",
       "      <td>0.145635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Title_Mr</td>\n",
       "      <td>0.122074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Name_Len</td>\n",
       "      <td>0.110421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Pclass</td>\n",
       "      <td>0.086466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Ticket_Len</td>\n",
       "      <td>0.063112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.060494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Title_Mrs</td>\n",
       "      <td>0.058303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SibSp</td>\n",
       "      <td>0.042703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Title_Miss</td>\n",
       "      <td>0.042529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Fare</td>\n",
       "      <td>0.038885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Parch</td>\n",
       "      <td>0.030853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Cabin_num_nan_category</td>\n",
       "      <td>0.027998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cabin_Letter_0</td>\n",
       "      <td>0.026384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Embarked_S</td>\n",
       "      <td>0.023194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Embarked_C</td>\n",
       "      <td>0.021436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cabin_Letter_E</td>\n",
       "      <td>0.018369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Title_Master</td>\n",
       "      <td>0.014367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Cabin_num_(1.999, 28.667]</td>\n",
       "      <td>0.009303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Cabin_num_(28.667, 65.667]</td>\n",
       "      <td>0.009005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Embarked_Q</td>\n",
       "      <td>0.007254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cabin_Letter_C</td>\n",
       "      <td>0.006747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cabin_Letter_D</td>\n",
       "      <td>0.006655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Cabin_num_(65.667, 148.0]</td>\n",
       "      <td>0.005909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Title_Rev</td>\n",
       "      <td>0.005716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Age_Null_Flag</td>\n",
       "      <td>0.004649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cabin_Letter_B</td>\n",
       "      <td>0.004415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cabin_Letter_F</td>\n",
       "      <td>0.002084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Title_Dr</td>\n",
       "      <td>0.001924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cabin_Letter_A</td>\n",
       "      <td>0.001737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cabin_Letter_G</td>\n",
       "      <td>0.001379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Title_Mme</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Title_Sir</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Title_Ms</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cabin_Letter_T</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Title_Capt</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Title_Mlle</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Title_Col</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Title_Major</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Title_Lady</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Title_Jonkheer</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Title_Dona</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Title_Don</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Title_Countess</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      variable  importance\n",
       "19                         Sex    0.145635\n",
       "35                    Title_Mr    0.122074\n",
       "16                    Name_Len    0.110421\n",
       "18                      Pclass    0.086466\n",
       "21                  Ticket_Len    0.063112\n",
       "0                          Age    0.060494\n",
       "36                   Title_Mrs    0.058303\n",
       "20                       SibSp    0.042703\n",
       "32                  Title_Miss    0.042529\n",
       "15                        Fare    0.038885\n",
       "17                       Parch    0.030853\n",
       "14      Cabin_num_nan_category    0.027998\n",
       "2               Cabin_Letter_0    0.026384\n",
       "42                  Embarked_S    0.023194\n",
       "40                  Embarked_C    0.021436\n",
       "7               Cabin_Letter_E    0.018369\n",
       "31                Title_Master    0.014367\n",
       "11   Cabin_num_(1.999, 28.667]    0.009303\n",
       "12  Cabin_num_(28.667, 65.667]    0.009005\n",
       "41                  Embarked_Q    0.007254\n",
       "5               Cabin_Letter_C    0.006747\n",
       "6               Cabin_Letter_D    0.006655\n",
       "13   Cabin_num_(65.667, 148.0]    0.005909\n",
       "38                   Title_Rev    0.005716\n",
       "1                Age_Null_Flag    0.004649\n",
       "4               Cabin_Letter_B    0.004415\n",
       "8               Cabin_Letter_F    0.002084\n",
       "27                    Title_Dr    0.001924\n",
       "3               Cabin_Letter_A    0.001737\n",
       "9               Cabin_Letter_G    0.001379\n",
       "34                   Title_Mme    0.000000\n",
       "39                   Title_Sir    0.000000\n",
       "37                    Title_Ms    0.000000\n",
       "10              Cabin_Letter_T    0.000000\n",
       "22                  Title_Capt    0.000000\n",
       "33                  Title_Mlle    0.000000\n",
       "23                   Title_Col    0.000000\n",
       "30                 Title_Major    0.000000\n",
       "29                  Title_Lady    0.000000\n",
       "28              Title_Jonkheer    0.000000\n",
       "26                  Title_Dona    0.000000\n",
       "25                   Title_Don    0.000000\n",
       "24              Title_Countess    0.000000"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat((pd.DataFrame(X_train.columns, columns = ['variable']), \n",
    "           pd.DataFrame(pipe.named_steps[\"gradientboostingclassifier\"].feature_importances_, columns = ['importance'])), \n",
    "          axis = 1).sort_values(by='importance', ascending = False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X_train_df, y_train_df)\n",
    "\n",
    "test_df_noid = test_df.drop(\"PassengerId\", axis=1).copy()\n",
    "y_pred = pipe.predict(test_df_noid).astype(int)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": test_df[\"PassengerId\"].astype(int),\n",
    "        \"Survived\": y_pred\n",
    "    })\n",
    "submission.to_csv('../output/submission_gradientboosting.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Sex</td>\n",
       "      <td>0.163490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Title_Mr</td>\n",
       "      <td>0.140291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Name_Len</td>\n",
       "      <td>0.111651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Pclass</td>\n",
       "      <td>0.079889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.069135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SibSp</td>\n",
       "      <td>0.051890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Title_Miss</td>\n",
       "      <td>0.048038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Ticket_Len</td>\n",
       "      <td>0.043945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Title_Mrs</td>\n",
       "      <td>0.043065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Fare</td>\n",
       "      <td>0.040856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Cabin_num_nan_category</td>\n",
       "      <td>0.035850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Parch</td>\n",
       "      <td>0.025271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cabin_Letter_0</td>\n",
       "      <td>0.023136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Title_Master</td>\n",
       "      <td>0.020044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Embarked_S</td>\n",
       "      <td>0.015606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Embarked_C</td>\n",
       "      <td>0.013436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Cabin_num_(1.999, 28.667]</td>\n",
       "      <td>0.012014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cabin_Letter_E</td>\n",
       "      <td>0.010430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Embarked_Q</td>\n",
       "      <td>0.009635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Age_Null_Flag</td>\n",
       "      <td>0.008129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Cabin_num_(28.667, 65.667]</td>\n",
       "      <td>0.007153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Title_Rev</td>\n",
       "      <td>0.005939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cabin_Letter_C</td>\n",
       "      <td>0.004967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cabin_Letter_D</td>\n",
       "      <td>0.004934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cabin_Letter_B</td>\n",
       "      <td>0.003690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Cabin_num_(65.667, 148.0]</td>\n",
       "      <td>0.003510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cabin_Letter_F</td>\n",
       "      <td>0.001606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cabin_Letter_A</td>\n",
       "      <td>0.001025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Title_Dr</td>\n",
       "      <td>0.000780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cabin_Letter_G</td>\n",
       "      <td>0.000594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Title_Jonkheer</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Title_Lady</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Title_Major</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Title_Dona</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Title_Mlle</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Title_Mme</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Title_Countess</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Title_Ms</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Title_Col</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Title_Sir</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Title_Capt</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cabin_Letter_T</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Title_Don</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      variable  importance\n",
       "19                         Sex    0.163490\n",
       "35                    Title_Mr    0.140291\n",
       "16                    Name_Len    0.111651\n",
       "18                      Pclass    0.079889\n",
       "0                          Age    0.069135\n",
       "20                       SibSp    0.051890\n",
       "32                  Title_Miss    0.048038\n",
       "21                  Ticket_Len    0.043945\n",
       "36                   Title_Mrs    0.043065\n",
       "15                        Fare    0.040856\n",
       "14      Cabin_num_nan_category    0.035850\n",
       "17                       Parch    0.025271\n",
       "2               Cabin_Letter_0    0.023136\n",
       "31                Title_Master    0.020044\n",
       "42                  Embarked_S    0.015606\n",
       "40                  Embarked_C    0.013436\n",
       "11   Cabin_num_(1.999, 28.667]    0.012014\n",
       "7               Cabin_Letter_E    0.010430\n",
       "41                  Embarked_Q    0.009635\n",
       "1                Age_Null_Flag    0.008129\n",
       "12  Cabin_num_(28.667, 65.667]    0.007153\n",
       "38                   Title_Rev    0.005939\n",
       "5               Cabin_Letter_C    0.004967\n",
       "6               Cabin_Letter_D    0.004934\n",
       "4               Cabin_Letter_B    0.003690\n",
       "13   Cabin_num_(65.667, 148.0]    0.003510\n",
       "8               Cabin_Letter_F    0.001606\n",
       "3               Cabin_Letter_A    0.001025\n",
       "27                    Title_Dr    0.000780\n",
       "9               Cabin_Letter_G    0.000594\n",
       "28              Title_Jonkheer    0.000000\n",
       "29                  Title_Lady    0.000000\n",
       "30                 Title_Major    0.000000\n",
       "26                  Title_Dona    0.000000\n",
       "33                  Title_Mlle    0.000000\n",
       "34                   Title_Mme    0.000000\n",
       "24              Title_Countess    0.000000\n",
       "37                    Title_Ms    0.000000\n",
       "23                   Title_Col    0.000000\n",
       "39                   Title_Sir    0.000000\n",
       "22                  Title_Capt    0.000000\n",
       "10              Cabin_Letter_T    0.000000\n",
       "25                   Title_Don    0.000000"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat((pd.DataFrame(X_train.columns, columns = ['variable']), \n",
    "           pd.DataFrame(pipe.named_steps[\"gradientboostingclassifier\"].feature_importances_, columns = ['importance'])), \n",
    "          axis = 1).sort_values(by='importance', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try scaling and feature selection"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "param_grid = dict(scaling=[None, MinMaxScaler(), RobustScaler()],\n",
    "                  reduce_dim=[None, PCA(), PCA(5), PCA(10), PCA(15), PCA(20), PCA(25), PCA(30)],\n",
    "                  clf=[GradientBoostingClassifier(learning_rate=0.01,\n",
    "                                                max_depth=6,\n",
    "                                                max_features=\"sqrt\",\n",
    "                                                min_samples_leaf=3,\n",
    "                                                min_samples_split=3,\n",
    "                                                n_estimators=200)]\n",
    "                 )\n",
    "pipe = Pipeline([('scaling', StandardScaler()), ('reduce_dim', PCA()), ('clf', RandomForestClassifier())]) \n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=3, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**try scaling for Gradient boosting**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# RobustScaler\n",
    "pipe = make_pipeline(RobustScaler(), GradientBoostingClassifier(learning_rate=0.01,\n",
    "                                                max_depth=6,\n",
    "                                                max_features=\"sqrt\",\n",
    "                                                min_samples_leaf=3,\n",
    "                                                min_samples_split=3,\n",
    "                                                n_estimators=200))\n",
    "pipe.fit(X_train, y_train)\n",
    "print(\"test: \", pipe.score(X_test, y_test))\n",
    "\n",
    "scores = cross_val_score(pipe, X_train_df, y_train_df, n_jobs=3)\n",
    "print(\"mean of cross val score for X_train_df: \", scores.mean())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pd.concat((pd.DataFrame(X_train.columns, columns = ['variable']), \n",
    "           pd.DataFrame(pipe.named_steps[\"gradientboostingclassifier\"].feature_importances_, columns = ['importance'])), \n",
    "          axis = 1).sort_values(by='importance', ascending = False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# MinMaxScaler\n",
    "pipe = make_pipeline(MinMaxScaler(), GradientBoostingClassifier(learning_rate=0.01,\n",
    "                                                max_depth=6,\n",
    "                                                max_features=\"sqrt\",\n",
    "                                                min_samples_leaf=3,\n",
    "                                                min_samples_split=3,\n",
    "                                                n_estimators=200))\n",
    "pipe.fit(X_train, y_train)\n",
    "print(\"test: \", pipe.score(X_test, y_test))\n",
    "\n",
    "scores = cross_val_score(pipe, X_train_df, y_train_df, n_jobs=3)\n",
    "print(\"mean of cross val score for X_train_df: \", scores.mean())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pd.concat((pd.DataFrame(X_train.columns, columns = ['variable']), \n",
    "           pd.DataFrame(pipe.named_steps[\"gradientboostingclassifier\"].feature_importances_, columns = ['importance'])), \n",
    "          axis = 1).sort_values(by='importance', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**try feature selection**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#PCA\n",
    "param_grid = {'pca__n_components':[5, 10, 15, 20, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 40]}\n",
    "\n",
    "pipe = make_pipeline(PCA(n_components=30), GradientBoostingClassifier(learning_rate=0.01,\n",
    "                                                max_depth=6,\n",
    "                                                max_features=\"sqrt\",\n",
    "                                                min_samples_leaf=3,\n",
    "                                                min_samples_split=3,\n",
    "                                                n_estimators=200))\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv=5, n_jobs=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pipe = make_pipeline(PCA(n_components=20), GradientBoostingClassifier(learning_rate=0.01,\n",
    "                                                max_depth=6,\n",
    "                                                max_features=\"sqrt\",\n",
    "                                                min_samples_leaf=3,\n",
    "                                                min_samples_split=3,\n",
    "                                                n_estimators=200))\n",
    "pipe.fit(X_train, y_train)\n",
    "print(\"test: \", pipe.score(X_test, y_test))\n",
    "\n",
    "scores = cross_val_score(pipe, X_train_df, y_train_df, n_jobs=3)\n",
    "print(\"mean of cross val score for X_train_df: \", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "param_grid = [\n",
    "{'classifier': [SVC()], \n",
    " 'preprocessing': [StandardScaler(), None], \n",
    " 'classifier__gamma': [0.001, 0.01, 0.1, 1, 10, 100], \n",
    " 'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100]},\n",
    "{'classifier': [RandomForestClassifier(n_estimators=100)], \n",
    " 'preprocessing': [None], \n",
    " 'classifier__max_features': [1, 2, 3]}]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Individual steps may also be replaced as parameters, and non-final steps may be ignored by setting them to None:\n",
    "# http://scikit-learn.org/stable/modules/pipeline.html\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "param_grid = dict(reduce_dim=[None, PCA(5), PCA(10)],\n",
    "                   clf=[SVC(), LogisticRegression()],\n",
    "                   clf__C=[0.1, 10, 100])\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
