{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# data analysis and wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# train, test, validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "# decomposition\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "# feature engineering\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# feature selection\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../input/train.csv')\n",
    "test_df = pd.read_csv('../input/test.csv')\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# modify features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make ticket length feature\n",
    "https://www.kaggle.com/yuanxuan/titanic-random-forest-82-78/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Ticket_Len'] = train_df['Ticket'].apply(lambda x: len(x))\n",
    "test_df['Ticket_Len'] = test_df['Ticket'].apply(lambda x: len(x))\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df['Ticket_Len'].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_df['Ticket_Len'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make Cabin First character feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Cabin_Letter\"] = train_df[\"Cabin\"].fillna('0').apply(lambda x: x[0])\n",
    "test_df[\"Cabin_Letter\"] = test_df[\"Cabin\"].fillna('0').apply(lambda x: x[0])\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df[\"Cabin_Letter\"].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.barplot(data=train_df, x=\"Cabin_Letter\", y=\"Survived\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_df[\"Cabin_Letter\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make dummy variable for Cabin_Letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1309, 14)\n",
      "(891, 22) (418, 21)\n"
     ]
    }
   ],
   "source": [
    "train_test_df = pd.concat((train_df, test_df))\n",
    "\n",
    "print(train_test_df.shape)\n",
    "\n",
    "# apply get_dummies for Cabin_Letter\n",
    "train_test_df = pd.get_dummies(train_test_df, columns=[\"Cabin_Letter\"])\n",
    "\n",
    "#train_test_df.head()\n",
    "train_df = train_test_df.iloc[:train_df.shape[0]]\n",
    "test_df = train_test_df.iloc[train_df.shape[0]:]\n",
    "\n",
    "# drop added Survived column from test_df\n",
    "test_df = test_df.drop(\"Survived\", axis=1)\n",
    "print(train_df.shape, test_df.shape)\n",
    "\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make CabinBool feature\n",
    "**I think the idea here is that people with recorded cabin numbers are of higher socioeconomic class, and thus more likely to survive. **\n",
    "https://www.kaggle.com/nadintamer/titanic-survival-predictions-beginner\n",
    "\n",
    "- I tried it\n",
    "  - but gradient boosting result became worse. from 0.79904 to 0.77990\n",
    "  - more than cabinbool is necessary? should i use first letter of cabin name?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df[\"CabinBool\"] = (train_df[\"Cabin\"].notnull().astype('int'))\n",
    "test_df[\"CabinBool\"] = (test_df[\"Cabin\"].notnull().astype('int'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make Cabin number feature\n",
    "https://www.kaggle.com/yuanxuan/titanic-random-forest-82-78/notebook"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df['Cabin'].apply(lambda x: str(x).split(' ')[-1][1:]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:4619: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "for i in [train_df, test_df]:\n",
    "    i['Cabin_num1'] = i['Cabin'].apply(lambda x: str(x).split(' ')[-1][1:])\n",
    "    i['Cabin_num1'].replace('an', np.NaN, inplace = True)\n",
    "    i['Cabin_num1'] = i['Cabin_num1'].apply(lambda x: int(x) if not pd.isnull(x) and x != '' else np.NaN)\n",
    "    i['Cabin_num'] = pd.qcut(train_df['Cabin_num1'], 3)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat((train_df, pd.get_dummies(train_df['Cabin_num'], prefix = 'Cabin_num')), axis = 1)\n",
    "test_df = pd.concat((test_df, pd.get_dummies(test_df['Cabin_num'], prefix = 'Cabin_num')), axis = 1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_df['Cabin_num']\n",
    "del test_df['Cabin_num']\n",
    "del train_df['Cabin_num1']\n",
    "del test_df['Cabin_num1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Cabin', 'Embarked', 'Fare', 'Name', 'Parch', 'PassengerId',\n",
       "       'Pclass', 'Sex', 'SibSp', 'Survived', 'Ticket', 'Ticket_Len',\n",
       "       'Cabin_Letter_0', 'Cabin_Letter_A', 'Cabin_Letter_B', 'Cabin_Letter_C',\n",
       "       'Cabin_Letter_D', 'Cabin_Letter_E', 'Cabin_Letter_F', 'Cabin_Letter_G',\n",
       "       'Cabin_Letter_T', 'Cabin_num_(1.999, 28.667]',\n",
       "       'Cabin_num_(28.667, 65.667]', 'Cabin_num_(65.667, 148.0]'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df[['Cabin_num_(1.999, 28.667]', \n",
    "          'Cabin_num_(28.667, 65.667]',\n",
    "          'Cabin_num_(65.667, 148.0]']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## del Ticket, Cabin columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del Ticket, Cabin columns\n",
    "train_df = train_df.drop(['Ticket', 'Cabin'], axis=1)\n",
    "test_df = test_df.drop(['Ticket', 'Cabin'], axis=1)\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add title\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.Title.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fill nan of Age by Title and Pclass\n",
    "https://www.kaggle.com/yuanxuan/titanic-random-forest-82-78/notebook\n",
    "\n",
    "There is mistake in the original notebook.\n",
    "test_df was filled by train_df.\n",
    "So I will skip it."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data = train_df.groupby(['Title', 'Pclass'])['Age']\n",
    "train_df['Age'] = data.transform(lambda x: x.fillna(x.mean()))\n",
    "test_df['Age'] = data.transform(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert title to numerical or one hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try one hot encoding without delete rare title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 24) (418, 23)\n",
      "(1309, 24)\n",
      "(891, 41) (418, 40)\n"
     ]
    }
   ],
   "source": [
    "# try one hote encoding without delete rare title\n",
    "#\n",
    "# concat train and test data. and apply get_dummies for Title. \n",
    "# then split to original size. also drop Survived column from test_df\n",
    "print(train_df.shape, test_df.shape)\n",
    "\n",
    "# concat train and test data\n",
    "#   test_df's Survived column is filled with NaN\n",
    "train_test_df = pd.concat((train_df, test_df))\n",
    "\n",
    "print(train_test_df.shape)\n",
    "\n",
    "# apply get_dummies for Title\n",
    "train_test_df = pd.get_dummies(train_test_df, columns=[\"Title\"])\n",
    "\n",
    "#train_test_df.head()\n",
    "train_df = train_test_df.iloc[:train_df.shape[0]]\n",
    "test_df = train_test_df.iloc[train_df.shape[0]:]\n",
    "\n",
    "# drop added Survived column from test_df\n",
    "test_df = test_df.drop(\"Survived\", axis=1)\n",
    "print(train_df.shape, test_df.shape)\n",
    "\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Cabin_Letter_0', 'Cabin_Letter_A', 'Cabin_Letter_B',\n",
       "       'Cabin_Letter_C', 'Cabin_Letter_D', 'Cabin_Letter_E', 'Cabin_Letter_F',\n",
       "       'Cabin_Letter_G', 'Cabin_Letter_T', 'Cabin_num_(1.999, 28.667]',\n",
       "       'Cabin_num_(28.667, 65.667]', 'Cabin_num_(65.667, 148.0]', 'Embarked',\n",
       "       'Fare', 'Name', 'Parch', 'PassengerId', 'Pclass', 'Sex', 'SibSp',\n",
       "       'Survived', 'Ticket_Len', 'Title_Capt', 'Title_Col', 'Title_Countess',\n",
       "       'Title_Don', 'Title_Dona', 'Title_Dr', 'Title_Jonkheer', 'Title_Lady',\n",
       "       'Title_Major', 'Title_Master', 'Title_Miss', 'Title_Mlle', 'Title_Mme',\n",
       "       'Title_Mr', 'Title_Mrs', 'Title_Ms', 'Title_Rev', 'Title_Sir'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### del rare title and map value"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# del rare title and map value\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\n",
    "                                                 'Don', 'Dr', 'Major', 'Rev', 'Sir',\n",
    "                                                 'Jonkheer', 'Dona'], 'Rare')\n",
    "\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "    \n",
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset['Title'].map(title_mapping)\n",
    "    dataset['Title'] = dataset['Title'].fillna(0)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make name length feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "train_df['Name_Len'] = train_df['Name'].apply(lambda x: len(x))\n",
    "test_df['Name_Len'] = test_df['Name'].apply(lambda x: len(x))\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df[\"Name_Len\"].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.groupby(\"Name_Len\").Survived.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## map value to Sex "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "for dataset in combine:\n",
    "    dataset[\"Sex\"] = dataset[\"Sex\"].map({'female':1, 'male':0}).astype(int)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make Age_Null_Flag if the Age is nulll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "train_df['Age_Null_Flag'] = train_df['Age'].apply(lambda x: 1 if pd.isnull(x) else 0)\n",
    "test_df['Age_Null_Flag'] = test_df['Age'].apply(lambda x: 1 if pd.isnull(x) else 0)\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df[\"Age_Null_Flag\"].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_df[\"Age_Null_Flag\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fill na value"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.isna().any()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_df.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fill na of Age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### by Sex and Pclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "guess_ages = np.zeros((2,3))\n",
    "\n",
    "for dataset in combine:\n",
    "    for i in range(0, 2):\n",
    "        for j in range(0, 3):\n",
    "            guess_df = dataset[(dataset['Sex'] == i) & \\\n",
    "                                  (dataset['Pclass'] == j+1)]['Age'].dropna()\n",
    "\n",
    "            # age_mean = guess_df.mean()\n",
    "            # age_std = guess_df.std()\n",
    "            # age_guess = rnd.uniform(age_mean - age_std, age_mean + age_std)\n",
    "\n",
    "            age_guess = guess_df.median()\n",
    "\n",
    "            # Convert random age float to nearest .5 age\n",
    "            guess_ages[i,j] = int( age_guess/0.5 + 0.5 ) * 0.5\n",
    "            \n",
    "    for i in range(0, 2):\n",
    "        for j in range(0, 3):\n",
    "            dataset.loc[ (dataset.Age.isnull()) & (dataset.Sex == i) & (dataset.Pclass == j+1),\\\n",
    "                    'Age'] = guess_ages[i,j]\n",
    "\n",
    "    dataset['Age'] = dataset['Age'].astype(int)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tried keep Age feature and don't add AgeBand numerical feature\n",
    "if both are there, it is duplicate information\n",
    "\n",
    "#### 2018/03/17 tried Age instead of Age band. But AgeBand is better score for almost all models.\n",
    "svc score was same of little bit better.\n",
    "random forest score became worse.\n",
    "so AgeBand is better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add age band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "train_df['AgeBand'] = pd.cut(train_df['Age'], 5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overwrite AgeBand number on Age. means, drop Age and AgeBand text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "for dataset in combine:\n",
    "    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n",
    "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
    "    dataset.loc[ dataset['Age'] > 64, 'Age'] = 4\n",
    "train_df = train_df.drop(['AgeBand'], axis=1)\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new feature \"FamilySize\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in combine:\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset['IsAlone'] = 0\n",
    "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset['Age*Class'] = dataset.Age * dataset.Pclass"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### select family related feature\n",
    "Parch, SibSp, FaimilySize, IsAlone\n",
    "\n",
    "2018/03/18 Parch and SibSp only was best for almost all models"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# drop Parch, SibSp, FaimilySize\n",
    "\n",
    "train_df = train_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\n",
    "test_df = test_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\n",
    "combine = [train_df, test_df]\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep Parch, SibSp only. this was best amoung familly related features\n",
    "\n",
    "train_df = train_df.drop(['FamilySize', 'IsAlone'], axis=1)\n",
    "test_df = test_df.drop(['FamilySize', 'IsAlone'], axis=1)\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# keep FamilySize only\n",
    "\n",
    "train_df = train_df.drop(['Parch', 'SibSp', 'IsAlone'], axis=1)\n",
    "test_df = test_df.drop(['Parch', 'SibSp', 'IsAlone'], axis=1)\n",
    "combine = [train_df, test_df]\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fill missing Embarked "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_port = train_df.Embarked.dropna().mode()[0]\n",
    "for dataset in combine:\n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna(freq_port)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Embarked categorical feature to numeric"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for dataset in combine:\n",
    "    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## try one hot encoding for Embarked categorical feature\n",
    "2018/03/18 this is better than using converting categorical to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 44) (418, 43)\n",
      "(1309, 44)\n",
      "(891, 46) (418, 45)\n"
     ]
    }
   ],
   "source": [
    "# try one hote encoding for Embarked\n",
    "#\n",
    "# concat train and test data. and apply get_dummies for Title. \n",
    "# then split to original size. also drop Survived column from test_df\n",
    "print(train_df.shape, test_df.shape)\n",
    "\n",
    "# concat train and test data\n",
    "#   test_df's Survived column is filled with NaN\n",
    "train_test_df = pd.concat((train_df, test_df))\n",
    "\n",
    "print(train_test_df.shape)\n",
    "\n",
    "# apply get_dummies for Title\n",
    "train_test_df = pd.get_dummies(train_test_df, columns=[\"Embarked\"])\n",
    "\n",
    "#train_test_df.head()\n",
    "train_df = train_test_df.iloc[:train_df.shape[0]]\n",
    "test_df = train_test_df.iloc[train_df.shape[0]:]\n",
    "\n",
    "# drop added Survived column from test_df\n",
    "test_df = test_df.drop(\"Survived\", axis=1)\n",
    "print(train_df.shape, test_df.shape)\n",
    "\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fill na of test data Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Fare'].fillna(test_df['Fare'].dropna().median(), inplace=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make Fareband feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "train_df['FareBand'] = pd.qcut(train_df['Fare'], 4)\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
    "    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "\n",
    "train_df = train_df.drop(['FareBand'], axis=1)\n",
    "\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try more fare band number\n",
    "\n",
    "- no difference\n",
    "\n",
    "### keep Fare feature and add FareBand numerical feature¶\n",
    "\n",
    "- not good result"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fareband = pd.qcut(train_df['Fare'], 6)\n",
    "fareband.unique()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df['FareBand'] = pd.qcut(train_df['Fare'], 6)\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset.loc[ dataset['Fare'] <= 7.775, 'Fare'] = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.775) & (dataset['Fare'] <= 8.662), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 8.662) & (dataset['Fare'] <= 14.454), 'Fare']   = 2\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 26.0), 'Fare']   = 3\n",
    "    dataset.loc[(dataset['Fare'] > 26.0) & (dataset['Fare'] <= 52.369), 'Fare']   = 4\n",
    "    \n",
    "    dataset.loc[ dataset['Fare'] > 52.369, 'Fare'] = 5\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "\n",
    "train_df = train_df.drop(['FareBand'], axis=1)\n",
    "\n",
    "combine = [train_df, test_df]\n",
    "    \n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## drop Name, PassengerId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(['Name', 'PassengerId'], axis=1)\n",
    "test_df = test_df.drop(['Name'], axis=1)\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## final check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Age*Class</th>\n",
       "      <th>Age_Null_Flag</th>\n",
       "      <th>Cabin_Letter_0</th>\n",
       "      <th>Cabin_Letter_A</th>\n",
       "      <th>Cabin_Letter_B</th>\n",
       "      <th>Cabin_Letter_C</th>\n",
       "      <th>Cabin_Letter_D</th>\n",
       "      <th>Cabin_Letter_E</th>\n",
       "      <th>Cabin_Letter_F</th>\n",
       "      <th>...</th>\n",
       "      <th>Title_Mlle</th>\n",
       "      <th>Title_Mme</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Ms</th>\n",
       "      <th>Title_Rev</th>\n",
       "      <th>Title_Sir</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Age*Class  Age_Null_Flag  Cabin_Letter_0  Cabin_Letter_A  \\\n",
       "0    1          3              0               1               0   \n",
       "1    2          2              0               0               0   \n",
       "2    1          3              0               1               0   \n",
       "3    2          2              0               0               0   \n",
       "4    2          6              0               1               0   \n",
       "\n",
       "   Cabin_Letter_B  Cabin_Letter_C  Cabin_Letter_D  Cabin_Letter_E  \\\n",
       "0               0               0               0               0   \n",
       "1               0               1               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               1               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   Cabin_Letter_F     ...      Title_Mlle  Title_Mme  Title_Mr  Title_Mrs  \\\n",
       "0               0     ...               0          0         1          0   \n",
       "1               0     ...               0          0         0          1   \n",
       "2               0     ...               0          0         0          0   \n",
       "3               0     ...               0          0         0          1   \n",
       "4               0     ...               0          0         1          0   \n",
       "\n",
       "   Title_Ms  Title_Rev  Title_Sir  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0         0          0          0           0           0           1  \n",
       "1         0          0          0           1           0           0  \n",
       "2         0          0          0           0           0           1  \n",
       "3         0          0          0           0           0           1  \n",
       "4         0          0          0           0           0           1  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Age*Class</th>\n",
       "      <th>Age_Null_Flag</th>\n",
       "      <th>Cabin_Letter_0</th>\n",
       "      <th>Cabin_Letter_A</th>\n",
       "      <th>Cabin_Letter_B</th>\n",
       "      <th>Cabin_Letter_C</th>\n",
       "      <th>Cabin_Letter_D</th>\n",
       "      <th>Cabin_Letter_E</th>\n",
       "      <th>Cabin_Letter_F</th>\n",
       "      <th>...</th>\n",
       "      <th>Title_Mlle</th>\n",
       "      <th>Title_Mme</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Ms</th>\n",
       "      <th>Title_Rev</th>\n",
       "      <th>Title_Sir</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Age*Class  Age_Null_Flag  Cabin_Letter_0  Cabin_Letter_A  \\\n",
       "0    2          6              0               1               0   \n",
       "1    2          6              0               1               0   \n",
       "2    3          6              0               1               0   \n",
       "3    1          3              0               1               0   \n",
       "4    1          3              0               1               0   \n",
       "\n",
       "   Cabin_Letter_B  Cabin_Letter_C  Cabin_Letter_D  Cabin_Letter_E  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   Cabin_Letter_F     ...      Title_Mlle  Title_Mme  Title_Mr  Title_Mrs  \\\n",
       "0               0     ...               0          0         1          0   \n",
       "1               0     ...               0          0         0          1   \n",
       "2               0     ...               0          0         1          0   \n",
       "3               0     ...               0          0         1          0   \n",
       "4               0     ...               0          0         0          1   \n",
       "\n",
       "   Title_Ms  Title_Rev  Title_Sir  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0         0          0          0           0           1           0  \n",
       "1         0          0          0           0           0           1  \n",
       "2         0          0          0           0           1           0  \n",
       "3         0          0          0           0           0           1  \n",
       "4         0          0          0           0           0           1  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model and estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = train_df.drop(\"Survived\", axis=1)\n",
    "y_train_df = train_df[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/test data shape (596, 43) (295, 43)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train_df, y_train_df, test_size=0.33, random_state=42)\n",
    "print(\"train/test data shape\", X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validated score of the best_estimator:  0.815436241611\n",
      "best parameters: {'C': 100, 'gamma': 0.001}\n",
      "test:  0.840677966102\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASIAAAD3CAYAAAC5OlmeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAGT5JREFUeJzt3Xu0XGV5x/HvL4EQCLdc5BYQsFLbGKliEJa6EKpCUAtYURNbBaVmUUHbqm1hecHici3AtUQtFI2YclmLm/RibIMRwUttARMQgUCBgAiB1BgSkDvJOU//2HvCnMk5M+/k7H32npnfZ629zsyePc+8M8DD3u/77vdRRGBmVqVJVTfAzMyJyMwq50RkZpVzIjKzyjkRmVnlnIjMrHJORGZWOSciM6ucE5GZVc6JyMwqt13VDTCzch1z1LR4fMNQ0rG33vHC8oiY3+4YSfOBrwGTgYsj4pyW118OXArsnh9zRkQsaxfTicisz63fMMQty/dNOnb7vR+Y1e51SZOBC4G3A2uAFZKWRsTdTYd9FrgmIi6SNAdYBhzQLq4TkVnfC4ZiuKhgbwBWR8SDAJKuAo4HmhNRALvmj3cDHusU1InIrM8FMExhq2zMBh5per4GOKzlmC8AP5D0cWAa8LZOQd1ZbdbngmBTDCVtwCxJK5u2RS3hNOpHjLQQuCQi9gXeAVwuqW2u6etEJGm+pHslrZZ0xiiv7yDp6vz1WyQd0PTamfn+eyUdM1bMpue/lbReUkiaNc7PWCJpnaS7xvtdJM2U9CNJT0u6YJy/1xGSbpO0WdKJ7WJ1Mtp3LDKWpBmSrpd0f/53etGxlPl6/nvdIemQsuJJOik//n5JJ3X7Gw0TSRuwPiLmNW2LW0KtAfZrer4vW196nQJcAxARNwFTgbZ9T0REX25kvfUPAK8ApgC/BOa0HPMx4Bv54wXA1fnjOfnxOwAH5nEmjxHz4fz5oWTXyY8Cs7b1M/LXjgAOAe4q4LtMA94MnApcMM7f6wDgYOAy4MRx/vMZ8R2LjgWcRzZaA3AGcG7Rscj+b38d2VnC4cAtZcQDZgAP5n+n54+np/4+f3Tw9rH+0dlJG7Cyw++zXf75Bzb9e/LqlmOuA07OH/8hWaJSu7j9fEa0pVMtIl4EGp1qzY4nG2YEuBZ4qyTl+6+KiBci4lfA6jxea8z/AZ7Pn68ALgd2GudnEBE/BTYU8V0i4pmI+Bnw/Hh/r4h4KCLuAMbd8znKdyw6VvPvcSlwQgmxjgcui8zNwO6S9i4h3jHA9RGxISI2AtcDbYfYW3VxRtRWRGwGTgeWA/eQjY6tknS2pOPywz4FfFTSL4EryZJS2+D93Fmd0qm25ZiI2CzpSWBmvv/mlvfOzh83x9yUb83HTS7gM4r8LuvHiLktn9FL9oyItQARsVbSHiXEGu03mw2sLTjeWPuTBDDUPg90JbI5Qcta9n2+6fHdwJu6idnPiSilU22sY8ba33oGOdpxqe1IaV+nGN0e08543z+Iiv7Nivh3ZVSFDd6XpJ8vzVI61bYcI2k7sjkPG9q8t3X/dsD2Lce1TmHt9jOK/i6pumlPL/hN4zIp/7uuhFjb+pt1G29c/2yCYChxq0o/J6IVwEGSDpQ0hawDd2nLMUuBxgjEicCN+bXsUmBBPhJ1IHAQ8PNRYr4R2LHlM54d52cU/V1SpXxGL2n+PU4CvltCrKXAh/LRrsOBJxuXXAXHWw4cLWl6PsJ2dL4vSQRsStwqM94RizpvZKMQ95GNBn0m33c2cFz+eCrwHbKO4p8Dr2h672fy990LHDtWzKbn64Engc3AU8APxvEZV5L1M2wi+7/hKeP8Lg+RnR09ncebs42/16H5+58BHgdWjeOfzVbfschYZP1jNwD3539nFB2L7JLpwvz3uhOYV1Y84CP5P9vVwIe7+X3mvmb7uO+RvZM2OoyalbUp/5Jm1qfmHjwl/uU/20/jafiDl6+9NSLmldykrfRzZ7WZ5YaSxlWq40Rk1ucCJyIzq4HhcCIyswr5jMjMKheITdE64b9e+nke0bhp6yUQBjJumbF7LW6ZscuK2zgjStmq4kTUXln/Mvda3DJj91rcMmOXFFcMxaSkrSq+NDPrc9kKjfU+5xi4RLTj7lNjl32mJR278147scecmYXP+Oy1uGXG7rW4ZcbuJu5Tjz3Dc088n3wt5c7qmtlln2mcePmxVTfDbFyu/eB1ycdGqNLLrhQDl4jMBtGwz4jMrEqBeDHq/Z96vVtnZuPWC53V9W6dmRViKJS0pUio9nK+pNvz7T5JT3SK6TMisz4XiKGCzjmUUHI6Iv6m6fiPA6/rFHfCzogSsmgh9b/MbGvDMSlpS5BSUabZQrLF4dqakETUlEWPJavntVDSnJbDTgE2RsQrgfOBc/P3ziFbtvTVZCVU/imPB3AJXZZVMRs02S0ek5K2BMkVRSTtT1b/7MZOQSfqjKiMGmNEgbWxzPpV46bXlI1iSk43LACujYjWghJbmag+orJqjJlZBxF0M6FxfYelYrupKLIAOC3lQyfqjKiMGmPpHy4tamT45zZ2Knhq1m/EcOKWIKnai6RXkZXHvikl6EQlojJqjCWLiMURMS8i5u04fWqXTTfrbVml12Luvo+0ktOQdVJfFYnVOSbq0mxLFgUeJcuiH2g5plHr6Saa6nJJWgpcIekrwD60r/9lZqMoavgeOpeczp9/oZuYE5KI8j6fRhadDCxpZFGyOkpLgW8Dl0taTXYmtCB/7ypJ1wB3k9UMO63R+SXpSuBIsg62NcBZEfHtifhOZr0ikNesbuiURSPieeC9Y7z3S8CXRtm/sOBmmvWlIs+IyuCZ1WZ9rhfWrHYiMutzAamzpivjRGQ2ALxCo5lVKkI+IzKz6nmpWDOrVLYwmi/NzKxSXjzfzCoW4OF7M6uWZ1abWS3UffF8JyKzPpetR+QzIjOrmC/NzKxSWR9RvS/NKm/dtlb3kDRT0o8kPS3pgolut1kvGUJJW1UqPSNKqZFEU3UPSQvIqnu8H3ge+BwwN9/MbBSB2Dxc7+H7qs+Itrm6R0Q8ExE/I0tIZtZGgWtWl6LqRJRSI2lEdQ+gUd3DzBI0Rs2KKjldhqoT0Xiqe6R/iKt42IArsNJrx37d/Jj3Sbpb0ipJV3SKWfWoWTfVPda0VPdIFhGLgcUAe8yZ2VUSM+t1Rc6sTunXlXQQcCbwpojYKGmPTnGrPiNKqZHUqO4BTdU9JrCNZj2vwD6ilH7djwIXRsRGgIhY1ylopWdE46nuASDpIWBXYIqkE4CjW0bczAZetlRsYf0/KVWbfx9A0n+T/Xf9hYj4frugVV+ajbe6xwGlNs6sH0RXw/ezJK1ser4479poSOmz3Y6s/uCRZN0t/yVpbkQ8MdaHVp6IzKxcXS6Mtj4i5rV5PbVf9+aI2AT8StK9ZIlpxVhBq+4jMrMJMBxK2hKk9Ov+O3AUgKRZZJdqD7YL6jMisz5XZB9RYr/ucuBoSXcDQ8DfRsTj7eI6EZkNgCLvvk/o1w3gk/mWxInIrM95hUYzq17A5povA+JEZNbnCp5HVAonIrMB4ERkZpVyH5GZ1UI4EZlZ1Vxy2swqFeE+IjOrnBga9vC9mVWs7n1EtU2TCWWGjpB0m6TNkk6soo1mvaAxj6igm15LUctE1LQc5bHAHGChpDkthz0MnAx0XA/XbKBF1k+UslWlrpdmW5ajBJDUWI5yy+qLEfFQ/tpwFQ006yV1HzWr5RkRaWWGzCxBkPURpWxVqesZ0bhLCI0IJi0CFgHsvNdO2xrGrEd5ZvW2SlmOMpnLCdmgGx6udyKq66VZynKUZpYg64iu96VZLRNRXlq6sRzlPcA1jeUoJR0HIOlQSWvIKnx8U9Kq6lpsVm91H76v66VZynKUK8gu2cysgyKH5iXNB75Gtmb1xRFxTsvrJwNfBh7Nd10QERe3i1nbRGRmxSnqsiul5HTu6og4PTVuLS/NzKw4QVr/UGKySik53TUnIrMBEIlbgtQ5fu+RdIekayXtN8rrIzgRmfW7gBhW0kZecrppW9QSLWWO3/eAAyLiYOCHwKWdmug+IrMB0EUf0bhLTrcUU/wWcG6nDx24RDRl0mb233F94XG311DhMRtWP7tnabFtMBQ4arZljh/ZqNgC4APNB0jaOyLW5k+PI5uC09bAJSKzQdO416yQWGklpz+Rz/fbDGwgWyWjLScis34XwMSWnD4TOLObmE5EZgOgyrWGUjgRmQ0CJyIzq9aWofnaciIy63fRJ4vnSzpc0gpJT0t6UdKQpN+V3TgzK0iBU6vLkDqz+gJgIXA/sCPwF8A/ltWoVJKWSFon6a6q22JWb0rcqpF8i0dErAYmR8RQRPwzcFR5zUp2CTC/6kaY1V7Nz4hS+4iezVdKvF3SecBaYFp5zUoTET+VdEDV7TCrvZqPmqWeEX2QbBbl6cAzZPeavKesRplZgbq76bUSSWdEEfHr/OFzwD+U15xyNFfx2H3vqRW3xqwC/XBGJOldkn4haYOk30l6qpdGzSJicUTMi4h502ZMqbo5ZhMvlLZVJLWP6KvAnwJ3RtR9sriZtVLN/6tN7SN6BLirbklI0pXATcCrJK2RdErVbTKrndQRsx4YNfs7YJmknwAvNHZGxFdKaVWiiFhY5eeb9YZqL7tSpCaiLwFPA1MBd7KY9ZpaXctsLTURzYiIo0ttiZmVZ7jqBrSX2kf0Q0lORGa9qLEwWo1HzVIT0WnA9yU914vD92aDTpG2VSUpEUXELhExKSJ2jIhd8+e7lt04MytIgaNmkuZLulfSaklntDnuREkhqV1VEKCL9YgkHQwc0PyeiPjX1PfXxSSCqdpceNx377Kq8JgNT01rreZbjIvWv6WUuM8NeTyjbMMVXUallpyWtAvwCeCWlLhJiUjSEuBgYBUvdXsF0HOJyGwQFXjZtaXkNICkRsnp1v9bfhE4D/h0StDUM6LDI2JO4rFmVjfFnUGNVnL6sOYDJL0O2C8i/kNSUiJK7ay+SZITkVkvCrLrmJRtnCWnJU0Czgc+1U0TU8+ILiVLRv9HNrNaQOS1rc2s5rq4NBtvyeldgLnAjyUB7AUslXRcRKwcK2hqIlpCtibRndR+apSZbWWCSk5HxJPArMZzST8GPt0uCUF6Ino4LyVrZr2ooESUWHK6a6mJ6H8lXQF8j5E3vXrUzKzmip6s2KnkdMv+I1NipiaiHckSUPNtHhM2fJ9PH3gXsC4i5ub7ZgBXk81tegh4X0RsnIj2mPWcfrj7PiI+XHZDOriErKTRZU37zgBuiIhz8tmdZwB/X0HbzOqvH+6+lzQVOAV4NdlSIABExEdKatcIY1TrOB44Mn98KfBjnIjMRqWaDzGlziO6nGwY7hjgJ2RDdk+V1ahEe0bEWoD87x4Vt8esnhJveK39Ta/AKyPic8AzEXEp8E7gNeU1q1iSFjUmaD29YVPVzTGbeDVfKjY1ETX+631C0lxgN7JO4ir9RtLeAPnfdWMd2FzFY+cZ209YA81qo08S0WJJ04HPAkvJbnA7t7RWpVkKnJQ/Pgn4boVtMau1ul+apQ7f7wY0Rs4uzP9ulvTaiLi9+GaNlFfrOJLsPpg1wFnAOcA1eeWOh4H3lt0OMytHaiJ6PTCPbEIjZH1EK4BTJX0nIs4ro3ENbap1vLXMzzXrG/0wfA/MBA6JiKcBJJ0FXAscAdxKtu6ImdVR1H/4PjURvRx4sen5JmD/iHhO0gtjvMfM6qJPzoiuAG6W1OgQ/hPgSknT2HplNjOrEVH/ktOpt3h8UdIy4M1k3+vUptv6/6ysxplZQfohEQFExK1k/UFm1ksqHppPkZyIzKyHORHVy/TJz/P+XYvv1tpt0g6Fx2x4cLNng9v49MuomZn1Mp8RmVmlKr6PLIUTkdkAqHtndepNr2bWywq8+17SfEn3Slqdr47a+vqpku6UdLukn6XURHQiMhsARd19L2ky2Y3vxwJzgIWjJJorIuI1EfFastu/vtIprhOR2SAo7ozoDcDqiHgwIl4EriJbtvmlj4r4XdPTaSmR3Udk1ucKXmtoNvBI0/M1wGFbfaZ0GvBJYArwx52C1uqMSNISSesk3dW0b4ak6yXdn/+dnu+XpK/n16l3SDqkupab1Vz6GdGsprr3KyUtaok0Wl2irdJcRFwYEb9HVtDis52aV6tERFY2aH7LvkbZoIOAG/LnkF2jHpRvi4CLJqiNZj2niz6i9Y1llfNtcUuoNcB+Tc/3BR5r89FXASd0al+tElFE/BTY0LL7eLJyQeR/T2jaf1lkbgZ2b6xhbWYtiusjWgEcJOlASVOABWTLNm8h6aCmp+8E7u8UtBf6iEaUDZLUKBs02rXqbGDtBLfPrP4K6iOKiM2STgeWA5OBJRGxStLZwMqIWAqcLultZOuWbeSlteXH1AuJaCxJ16qQlRMiu3xj9uzJZbbJrH4Kvvs+IpYBy1r2fb7p8V91G7NWl2ZjGKtsUPK1anM5oZkze+ErmxWsT8oJVWmsskFLgQ/lo2eHA082LuHMbCQNp21VqdWlWZdlg5YB7wBWA8/yUrkjM2tR93vNapWIuikbFBEBnFZui8z6gO++N7NacCIysyr1TRUPM+txTkRmVjVFvTORE5FZv+ujktN9Y3smscfkaYXHfXL4ucJjNjw/vFNpsW1A1PuEaPASkdkgcme1mVXPicjMKuWS02ZWC05EZlYlT2g0s1rQcL0zkRORWb/rgZteK1mPqKhqHZJOyo+/X1LH5SjNBlXd1yOqamG0SxhntQ5JM8jWKzqMrOjbWY3kZWYtJrbk9Ccl3Z2fONwgaf9OMStJRAVV6zgGuD4iNkTERuB6tk5uZsaEl5z+BTAvIg4GriUrO91WnZaKHVGtA+hUrWOs/WbWLICItK2zlJLTP4qIZ/OnN5OtJ99WnRLRWMaq1tFVFY9G5crfPj5UaOPMekGBfUTdngCcAlzXKWidElG31Tq2qYrHy2a6nJANlsY8osRLs0JKTgNI+nNgHvDlTm2sUyLqtlrHcuBoSdPzTuqj831m1iz1siy7NCuk5HReYPEzwHER8UKnJlYyj6iIah0RsUHSF8lK4AKcHRGtHeBmRqEzq7eUnAYeJSs5/YERnyW9DvgmMD8i1m0dYmuVJKKiqnVExBJgSYFNM+tPE1ty+svAzsB3JAE8HBHHtYvrmdVmA2CCS06/rduYTkRm/S4A32tmZlXzmtVmVj1X8TCzqnk9IjOrVg8sAzJwiSgINkXxt3n84oXiSxSZFSGbWV3vTDRwichsILmz2syq5jMiM6tWhOcRmVn1PGpmZtXzpZmZVSrqP7O6tPWIyq7UIen1ku7M3/N15bf5mtkoilsqthRlLox2CeVW6rgoP7bxPi+cbzaWAqt4lKG0RFRmpY78tV0j4qZ8vaLLmmKZWQtFJG1Vmeg+ohGVOiRta6WO2fnj1v1m1iqAIXdWp+i2UkfyAt6QVfEgu4xjv9lePN8Gi6j2bCfFRC+eX1SljjWMrJU0ZgUPcBUPs0HurB5NIZU68teeknR4Plr2oaZYZtZqUBNRXqnjJuBVktbk1TnOAd4u6X7g7flzyNa/fZCsUse3gI9BVqkDaFTqWMHISh1/CVycv+cBEoq4mQ2kILvpNWVLIGm+pHvzqTNnjPL6EZJuk7RZ0okpMUvrIyq7UkdErATmjqeNZoOiqD4iSZOBC8lOJNYAKyQtjYi7mw57GDgZ+HRq3Lp0VptZmYq77HoDsDoiHgSQdBXZ9JstiSgiHspfS57P7URk1u8iYDg5J8yStLLp+eKWaq+jTak5bJwtdCIyGwjp95qtj4h5bV7vaupMKiciswFQ4DyisabUjMtED9+bWRWKG75fARwk6UBJU4AFZNNvxsWJyKzfNSq9pmydQkVsBk4nm+N3D3BNRKySdLak4wAkHSppDfBe4JuSVnWKO3CXZrfd8eL6qfv86teJh88C1pfQjJrEvafE2H0bt8zY3cTdPz1ssZMVI2IZ2dy/5n2fb3q8gpF3PnQ0cIkoIl6WeqyklR067rZJr8UtM3avxS0zdplt9gqNZlatAIbqvUSjE5FZ3wsIJ6JetrjzIQMRt8zYvRa3zNjltbnml2aKmjfQeoekvYCvAocCLwAPAX8dEfdV2a5Bt9uUPeONe4116+dI33/ka7eW1k/Vhs+IrBD5ciz/BlwaEQvyfa8F9gSciKpW8xMOJyIrylHApoj4RmNHRNxeYXusmRORDYi5wK1VN8JGEQFDQ1W3oi0nIrNBUPMzIt/iYUVZBby+6kbYGAZ1qVgbODcCO0j6aGNHfs/RWypskwGQeJ9Zwr1mZXEiskLky/2+m2xN8gfyGx2/QAFLRNg4BUQMJ21VcR+RFSYiHgPeV3U7bBQVnu2kcCIyGwQ176x2IjLrdx6+N7M6iPTF8yvhRGTW96odmk/hRGTW7xpLxdaYh+/NBkEMp20JEkpO7yDp6vz1WyQd0CmmE5FZnwsghiNp66Sp5PSxwBxgoaQ5LYedAmyMiFcC5wPndorrRGTW7yKKPCPaUnI6Il4EGiWnmx0PXJo/vhZ4a75MzJjcR2Q2AKK44fuUktNbjomIzZKeBGbSpkKJE5FZn3uKjct/GNfOSjx8qqSVTc8XR0TzErYpJae7LkvtRGTW5yJifoHhUkpON45ZI2k7YDdgQ7ug7iMys26klJxeCpyUPz4RuDE6LI7vMyIzS5b3+TRKTk8GljRKTgMrI2Ip8G3gckmryc6EFnSK6yoeZlY5X5qZWeWciMysck5EZlY5JyIzq5wTkZlVzonIzCrnRGRmlXMiMrPK/T/kmfDb307sWAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make wide the ranges\n",
    "\n",
    "param_grid = {'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "              'gamma': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]}\n",
    "\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5, n_jobs=3)\n",
    "\n",
    "# no meaning to use cross_val for grid_search model because it is incluced in grid search\n",
    "#scores = cross_val_score(grid_search, X_train, y_train, cv=5, n_jobs=6)\n",
    "#print(\"mean of train scores\", scores.mean())\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "plt.matshow(grid_search.cv_results_['mean_test_score'].reshape(8, -1),\n",
    "            vmin=0, cmap=\"viridis\")\n",
    "plt.xlabel(\"C\")\n",
    "plt.ylabel(\"gamma\")\n",
    "plt.xticks(range(len(param_grid['C'])), param_grid['C'])\n",
    "plt.yticks(range(len(param_grid['gamma'])), param_grid['gamma'])\n",
    "plt.colorbar()\n",
    "\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-100.        , -100.        , -100.        , -100.        ,\n",
       "        -100.        , -100.        , -100.        , -100.        ,\n",
       "          -7.43975181, -100.        , -100.        , -100.        ,\n",
       "        -100.        , -100.        , -100.        ,  -31.28392538,\n",
       "        -100.        , -100.        , -100.        , -100.        ,\n",
       "        -100.        , -100.        ,  -73.88202569, -100.        ,\n",
       "        -100.        , -100.        , -100.        , -100.        ,\n",
       "        -100.        ,  -10.88303604,  -35.23619089,  -86.70386171,\n",
       "         -94.02726709, -100.        , -100.        , -100.        ,\n",
       "        -100.        , -100.        , -100.        ,  -19.26225998,\n",
       "        -100.        , -100.        , -100.        , -100.        ,\n",
       "        -100.        , -100.        ,   -9.01054356, -100.        ,\n",
       "        -100.        , -100.        , -100.        ,  -94.83747243,\n",
       "        -100.        , -100.        , -100.        , -100.        ,\n",
       "        -100.        , -100.        , -100.        , -100.        ,\n",
       "        -100.        ,  -31.24566843, -100.        , -100.        ,\n",
       "         -52.40074752,  -99.10699356,   -8.0880365 , -100.        ,\n",
       "        -100.        , -100.        , -100.        , -100.        ,\n",
       "        -100.        , -100.        , -100.        , -100.        ,\n",
       "         -42.46152489, -100.        , -100.        , -100.        ,\n",
       "        -100.        , -100.        ,  -35.75064402,   -5.78784299,\n",
       "        -100.        , -100.        , -100.        , -100.        ,\n",
       "        -100.        , -100.        , -100.        ,   -2.33500363,\n",
       "        -100.        , -100.        , -100.        , -100.        ,\n",
       "        -100.        , -100.        ,  -24.75931184, -100.        ,\n",
       "        -100.        , -100.        , -100.        , -100.        ,\n",
       "         -43.74712701, -100.        , -100.        , -100.        ,\n",
       "        -100.        , -100.        ,  -56.76983482,  -14.85357759,\n",
       "        -100.        , -100.        , -100.        , -100.        ,\n",
       "        -100.        , -100.        , -100.        , -100.        ,\n",
       "        -100.        , -100.        , -100.        , -100.        ,\n",
       "        -100.        ,  -83.65750054, -100.        , -100.        ,\n",
       "        -100.        , -100.        ,  -54.05756418,  -23.73457049,\n",
       "        -100.        , -100.        , -100.        ,  -78.13252262,\n",
       "        -100.        , -100.        ,  -93.81784638, -100.        ,\n",
       "        -100.        ,  100.        ,  100.        ,  100.        ,\n",
       "         100.        ,  100.        ,   73.02801956,  100.        ,\n",
       "         100.        ,  100.        ,  100.        ,  100.        ,\n",
       "         100.        ,  100.        ,  100.        ,  100.        ,\n",
       "         100.        ,  100.        ,  100.        ,  100.        ,\n",
       "         100.        ,  100.        ,  100.        ,  100.        ,\n",
       "          97.68153083,  100.        ,  100.        ,   91.16100679,\n",
       "          74.14165732,  100.        ,  100.        ,  100.        ,\n",
       "         100.        ,  100.        ,  100.        ,  100.        ,\n",
       "         100.        ,  100.        ,   65.4984026 ,   55.50153505,\n",
       "         100.        ,    1.41767138,  100.        ,  100.        ,\n",
       "         100.        ,  100.        ,  100.        ,   92.19874759,\n",
       "         100.        ,   26.54548229,  100.        ,  100.        ,\n",
       "         100.        ,  100.        ,  100.        ,  100.        ,\n",
       "         100.        ,  100.        ,  100.        ,  100.        ,\n",
       "         100.        ,  100.        ,   63.87784028,  100.        ,\n",
       "         100.        ,  100.        ,  100.        ,  100.        ,\n",
       "          81.76051938,   76.99303707,  100.        ,  100.        ,\n",
       "         100.        ,  100.        ,  100.        ,  100.        ,\n",
       "         100.        ,  100.        ,   90.35761551,  100.        ,\n",
       "         100.        ,  100.        ,  100.        ,  100.        ,\n",
       "         100.        ,  100.        ,  100.        ,   13.2118079 ,\n",
       "         100.        ,  100.        ,  100.        ,  100.        ,\n",
       "         100.        ,  100.        ,  100.        ,  100.        ,\n",
       "          48.13651051,  100.        ,  100.        ,  100.        ,\n",
       "         100.        ,  100.        ,  100.        ,  100.        ,\n",
       "         100.        ,  100.        ,  100.        ,  100.        ,\n",
       "         100.        ,  100.        ,  100.        ,  100.        ,\n",
       "          85.40908417,  100.        ,  100.        ,  100.        ,\n",
       "         100.        ,   85.91712739,  100.        ,   39.7645928 ,\n",
       "         100.        ,  100.        ,  100.        ,  100.        ,\n",
       "         100.        ,  100.        ,  100.        ,  100.        ,\n",
       "         100.        ,  100.        ,  100.        ,   50.67046321,\n",
       "         100.        ,  100.        ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_.dual_coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random forest result for compare"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "param_grid = {'randomforestclassifier__n_estimators': [5, 10, 20, 30, 50, 100, 200, 300, 400, 500],\n",
    "              'randomforestclassifier__max_features': [1, 'auto', None],\n",
    "             'randomforestclassifier__max_depth':[1, 5, 10, 20, 30, None],\n",
    "             'randomforestclassifier__min_samples_leaf': [1,2,4],\n",
    "             \"randomforestclassifier__min_samples_split\" : [2, 5, 10, 13, 16]}\n",
    "\n",
    "pipe = make_pipeline(RandomForestClassifier())\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=6)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## output of upper code\n",
    "\n",
    "Mean cross-validated score of the best_estimator:  0.8389261744966443\n",
    "best parameters: {'randomforestclassifier__max_depth': 10, 'randomforestclassifier__max_features': 1, 'randomforestclassifier__min_samples_leaf': 1, 'randomforestclassifier__min_samples_split': 13, 'randomforestclassifier__n_estimators': 300}\n",
    "test:  0.8271186440677966"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test:  0.820338983051\n",
      "mean of cross val score:  0.814814814815\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(RandomForestClassifier(max_depth=10, \n",
    "                                            max_features=1,\n",
    "                                            min_samples_leaf=1, \n",
    "                                            min_samples_split=13, \n",
    "                                            n_estimators=300))\n",
    "pipe.fit(X_train, y_train)\n",
    "print(\"test: \", pipe.score(X_test, y_test))\n",
    "\n",
    "scores = cross_val_score(pipe, X_train_df, y_train_df, n_jobs=3)\n",
    "print(\"mean of cross val score: \", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Sex</td>\n",
       "      <td>0.138943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Title_Mr</td>\n",
       "      <td>0.118744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Name_Len</td>\n",
       "      <td>0.094135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Title_Mrs</td>\n",
       "      <td>0.065831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Title_Miss</td>\n",
       "      <td>0.063248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Pclass</td>\n",
       "      <td>0.055639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Age*Class</td>\n",
       "      <td>0.048975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Ticket_Len</td>\n",
       "      <td>0.041558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Fare</td>\n",
       "      <td>0.040287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cabin_Letter_0</td>\n",
       "      <td>0.039663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SibSp</td>\n",
       "      <td>0.034011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.026317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Parch</td>\n",
       "      <td>0.026059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Embarked_S</td>\n",
       "      <td>0.020904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Embarked_C</td>\n",
       "      <td>0.018908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cabin_Letter_E</td>\n",
       "      <td>0.018612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cabin_Letter_B</td>\n",
       "      <td>0.018340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Cabin_num_(1.999, 28.667]</td>\n",
       "      <td>0.017025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Cabin_num_(65.667, 148.0]</td>\n",
       "      <td>0.015091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Age_Null_Flag</td>\n",
       "      <td>0.014127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Cabin_num_(28.667, 65.667]</td>\n",
       "      <td>0.013933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cabin_Letter_D</td>\n",
       "      <td>0.013320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Embarked_Q</td>\n",
       "      <td>0.010187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cabin_Letter_C</td>\n",
       "      <td>0.009671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Title_Master</td>\n",
       "      <td>0.008655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cabin_Letter_F</td>\n",
       "      <td>0.005787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Title_Rev</td>\n",
       "      <td>0.003022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cabin_Letter_A</td>\n",
       "      <td>0.002890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Title_Dr</td>\n",
       "      <td>0.002474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Title_Mlle</td>\n",
       "      <td>0.002182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cabin_Letter_G</td>\n",
       "      <td>0.002150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Title_Ms</td>\n",
       "      <td>0.001859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Title_Col</td>\n",
       "      <td>0.001745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Title_Lady</td>\n",
       "      <td>0.001320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Title_Mme</td>\n",
       "      <td>0.001189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Cabin_Letter_T</td>\n",
       "      <td>0.001083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Title_Countess</td>\n",
       "      <td>0.001078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Title_Capt</td>\n",
       "      <td>0.001039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Title_Jonkheer</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Title_Dona</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Title_Don</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Title_Sir</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Title_Major</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      variable  importance\n",
       "19                         Sex    0.138943\n",
       "35                    Title_Mr    0.118744\n",
       "16                    Name_Len    0.094135\n",
       "36                   Title_Mrs    0.065831\n",
       "32                  Title_Miss    0.063248\n",
       "18                      Pclass    0.055639\n",
       "1                    Age*Class    0.048975\n",
       "21                  Ticket_Len    0.041558\n",
       "15                        Fare    0.040287\n",
       "3               Cabin_Letter_0    0.039663\n",
       "20                       SibSp    0.034011\n",
       "0                          Age    0.026317\n",
       "17                       Parch    0.026059\n",
       "42                  Embarked_S    0.020904\n",
       "40                  Embarked_C    0.018908\n",
       "8               Cabin_Letter_E    0.018612\n",
       "5               Cabin_Letter_B    0.018340\n",
       "12   Cabin_num_(1.999, 28.667]    0.017025\n",
       "14   Cabin_num_(65.667, 148.0]    0.015091\n",
       "2                Age_Null_Flag    0.014127\n",
       "13  Cabin_num_(28.667, 65.667]    0.013933\n",
       "7               Cabin_Letter_D    0.013320\n",
       "41                  Embarked_Q    0.010187\n",
       "6               Cabin_Letter_C    0.009671\n",
       "31                Title_Master    0.008655\n",
       "9               Cabin_Letter_F    0.005787\n",
       "38                   Title_Rev    0.003022\n",
       "4               Cabin_Letter_A    0.002890\n",
       "27                    Title_Dr    0.002474\n",
       "33                  Title_Mlle    0.002182\n",
       "10              Cabin_Letter_G    0.002150\n",
       "37                    Title_Ms    0.001859\n",
       "23                   Title_Col    0.001745\n",
       "29                  Title_Lady    0.001320\n",
       "34                   Title_Mme    0.001189\n",
       "11              Cabin_Letter_T    0.001083\n",
       "24              Title_Countess    0.001078\n",
       "22                  Title_Capt    0.001039\n",
       "28              Title_Jonkheer    0.000000\n",
       "26                  Title_Dona    0.000000\n",
       "25                   Title_Don    0.000000\n",
       "39                   Title_Sir    0.000000\n",
       "30                 Title_Major    0.000000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat((pd.DataFrame(X_train.columns, columns = ['variable']), \n",
    "           pd.DataFrame(pipe.named_steps[\"randomforestclassifier\"].feature_importances_, columns = ['importance'])), \n",
    "          axis = 1).sort_values(by='importance', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "AdaBoostClassifier(base_estimator=None, n_estimators=50,\n",
    "                   learning_rate=1.0, algorithm='SAMME.R',\n",
    "                   random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "param_grid = {'learning_rate': [0.001, 0.01, 0.1, 1, 10],\n",
    "              'n_estimators': [3, 5, 7, 10, 50, 100, 200, 400, 500, 600, 700, 800, 1000],\n",
    "              'min_samples_split':[2, 3, 4, 5],\n",
    "              'min_samples_leaf': [1, 3, 5, 9, 17],\n",
    "              'max_depth':[1,2,3,4,5,6],\n",
    "              'max_features': ['auto', 'sqrt', 'log2'],}\n",
    "\n",
    "grid_search = GridSearchCV(GradientBoostingClassifier(), param_grid, cv=5, n_jobs=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "plt.matshow(grid_search.cv_results_['mean_test_score'].reshape(6, -1),\n",
    "            vmin=0, cmap=\"viridis\")\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.ylabel(\"learning_rate\")\n",
    "plt.xticks(range(len(param_grid['n_estimators'])), param_grid['n_estimators'])\n",
    "plt.yticks(range(len(param_grid['learning_rate'])), param_grid['learning_rate'])\n",
    "plt.colorbar()\n",
    "\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# output of upper code\n",
    "\n",
    "Mean cross-validated score of the best_estimator:  0.843959731544\n",
    "best parameters: {'learning_rate': 0.01, 'max_depth': 6, 'max_features': 'sqrt', 'min_samples_leaf': 3, 'min_samples_split': 3, 'n_estimators': 200}\n",
    "test:  0.830508474576\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test:  0.823728813559\n",
      "mean of cross val score for X_train_df:  0.832772166105\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(GradientBoostingClassifier(learning_rate=0.01,\n",
    "                                                max_depth=6,\n",
    "                                                max_features=\"sqrt\",\n",
    "                                                min_samples_leaf=3,\n",
    "                                                min_samples_split=3,\n",
    "                                                n_estimators=200))\n",
    "pipe.fit(X_train, y_train)\n",
    "print(\"test: \", pipe.score(X_test, y_test))\n",
    "\n",
    "scores = cross_val_score(pipe, X_train_df, y_train_df, n_jobs=3)\n",
    "print(\"mean of cross val score for X_train_df: \", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Title_Mr</td>\n",
       "      <td>0.138897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Sex</td>\n",
       "      <td>0.134356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Name_Len</td>\n",
       "      <td>0.110845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Pclass</td>\n",
       "      <td>0.080815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Ticket_Len</td>\n",
       "      <td>0.066736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Age*Class</td>\n",
       "      <td>0.056628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Title_Mrs</td>\n",
       "      <td>0.052123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Title_Miss</td>\n",
       "      <td>0.041257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SibSp</td>\n",
       "      <td>0.040913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Fare</td>\n",
       "      <td>0.040151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Parch</td>\n",
       "      <td>0.031429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cabin_Letter_0</td>\n",
       "      <td>0.028312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.023741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Embarked_S</td>\n",
       "      <td>0.022462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cabin_Letter_E</td>\n",
       "      <td>0.021352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Embarked_C</td>\n",
       "      <td>0.020224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Cabin_num_(28.667, 65.667]</td>\n",
       "      <td>0.013309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Cabin_num_(1.999, 28.667]</td>\n",
       "      <td>0.013247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cabin_Letter_D</td>\n",
       "      <td>0.009559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Title_Master</td>\n",
       "      <td>0.008981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cabin_Letter_B</td>\n",
       "      <td>0.007434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Age_Null_Flag</td>\n",
       "      <td>0.007230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Embarked_Q</td>\n",
       "      <td>0.006707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cabin_Letter_C</td>\n",
       "      <td>0.005383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Cabin_num_(65.667, 148.0]</td>\n",
       "      <td>0.005261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Title_Rev</td>\n",
       "      <td>0.004926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Title_Dr</td>\n",
       "      <td>0.002957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cabin_Letter_A</td>\n",
       "      <td>0.002041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cabin_Letter_F</td>\n",
       "      <td>0.001496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cabin_Letter_G</td>\n",
       "      <td>0.001229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Title_Mme</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Title_Sir</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Title_Ms</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Title_Major</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Title_Mlle</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Title_Lady</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Title_Dona</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Title_Don</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Title_Countess</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Title_Col</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Title_Capt</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Cabin_Letter_T</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Title_Jonkheer</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      variable  importance\n",
       "35                    Title_Mr    0.138897\n",
       "19                         Sex    0.134356\n",
       "16                    Name_Len    0.110845\n",
       "18                      Pclass    0.080815\n",
       "21                  Ticket_Len    0.066736\n",
       "1                    Age*Class    0.056628\n",
       "36                   Title_Mrs    0.052123\n",
       "32                  Title_Miss    0.041257\n",
       "20                       SibSp    0.040913\n",
       "15                        Fare    0.040151\n",
       "17                       Parch    0.031429\n",
       "3               Cabin_Letter_0    0.028312\n",
       "0                          Age    0.023741\n",
       "42                  Embarked_S    0.022462\n",
       "8               Cabin_Letter_E    0.021352\n",
       "40                  Embarked_C    0.020224\n",
       "13  Cabin_num_(28.667, 65.667]    0.013309\n",
       "12   Cabin_num_(1.999, 28.667]    0.013247\n",
       "7               Cabin_Letter_D    0.009559\n",
       "31                Title_Master    0.008981\n",
       "5               Cabin_Letter_B    0.007434\n",
       "2                Age_Null_Flag    0.007230\n",
       "41                  Embarked_Q    0.006707\n",
       "6               Cabin_Letter_C    0.005383\n",
       "14   Cabin_num_(65.667, 148.0]    0.005261\n",
       "38                   Title_Rev    0.004926\n",
       "27                    Title_Dr    0.002957\n",
       "4               Cabin_Letter_A    0.002041\n",
       "9               Cabin_Letter_F    0.001496\n",
       "10              Cabin_Letter_G    0.001229\n",
       "34                   Title_Mme    0.000000\n",
       "39                   Title_Sir    0.000000\n",
       "37                    Title_Ms    0.000000\n",
       "30                 Title_Major    0.000000\n",
       "33                  Title_Mlle    0.000000\n",
       "29                  Title_Lady    0.000000\n",
       "26                  Title_Dona    0.000000\n",
       "25                   Title_Don    0.000000\n",
       "24              Title_Countess    0.000000\n",
       "23                   Title_Col    0.000000\n",
       "22                  Title_Capt    0.000000\n",
       "11              Cabin_Letter_T    0.000000\n",
       "28              Title_Jonkheer    0.000000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat((pd.DataFrame(X_train.columns, columns = ['variable']), \n",
    "           pd.DataFrame(pipe.named_steps[\"gradientboostingclassifier\"].feature_importances_, columns = ['importance'])), \n",
    "          axis = 1).sort_values(by='importance', ascending = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
