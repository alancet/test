{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# data analysis and wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# train, test, validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "\n",
    "# scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "# decomposition\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "# feature engineering\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# feature selection\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    \"\"\"Utility function to report best scores\n",
    "    \"\"\"\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Rank: {0}\".format(i))\n",
    "            print(\"Score: {0:f} (std: {1:f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Pars: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "            \n",
    "\n",
    "def report2(results, n_top=3):\n",
    "    \"\"\"Utility function to report best scores\n",
    "    \"\"\"\n",
    "    print(\"Rank|Score(std)|Params\", list(results['params'][0].keys()))\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"{0}|\".format(i), end=\"\")\n",
    "            print(\"{0:f}(std:{1:f})|\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]), end=\"\")\n",
    "            print(\"{0}\".format(list(results['params'][candidate].values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../input/train.csv')\n",
    "test_df = pd.read_csv('../input/test.csv')\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# modify features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make ticket length feature\n",
    "https://www.kaggle.com/yuanxuan/titanic-random-forest-82-78/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Ticket_Len'] = train_df['Ticket'].apply(lambda x: len(x))\n",
    "test_df['Ticket_Len'] = test_df['Ticket'].apply(lambda x: len(x))\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.barplot(data=train_df, x=\"Ticket_Len\", y=\"Survived\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df['Ticket_Len'].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_df['Ticket_Len'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make Cabin First character feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Cabin_Letter\"] = train_df[\"Cabin\"].fillna('0').apply(lambda x: x[0])\n",
    "test_df[\"Cabin_Letter\"] = test_df[\"Cabin\"].fillna('0').apply(lambda x: x[0])\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.barplot(data=train_df, x=\"Cabin_Letter\", y=\"Survived\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.groupby(\"Cabin_Letter\").Survived.value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df[\"Cabin_Letter\"].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.barplot(data=train_df, x=\"Cabin_Letter\", y=\"Survived\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_df[\"Cabin_Letter\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make one Cabin_Letter feature by numerical"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_test_df = pd.concat((train_df, test_df))\n",
    "train_test_df.Cabin_Letter.value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cabin_letter_map = {'0': 0, 'A': 1, 'B': 2,\n",
    "                   'C':3, 'D':4, 'E':5,\n",
    "                   'F':6, 'G':7, 'T':8}\n",
    "for dataset in combine:\n",
    "    dataset['Cabin_Letter'] = dataset['Cabin_Letter'].map(cabin_letter_map).astype(int)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make dummy variable for Cabin_Letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1309, 14)\n",
      "(891, 22) (418, 21)\n"
     ]
    }
   ],
   "source": [
    "train_test_df = pd.concat((train_df, test_df))\n",
    "\n",
    "print(train_test_df.shape)\n",
    "\n",
    "# apply get_dummies for Cabin_Letter\n",
    "train_test_df = pd.get_dummies(train_test_df, columns=[\"Cabin_Letter\"])\n",
    "\n",
    "#train_test_df.head()\n",
    "train_df = train_test_df.iloc[:train_df.shape[0]]\n",
    "test_df = train_test_df.iloc[train_df.shape[0]:]\n",
    "\n",
    "# drop added Survived column from test_df\n",
    "test_df = test_df.drop(\"Survived\", axis=1)\n",
    "print(train_df.shape, test_df.shape)\n",
    "\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**if you made Cabin_num features too, duplicate feature for NaN. delete one of these**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df = train_df.drop(\"Cabin_Letter_0\", axis=1)\n",
    "test_df = test_df.drop(\"Cabin_Letter_0\", axis=1)\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>...</th>\n",
       "      <th>Ticket_Len</th>\n",
       "      <th>Cabin_Letter_0</th>\n",
       "      <th>Cabin_Letter_A</th>\n",
       "      <th>Cabin_Letter_B</th>\n",
       "      <th>Cabin_Letter_C</th>\n",
       "      <th>Cabin_Letter_D</th>\n",
       "      <th>Cabin_Letter_E</th>\n",
       "      <th>Cabin_Letter_F</th>\n",
       "      <th>Cabin_Letter_G</th>\n",
       "      <th>Cabin_Letter_T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age Cabin Embarked     Fare  \\\n",
       "0  22.0   NaN        S   7.2500   \n",
       "1  38.0   C85        C  71.2833   \n",
       "2  26.0   NaN        S   7.9250   \n",
       "3  35.0  C123        S  53.1000   \n",
       "4  35.0   NaN        S   8.0500   \n",
       "\n",
       "                                                Name  Parch  PassengerId  \\\n",
       "0                            Braund, Mr. Owen Harris      0            1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...      0            2   \n",
       "2                             Heikkinen, Miss. Laina      0            3   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)      0            4   \n",
       "4                           Allen, Mr. William Henry      0            5   \n",
       "\n",
       "   Pclass     Sex  SibSp       ...        Ticket_Len Cabin_Letter_0  \\\n",
       "0       3    male      1       ...                 9              1   \n",
       "1       1  female      1       ...                 8              0   \n",
       "2       3  female      0       ...                16              1   \n",
       "3       1  female      1       ...                 6              0   \n",
       "4       3    male      0       ...                 6              1   \n",
       "\n",
       "   Cabin_Letter_A  Cabin_Letter_B  Cabin_Letter_C  Cabin_Letter_D  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               1               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               1               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   Cabin_Letter_E  Cabin_Letter_F  Cabin_Letter_G  Cabin_Letter_T  \n",
       "0               0               0               0               0  \n",
       "1               0               0               0               0  \n",
       "2               0               0               0               0  \n",
       "3               0               0               0               0  \n",
       "4               0               0               0               0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Cabin', 'Embarked', 'Fare', 'Name', 'Parch', 'PassengerId',\n",
       "       'Pclass', 'Sex', 'SibSp', 'Survived', 'Ticket', 'Ticket_Len',\n",
       "       'Cabin_Letter_0', 'Cabin_Letter_A', 'Cabin_Letter_B', 'Cabin_Letter_C',\n",
       "       'Cabin_Letter_D', 'Cabin_Letter_E', 'Cabin_Letter_F', 'Cabin_Letter_G',\n",
       "       'Cabin_Letter_T'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>...</th>\n",
       "      <th>Ticket_Len</th>\n",
       "      <th>Cabin_Letter_0</th>\n",
       "      <th>Cabin_Letter_A</th>\n",
       "      <th>Cabin_Letter_B</th>\n",
       "      <th>Cabin_Letter_C</th>\n",
       "      <th>Cabin_Letter_D</th>\n",
       "      <th>Cabin_Letter_E</th>\n",
       "      <th>Cabin_Letter_F</th>\n",
       "      <th>Cabin_Letter_G</th>\n",
       "      <th>Cabin_Letter_T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>0</td>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>0</td>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>0</td>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>0</td>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>1</td>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age Cabin Embarked     Fare                                          Name  \\\n",
       "0  34.5   NaN        Q   7.8292                              Kelly, Mr. James   \n",
       "1  47.0   NaN        S   7.0000              Wilkes, Mrs. James (Ellen Needs)   \n",
       "2  62.0   NaN        Q   9.6875                     Myles, Mr. Thomas Francis   \n",
       "3  27.0   NaN        S   8.6625                              Wirz, Mr. Albert   \n",
       "4  22.0   NaN        S  12.2875  Hirvonen, Mrs. Alexander (Helga E Lindqvist)   \n",
       "\n",
       "   Parch  PassengerId  Pclass     Sex  SibSp       ...       Ticket_Len  \\\n",
       "0      0          892       3    male      0       ...                6   \n",
       "1      0          893       3  female      1       ...                6   \n",
       "2      0          894       2    male      0       ...                6   \n",
       "3      0          895       3    male      0       ...                6   \n",
       "4      1          896       3  female      1       ...                7   \n",
       "\n",
       "   Cabin_Letter_0  Cabin_Letter_A  Cabin_Letter_B  Cabin_Letter_C  \\\n",
       "0               1               0               0               0   \n",
       "1               1               0               0               0   \n",
       "2               1               0               0               0   \n",
       "3               1               0               0               0   \n",
       "4               1               0               0               0   \n",
       "\n",
       "   Cabin_Letter_D  Cabin_Letter_E  Cabin_Letter_F  Cabin_Letter_G  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   Cabin_Letter_T  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make CabinBool feature\n",
    "**I think the idea here is that people with recorded cabin numbers are of higher socioeconomic class, and thus more likely to survive. **\n",
    "https://www.kaggle.com/nadintamer/titanic-survival-predictions-beginner\n",
    "\n",
    "- I tried it\n",
    "  - but gradient boosting result became worse. from 0.79904 to 0.77990\n",
    "  - more than cabinbool is necessary? should i use first letter of cabin name?\n",
    "\n",
    "**CabinBool is inclueded in Cabin letter and cabin number**\n",
    "**no need to use**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df[\"CabinBool\"] = (train_df[\"Cabin\"].notnull().astype('int'))\n",
    "test_df[\"CabinBool\"] = (test_df[\"Cabin\"].notnull().astype('int'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make Cabin number feature\n",
    "https://www.kaggle.com/yuanxuan/titanic-random-forest-82-78/notebook"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df['Cabin'].apply(lambda x: str(x).split(' ')[-1][1:]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/yuki/.local/lib/python3.6/site-packages/pandas/core/generic.py:4619: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "for i in [train_df, test_df]:\n",
    "    i['Cabin_num1'] = i['Cabin'].apply(lambda x: str(x).split(' ')[-1][1:])\n",
    "    i['Cabin_num1'].replace('an', np.NaN, inplace = True)\n",
    "    i['Cabin_num1'] = i['Cabin_num1'].apply(lambda x: int(x) if not pd.isnull(x) and x != '' else np.NaN)\n",
    "    i['Cabin_num'] = pd.qcut(train_df['Cabin_num1'], 3)\n",
    "    i['Cabin_num'] = i['Cabin_num'].cat.add_categories([\"nan_category\"])\n",
    "    i['Cabin_num'] = i['Cabin_num'].fillna(\"nan_category\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat((train_df, pd.get_dummies(train_df['Cabin_num'], prefix='Cabin_num')), axis = 1)\n",
    "test_df = pd.concat((test_df, pd.get_dummies(test_df['Cabin_num'], prefix='Cabin_num')), axis = 1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.barplot(data=train_df, x=\"Cabin_num\", y=\"Survived\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.groupby([\"Cabin_num\"])[\"Survived\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_df['Cabin_num']\n",
    "del test_df['Cabin_num']\n",
    "del train_df['Cabin_num1']\n",
    "del test_df['Cabin_num1']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df[['Cabin_num_(1.999, 28.667]', \n",
    "          'Cabin_num_(28.667, 65.667]',\n",
    "          'Cabin_num_(65.667, 148.0]']].head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df[[\"Cabin_Letter_0\", \"Cabin_num_nan_category\"]].head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## del Ticket, Cabin columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del Ticket, Cabin columns\n",
    "train_df = train_df.drop(['Ticket', 'Cabin'], axis=1)\n",
    "test_df = test_df.drop(['Ticket', 'Cabin'], axis=1)\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add title\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.barplot(data=train_df, x=\"Title\", y=\"Survived\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.Title.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make name length feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Name_Len'] = train_df['Name'].apply(lambda x: len(x))\n",
    "test_df['Name_Len'] = test_df['Name'].apply(lambda x: len(x))\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df[\"Name_Len\"].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.barplot(data=train_df, x=\"Name_Len\", y=\"Survived\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.groupby(\"Name_Len\").Survived.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## map value to Sex "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in combine:\n",
    "    dataset[\"Sex\"] = dataset[\"Sex\"].map({'female':1, 'male':0}).astype(int)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make Age_Null_Flag if the Age is nulll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Age_Null_Flag'] = train_df['Age'].apply(lambda x: 1 if pd.isnull(x) else 0)\n",
    "test_df['Age_Null_Flag'] = test_df['Age'].apply(lambda x: 1 if pd.isnull(x) else 0)\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.barplot(data=train_df, x=\"Age_Null_Flag\", y=\"Survived\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df[\"Age_Null_Flag\"].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_df[\"Age_Null_Flag\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fill na of Age\n",
    "\n",
    "options\n",
    "\n",
    "- by Sex and Pclass\n",
    "- by Title and Pclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### by Sex and Pclass"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "guess_ages = np.zeros((2,3))\n",
    "\n",
    "for dataset in combine:\n",
    "    for i in range(0, 2):\n",
    "        for j in range(0, 3):\n",
    "            guess_df = dataset[(dataset['Sex'] == i) & \\\n",
    "                                  (dataset['Pclass'] == j+1)]['Age'].dropna()\n",
    "\n",
    "            # age_mean = guess_df.mean()\n",
    "            # age_std = guess_df.std()\n",
    "            # age_guess = rnd.uniform(age_mean - age_std, age_mean + age_std)\n",
    "\n",
    "            age_guess = guess_df.median()\n",
    "\n",
    "            # Convert random age float to nearest .5 age\n",
    "            guess_ages[i,j] = int( age_guess/0.5 + 0.5 ) * 0.5\n",
    "            \n",
    "    for i in range(0, 2):\n",
    "        for j in range(0, 3):\n",
    "            dataset.loc[ (dataset.Age.isnull()) & (dataset.Sex == i) & (dataset.Pclass == j+1),\\\n",
    "                    'Age'] = guess_ages[i,j]\n",
    "\n",
    "    dataset['Age'] = dataset['Age'].astype(int)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.barplot(data=train_df, x=\"Age\", y=\"Survived\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fill nan of Age by Title and Pclass\n",
    "https://www.kaggle.com/yuanxuan/titanic-random-forest-82-78/notebook\n",
    "\n",
    "There is mistake in the original notebook.\n",
    "test_df was filled by train_df.\n",
    "So I modified."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "groupedAge_train = train_df.groupby(['Title', 'Pclass'])['Age']\n",
    "groupedAge_train.mean()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_test_df = pd.concat((train_df, test_df))\n",
    "groupedAge_train_test = train_test_df.groupby(['Title', 'Pclass'])['Age']\n",
    "filledAge = groupedAge_train_test.transform(lambda x:x.fillna(x.mean()))\n",
    "train_test_df[filledAge.isna()]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "groupedByTitleOnly_Age_train_test = train_test_df.groupby(['Title'])['Age']\n",
    "groupedByTitleOnly_Age_train_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_df = pd.concat((train_df, test_df))\n",
    "groupedAge_train_test = train_test_df.groupby(['Title', 'Pclass'])['Age']\n",
    "train_test_df.Age = groupedAge_train_test.transform(lambda x:x.fillna(x.mean()))\n",
    "\n",
    "groupedByTitleOnly_Age_train_test = train_test_df.groupby(['Title'])['Age']\n",
    "train_test_df.Age = groupedByTitleOnly_Age_train_test.transform(lambda x:x.fillna(x.mean()))\n",
    "\n",
    "train_df = train_test_df.iloc[:train_df.shape[0]]\n",
    "test_df = train_test_df.iloc[train_df.shape[0]:]\n",
    "\n",
    "combine = [train_df, test_df]\n",
    "test_df = test_df.drop([\"Survived\"], axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "groupedAge_train_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_df.Age.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((891, 27), (418, 26))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head(30)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_df.head(30)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.isna().any()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_df.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tried keep Age feature and don't add AgeBand numerical feature\n",
    "if both are there, it is duplicate information\n",
    "\n",
    "#### 2018/03/17 tried Age instead of Age band. But AgeBand is better score for almost all models.\n",
    "svc score was same of little bit better.\n",
    "random forest score became worse.\n",
    "so AgeBand is better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add age band\n",
    "\n",
    "- 5 age band by pd.cut\n",
    "- 10 age band by pd.cut: this is better score.\n",
    "\n",
    "if i use pd.qcut, band become too short for young adult around 25."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pd.cut(train_df['Age'], 10).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "train_df['AgeBand'] = pd.cut(train_df['Age'], 5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df['AgeBand'] = pd.cut(train_df['Age'], 10)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.barplot(x=\"AgeBand\", data=train_df, y=\"Survived\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overwrite AgeBand number on Age. means, drop Age and AgeBand text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuki/.local/lib/python3.6/site-packages/pandas/core/indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "# 5 age band\n",
    "for dataset in combine:\n",
    "    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n",
    "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
    "    dataset.loc[ dataset['Age'] > 64, 'Age'] = 4\n",
    "train_df = train_df.drop(['AgeBand'], axis=1)\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 10 age band\n",
    "for dataset in combine:\n",
    "    dataset.loc[ dataset['Age'] <= 8, 'Age'] = 0\n",
    "    dataset.loc[(dataset['Age'] > 8) & (dataset['Age'] <= 16), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 24), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 24) & (dataset['Age'] <= 32), 'Age'] = 3\n",
    "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 40), 'Age'] = 4\n",
    "    dataset.loc[(dataset['Age'] > 40) & (dataset['Age'] <= 48), 'Age'] = 5\n",
    "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 56), 'Age'] = 6\n",
    "    dataset.loc[(dataset['Age'] > 56) & (dataset['Age'] <= 64), 'Age'] = 7\n",
    "    dataset.loc[(dataset['Age'] > 64) & (dataset['Age'] <= 72), 'Age'] = 8\n",
    "    dataset.loc[ dataset['Age'] > 72, 'Age'] = 9\n",
    "train_df = train_df.drop(['AgeBand'], axis=1)\n",
    "combine = [train_df, test_df]\n",
    "\n",
    "\"\"\"\n",
    "(24.0, 32.0]    275\n",
    "(16.0, 24.0]    220\n",
    "(32.0, 40.0]    148\n",
    "(40.0, 48.0]     68\n",
    "(-0.08, 8.0]     54\n",
    "(8.0, 16.0]      46\n",
    "(48.0, 56.0]     45\n",
    "(56.0, 64.0]     24\n",
    "(64.0, 72.0]      9\n",
    "(72.0, 80.0]      2\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.barplot(data=train_df, x=\"Age\", y=\"Survived\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert Title to numerical or one hot encoding\n",
    "\n",
    "several options\n",
    "\n",
    "- one hot encoding, no deleting rare title\n",
    "- change rare title to \"Rare\" and map value\n",
    "- change rare title to \"Rare\" and one hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one hot encoding, no deleteing rare title"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# try one hote encoding without delete rare title\n",
    "#\n",
    "# concat train and test data. and apply get_dummies for Title. \n",
    "# then split to original size. also drop Survived column from test_df\n",
    "print(train_df.shape, test_df.shape)\n",
    "\n",
    "# concat train and test data\n",
    "#   test_df's Survived column is filled with NaN\n",
    "train_test_df = pd.concat((train_df, test_df))\n",
    "\n",
    "print(train_test_df.shape)\n",
    "\n",
    "# apply get_dummies for Title\n",
    "train_test_df = pd.get_dummies(train_test_df, columns=[\"Title\"])\n",
    "\n",
    "#train_test_df.head()\n",
    "train_df = train_test_df.iloc[:train_df.shape[0]]\n",
    "test_df = train_test_df.iloc[train_df.shape[0]:]\n",
    "\n",
    "# drop added Survived column from test_df\n",
    "test_df = test_df.drop(\"Survived\", axis=1)\n",
    "print(train_df.shape, test_df.shape)\n",
    "\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OR change rare title to \"Rare\" and map value"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_test_df = pd.concat((train_df, test_df))\n",
    "print(train_test_df.Title.value_counts(dropna=False))\n",
    "\n",
    "f, ax = plt.subplots(figsize=(20, 6))\n",
    "sns.barplot(data=train_test_df, x=\"Title\", y=\"Survived\", ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**del rare title and map value**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# del rare title and map value\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\n",
    "                                                 'Don', 'Dr', 'Major', 'Rev', 'Sir',\n",
    "                                                 'Jonkheer', 'Dona'], 'Rare')\n",
    "\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "    \n",
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rave\": 5}\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset['Title'].map(title_mapping)\n",
    "    dataset['Title'] = dataset['Title'].fillna(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Replacing rare titles with more common ones**\n",
    "\n",
    "https://www.kaggle.com/konstantinmasich/titanic-0-82-0-83/"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mapping = {'Mlle': 'Miss', \n",
    "            'Major': 'Mr', \n",
    "            'Col': 'Mr', \n",
    "            'Sir': 'Mr',\n",
    "            'Don': 'Mr', \n",
    "            'Mme': 'Miss',\n",
    "            'Jonkheer': 'Mr',\n",
    "            'Lady': 'Mrs', \n",
    "            'Capt': 'Mr', \n",
    "            'Countess': 'Mrs',\n",
    "            'Ms': 'Miss',\n",
    "            'Dona': 'Mrs'}\n",
    "\n",
    "train_df.replace({'Title': mapping}, inplace=True)\n",
    "test_df.replace({'Title': mapping}, inplace=True)\n",
    "\n",
    "combine = [train_df, test_df]\n",
    "\n",
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rev\": 5, \"Dr\":6}\n",
    "\n",
    "train_df['Title'] = train_df['Title'].map(title_mapping)\n",
    "test_df['Title'] = test_df['Title'].map(title_mapping)\n",
    "\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.Title.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.countplot(data=train_df, x=\"Title\", hue=\"Survived\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### change rare title to \"Rare\" and one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 32) (418, 31)\n"
     ]
    }
   ],
   "source": [
    "mapping = {'Mlle': 'Miss', \n",
    "            'Major': 'Mr', \n",
    "            'Col': 'Mr', \n",
    "            'Sir': 'Mr',\n",
    "            'Don': 'Mr', \n",
    "            'Mme': 'Miss',\n",
    "            'Jonkheer': 'Mr',\n",
    "            'Lady': 'Mrs', \n",
    "            'Capt': 'Mr', \n",
    "            'Countess': 'Mrs',\n",
    "            'Ms': 'Miss',\n",
    "            'Dona': 'Mrs'}\n",
    "\n",
    "train_df.replace({'Title': mapping}, inplace=True)\n",
    "test_df.replace({'Title': mapping}, inplace=True)\n",
    "\n",
    "combine = [train_df, test_df]\n",
    "\n",
    "train_test_df = pd.concat((train_df, test_df))\n",
    "train_test_df = pd.get_dummies(train_test_df, columns=[\"Title\"])\n",
    "\n",
    "train_df = train_test_df.iloc[:train_df.shape[0]]\n",
    "test_df = train_test_df.iloc[train_df.shape[0]:]\n",
    "\n",
    "test_df = test_df.drop(\"Survived\", axis=1)\n",
    "print(train_df.shape, test_df.shape)\n",
    "\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Age_Null_Flag', 'Cabin_Letter_0', 'Cabin_Letter_A',\n",
       "       'Cabin_Letter_B', 'Cabin_Letter_C', 'Cabin_Letter_D', 'Cabin_Letter_E',\n",
       "       'Cabin_Letter_F', 'Cabin_Letter_G', 'Cabin_Letter_T',\n",
       "       'Cabin_num_(1.999, 28.667]', 'Cabin_num_(28.667, 65.667]',\n",
       "       'Cabin_num_(65.667, 148.0]', 'Cabin_num_nan_category', 'Embarked',\n",
       "       'Fare', 'Name', 'Name_Len', 'Parch', 'PassengerId', 'Pclass', 'Sex',\n",
       "       'SibSp', 'Survived', 'Ticket_Len', 'Title_Dr', 'Title_Master',\n",
       "       'Title_Miss', 'Title_Mr', 'Title_Mrs', 'Title_Rev'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new feature \"FamilySize\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/home/yuki/.local/lib/python3.6/site-packages/pandas/core/indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "for dataset in combine:\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset['IsAlone'] = 0\n",
    "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset['Age*Class'] = dataset.Age * dataset.Pclass"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.barplot(data=train_df, x=\"FamilySize\", y=\"Survived\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.barplot(data=train_df, x=\"IsAlone\", y=\"Survived\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.countplot(data=train_df, x=\"Age*Class\", hue=\"Survived\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### select family related feature\n",
    "Parch, SibSp, FaimilySize, IsAlone\n",
    "\n",
    "2018/03/18 Parch and SibSp only was best for almost all models"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# keep all"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# keep Parch, SibSp only. this was best amoung familly related features\n",
    "\n",
    "train_df = train_df.drop(['FamilySize', 'IsAlone'], axis=1)\n",
    "test_df = test_df.drop(['FamilySize', 'IsAlone'], axis=1)\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Age_Null_Flag</th>\n",
       "      <th>Cabin_Letter_0</th>\n",
       "      <th>Cabin_Letter_A</th>\n",
       "      <th>Cabin_Letter_B</th>\n",
       "      <th>Cabin_Letter_C</th>\n",
       "      <th>Cabin_Letter_D</th>\n",
       "      <th>Cabin_Letter_E</th>\n",
       "      <th>Cabin_Letter_F</th>\n",
       "      <th>Cabin_Letter_G</th>\n",
       "      <th>...</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Ticket_Len</th>\n",
       "      <th>Title_Dr</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Rev</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Age*Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Age_Null_Flag  Cabin_Letter_0  Cabin_Letter_A  Cabin_Letter_B  \\\n",
       "0  1.0              0               1               0               0   \n",
       "1  2.0              0               0               0               0   \n",
       "2  1.0              0               1               0               0   \n",
       "3  2.0              0               0               0               0   \n",
       "4  2.0              0               1               0               0   \n",
       "\n",
       "   Cabin_Letter_C  Cabin_Letter_D  Cabin_Letter_E  Cabin_Letter_F  \\\n",
       "0               0               0               0               0   \n",
       "1               1               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               1               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   Cabin_Letter_G    ...      Survived  Ticket_Len  Title_Dr  Title_Master  \\\n",
       "0               0    ...           0.0           9         0             0   \n",
       "1               0    ...           1.0           8         0             0   \n",
       "2               0    ...           1.0          16         0             0   \n",
       "3               0    ...           1.0           6         0             0   \n",
       "4               0    ...           0.0           6         0             0   \n",
       "\n",
       "   Title_Miss Title_Mr  Title_Mrs Title_Rev  FamilySize  Age*Class  \n",
       "0           0        1          0         0           2        3.0  \n",
       "1           0        0          1         0           2        2.0  \n",
       "2           1        0          0         0           1        3.0  \n",
       "3           0        0          1         0           2        2.0  \n",
       "4           0        1          0         0           1        6.0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep FamilySize only\n",
    "\n",
    "train_df = train_df.drop(['Parch', 'SibSp', 'IsAlone'], axis=1)\n",
    "test_df = test_df.drop(['Parch', 'SibSp', 'IsAlone'], axis=1)\n",
    "combine = [train_df, test_df]\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# keep IsAlone only (drop Parch, SibSp, FaimilySize)\n",
    "\n",
    "train_df = train_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\n",
    "test_df = test_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\n",
    "combine = [train_df, test_df]\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fill missing Embarked "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_port = train_df.Embarked.dropna().mode()[0]\n",
    "for dataset in combine:\n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna(freq_port)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Embarked categorical feature to numeric"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for dataset in combine:\n",
    "    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## try one hot encoding for Embarked categorical feature\n",
    "2018/03/18 this is better than using converting categorical to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 32) (418, 31)\n",
      "(1309, 32)\n",
      "(891, 34) (418, 34)\n"
     ]
    }
   ],
   "source": [
    "# try one hote encoding for Embarked\n",
    "#\n",
    "# concat train and test data. and apply get_dummies for Title. \n",
    "# then split to original size. also drop Survived column from test_df\n",
    "print(train_df.shape, test_df.shape)\n",
    "\n",
    "# concat train and test data\n",
    "#   test_df's Survived column is filled with NaN\n",
    "train_test_df = pd.concat((train_df, test_df))\n",
    "\n",
    "print(train_test_df.shape)\n",
    "\n",
    "# apply get_dummies for Title\n",
    "train_test_df = pd.get_dummies(train_test_df, columns=[\"Embarked\"])\n",
    "\n",
    "#train_test_df.head()\n",
    "train_df = train_test_df.iloc[:train_df.shape[0]]\n",
    "test_df = train_test_df.iloc[train_df.shape[0]:]\n",
    "\n",
    "print(train_df.shape, test_df.shape)\n",
    "\n",
    "# drop added Survived column from test_df\n",
    "test_df = test_df.drop(\"Survived\", axis=1)\n",
    "\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Age*Class</th>\n",
       "      <th>Age_Null_Flag</th>\n",
       "      <th>Cabin_Letter_0</th>\n",
       "      <th>Cabin_Letter_A</th>\n",
       "      <th>Cabin_Letter_B</th>\n",
       "      <th>Cabin_Letter_C</th>\n",
       "      <th>Cabin_Letter_D</th>\n",
       "      <th>Cabin_Letter_E</th>\n",
       "      <th>Cabin_Letter_F</th>\n",
       "      <th>...</th>\n",
       "      <th>Ticket_Len</th>\n",
       "      <th>Title_Dr</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Rev</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Age*Class  Age_Null_Flag  Cabin_Letter_0  Cabin_Letter_A  \\\n",
       "0  1.0        3.0              0               1               0   \n",
       "1  2.0        2.0              0               0               0   \n",
       "2  1.0        3.0              0               1               0   \n",
       "3  2.0        2.0              0               0               0   \n",
       "4  2.0        6.0              0               1               0   \n",
       "\n",
       "   Cabin_Letter_B  Cabin_Letter_C  Cabin_Letter_D  Cabin_Letter_E  \\\n",
       "0               0               0               0               0   \n",
       "1               0               1               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               1               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   Cabin_Letter_F     ...      Ticket_Len  Title_Dr  Title_Master  Title_Miss  \\\n",
       "0               0     ...               9         0             0           0   \n",
       "1               0     ...               8         0             0           0   \n",
       "2               0     ...              16         0             0           1   \n",
       "3               0     ...               6         0             0           0   \n",
       "4               0     ...               6         0             0           0   \n",
       "\n",
       "   Title_Mr  Title_Mrs  Title_Rev  Embarked_C Embarked_Q  Embarked_S  \n",
       "0         1          0          0           0          0           1  \n",
       "1         0          1          0           1          0           0  \n",
       "2         0          0          0           0          0           1  \n",
       "3         0          1          0           0          0           1  \n",
       "4         1          0          0           0          0           1  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fill na of test data Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Fare'].fillna(test_df['Fare'].dropna().median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Age*Class</th>\n",
       "      <th>Age_Null_Flag</th>\n",
       "      <th>Cabin_Letter_0</th>\n",
       "      <th>Cabin_Letter_A</th>\n",
       "      <th>Cabin_Letter_B</th>\n",
       "      <th>Cabin_Letter_C</th>\n",
       "      <th>Cabin_Letter_D</th>\n",
       "      <th>Cabin_Letter_E</th>\n",
       "      <th>Cabin_Letter_F</th>\n",
       "      <th>...</th>\n",
       "      <th>Ticket_Len</th>\n",
       "      <th>Title_Dr</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Rev</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.5</td>\n",
       "      <td>103.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Age*Class  Age_Null_Flag  Cabin_Letter_0  Cabin_Letter_A  \\\n",
       "0  34.5      103.5              0               1               0   \n",
       "1  47.0      141.0              0               1               0   \n",
       "2  62.0      124.0              0               1               0   \n",
       "3  27.0       81.0              0               1               0   \n",
       "4  22.0       66.0              0               1               0   \n",
       "\n",
       "   Cabin_Letter_B  Cabin_Letter_C  Cabin_Letter_D  Cabin_Letter_E  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   Cabin_Letter_F     ...      Ticket_Len  Title_Dr  Title_Master  Title_Miss  \\\n",
       "0               0     ...               6         0             0           0   \n",
       "1               0     ...               6         0             0           0   \n",
       "2               0     ...               6         0             0           0   \n",
       "3               0     ...               6         0             0           0   \n",
       "4               0     ...               7         0             0           0   \n",
       "\n",
       "   Title_Mr  Title_Mrs  Title_Rev  Embarked_C Embarked_Q  Embarked_S  \n",
       "0         1          0          0           0          1           0  \n",
       "1         0          1          0           0          0           1  \n",
       "2         1          0          0           0          1           0  \n",
       "3         1          0          0           0          0           1  \n",
       "4         0          1          0           0          0           1  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.Fare.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make Fareband feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/yuki/.local/lib/python3.6/site-packages/pandas/core/indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "train_df['FareBand'] = pd.qcut(train_df['Fare'], 4)\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
    "    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n",
    "    #print(dataset['Fare'].value_counts())\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "\n",
    "train_df = train_df.drop(['FareBand'], axis=1)\n",
    "\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try more fare band number\n",
    "\n",
    "- no difference\n",
    "\n",
    "### keep Fare feature and add FareBand numerical feature¶\n",
    "\n",
    "- not good result"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fareband = pd.qcut(train_df['Fare'], 6)\n",
    "fareband.unique()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df['FareBand'] = pd.qcut(train_df['Fare'], 6)\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset.loc[ dataset['Fare'] <= 7.775, 'Fare'] = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.775) & (dataset['Fare'] <= 8.662), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 8.662) & (dataset['Fare'] <= 14.454), 'Fare']   = 2\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 26.0), 'Fare']   = 3\n",
    "    dataset.loc[(dataset['Fare'] > 26.0) & (dataset['Fare'] <= 52.369), 'Fare']   = 4\n",
    "    \n",
    "    dataset.loc[ dataset['Fare'] > 52.369, 'Fare'] = 5\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "\n",
    "train_df = train_df.drop(['FareBand'], axis=1)\n",
    "\n",
    "combine = [train_df, test_df]\n",
    "    \n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## drop Name, PassengerId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(['Name', 'PassengerId'], axis=1)\n",
    "test_df = test_df.drop(['Name'], axis=1)\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## final check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Age*Class</th>\n",
       "      <th>Age_Null_Flag</th>\n",
       "      <th>Cabin_Letter_0</th>\n",
       "      <th>Cabin_Letter_A</th>\n",
       "      <th>Cabin_Letter_B</th>\n",
       "      <th>Cabin_Letter_C</th>\n",
       "      <th>Cabin_Letter_D</th>\n",
       "      <th>Cabin_Letter_E</th>\n",
       "      <th>Cabin_Letter_F</th>\n",
       "      <th>...</th>\n",
       "      <th>Ticket_Len</th>\n",
       "      <th>Title_Dr</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Rev</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Age*Class  Age_Null_Flag  Cabin_Letter_0  Cabin_Letter_A  \\\n",
       "0  1.0        3.0              0               1               0   \n",
       "1  2.0        2.0              0               0               0   \n",
       "2  1.0        3.0              0               1               0   \n",
       "3  2.0        2.0              0               0               0   \n",
       "4  2.0        6.0              0               1               0   \n",
       "\n",
       "   Cabin_Letter_B  Cabin_Letter_C  Cabin_Letter_D  Cabin_Letter_E  \\\n",
       "0               0               0               0               0   \n",
       "1               0               1               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               1               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   Cabin_Letter_F     ...      Ticket_Len  Title_Dr  Title_Master  Title_Miss  \\\n",
       "0               0     ...               9         0             0           0   \n",
       "1               0     ...               8         0             0           0   \n",
       "2               0     ...              16         0             0           1   \n",
       "3               0     ...               6         0             0           0   \n",
       "4               0     ...               6         0             0           0   \n",
       "\n",
       "   Title_Mr  Title_Mrs  Title_Rev  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0         1          0          0           0           0           1  \n",
       "1         0          1          0           1           0           0  \n",
       "2         0          0          0           0           0           1  \n",
       "3         0          1          0           0           0           1  \n",
       "4         1          0          0           0           0           1  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Age*Class', 'Age_Null_Flag', 'Cabin_Letter_0', 'Cabin_Letter_A',\n",
       "       'Cabin_Letter_B', 'Cabin_Letter_C', 'Cabin_Letter_D', 'Cabin_Letter_E',\n",
       "       'Cabin_Letter_F', 'Cabin_Letter_G', 'Cabin_Letter_T',\n",
       "       'Cabin_num_(1.999, 28.667]', 'Cabin_num_(28.667, 65.667]',\n",
       "       'Cabin_num_(65.667, 148.0]', 'Cabin_num_nan_category', 'FamilySize',\n",
       "       'Fare', 'Name_Len', 'Pclass', 'Sex', 'Survived', 'Ticket_Len',\n",
       "       'Title_Dr', 'Title_Master', 'Title_Miss', 'Title_Mr', 'Title_Mrs',\n",
       "       'Title_Rev', 'Embarked_C', 'Embarked_Q', 'Embarked_S'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Age*Class</th>\n",
       "      <th>Age_Null_Flag</th>\n",
       "      <th>Cabin_Letter_0</th>\n",
       "      <th>Cabin_Letter_A</th>\n",
       "      <th>Cabin_Letter_B</th>\n",
       "      <th>Cabin_Letter_C</th>\n",
       "      <th>Cabin_Letter_D</th>\n",
       "      <th>Cabin_Letter_E</th>\n",
       "      <th>Cabin_Letter_F</th>\n",
       "      <th>...</th>\n",
       "      <th>Ticket_Len</th>\n",
       "      <th>Title_Dr</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Rev</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.5</td>\n",
       "      <td>103.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Age*Class  Age_Null_Flag  Cabin_Letter_0  Cabin_Letter_A  \\\n",
       "0  34.5      103.5              0               1               0   \n",
       "1  47.0      141.0              0               1               0   \n",
       "2  62.0      124.0              0               1               0   \n",
       "3  27.0       81.0              0               1               0   \n",
       "4  22.0       66.0              0               1               0   \n",
       "\n",
       "   Cabin_Letter_B  Cabin_Letter_C  Cabin_Letter_D  Cabin_Letter_E  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   Cabin_Letter_F     ...      Ticket_Len  Title_Dr  Title_Master  Title_Miss  \\\n",
       "0               0     ...               6         0             0           0   \n",
       "1               0     ...               6         0             0           0   \n",
       "2               0     ...               6         0             0           0   \n",
       "3               0     ...               6         0             0           0   \n",
       "4               0     ...               7         0             0           0   \n",
       "\n",
       "   Title_Mr  Title_Mrs  Title_Rev  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0         1          0          0           0           1           0  \n",
       "1         0          1          0           0           0           1  \n",
       "2         1          0          0           0           1           0  \n",
       "3         1          0          0           0           0           1  \n",
       "4         0          1          0           0           0           1  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Age*Class', 'Age_Null_Flag', 'Cabin_Letter_0', 'Cabin_Letter_A',\n",
       "       'Cabin_Letter_B', 'Cabin_Letter_C', 'Cabin_Letter_D', 'Cabin_Letter_E',\n",
       "       'Cabin_Letter_F', 'Cabin_Letter_G', 'Cabin_Letter_T',\n",
       "       'Cabin_num_(1.999, 28.667]', 'Cabin_num_(28.667, 65.667]',\n",
       "       'Cabin_num_(65.667, 148.0]', 'Cabin_num_nan_category', 'FamilySize',\n",
       "       'Fare', 'Name_Len', 'PassengerId', 'Pclass', 'Sex', 'Ticket_Len',\n",
       "       'Title_Dr', 'Title_Master', 'Title_Miss', 'Title_Mr', 'Title_Mrs',\n",
       "       'Title_Rev', 'Embarked_C', 'Embarked_Q', 'Embarked_S'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.columns"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "colormap = plt.cm.viridis\n",
    "plt.figure(figsize=(30,30))\n",
    "plt.title('Pearson Correlation of Features', y=1.05, size=15)\n",
    "sns.heatmap(train_df.astype(float).corr(), \n",
    "            linewidths=0.1,vmax=1.0,\n",
    "            square=True, cmap=colormap, \n",
    "            linecolor='white', annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# try to delete some features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Age*Class is duplicated. Age and Pclass is enough, i think"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df = train_df.drop(['Age*Class'], axis=1)\n",
    "test_df = test_df.drop(['Age*Class'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Name_Len looks no meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(['Name_Len'], axis=1)\n",
    "test_df = test_df.drop(['Name_Len'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ticket_Len looks no meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(['Ticket_Len'], axis=1)\n",
    "test_df = test_df.drop(['Ticket_Len'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cabin_Num looks no meaning. Cabin null feature is included in Cabinb_Letter value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(['Cabin_num_(1.999, 28.667]', 'Cabin_num_(28.667, 65.667]',\n",
    "                          'Cabin_num_(65.667, 148.0]', 'Cabin_num_nan_category'], axis=1)\n",
    "test_df = test_df.drop(['Cabin_num_(1.999, 28.667]', 'Cabin_num_(28.667, 65.667]',\n",
    "                        'Cabin_num_(65.667, 148.0]', 'Cabin_num_nan_category'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 26) (418, 26)\n",
      "Index(['Age', 'Age*Class', 'Age_Null_Flag', 'Cabin_Letter_0', 'Cabin_Letter_A',\n",
      "       'Cabin_Letter_B', 'Cabin_Letter_C', 'Cabin_Letter_D', 'Cabin_Letter_E',\n",
      "       'Cabin_Letter_F', 'Cabin_Letter_G', 'Cabin_Letter_T', 'FamilySize',\n",
      "       'Fare', 'Pclass', 'Sex', 'Survived', 'Title_Dr', 'Title_Master',\n",
      "       'Title_Miss', 'Title_Mr', 'Title_Mrs', 'Title_Rev', 'Embarked_C',\n",
      "       'Embarked_Q', 'Embarked_S'],\n",
      "      dtype='object') Index(['Age', 'Age*Class', 'Age_Null_Flag', 'Cabin_Letter_0', 'Cabin_Letter_A',\n",
      "       'Cabin_Letter_B', 'Cabin_Letter_C', 'Cabin_Letter_D', 'Cabin_Letter_E',\n",
      "       'Cabin_Letter_F', 'Cabin_Letter_G', 'Cabin_Letter_T', 'FamilySize',\n",
      "       'Fare', 'PassengerId', 'Pclass', 'Sex', 'Title_Dr', 'Title_Master',\n",
      "       'Title_Miss', 'Title_Mr', 'Title_Mrs', 'Title_Rev', 'Embarked_C',\n",
      "       'Embarked_Q', 'Embarked_S'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape, test_df.shape)\n",
    "print(train_df.columns, test_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Age*Class</th>\n",
       "      <th>Age_Null_Flag</th>\n",
       "      <th>Cabin_Letter_0</th>\n",
       "      <th>Cabin_Letter_A</th>\n",
       "      <th>Cabin_Letter_B</th>\n",
       "      <th>Cabin_Letter_C</th>\n",
       "      <th>Cabin_Letter_D</th>\n",
       "      <th>Cabin_Letter_E</th>\n",
       "      <th>Cabin_Letter_F</th>\n",
       "      <th>...</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Title_Dr</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Rev</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Age*Class  Age_Null_Flag  Cabin_Letter_0  Cabin_Letter_A  \\\n",
       "0  1.0        3.0              0               1               0   \n",
       "1  2.0        2.0              0               0               0   \n",
       "2  1.0        3.0              0               1               0   \n",
       "3  2.0        2.0              0               0               0   \n",
       "4  2.0        6.0              0               1               0   \n",
       "\n",
       "   Cabin_Letter_B  Cabin_Letter_C  Cabin_Letter_D  Cabin_Letter_E  \\\n",
       "0               0               0               0               0   \n",
       "1               0               1               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               1               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   Cabin_Letter_F     ...      Survived  Title_Dr  Title_Master  Title_Miss  \\\n",
       "0               0     ...           0.0         0             0           0   \n",
       "1               0     ...           1.0         0             0           0   \n",
       "2               0     ...           1.0         0             0           1   \n",
       "3               0     ...           1.0         0             0           0   \n",
       "4               0     ...           0.0         0             0           0   \n",
       "\n",
       "   Title_Mr  Title_Mrs  Title_Rev  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0         1          0          0           0           0           1  \n",
       "1         0          1          0           1           0           0  \n",
       "2         0          0          0           0           0           1  \n",
       "3         0          1          0           0           0           1  \n",
       "4         1          0          0           0           0           1  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Age*Class</th>\n",
       "      <th>Age_Null_Flag</th>\n",
       "      <th>Cabin_Letter_0</th>\n",
       "      <th>Cabin_Letter_A</th>\n",
       "      <th>Cabin_Letter_B</th>\n",
       "      <th>Cabin_Letter_C</th>\n",
       "      <th>Cabin_Letter_D</th>\n",
       "      <th>Cabin_Letter_E</th>\n",
       "      <th>Cabin_Letter_F</th>\n",
       "      <th>...</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Title_Dr</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Rev</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.5</td>\n",
       "      <td>103.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Age*Class  Age_Null_Flag  Cabin_Letter_0  Cabin_Letter_A  \\\n",
       "0  34.5      103.5              0               1               0   \n",
       "1  47.0      141.0              0               1               0   \n",
       "2  62.0      124.0              0               1               0   \n",
       "3  27.0       81.0              0               1               0   \n",
       "4  22.0       66.0              0               1               0   \n",
       "\n",
       "   Cabin_Letter_B  Cabin_Letter_C  Cabin_Letter_D  Cabin_Letter_E  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   Cabin_Letter_F     ...      Sex  Title_Dr  Title_Master  Title_Miss  \\\n",
       "0               0     ...        0         0             0           0   \n",
       "1               0     ...        1         0             0           0   \n",
       "2               0     ...        0         0             0           0   \n",
       "3               0     ...        0         0             0           0   \n",
       "4               0     ...        1         0             0           0   \n",
       "\n",
       "   Title_Mr  Title_Mrs  Title_Rev  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0         1          0          0           0           1           0  \n",
       "1         0          1          0           0           0           1  \n",
       "2         1          0          0           0           1           0  \n",
       "3         1          0          0           0           0           1  \n",
       "4         0          1          0           0           0           1  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model and estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = train_df.drop(\"Survived\", axis=1)\n",
    "y_train_df = train_df[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/test data shape (668, 25) (223, 25)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train_df, y_train_df, test_size=0.25, random_state=42)\n",
    "print(\"train/test data shape\", X_train.shape, X_test.shape)\n",
    "# 33, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done 462 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=3)]: Done 1200 out of 1200 | elapsed:    9.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'svc__C': 30, 'svc__gamma': 0.008}\n",
      "Mean cross-validated score of the best_estimator:  0.8278443113772455\n",
      "test:  0.8340807174887892\n",
      "confusion matrix:  [[119  15]\n",
      " [ 22  67]]\n",
      "\n",
      "Rank|Score(std)|Params ['svc__C', 'svc__gamma']\n",
      "1|0.827844(std:0.027025)|[30, 0.008]\n",
      "2|0.826347(std:0.020626)|[500, 0.008]\n",
      "3|0.824850(std:0.036713)|[1, 0.03]\n",
      "3|0.824850(std:0.032172)|[10, 0.01]\n",
      "3|0.824850(std:0.028420)|[30, 0.01]\n",
      "3|0.824850(std:0.030710)|[500, 0.01]\n",
      "3|0.824850(std:0.024199)|[1000, 0.005]\n",
      "8|0.823353(std:0.037051)|[1, 0.04]\n",
      "8|0.823353(std:0.034554)|[1, 0.05]\n",
      "8|0.823353(std:0.027659)|[70, 0.005]\n",
      "8|0.823353(std:0.038132)|[100, 0.001]\n",
      "8|0.823353(std:0.025057)|[1000, 0.008]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5d3081c828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "param_grid = {'svc__C': [0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 30, 50, 70, 80, 90, 100, 500, 1000],\n",
    "              'svc__gamma': [0.001, 0.005, 0.008, 0.01, 0.03, 0.04, 0.05, 0.1, 1, 10, 100, 1000, 10000, 100000, 1000000]}\n",
    "\n",
    "pipe = make_pipeline(SVC())\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv=5, n_jobs=3, verbose=1)\n",
    "\n",
    "# no meaning to use cross_val for grid_search model because it is incluced in grid search\n",
    "#scores = cross_val_score(grid_search, X_train, y_train, cv=5, n_jobs=6)\n",
    "#print(\"mean of train scores\", scores.mean())\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "plt.matshow(grid_search.cv_results_['mean_test_score'].reshape(16, -1),\n",
    "            vmin=0, cmap=\"viridis\")\n",
    "plt.xlabel(\"C\")\n",
    "plt.ylabel(\"gamma\")\n",
    "plt.xticks(range(len(param_grid['svc__C'])), param_grid['svc__C'])\n",
    "plt.yticks(range(len(param_grid['svc__gamma'])), param_grid['svc__C'])\n",
    "plt.colorbar()\n",
    "\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))\n",
    "print(\"confusion matrix: \", confusion_matrix(y_test, grid_search.best_estimator_.predict(X_test)))\n",
    "print(\"\")\n",
    "report2(grid_search.cv_results_, n_top=10)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "grid_search.best_estimator_.support_vectors_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "grid_search.best_estimator_.dual_coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### svc, minmax scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done 386 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=3)]: Done 1200 out of 1200 | elapsed:    9.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'svc__C': 10, 'svc__gamma': 0.1}\n",
      "Mean cross-validated score of the best_estimator:  0.8323353293413174\n",
      "test:  0.8026905829596412\n",
      "confusion matrix:  [[116  18]\n",
      " [ 26  63]]\n",
      "\n",
      "Rank|Score(std)|Params ['svc__C', 'svc__gamma']\n",
      "1|0.832335(std:0.029063)|[10, 0.1]\n",
      "2|0.830838(std:0.029672)|[30, 0.1]\n",
      "2|0.830838(std:0.024262)|[50, 0.04]\n",
      "2|0.830838(std:0.025689)|[90, 0.03]\n",
      "2|0.830838(std:0.028960)|[90, 0.05]\n",
      "2|0.830838(std:0.025689)|[100, 0.03]\n",
      "2|0.830838(std:0.029672)|[100, 0.05]\n",
      "8|0.829341(std:0.021678)|[30, 0.05]\n",
      "8|0.829341(std:0.028806)|[50, 0.1]\n",
      "8|0.829341(std:0.027131)|[70, 0.1]\n",
      "8|0.829341(std:0.027131)|[80, 0.1]\n",
      "8|0.829341(std:0.029696)|[1000, 0.01]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5d05cb5b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "param_grid = {'svc__C': [0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 30, 50, 70, 80, 90, 100, 500, 1000],\n",
    "              'svc__gamma': [0.001, 0.005, 0.008, 0.01, 0.03, 0.04, 0.05, 0.1, 1, 10, 100, 1000, 10000, 100000, 1000000]}\n",
    "\n",
    "pipe = make_pipeline(MinMaxScaler(), SVC())\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv=5, n_jobs=3, verbose=1)\n",
    "\n",
    "# no meaning to use cross_val for grid_search model because it is incluced in grid search\n",
    "#scores = cross_val_score(grid_search, X_train, y_train, cv=5, n_jobs=6)\n",
    "#print(\"mean of train scores\", scores.mean())\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "plt.matshow(grid_search.cv_results_['mean_test_score'].reshape(16, -1),\n",
    "            vmin=0, cmap=\"viridis\")\n",
    "plt.xlabel(\"C\")\n",
    "plt.ylabel(\"gamma\")\n",
    "plt.xticks(range(len(param_grid['svc__C'])), param_grid['svc__C'])\n",
    "plt.yticks(range(len(param_grid['svc__gamma'])), param_grid['svc__C'])\n",
    "plt.colorbar()\n",
    "\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))\n",
    "print(\"confusion matrix: \", confusion_matrix(y_test, grid_search.best_estimator_.predict(X_test)))\n",
    "print(\"\")\n",
    "report2(grid_search.cv_results_, n_top=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### svc, robust scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done 386 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=3)]: Done 1200 out of 1200 | elapsed:    9.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'svc__C': 10, 'svc__gamma': 0.1}\n",
      "Mean cross-validated score of the best_estimator:  0.8323353293413174\n",
      "test:  0.8026905829596412\n",
      "confusion matrix:  [[116  18]\n",
      " [ 26  63]]\n",
      "\n",
      "Rank|Score(std)|Params ['svc__C', 'svc__gamma']\n",
      "1|0.832335(std:0.029063)|[10, 0.1]\n",
      "2|0.830838(std:0.029672)|[30, 0.1]\n",
      "2|0.830838(std:0.024262)|[50, 0.04]\n",
      "2|0.830838(std:0.025689)|[90, 0.03]\n",
      "2|0.830838(std:0.028960)|[90, 0.05]\n",
      "2|0.830838(std:0.025689)|[100, 0.03]\n",
      "2|0.830838(std:0.029672)|[100, 0.05]\n",
      "8|0.829341(std:0.021678)|[30, 0.05]\n",
      "8|0.829341(std:0.028806)|[50, 0.1]\n",
      "8|0.829341(std:0.027131)|[70, 0.1]\n",
      "8|0.829341(std:0.027131)|[80, 0.1]\n",
      "8|0.829341(std:0.029696)|[1000, 0.01]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5d3082d5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "param_grid = {'svc__C': [0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 30, 50, 70, 80, 90, 100, 500, 1000],\n",
    "              'svc__gamma': [0.001, 0.005, 0.008, 0.01, 0.03, 0.04, 0.05, 0.1, 1, 10, 100, 1000, 10000, 100000, 1000000]}\n",
    "\n",
    "pipe = make_pipeline(RobustScaler(), SVC())\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv=5, n_jobs=3, verbose=1)\n",
    "\n",
    "# no meaning to use cross_val for grid_search model because it is incluced in grid search\n",
    "#scores = cross_val_score(grid_search, X_train, y_train, cv=5, n_jobs=6)\n",
    "#print(\"mean of train scores\", scores.mean())\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "plt.matshow(grid_search.cv_results_['mean_test_score'].reshape(16, -1),\n",
    "            vmin=0, cmap=\"viridis\")\n",
    "plt.xlabel(\"C\")\n",
    "plt.ylabel(\"gamma\")\n",
    "plt.xticks(range(len(param_grid['svc__C'])), param_grid['svc__C'])\n",
    "plt.yticks(range(len(param_grid['svc__gamma'])), param_grid['svc__C'])\n",
    "plt.colorbar()\n",
    "\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))\n",
    "print(\"confusion matrix: \", confusion_matrix(y_test, grid_search.best_estimator_.predict(X_test)))\n",
    "print(\"\")\n",
    "report2(grid_search.cv_results_, n_top=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### svc, StandardScaler scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'svc__C': [0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 30, 50, 70, 80, 90, 100, 500, 1000],\n",
    "              'svc__gamma': [0.001, 0.005, 0.008, 0.01, 0.03, 0.04, 0.05, 0.1, 1, 10, 100, 1000, 10000, 100000, 1000000]}\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(), SVC())\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv=5, n_jobs=3, verbose=1)\n",
    "\n",
    "# no meaning to use cross_val for grid_search model because it is incluced in grid search\n",
    "#scores = cross_val_score(grid_search, X_train, y_train, cv=5, n_jobs=6)\n",
    "#print(\"mean of train scores\", scores.mean())\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "plt.matshow(grid_search.cv_results_['mean_test_score'].reshape(16, -1),\n",
    "            vmin=0, cmap=\"viridis\")\n",
    "plt.xlabel(\"C\")\n",
    "plt.ylabel(\"gamma\")\n",
    "plt.xticks(range(len(param_grid['svc__C'])), param_grid['svc__C'])\n",
    "plt.yticks(range(len(param_grid['svc__gamma'])), param_grid['svc__C'])\n",
    "plt.colorbar()\n",
    "\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))\n",
    "print(\"confusion matrix: \", confusion_matrix(y_test, grid_search.best_estimator_.predict(X_test)))\n",
    "print(\"\")\n",
    "report2(grid_search.cv_results_, n_top=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n",
      "best parameters: {'kneighborsclassifier__n_neighbors': 3}\n",
      "Mean cross-validated score of the best_estimator:  0.8173652694610778\n",
      "test:  0.820627802690583\n",
      "confusion matrix:  [[114  20]\n",
      " [ 20  69]]\n",
      "\n",
      "Rank|Score(std)|Params ['kneighborsclassifier__n_neighbors']\n",
      "1|0.817365(std:0.039016)|[3]\n",
      "2|0.809880(std:0.031434)|[9]\n",
      "3|0.805389(std:0.033716)|[4]\n",
      "3|0.805389(std:0.030008)|[8]\n",
      "5|0.803892(std:0.032144)|[7]\n",
      "6|0.802395(std:0.021719)|[10]\n",
      "7|0.799401(std:0.024624)|[6]\n",
      "8|0.796407(std:0.025896)|[5]\n",
      "9|0.794910(std:0.026436)|[15]\n",
      "10|0.784431(std:0.029338)|[20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done  55 out of  55 | elapsed:    0.5s finished\n"
     ]
    }
   ],
   "source": [
    "# no cale\n",
    "param_grid = {'kneighborsclassifier__n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20]}\n",
    "\n",
    "pipe = make_pipeline(KNeighborsClassifier())\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv=5, n_jobs=3, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))\n",
    "print(\"confusion matrix: \", confusion_matrix(y_test, grid_search.best_estimator_.predict(X_test)))\n",
    "print(\"\")\n",
    "report2(grid_search.cv_results_, n_top=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### minmax scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n",
      "best parameters: {'kneighborsclassifier__n_neighbors': 3}\n",
      "Mean cross-validated score of the best_estimator:  0.842814371257485\n",
      "test:  0.8071748878923767\n",
      "confusion matrix:  [[112  22]\n",
      " [ 21  68]]\n",
      "\n",
      "Rank|Score(std)|Params ['kneighborsclassifier__n_neighbors']\n",
      "1|0.842814(std:0.024442)|[3]\n",
      "2|0.826347(std:0.030211)|[5]\n",
      "3|0.824850(std:0.026373)|[9]\n",
      "4|0.823353(std:0.022240)|[7]\n",
      "5|0.821856(std:0.019028)|[8]\n",
      "6|0.818862(std:0.025317)|[4]\n",
      "6|0.818862(std:0.020605)|[6]\n",
      "8|0.817365(std:0.020383)|[10]\n",
      "9|0.815868(std:0.022824)|[15]\n",
      "10|0.809880(std:0.034467)|[20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done  55 out of  55 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "# minmax scaler\n",
    "param_grid = {'kneighborsclassifier__n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20]}\n",
    "\n",
    "pipe = make_pipeline(MinMaxScaler(), KNeighborsClassifier())\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv=5, n_jobs=3, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))\n",
    "print(\"confusion matrix: \", confusion_matrix(y_test, grid_search.best_estimator_.predict(X_test)))\n",
    "print(\"\")\n",
    "report2(grid_search.cv_results_, n_top=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### robust scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n",
      "best parameters: {'kneighborsclassifier__n_neighbors': 3}\n",
      "Mean cross-validated score of the best_estimator:  0.842814371257485\n",
      "test:  0.8071748878923767\n",
      "confusion matrix:  [[112  22]\n",
      " [ 21  68]]\n",
      "\n",
      "Rank|Score(std)|Params ['kneighborsclassifier__n_neighbors']\n",
      "1|0.842814(std:0.024442)|[3]\n",
      "2|0.826347(std:0.030211)|[5]\n",
      "3|0.824850(std:0.026373)|[9]\n",
      "4|0.823353(std:0.022240)|[7]\n",
      "5|0.821856(std:0.019028)|[8]\n",
      "6|0.818862(std:0.025317)|[4]\n",
      "6|0.818862(std:0.020605)|[6]\n",
      "8|0.817365(std:0.020383)|[10]\n",
      "9|0.815868(std:0.022824)|[15]\n",
      "10|0.809880(std:0.034467)|[20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done  55 out of  55 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "# robust scaler\n",
    "param_grid = {'kneighborsclassifier__n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20]}\n",
    "\n",
    "pipe = make_pipeline(RobustScaler(), KNeighborsClassifier())\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv=5, n_jobs=3, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))\n",
    "print(\"confusion matrix: \", confusion_matrix(y_test, grid_search.best_estimator_.predict(X_test)))\n",
    "print(\"\")\n",
    "report2(grid_search.cv_results_, n_top=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StandardScaler\n",
    "param_grid = {'kneighborsclassifier__n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20]}\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(), KNeighborsClassifier())\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv=5, n_jobs=3, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))\n",
    "print(\"confusion matrix: \", confusion_matrix(y_test, grid_search.best_estimator_.predict(X_test)))\n",
    "print(\"\")\n",
    "report2(grid_search.cv_results_, n_top=10)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## try several SVC, KNeighborsClassifier models and preprocessing conbinations"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "param_grid = dict(scaling=[None, MinMaxScaler(), RobustScaler()],\n",
    "                  reduce_dim=[None, PCA(), PCA(5)],\n",
    "                  clf=[SVC(C=100, gamma=0.01), KNeighborsClassifier(n_neighbors=8)]\n",
    "                 )\n",
    "pipe = Pipeline([('scaling', StandardScaler()), ('reduce_dim', PCA()), ('clf', SVC())]) \n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=3, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))\n",
    "print(\"confusion matrix: \", confusion_matrix(y_test, grid_search.best_estimator_.predict(X_test)))\n",
    "print(\"\")\n",
    "report2(grid_search.cv_results_, n_top=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random forest result for compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**normal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 675 candidates, totalling 3375 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 220 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=6)]: Done 1420 tasks      | elapsed:   18.8s\n",
      "[Parallel(n_jobs=6)]: Done 3364 out of 3375 | elapsed:   45.8s remaining:    0.1s\n",
      "[Parallel(n_jobs=6)]: Done 3375 out of 3375 | elapsed:   46.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'randomforestclassifier__max_depth': 20, 'randomforestclassifier__max_features': 1, 'randomforestclassifier__min_samples_split': 7, 'randomforestclassifier__n_estimators': 20}\n",
      "Mean cross-validated score of the best_estimator:  0.8398203592814372\n",
      "test:  0.820627802690583\n",
      "confusion matrix:  [[118  16]\n",
      " [ 24  65]]\n",
      "\n",
      "Rank|Score(std)|Params ['randomforestclassifier__max_depth', 'randomforestclassifier__max_features', 'randomforestclassifier__min_samples_split', 'randomforestclassifier__n_estimators']\n",
      "1|0.839820(std:0.036515)|[20, 1, 7, 20]\n",
      "2|0.838323(std:0.025005)|[7, 'sqrt', 2, 100]\n",
      "2|0.838323(std:0.025279)|[7, 'sqrt', 5, 20]\n",
      "2|0.838323(std:0.025535)|[7, 'sqrt', 5, 100]\n",
      "5|0.836826(std:0.022181)|[7, 'sqrt', 3, 40]\n",
      "5|0.836826(std:0.031508)|[7, 'log2', 2, 60]\n",
      "5|0.836826(std:0.020451)|[13, 'sqrt', 7, 100]\n",
      "5|0.836826(std:0.025702)|[13, 'log2', 5, 40]\n",
      "5|0.836826(std:0.025345)|[20, 'log2', 7, 40]\n",
      "5|0.836826(std:0.016950)|[None, 1, 6, 20]\n",
      "5|0.836826(std:0.019403)|[None, 1, 6, 30]\n",
      "5|0.836826(std:0.029304)|[None, 'sqrt', 7, 100]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# too wide\n",
    "param_grid = {'randomforestclassifier__max_depth':[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 15, 20, 25 None],\n",
    "             'randomforestclassifier__max_features': [1, 'sqrt', 'log2', None],\n",
    "             'randomforestclassifier__min_samples_leaf': [1,2,3,4,5],\n",
    "             \"randomforestclassifier__min_samples_split\" : [2,3,4,5,6,7],\n",
    "             'randomforestclassifier__n_estimators': [10, 20, 30, 40, 50, 60, 70, 100],\n",
    "              }\n",
    "\"\"\"\n",
    "# narrow down\n",
    "param_grid = {'randomforestclassifier__max_depth':[5, 7, 8, 9,  13, 15, 20, 25, None],\n",
    "             'randomforestclassifier__max_features': [1, 'sqrt', 'log2'],\n",
    "#             'randomforestclassifier__min_samples_leaf': [1,2,3 ,5],\n",
    "             \"randomforestclassifier__min_samples_split\" : [2,3, 5,6,7],\n",
    "             'randomforestclassifier__n_estimators': [20, 30, 40,  60, 100],\n",
    "              }\n",
    "pipe = make_pipeline(RandomForestClassifier())\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=6, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))\n",
    "print(\"confusion matrix: \", confusion_matrix(y_test, grid_search.best_estimator_.predict(X_test)))\n",
    "print(\"\")\n",
    "report2(grid_search.cv_results_, n_top=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Title_Mr</td>\n",
       "      <td>0.140885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Sex</td>\n",
       "      <td>0.133952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>FamilySize</td>\n",
       "      <td>0.092451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Title_Mrs</td>\n",
       "      <td>0.090020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Pclass</td>\n",
       "      <td>0.083328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Fare</td>\n",
       "      <td>0.083103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Age*Class</td>\n",
       "      <td>0.070859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Title_Miss</td>\n",
       "      <td>0.066047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.040539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cabin_Letter_0</td>\n",
       "      <td>0.035484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Embarked_S</td>\n",
       "      <td>0.024550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Age_Null_Flag</td>\n",
       "      <td>0.022189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Embarked_C</td>\n",
       "      <td>0.022186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cabin_Letter_B</td>\n",
       "      <td>0.016178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Embarked_Q</td>\n",
       "      <td>0.014926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Title_Master</td>\n",
       "      <td>0.011642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cabin_Letter_E</td>\n",
       "      <td>0.011584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cabin_Letter_C</td>\n",
       "      <td>0.010368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Title_Rev</td>\n",
       "      <td>0.008521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cabin_Letter_D</td>\n",
       "      <td>0.005565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cabin_Letter_F</td>\n",
       "      <td>0.005535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cabin_Letter_A</td>\n",
       "      <td>0.003519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Title_Dr</td>\n",
       "      <td>0.002965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cabin_Letter_G</td>\n",
       "      <td>0.002450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Cabin_Letter_T</td>\n",
       "      <td>0.001154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          variable  importance\n",
       "19        Title_Mr    0.140885\n",
       "15             Sex    0.133952\n",
       "12      FamilySize    0.092451\n",
       "20       Title_Mrs    0.090020\n",
       "14          Pclass    0.083328\n",
       "13            Fare    0.083103\n",
       "1        Age*Class    0.070859\n",
       "18      Title_Miss    0.066047\n",
       "0              Age    0.040539\n",
       "3   Cabin_Letter_0    0.035484\n",
       "24      Embarked_S    0.024550\n",
       "2    Age_Null_Flag    0.022189\n",
       "22      Embarked_C    0.022186\n",
       "5   Cabin_Letter_B    0.016178\n",
       "23      Embarked_Q    0.014926\n",
       "17    Title_Master    0.011642\n",
       "8   Cabin_Letter_E    0.011584\n",
       "6   Cabin_Letter_C    0.010368\n",
       "21       Title_Rev    0.008521\n",
       "7   Cabin_Letter_D    0.005565\n",
       "9   Cabin_Letter_F    0.005535\n",
       "4   Cabin_Letter_A    0.003519\n",
       "16        Title_Dr    0.002965\n",
       "10  Cabin_Letter_G    0.002450\n",
       "11  Cabin_Letter_T    0.001154"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat((pd.DataFrame(X_train.columns, columns = ['variable']), \n",
    "           pd.DataFrame(grid_search.best_estimator_.named_steps[\"randomforestclassifier\"].feature_importances_, columns = ['importance'])), \n",
    "          axis = 1).sort_values(by='importance', ascending = False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pipe.fit(X_train_df, y_train_df)\n",
    "\n",
    "test_df_noid = test_df.drop(\"PassengerId\", axis=1).copy()\n",
    "y_pred = pipe.predict(test_df_noid).astype(int)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": test_df[\"PassengerId\"].astype(int),\n",
    "        \"Survived\": y_pred\n",
    "    })\n",
    "submission.to_csv('../output/submission_randomforest.csv', index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "output of upper code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**just trial of PolynomialFeatures(degree=2)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 675 candidates, totalling 3375 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 116 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=6)]: Done 716 tasks      | elapsed:   12.1s\n",
      "[Parallel(n_jobs=6)]: Done 1716 tasks      | elapsed:   30.2s\n",
      "[Parallel(n_jobs=6)]: Done 3116 tasks      | elapsed:   57.8s\n",
      "[Parallel(n_jobs=6)]: Done 3364 out of 3375 | elapsed:  1.1min remaining:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'randomforestclassifier__max_depth': 8, 'randomforestclassifier__max_features': 'log2', 'randomforestclassifier__min_samples_split': 7, 'randomforestclassifier__n_estimators': 100}\n",
      "Mean cross-validated score of the best_estimator:  0.842814371257485\n",
      "test:  0.8295964125560538\n",
      "confusion matrix:  [[116  18]\n",
      " [ 20  69]]\n",
      "\n",
      "Rank|Score(std)|Params ['randomforestclassifier__max_depth', 'randomforestclassifier__max_features', 'randomforestclassifier__min_samples_split', 'randomforestclassifier__n_estimators']\n",
      "1|0.842814(std:0.025301)|[8, 'log2', 7, 100]\n",
      "1|0.842814(std:0.025196)|[9, 1, 3, 40]\n",
      "1|0.842814(std:0.022905)|[None, 1, 6, 40]\n",
      "4|0.841317(std:0.023181)|[8, 'log2', 7, 30]\n",
      "5|0.839820(std:0.034126)|[5, 'sqrt', 3, 30]\n",
      "5|0.839820(std:0.021339)|[7, 'log2', 6, 30]\n",
      "5|0.839820(std:0.025489)|[8, 'log2', 3, 20]\n",
      "5|0.839820(std:0.022210)|[8, 'log2', 5, 100]\n",
      "9|0.838323(std:0.024379)|[5, 'sqrt', 5, 40]\n",
      "9|0.838323(std:0.025204)|[5, 'sqrt', 7, 40]\n",
      "9|0.838323(std:0.029161)|[8, 'log2', 5, 60]\n",
      "9|0.838323(std:0.025005)|[9, 1, 5, 40]\n",
      "9|0.838323(std:0.019066)|[9, 1, 5, 60]\n",
      "9|0.838323(std:0.025201)|[9, 1, 6, 30]\n",
      "9|0.838323(std:0.021721)|[13, 1, 6, 60]\n",
      "9|0.838323(std:0.014936)|[13, 1, 7, 40]\n",
      "9|0.838323(std:0.018898)|[25, 1, 6, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 3375 out of 3375 | elapsed:  1.1min finished\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# too wide\n",
    "param_grid = {'randomforestclassifier__max_depth':[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 15, 20, 25 None],\n",
    "             'randomforestclassifier__max_features': [1, 'sqrt', 'log2', None],\n",
    "             'randomforestclassifier__min_samples_leaf': [1,2,3,4,5],\n",
    "             \"randomforestclassifier__min_samples_split\" : [2,3,4,5,6,7],\n",
    "             'randomforestclassifier__n_estimators': [10, 20, 30, 40, 50, 60, 70, 100],\n",
    "              }\n",
    "\"\"\"\n",
    "# narrow down\n",
    "param_grid = {'randomforestclassifier__max_depth':[5, 7, 8, 9,  13, 15, 20, 25, None],\n",
    "             'randomforestclassifier__max_features': [1, 'sqrt', 'log2'],\n",
    "#             'randomforestclassifier__min_samples_leaf': [1,2,3 ,5],\n",
    "             \"randomforestclassifier__min_samples_split\" : [2,3, 5,6,7],\n",
    "             'randomforestclassifier__n_estimators': [20, 30, 40,  60, 100],\n",
    "              }\n",
    "pipe = make_pipeline(PolynomialFeatures(degree=2), RandomForestClassifier())\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=6, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))\n",
    "print(\"confusion matrix: \", confusion_matrix(y_test, grid_search.best_estimator_.predict(X_test)))\n",
    "print(\"\")\n",
    "report2(grid_search.cv_results_, n_top=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.040357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Title_Dr</td>\n",
       "      <td>0.033135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.032877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.032692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.026718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Title_Mrs</td>\n",
       "      <td>0.026518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.025271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.022741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.019284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.017880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.017838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.017805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.017801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.017682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.016248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.014689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.014565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.014332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.013519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Title_Rev</td>\n",
       "      <td>0.013070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.013060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Sex</td>\n",
       "      <td>0.011723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Fare</td>\n",
       "      <td>0.011108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>351 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      variable  importance\n",
       "263        NaN    0.040357\n",
       "296        NaN    0.036457\n",
       "16    Title_Dr    0.033135\n",
       "286        NaN    0.032877\n",
       "290        NaN    0.032692\n",
       "69         NaN    0.026718\n",
       "20   Title_Mrs    0.026518\n",
       "65         NaN    0.025271\n",
       "107        NaN    0.022741\n",
       "330        NaN    0.020327\n",
       "275        NaN    0.019284\n",
       "41         NaN    0.017880\n",
       "266        NaN    0.017838\n",
       "301        NaN    0.017805\n",
       "45         NaN    0.017801\n",
       "267        NaN    0.017682\n",
       "285        NaN    0.016248\n",
       "262        NaN    0.015853\n",
       "323        NaN    0.015495\n",
       "261        NaN    0.014689\n",
       "335        NaN    0.014565\n",
       "114        NaN    0.014332\n",
       "295        NaN    0.013519\n",
       "21   Title_Rev    0.013070\n",
       "279        NaN    0.013060\n",
       "274        NaN    0.012805\n",
       "109        NaN    0.012454\n",
       "53         NaN    0.012405\n",
       "15         Sex    0.011723\n",
       "13        Fare    0.011108\n",
       "..         ...         ...\n",
       "256        NaN    0.000000\n",
       "258        NaN    0.000000\n",
       "136        NaN    0.000000\n",
       "196        NaN    0.000000\n",
       "137        NaN    0.000000\n",
       "142        NaN    0.000000\n",
       "143        NaN    0.000000\n",
       "144        NaN    0.000000\n",
       "145        NaN    0.000000\n",
       "146        NaN    0.000000\n",
       "147        NaN    0.000000\n",
       "153        NaN    0.000000\n",
       "156        NaN    0.000000\n",
       "157        NaN    0.000000\n",
       "159        NaN    0.000000\n",
       "162        NaN    0.000000\n",
       "163        NaN    0.000000\n",
       "164        NaN    0.000000\n",
       "165        NaN    0.000000\n",
       "166        NaN    0.000000\n",
       "172        NaN    0.000000\n",
       "176        NaN    0.000000\n",
       "181        NaN    0.000000\n",
       "182        NaN    0.000000\n",
       "183        NaN    0.000000\n",
       "184        NaN    0.000000\n",
       "189        NaN    0.000000\n",
       "190        NaN    0.000000\n",
       "194        NaN    0.000000\n",
       "0          Age    0.000000\n",
       "\n",
       "[351 rows x 2 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat((pd.DataFrame(X_train.columns, columns = ['variable']), \n",
    "           pd.DataFrame(grid_search.best_estimator_.named_steps[\"randomforestclassifier\"].feature_importances_, columns = ['importance'])), \n",
    "          axis = 1).sort_values(by='importance', ascending = False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X_train_df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pipe = make_pipeline(RandomForestClassifier(max_depth=7, \n",
    "                                            max_features=\"auto\",\n",
    "                                            min_samples_leaf=1, \n",
    "                                            min_samples_split=3, \n",
    "                                            n_estimators=100))\n",
    "pipe.fit(X_train, y_train)\n",
    "print(\"test: \", pipe.score(X_test, y_test))\n",
    "\n",
    "scores = cross_val_score(pipe, X_train_df, y_train_df, n_jobs=3)\n",
    "print(\"mean of cross val score: \", scores.mean())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pd.concat((pd.DataFrame(X_train.columns, columns = ['variable']), \n",
    "           pd.DataFrame(pipe.named_steps[\"randomforestclassifier\"].feature_importances_, columns = ['importance'])), \n",
    "          axis = 1).sort_values(by='importance', ascending = False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### try several scaling and feature selections for random forest"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "param_grid = dict(scaling=[None, MinMaxScaler(), RobustScaler()],\n",
    "                  reduce_dim=[None, PCA(), PCA(5)],\n",
    "                  clf=[RandomForestClassifier(max_depth=7, \n",
    "                                            max_features=\"auto\",\n",
    "                                            min_samples_leaf=1, \n",
    "                                            min_samples_split=3, \n",
    "                                            n_estimators=100)]\n",
    "                 )\n",
    "pipe = Pipeline([('scaling', StandardScaler()), ('reduce_dim', PCA()), ('clf', RandomForestClassifier())]) \n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=3, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))\n",
    "print(\"confusion matrix: \", confusion_matrix(y_test, grid_search.best_estimator_.predict(X_test)))\n",
    "print(\"\")\n",
    "report2(grid_search.cv_results_, n_top=10)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "**try scaling for random forest**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# RobustScaler(), \n",
    "pipe = make_pipeline(RobustScaler(), RandomForestClassifier(max_depth=10, \n",
    "                                            max_features=1,\n",
    "                                            min_samples_leaf=1, \n",
    "                                            min_samples_split=13, \n",
    "                                            n_estimators=300))\n",
    "pipe.fit(X_train, y_train)\n",
    "print(\"test: \", pipe.score(X_test, y_test))\n",
    "\n",
    "scores = cross_val_score(pipe, X_train_df, y_train_df, n_jobs=3)\n",
    "print(\"mean of cross val score: \", scores.mean())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# MinMaxScaler(), \n",
    "pipe = make_pipeline(MinMaxScaler(), RandomForestClassifier(max_depth=10, \n",
    "                                            max_features=1,\n",
    "                                            min_samples_leaf=1, \n",
    "                                            min_samples_split=13, \n",
    "                                            n_estimators=300))\n",
    "pipe.fit(X_train, y_train)\n",
    "print(\"test: \", pipe.score(X_test, y_test))\n",
    "\n",
    "scores = cross_val_score(pipe, X_train_df, y_train_df, n_jobs=3)\n",
    "print(\"mean of cross val score: \", scores.mean())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "**try feature selection**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#pca\n",
    "param_grid = {'pca__n_components':[5, 10, 15, 20, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 40]}\n",
    "\n",
    "pipe = make_pipeline(PCA(n_components=30), RandomForestClassifier(max_depth=10, \n",
    "                                            max_features=1,\n",
    "                                            min_samples_leaf=1, \n",
    "                                            min_samples_split=13, \n",
    "                                            n_estimators=300))\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=6)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pipe = make_pipeline(PCA(n_components=15), RandomForestClassifier(max_depth=10, \n",
    "                                            max_features=1,\n",
    "                                            min_samples_leaf=1, \n",
    "                                            min_samples_split=13, \n",
    "                                            n_estimators=300))\n",
    "pipe.fit(X_train, y_train)\n",
    "print(\"test: \", pipe.score(X_test, y_test))\n",
    "\n",
    "scores = cross_val_score(pipe, X_train_df, y_train_df, n_jobs=3)\n",
    "print(\"mean of cross val score: \", scores.mean())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test:  0.840677966102\n",
    "mean of cross val score:  0.82379349046"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "param_grid = {'max_depth': [0,1,2,3,4,5,6,7],\n",
    "              'min_child_weight':[0.8,0.9, 1],\n",
    "              'gamma':[0, 0.1, 0.2],\n",
    "            'subsample': [0.5, 0.7, 0.95],\n",
    "            'colsample_bytree': [1.0]}\n",
    "    \n",
    "grid_search = GridSearchCV(xgb.XGBClassifier(), param_grid, cv=5, n_jobs=6, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "AdaBoostClassifier(base_estimator=None, n_estimators=50,\n",
    "                   learning_rate=1.0, algorithm='SAMME.R',\n",
    "                   random_state=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4200 candidates, totalling 21000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 380 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=6)]: Done 872 tasks      | elapsed:   25.0s\n",
      "[Parallel(n_jobs=6)]: Done 1372 tasks      | elapsed:   44.3s\n",
      "[Parallel(n_jobs=6)]: Done 1977 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=6)]: Done 2427 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=6)]: Done 2977 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=6)]: Done 4156 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=6)]: Done 5272 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=6)]: Done 6187 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=6)]: Done 7982 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=6)]: Done 9032 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=6)]: Done 11099 tasks      | elapsed:  9.1min\n",
      "[Parallel(n_jobs=6)]: Done 12640 tasks      | elapsed: 10.5min\n",
      "[Parallel(n_jobs=6)]: Done 14614 tasks      | elapsed: 12.1min\n",
      "[Parallel(n_jobs=6)]: Done 16981 tasks      | elapsed: 13.8min\n",
      "[Parallel(n_jobs=6)]: Done 19004 tasks      | elapsed: 15.4min\n",
      "[Parallel(n_jobs=6)]: Done 21000 out of 21000 | elapsed: 17.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'learning_rate': 0.02, 'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 3, 'n_estimators': 100}\n",
      "Mean cross-validated score of the best_estimator:  0.8353293413173652\n",
      "test:  0.8295964125560538\n",
      "confusion matrix:  [[116  18]\n",
      " [ 20  69]]\n",
      "\n",
      "Rank|Score(std)|Params ['learning_rate', 'max_depth', 'max_features', 'min_samples_split', 'n_estimators']\n",
      "1|0.835329(std:0.026122)|[0.02, 5, 'log2', 3, 100]\n",
      "1|0.835329(std:0.036101)|[0.05, 4, None, 6, 500]\n",
      "1|0.835329(std:0.027902)|[0.2, 4, 'log2', 4, 50]\n",
      "4|0.833832(std:0.018328)|[0.007, 5, 'log2', 5, 300]\n",
      "4|0.833832(std:0.024373)|[0.02, 4, 'log2', 4, 300]\n",
      "4|0.833832(std:0.027356)|[0.1, 5, 'log2', 5, 50]\n",
      "4|0.833832(std:0.023661)|[0.2, 4, 'log2', 6, 50]\n",
      "8|0.832335(std:0.020066)|[0.005, 6, 'log2', 4, 400]\n",
      "8|0.832335(std:0.020148)|[0.005, 6, 'log2', 5, 400]\n",
      "8|0.832335(std:0.025241)|[0.007, 4, 'log2', 3, 300]\n",
      "8|0.832335(std:0.022340)|[0.01, 4, 'log2', 5, 300]\n",
      "8|0.832335(std:0.021409)|[0.01, 5, 'log2', 5, 200]\n",
      "8|0.832335(std:0.020148)|[0.01, 5, 'log2', 6, 300]\n",
      "8|0.832335(std:0.024180)|[0.01, 6, 'log2', 6, 200]\n",
      "8|0.832335(std:0.026622)|[0.02, 5, 'log2', 4, 300]\n",
      "8|0.832335(std:0.023644)|[0.02, 6, 'log2', 4, 100]\n",
      "8|0.832335(std:0.015812)|[0.05, 4, 'log2', 2, 200]\n",
      "8|0.832335(std:0.020148)|[0.05, 5, 'log2', 6, 50]\n",
      "8|0.832335(std:0.035364)|[0.1, 3, None, 6, 500]\n",
      "8|0.832335(std:0.027883)|[0.1, 3, 'log2', 2, 200]\n",
      "8|0.832335(std:0.033048)|[0.1, 4, None, 6, 200]\n",
      "8|0.832335(std:0.026984)|[0.1, 5, 'log2', 4, 50]\n",
      "8|0.832335(std:0.030021)|[0.2, 3, 'sqrt', 4, 50]\n",
      "8|0.832335(std:0.037144)|[0.2, 4, None, 4, 100]\n",
      "8|0.832335(std:0.029084)|[0.2, 4, None, 5, 100]\n",
      "8|0.832335(std:0.037843)|[0.2, 5, 'log2', 3, 7]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# too wide\n",
    "param_grid = {'learning_rate': [0.001, 0.005, 0.007, 0.01, 0.02, 0.05, 0.1, 0.2],\n",
    "              'max_depth':[1,2,3,4,5,6,7,8],\n",
    "              'max_features': [None, 'sqrt', 'log2'],\n",
    "              'min_samples_leaf': [1, 2, 3, 4, 5, 6],\n",
    "              'min_samples_split':[2, 3, 4, 5, 6],\n",
    "              'n_estimators': [3, 5, 7, 10, 50, 100, 200, 300, 400, 500],\n",
    "              }\n",
    "\"\"\"\n",
    "\n",
    "# narrow in specific region\n",
    "param_grid = {'learning_rate': [0.005, 0.007, 0.01, 0.02, 0.05, 0.1, 0.2],\n",
    "              'max_depth':[3,4,5,6,7],\n",
    "              'max_features': [None, 'sqrt', 'log2'],\n",
    "#              'min_samples_leaf': [1, 2, 3, 4, 5],\n",
    "              'min_samples_split':[2, 3, 4, 5, 6],\n",
    "              'n_estimators': [7, 10, 50, 100, 200, 300, 400, 500],\n",
    "              }\n",
    "\n",
    "grid_search = GridSearchCV(GradientBoostingClassifier(), param_grid, cv=5, n_jobs=6, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))\n",
    "print(\"confusion matrix: \", confusion_matrix(y_test, grid_search.best_estimator_.predict(X_test)))\n",
    "print(\"\")\n",
    "report2(grid_search.cv_results_, n_top=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Title_Mr</td>\n",
       "      <td>0.183304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Sex</td>\n",
       "      <td>0.170797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Pclass</td>\n",
       "      <td>0.096607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>FamilySize</td>\n",
       "      <td>0.091544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Age*Class</td>\n",
       "      <td>0.070010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Title_Mrs</td>\n",
       "      <td>0.066313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Fare</td>\n",
       "      <td>0.055242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cabin_Letter_0</td>\n",
       "      <td>0.046298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Title_Miss</td>\n",
       "      <td>0.043423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.034689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Embarked_C</td>\n",
       "      <td>0.018909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cabin_Letter_E</td>\n",
       "      <td>0.018280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Embarked_S</td>\n",
       "      <td>0.018003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Title_Master</td>\n",
       "      <td>0.016693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Age_Null_Flag</td>\n",
       "      <td>0.010997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Embarked_Q</td>\n",
       "      <td>0.009779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cabin_Letter_D</td>\n",
       "      <td>0.009657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Title_Rev</td>\n",
       "      <td>0.008918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cabin_Letter_B</td>\n",
       "      <td>0.008124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cabin_Letter_C</td>\n",
       "      <td>0.006251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cabin_Letter_A</td>\n",
       "      <td>0.005722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cabin_Letter_F</td>\n",
       "      <td>0.004265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cabin_Letter_G</td>\n",
       "      <td>0.003963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Title_Dr</td>\n",
       "      <td>0.001474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Cabin_Letter_T</td>\n",
       "      <td>0.000738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          variable  importance\n",
       "19        Title_Mr    0.183304\n",
       "15             Sex    0.170797\n",
       "14          Pclass    0.096607\n",
       "12      FamilySize    0.091544\n",
       "1        Age*Class    0.070010\n",
       "20       Title_Mrs    0.066313\n",
       "13            Fare    0.055242\n",
       "3   Cabin_Letter_0    0.046298\n",
       "18      Title_Miss    0.043423\n",
       "0              Age    0.034689\n",
       "22      Embarked_C    0.018909\n",
       "8   Cabin_Letter_E    0.018280\n",
       "24      Embarked_S    0.018003\n",
       "17    Title_Master    0.016693\n",
       "2    Age_Null_Flag    0.010997\n",
       "23      Embarked_Q    0.009779\n",
       "7   Cabin_Letter_D    0.009657\n",
       "21       Title_Rev    0.008918\n",
       "5   Cabin_Letter_B    0.008124\n",
       "6   Cabin_Letter_C    0.006251\n",
       "4   Cabin_Letter_A    0.005722\n",
       "9   Cabin_Letter_F    0.004265\n",
       "10  Cabin_Letter_G    0.003963\n",
       "16        Title_Dr    0.001474\n",
       "11  Cabin_Letter_T    0.000738"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat((pd.DataFrame(X_train.columns, columns = ['variable']), \n",
    "           pd.DataFrame(grid_search.best_estimator_.feature_importances_, columns = ['importance'])), \n",
    "          axis = 1).sort_values(by='importance', ascending = False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# output of upper code\n",
    "\n",
    "Mean cross-validated score of the best_estimator:  0.843959731544\n",
    "best parameters: {'learning_rate': 0.01, 'max_depth': 6, 'max_features': 'sqrt', 'min_samples_leaf': 3, 'min_samples_split': 3, 'n_estimators': 200}\n",
    "test:  0.830508474576\n",
    "\n",
    "\n",
    "# 10 age band, parch, sibsp\n",
    "\n",
    "best parameters: {'learning_rate': 0.02, 'max_depth': 6, 'max_features': 'log2', 'min_samples_leaf': 3, 'min_samples_split': 3, 'n_estimators': 100}\n",
    "Mean cross-validated score of the best_estimator:  0.845637583893\n",
    "test:  0.820338983051\n",
    "\n",
    "\n",
    "\n",
    "# 10 age band, parch&sibsp, embarked num category\n",
    "\n",
    "best parameters: {'learning_rate': 0.02, 'max_depth': 4, 'max_features': 'log2', 'min_samples_leaf': 3, 'min_samples_split': 4, 'n_estimators': 200}\n",
    "Mean cross-validated score of the best_estimator:  0.843959731544\n",
    "test:  0.833898305085\n",
    "\n",
    "\n",
    "# 10 age band, parch&sibsp, embarked num category, rare title&map value\n",
    "\n",
    "best parameters: {'learning_rate': 0.05, 'max_depth': 4, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
    "Mean cross-validated score of the best_estimator:  0.842281879195\n",
    "test:  0.827118644068\n",
    "\n",
    "\n",
    "# 10 age band, familysize, embarked num category, rare title&map value\n",
    "\n",
    "best parameters: {'learning_rate': 0.05, 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 100}\n",
    "Mean cross-validated score of the best_estimator:  0.838926174497\n",
    "test:  0.84406779661\n",
    "\n",
    "\n",
    "\n",
    "# 10 age band, familysize, embarked num category, rare title&map value, no Name_Len\n",
    "\n",
    "best parameters: {'learning_rate': 0.007, 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
    "Mean cross-validated score of the best_estimator:  0.845637583893\n",
    "test:  0.833898305085\n",
    "\n",
    "\n",
    "# 10 age band, familysize, embarked num category, rare title&map value, no Name_Len, no Ticket_Len\n",
    "\n",
    "best parameters: {'learning_rate': 0.01, 'max_depth': 4, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}\n",
    "Mean cross-validated score of the best_estimator:  0.845637583893\n",
    "test:  0.837288135593\n",
    "\n",
    "\n",
    "## 10 age band, familysize, embarked num category, rare title&map value, no Name_Len, no Ticket_Len, one Cabin_Letter feature\n",
    "\n",
    "best parameters: {'learning_rate': 0.1, 'max_depth': 4, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 50}\n",
    "Mean cross-validated score of the best_estimator:  0.8489932885906041\n",
    "test:  0.8305084745762712\n",
    "\n",
    "\n",
    "## 10 age band, familysize, embarked num category, rare title&map value, no Name_Len, no Ticket_Len, one Cabin_Letter feature, del Cabin_Num features\n",
    "\n",
    "best parameters: {'learning_rate': 0.1, 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 50}\n",
    "Mean cross-validated score of the best_estimator:  0.8422818791946308\n",
    "test:  0.8305084745762712\n",
    "\n",
    "Rank|Score(std)|Params ['learning_rate', 'max_depth', 'max_features', 'min_samples_leaf', 'min_samples_split', 'n_estimators']\n",
    "1|0.842282(std:0.039318)|[0.1, 3, 'log2', 5, 2, 50]\n",
    "2|0.838926(std:0.037329)|[0.007, 4, 'log2', 5, 2, 400]\n",
    "2|0.838926(std:0.041292)|[0.02, 3, 'sqrt', 4, 6, 400]\n",
    "2|0.838926(std:0.038219)|[0.1, 3, 'sqrt', 4, 5, 50]\n",
    "2|0.838926(std:0.033613)|[0.1, 3, 'log2', 1, 5, 50]\n",
    "2|0.838926(std:0.041584)|[0.1, 3, 'log2', 4, 4, 50]\n",
    "2|0.838926(std:0.028890)|[0.1, 4, 'sqrt', 5, 4, 50]\n",
    "8|0.837248(std:0.040103)|[0.02, 3, 'sqrt', 5, 4, 300]\n",
    "8|0.837248(std:0.036323)|[0.02, 4, 'sqrt', 4, 4, 200]\n",
    "8|0.837248(std:0.028291)|[0.05, 3, None, 1, 2, 200]\n",
    "8|0.837248(std:0.028291)|[0.05, 3, None, 1, 4, 200]\n",
    "8|0.837248(std:0.033345)|[0.05, 5, 'log2', 5, 5, 50]\n",
    "8|0.837248(std:0.037624)|[0.1, 3, 'log2', 1, 4, 100]\n",
    "8|0.837248(std:0.025055)|[0.1, 3, 'log2', 1, 6, 200]\n",
    "8|0.837248(std:0.041710)|[0.1, 4, 'sqrt', 1, 3, 50]\n",
    "8|0.837248(std:0.030870)|[0.1, 4, 'log2', 5, 3, 50]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## GradientBoostingClassifier: 10 age band, familysize, embarked num category, rare title&map value, no Name_Len, no Ticket_Len, one Cabin_Letter feature, del Cabin_Num features, activate Age*Class again\n",
    "\n",
    "best parameters: {'learning_rate': 0.2, 'max_depth': 4, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 3, 'n_estimators': 10}\n",
    "Mean cross-validated score of the best_estimator:  0.8406040268456376\n",
    "test:  0.8406779661016949\n",
    "\n",
    "Rank|Score(std)|Params ['learning_rate', 'max_depth', 'max_features', 'min_samples_leaf', 'min_samples_split', 'n_estimators']\n",
    "1|0.840604(std:0.039600)|[0.2, 4, 'sqrt', 2, 3, 10]\n",
    "2|0.838926(std:0.044443)|[0.01, 3, 'log2', 4, 2, 400]\n",
    "2|0.838926(std:0.044709)|[0.02, 3, 'sqrt', 4, 4, 200]\n",
    "2|0.838926(std:0.044443)|[0.02, 3, 'sqrt', 4, 5, 200]\n",
    "2|0.838926(std:0.041648)|[0.02, 4, 'log2', 5, 4, 100]\n",
    "2|0.838926(std:0.043104)|[0.05, 3, 'sqrt', 4, 3, 100]\n",
    "2|0.838926(std:0.044903)|[0.1, 3, 'log2', 1, 2, 50]\n",
    "2|0.838926(std:0.025955)|[0.2, 6, 'sqrt', 4, 3, 7]\n",
    "9|0.837248(std:0.044516)|[0.01, 3, 'log2', 4, 4, 400]\n",
    "9|0.837248(std:0.043828)|[0.02, 3, 'sqrt', 4, 6, 300]\n",
    "9|0.837248(std:0.044516)|[0.02, 3, 'log2', 4, 6, 200]\n",
    "9|0.837248(std:0.043383)|[0.02, 4, 'sqrt', 1, 5, 200]\n",
    "9|0.837248(std:0.046819)|[0.05, 3, 'sqrt', 4, 4, 100]\n",
    "9|0.837248(std:0.031411)|[0.05, 3, 'sqrt', 5, 6, 100]\n",
    "9|0.837248(std:0.044677)|[0.05, 3, 'log2', 2, 5, 100]\n",
    "9|0.837248(std:0.043704)|[0.05, 3, 'log2', 4, 4, 100]\n",
    "9|0.837248(std:0.044711)|[0.05, 3, 'log2', 4, 6, 100]\n",
    "9|0.837248(std:0.032774)|[0.05, 5, 'log2', 4, 5, 50]\n",
    "9|0.837248(std:0.041284)|[0.1, 3, 'log2', 5, 2, 50]\n",
    "9|0.837248(std:0.040684)|[0.2, 4, 'sqrt', 5, 4, 7]\n",
    "\n",
    "\n",
    "### change ration of train/test split from 0.33 to 0.25\n",
    "\n",
    "best parameters: {'learning_rate': 0.2, 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 200}\n",
    "Mean cross-validated score of the best_estimator:  0.8473053892215568\n",
    "test:  0.8116591928251121\n",
    "confusion matrix:  [[114  20]\n",
    " [ 22  67]]\n",
    "\n",
    "Rank|Score(std)|Params ['learning_rate', 'max_depth', 'max_features', 'min_samples_leaf', 'min_samples_split', 'n_estimators']\n",
    "1|0.847305(std:0.032881)|[0.2, 5, 'log2', 5, 3, 200]\n",
    "2|0.845808(std:0.043098)|[0.05, 5, 'log2', 4, 6, 300]\n",
    "2|0.845808(std:0.041714)|[0.2, 6, 'sqrt', 4, 4, 50]\n",
    "4|0.844311(std:0.038319)|[0.1, 4, 'log2', 1, 5, 200]\n",
    "4|0.844311(std:0.036937)|[0.1, 4, 'log2', 5, 5, 400]\n",
    "4|0.844311(std:0.039819)|[0.2, 3, 'sqrt', 5, 5, 400]\n",
    "4|0.844311(std:0.028865)|[0.2, 4, 'sqrt', 3, 6, 300]\n",
    "4|0.844311(std:0.032183)|[0.2, 4, 'sqrt', 4, 3, 300]\n",
    "4|0.844311(std:0.027152)|[0.2, 4, 'sqrt', 4, 6, 200]\n",
    "4|0.844311(std:0.033087)|[0.2, 4, 'log2', 4, 3, 400]\n",
    "4|0.844311(std:0.032808)|[0.2, 4, 'log2', 5, 2, 400]\n",
    "4|0.844311(std:0.031058)|[0.2, 4, 'log2', 5, 3, 300]\n",
    "4|0.844311(std:0.040603)|[0.2, 5, 'sqrt', 5, 4, 400]\n",
    "4|0.844311(std:0.033699)|[0.2, 5, 'log2', 2, 4, 50]\n",
    "4|0.844311(std:0.038369)|[0.2, 6, 'sqrt', 2, 6, 200]\n",
    "4|0.844311(std:0.040308)|[0.2, 7, 'log2', 4, 3, 300]\n",
    "\n",
    "\n",
    "\n",
    "# 1 GradientBoostingClassifier\n",
    "\n",
    "- 10 age band\n",
    "- familysize\n",
    "- embarked num category\n",
    "- rare title&map value\n",
    "- no Name_Len\n",
    "- no Ticket_Len\n",
    "- one Cabin_Letter feature\n",
    "- del Cabin_Num features\n",
    "- activate Age*Class again\n",
    "- try another title mapping. from 5 category(inc. rare) to 6 category(complete map rare to other title)\n",
    "\n",
    "mapping = {'Mlle': 'Miss', \n",
    "            'Major': 'Mr', \n",
    "            'Col': 'Mr', \n",
    "            'Sir': 'Mr',\n",
    "            'Don': 'Mr', \n",
    "            'Mme': 'Miss',\n",
    "            'Jonkheer': 'Mr',\n",
    "            'Lady': 'Mrs', \n",
    "            'Capt': 'Mr', \n",
    "            'Countess': 'Mrs',\n",
    "            'Ms': 'Miss',\n",
    "            'Dona': 'Mrs'}\n",
    "titles = ['Dr', 'Master', 'Miss', 'Mr', 'Mrs', 'Rev']\n",
    "\n",
    "\n",
    "\n",
    "best parameters: {'learning_rate': 0.2, 'max_depth': 4, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 300}\n",
    "Mean cross-validated score of the best_estimator:  0.8473053892215568\n",
    "test:  0.8026905829596412\n",
    "confusion matrix:  [[113  21]\n",
    " [ 23  66]]\n",
    "\n",
    "Rank|Score(std)|Params ['learning_rate', 'max_depth', 'max_features', 'min_samples_leaf', 'min_samples_split', 'n_estimators']\n",
    "1|0.847305(std:0.023510)|[0.2, 4, 'log2', 4, 5, 300]\n",
    "2|0.844311(std:0.035000)|[0.2, 5, 'log2', 5, 3, 400]\n",
    "2|0.844311(std:0.024509)|[0.2, 6, 'sqrt', 4, 2, 50]\n",
    "4|0.842814(std:0.027134)|[0.1, 5, 'log2', 4, 3, 400]\n",
    "4|0.842814(std:0.028805)|[0.2, 4, 'log2', 5, 4, 400]\n",
    "4|0.842814(std:0.035875)|[0.2, 6, 'log2', 5, 6, 300]\n",
    "4|0.842814(std:0.029787)|[0.2, 7, 'sqrt', 3, 2, 300]\n",
    "8|0.841317(std:0.034481)|[0.01, 4, 'sqrt', 3, 5, 200]\n",
    "8|0.841317(std:0.042157)|[0.1, 4, 'sqrt', 1, 4, 200]\n",
    "8|0.841317(std:0.039613)|[0.1, 4, 'log2', 5, 6, 400]\n",
    "8|0.841317(std:0.042075)|[0.1, 5, 'sqrt', 1, 4, 100]\n",
    "8|0.841317(std:0.029249)|[0.1, 5, 'log2', 4, 5, 400]\n",
    "8|0.841317(std:0.030651)|[0.1, 5, 'log2', 4, 6, 400]\n",
    "8|0.841317(std:0.035506)|[0.1, 6, 'sqrt', 1, 2, 100]\n",
    "8|0.841317(std:0.040615)|[0.1, 6, 'log2', 1, 6, 100]\n",
    "8|0.841317(std:0.026786)|[0.1, 7, 'log2', 5, 5, 300]\n",
    "8|0.841317(std:0.039613)|[0.2, 3, 'sqrt', 4, 4, 400]\n",
    "8|0.841317(std:0.039354)|[0.2, 3, 'log2', 2, 2, 400]\n",
    "8|0.841317(std:0.035071)|[0.2, 3, 'log2', 5, 2, 400]\n",
    "8|0.841317(std:0.026313)|[0.2, 4, 'sqrt', 4, 4, 200]\n",
    "8|0.841317(std:0.027297)|[0.2, 4, 'sqrt', 4, 4, 300]\n",
    "8|0.841317(std:0.028622)|[0.2, 4, 'sqrt', 4, 5, 400]\n",
    "8|0.841317(std:0.031055)|[0.2, 4, 'log2', 2, 5, 300]\n",
    "8|0.841317(std:0.028887)|[0.2, 4, 'log2', 5, 6, 400]\n",
    "8|0.841317(std:0.031810)|[0.2, 6, 'sqrt', 2, 2, 400]\n",
    "8|0.841317(std:0.028887)|[0.2, 6, 'sqrt', 5, 2, 400]\n",
    "8|0.841317(std:0.034788)|[0.2, 6, 'log2', 1, 2, 100]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 3 GradientBoostingClassifier\n",
    "\n",
    "\n",
    "- age\n",
    "  - [ ] 5 age band\n",
    "  - [x] 10 age band\n",
    "- family\n",
    "  - [x] familysize\n",
    "  - [ ] parch,sib\n",
    "  - [ ] isalone\n",
    "- embarked\n",
    "  - [ ] integer encoding\n",
    "  - [x] one hot encoding\n",
    "- Title\n",
    "  - [ ] keep rare title and integer encoding\n",
    "  - [ ] change rare title to \"Rare\" and integer encoding\n",
    "  - [ ] change rare title to \"Rare\" and one hot encoding\n",
    "  - [x] change some rare title to usual title, other rare title to \"Rare\" and one hot encoding\n",
    "- [ ] Name_Len\n",
    "- [ ] Ticket_Len\n",
    "- Cabin_Letter\n",
    "  - [x] integer encoding\n",
    "  - [ ] one hot encoding\n",
    "- Cabin_Num\n",
    "  - [x] no\n",
    "  - [ ] integer encoding\n",
    "  - [ ] one hot encoding\n",
    "- [x] Age*Class\n",
    "\n",
    "\n",
    "best parameters: {'learning_rate': 0.05, 'max_depth': 4, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 50}\n",
    "Mean cross-validated score of the best_estimator:  0.8413173652694611\n",
    "test:  0.8295964125560538\n",
    "confusion matrix:  [[121  13]\n",
    " [ 25  64]]\n",
    "\n",
    "Rank|Score(std)|Params ['learning_rate', 'max_depth', 'max_features', 'min_samples_split', 'n_estimators']\n",
    "1|0.841317(std:0.032879)|[0.05, 4, 'log2', 2, 50]\n",
    "1|0.841317(std:0.031308)|[0.1, 4, 'sqrt', 4, 300]\n",
    "1|0.841317(std:0.028452)|[0.2, 3, 'sqrt', 2, 500]\n",
    "1|0.841317(std:0.037397)|[0.2, 4, 'sqrt', 4, 100]\n",
    "5|0.839820(std:0.036424)|[0.02, 4, 'sqrt', 6, 100]\n",
    "5|0.839820(std:0.028735)|[0.05, 4, 'log2', 4, 100]\n",
    "5|0.839820(std:0.028186)|[0.1, 5, 'sqrt', 5, 10]\n",
    "8|0.838323(std:0.032153)|[0.005, 4, 'sqrt', 2, 400]\n",
    "8|0.838323(std:0.036036)|[0.02, 6, 'sqrt', 6, 400]\n",
    "8|0.838323(std:0.028844)|[0.1, 4, 'log2', 4, 200]\n",
    "8|0.838323(std:0.030687)|[0.1, 4, 'log2', 5, 10]\n",
    "8|0.838323(std:0.038513)|[0.1, 4, 'log2', 6, 200]\n",
    "8|0.838323(std:0.032141)|[0.2, 3, 'sqrt', 2, 400]\n",
    "8|0.838323(std:0.029254)|[0.2, 4, 'log2', 3, 200]\n",
    "8|0.838323(std:0.036152)|[0.2, 4, 'log2', 3, 300]\n",
    "\n",
    "\n",
    "\n",
    "## 4 GradientBoostingClassifier\n",
    "\n",
    "\n",
    "- age\n",
    "  - [ ] 5 age band\n",
    "  - [x] 10 age band\n",
    "- family\n",
    "  - [x] familysize\n",
    "  - [ ] parch,sib\n",
    "  - [ ] isalone\n",
    "- embarked\n",
    "  - [ ] integer encoding\n",
    "  - [x] one hot encoding\n",
    "- Title\n",
    "  - [ ] keep rare title and integer encoding\n",
    "  - [ ] change rare title to \"Rare\" and integer encoding\n",
    "  - [ ] change rare title to \"Rare\" and one hot encoding\n",
    "  - [x] change some rare title to usual title, other rare title to \"Rare\" and one hot encoding\n",
    "- [ ] Name_Len\n",
    "- [ ] Ticket_Len\n",
    "- Cabin_Letter\n",
    "  - [ ] integer encoding\n",
    "  - [x] one hot encoding\n",
    "- Cabin_Num\n",
    "  - [x] no\n",
    "  - [ ] integer encoding\n",
    "  - [ ] one hot encoding\n",
    "- [x] Age*Class\n",
    "\n",
    "\n",
    "\n",
    "best parameters: {'learning_rate': 0.2, 'max_depth': 4, 'max_features': 'log2', 'min_samples_split': 6, 'n_estimators': 7}\n",
    "Mean cross-validated score of the best_estimator:  0.8413173652694611\n",
    "test:  0.820627802690583\n",
    "confusion matrix:  [[120  14]\n",
    " [ 26  63]]\n",
    "\n",
    "Rank|Score(std)|Params ['learning_rate', 'max_depth', 'max_features', 'min_samples_split', 'n_estimators']\n",
    "1|0.841317(std:0.020392)|[0.2, 4, 'log2', 6, 7]\n",
    "2|0.838323(std:0.029889)|[0.005, 6, 'log2', 5, 500]\n",
    "2|0.838323(std:0.023627)|[0.05, 5, 'log2', 6, 50]\n",
    "2|0.838323(std:0.029022)|[0.05, 5, 'log2', 6, 100]\n",
    "2|0.838323(std:0.026800)|[0.1, 4, 'sqrt', 6, 10]\n",
    "2|0.838323(std:0.025506)|[0.2, 4, 'log2', 6, 10]\n",
    "2|0.838323(std:0.017545)|[0.2, 5, 'log2', 6, 10]\n",
    "8|0.836826(std:0.025457)|[0.005, 6, 'log2', 6, 500]\n",
    "8|0.836826(std:0.023403)|[0.1, 4, 'sqrt', 4, 500]\n",
    "8|0.836826(std:0.041012)|[0.2, 3, 'sqrt', 3, 400]\n",
    "8|0.836826(std:0.031987)|[0.2, 3, 'log2', 6, 300]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**for submit, make model by best par and fit to all train data**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pipe = make_pipeline(GradientBoostingClassifier(learning_rate=0.2,\n",
    "                                                max_depth=4,\n",
    "                                                max_features=\"sqrt\",\n",
    "                                                min_samples_leaf=2,\n",
    "                                                min_samples_split=3,\n",
    "                                                n_estimators=10))\n",
    "pipe.fit(X_train, y_train)\n",
    "print(\"test: \", pipe.score(X_test, y_test))\n",
    "print(\"confusion matrix: \", confusion_matrix(y_test, pipe.predict(X_test)))\n",
    "\n",
    "scores = cross_val_score(pipe, X_train_df, y_train_df, n_jobs=3)\n",
    "print(\"mean of cross val score for X_train_df: \", scores.mean())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pipe.fit(X_train_df, y_train_df)\n",
    "\n",
    "test_df_noid = test_df.drop(\"PassengerId\", axis=1).copy()\n",
    "y_pred = pipe.predict(test_df_noid).astype(int)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": test_df[\"PassengerId\"].astype(int),\n",
    "        \"Survived\": y_pred\n",
    "    })\n",
    "submission.to_csv('../output/submission_gradientboosting.csv', index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pd.concat((pd.DataFrame(X_train.columns, columns = ['variable']), \n",
    "           pd.DataFrame(pipe.named_steps[\"gradientboostingclassifier\"].feature_importances_, columns = ['importance'])), \n",
    "          axis = 1).sort_values(by='importance', ascending = False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### try scaling and feature selection"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "param_grid = dict(scaling=[None, MinMaxScaler(), RobustScaler()],\n",
    "                  reduce_dim=[None, PCA(), PCA(5), PCA(10), PCA(15), PCA(20), PCA(25), PCA(30)],\n",
    "                  clf=[GradientBoostingClassifier(learning_rate=0.01,\n",
    "                                                max_depth=6,\n",
    "                                                max_features=\"sqrt\",\n",
    "                                                min_samples_leaf=3,\n",
    "                                                min_samples_split=3,\n",
    "                                                n_estimators=200)]\n",
    "                 )\n",
    "pipe = Pipeline([('scaling', StandardScaler()), ('reduce_dim', PCA()), ('clf', RandomForestClassifier())]) \n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=3, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "**try scaling for Gradient boosting**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# RobustScaler\n",
    "pipe = make_pipeline(RobustScaler(), GradientBoostingClassifier(learning_rate=0.01,\n",
    "                                                max_depth=6,\n",
    "                                                max_features=\"sqrt\",\n",
    "                                                min_samples_leaf=3,\n",
    "                                                min_samples_split=3,\n",
    "                                                n_estimators=200))\n",
    "pipe.fit(X_train, y_train)\n",
    "print(\"test: \", pipe.score(X_test, y_test))\n",
    "\n",
    "scores = cross_val_score(pipe, X_train_df, y_train_df, n_jobs=3)\n",
    "print(\"mean of cross val score for X_train_df: \", scores.mean())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pd.concat((pd.DataFrame(X_train.columns, columns = ['variable']), \n",
    "           pd.DataFrame(pipe.named_steps[\"gradientboostingclassifier\"].feature_importances_, columns = ['importance'])), \n",
    "          axis = 1).sort_values(by='importance', ascending = False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# MinMaxScaler\n",
    "pipe = make_pipeline(MinMaxScaler(), GradientBoostingClassifier(learning_rate=0.01,\n",
    "                                                max_depth=6,\n",
    "                                                max_features=\"sqrt\",\n",
    "                                                min_samples_leaf=3,\n",
    "                                                min_samples_split=3,\n",
    "                                                n_estimators=200))\n",
    "pipe.fit(X_train, y_train)\n",
    "print(\"test: \", pipe.score(X_test, y_test))\n",
    "\n",
    "scores = cross_val_score(pipe, X_train_df, y_train_df, n_jobs=3)\n",
    "print(\"mean of cross val score for X_train_df: \", scores.mean())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pd.concat((pd.DataFrame(X_train.columns, columns = ['variable']), \n",
    "           pd.DataFrame(pipe.named_steps[\"gradientboostingclassifier\"].feature_importances_, columns = ['importance'])), \n",
    "          axis = 1).sort_values(by='importance', ascending = False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "**try feature selection**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#PCA\n",
    "param_grid = {'pca__n_components':[5, 10, 15, 20, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 40]}\n",
    "\n",
    "pipe = make_pipeline(PCA(n_components=30), GradientBoostingClassifier(learning_rate=0.01,\n",
    "                                                max_depth=6,\n",
    "                                                max_features=\"sqrt\",\n",
    "                                                min_samples_leaf=3,\n",
    "                                                min_samples_split=3,\n",
    "                                                n_estimators=200))\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv=5, n_jobs=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pipe = make_pipeline(PCA(n_components=20), GradientBoostingClassifier(learning_rate=0.01,\n",
    "                                                max_depth=6,\n",
    "                                                max_features=\"sqrt\",\n",
    "                                                min_samples_leaf=3,\n",
    "                                                min_samples_split=3,\n",
    "                                                n_estimators=200))\n",
    "pipe.fit(X_train, y_train)\n",
    "print(\"test: \", pipe.score(X_test, y_test))\n",
    "\n",
    "scores = cross_val_score(pipe, X_train_df, y_train_df, n_jobs=3)\n",
    "print(\"mean of cross val score for X_train_df: \", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "param_grid = [\n",
    "{'classifier': [SVC()], \n",
    " 'preprocessing': [StandardScaler(), None], \n",
    " 'classifier__gamma': [0.001, 0.01, 0.1, 1, 10, 100], \n",
    " 'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100]},\n",
    "{'classifier': [RandomForestClassifier(n_estimators=100)], \n",
    " 'preprocessing': [None], \n",
    " 'classifier__max_features': [1, 2, 3]}]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Individual steps may also be replaced as parameters, and non-final steps may be ignored by setting them to None:\n",
    "# http://scikit-learn.org/stable/modules/pipeline.html\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "param_grid = dict(reduce_dim=[None, PCA(5), PCA(10)],\n",
    "                   clf=[SVC(), LogisticRegression()],\n",
    "                   clf__C=[0.1, 10, 100])\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
