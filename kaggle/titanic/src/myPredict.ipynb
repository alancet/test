{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# data analysis and wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# train, test, validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "# decomposition\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "# feature engineering\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# feature selection\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../input/train.csv')\n",
    "test_df = pd.read_csv('../input/test.csv')\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# modify features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make ticket length feature\n",
    "https://www.kaggle.com/yuanxuan/titanic-random-forest-82-78/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Ticket_Len'] = train_df['Ticket'].apply(lambda x: len(x))\n",
    "test_df['Ticket_Len'] = test_df['Ticket'].apply(lambda x: len(x))\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df['Ticket_Len'].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_df['Ticket_Len'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make Cabin First character feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Cabin_Letter\"] = train_df[\"Cabin\"].fillna('0').apply(lambda x: x[0])\n",
    "test_df[\"Cabin_Letter\"] = test_df[\"Cabin\"].fillna('0').apply(lambda x: x[0])\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df[\"Cabin_Letter\"].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.barplot(data=train_df, x=\"Cabin_Letter\", y=\"Survived\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_df[\"Cabin_Letter\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make dummy variable for Cabin_Letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1309, 14)\n",
      "(891, 22) (418, 21)\n"
     ]
    }
   ],
   "source": [
    "train_test_df = pd.concat((train_df, test_df))\n",
    "\n",
    "print(train_test_df.shape)\n",
    "\n",
    "# apply get_dummies for Cabin_Letter\n",
    "train_test_df = pd.get_dummies(train_test_df, columns=[\"Cabin_Letter\"])\n",
    "\n",
    "#train_test_df.head()\n",
    "train_df = train_test_df.iloc[:train_df.shape[0]]\n",
    "test_df = train_test_df.iloc[train_df.shape[0]:]\n",
    "\n",
    "# drop added Survived column from test_df\n",
    "test_df = test_df.drop(\"Survived\", axis=1)\n",
    "print(train_df.shape, test_df.shape)\n",
    "\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make CabinBool feature\n",
    "**I think the idea here is that people with recorded cabin numbers are of higher socioeconomic class, and thus more likely to survive. **\n",
    "https://www.kaggle.com/nadintamer/titanic-survival-predictions-beginner\n",
    "\n",
    "- I tried it\n",
    "  - but gradient boosting result became worse. from 0.79904 to 0.77990\n",
    "  - more than cabinbool is necessary? should i use first letter of cabin name?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df[\"CabinBool\"] = (train_df[\"Cabin\"].notnull().astype('int'))\n",
    "test_df[\"CabinBool\"] = (test_df[\"Cabin\"].notnull().astype('int'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make Cabin number feature\n",
    "https://www.kaggle.com/yuanxuan/titanic-random-forest-82-78/notebook"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df['Cabin'].apply(lambda x: str(x).split(' ')[-1][1:]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/yuki/.local/lib/python3.6/site-packages/pandas/core/generic.py:4619: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "for i in [train_df, test_df]:\n",
    "    i['Cabin_num1'] = i['Cabin'].apply(lambda x: str(x).split(' ')[-1][1:])\n",
    "    i['Cabin_num1'].replace('an', np.NaN, inplace = True)\n",
    "    i['Cabin_num1'] = i['Cabin_num1'].apply(lambda x: int(x) if not pd.isnull(x) and x != '' else np.NaN)\n",
    "    i['Cabin_num'] = pd.qcut(train_df['Cabin_num1'], 3)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat((train_df, pd.get_dummies(train_df['Cabin_num'], prefix = 'Cabin_num')), axis = 1)\n",
    "test_df = pd.concat((test_df, pd.get_dummies(test_df['Cabin_num'], prefix = 'Cabin_num')), axis = 1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_df['Cabin_num']\n",
    "del test_df['Cabin_num']\n",
    "del train_df['Cabin_num1']\n",
    "del test_df['Cabin_num1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Cabin', 'Embarked', 'Fare', 'Name', 'Parch', 'PassengerId',\n",
       "       'Pclass', 'Sex', 'SibSp', 'Survived', 'Ticket', 'Ticket_Len',\n",
       "       'Cabin_Letter_0', 'Cabin_Letter_A', 'Cabin_Letter_B', 'Cabin_Letter_C',\n",
       "       'Cabin_Letter_D', 'Cabin_Letter_E', 'Cabin_Letter_F', 'Cabin_Letter_G',\n",
       "       'Cabin_Letter_T', 'Cabin_num_(1.999, 28.667]',\n",
       "       'Cabin_num_(28.667, 65.667]', 'Cabin_num_(65.667, 148.0]'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df[['Cabin_num_(1.999, 28.667]', \n",
    "          'Cabin_num_(28.667, 65.667]',\n",
    "          'Cabin_num_(65.667, 148.0]']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## del Ticket, Cabin columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del Ticket, Cabin columns\n",
    "train_df = train_df.drop(['Ticket', 'Cabin'], axis=1)\n",
    "test_df = test_df.drop(['Ticket', 'Cabin'], axis=1)\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add title\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.Title.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fill nan of Age by Title and Pclass\n",
    "https://www.kaggle.com/yuanxuan/titanic-random-forest-82-78/notebook\n",
    "\n",
    "There is mistake in the original notebook.\n",
    "test_df was filled by train_df.\n",
    "So I will skip it."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data = train_df.groupby(['Title', 'Pclass'])['Age']\n",
    "train_df['Age'] = data.transform(lambda x: x.fillna(x.mean()))\n",
    "test_df['Age'] = data.transform(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert title to numerical or one hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try one hot encoding without delete rare title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 24) (418, 23)\n",
      "(1309, 24)\n",
      "(891, 41) (418, 40)\n"
     ]
    }
   ],
   "source": [
    "# try one hote encoding without delete rare title\n",
    "#\n",
    "# concat train and test data. and apply get_dummies for Title. \n",
    "# then split to original size. also drop Survived column from test_df\n",
    "print(train_df.shape, test_df.shape)\n",
    "\n",
    "# concat train and test data\n",
    "#   test_df's Survived column is filled with NaN\n",
    "train_test_df = pd.concat((train_df, test_df))\n",
    "\n",
    "print(train_test_df.shape)\n",
    "\n",
    "# apply get_dummies for Title\n",
    "train_test_df = pd.get_dummies(train_test_df, columns=[\"Title\"])\n",
    "\n",
    "#train_test_df.head()\n",
    "train_df = train_test_df.iloc[:train_df.shape[0]]\n",
    "test_df = train_test_df.iloc[train_df.shape[0]:]\n",
    "\n",
    "# drop added Survived column from test_df\n",
    "test_df = test_df.drop(\"Survived\", axis=1)\n",
    "print(train_df.shape, test_df.shape)\n",
    "\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Cabin_Letter_0', 'Cabin_Letter_A', 'Cabin_Letter_B',\n",
       "       'Cabin_Letter_C', 'Cabin_Letter_D', 'Cabin_Letter_E', 'Cabin_Letter_F',\n",
       "       'Cabin_Letter_G', 'Cabin_Letter_T', 'Cabin_num_(1.999, 28.667]',\n",
       "       'Cabin_num_(28.667, 65.667]', 'Cabin_num_(65.667, 148.0]', 'Embarked',\n",
       "       'Fare', 'Name', 'Parch', 'PassengerId', 'Pclass', 'Sex', 'SibSp',\n",
       "       'Survived', 'Ticket_Len', 'Title_Capt', 'Title_Col', 'Title_Countess',\n",
       "       'Title_Don', 'Title_Dona', 'Title_Dr', 'Title_Jonkheer', 'Title_Lady',\n",
       "       'Title_Major', 'Title_Master', 'Title_Miss', 'Title_Mlle', 'Title_Mme',\n",
       "       'Title_Mr', 'Title_Mrs', 'Title_Ms', 'Title_Rev', 'Title_Sir'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### del rare title and map value"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# del rare title and map value\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\n",
    "                                                 'Don', 'Dr', 'Major', 'Rev', 'Sir',\n",
    "                                                 'Jonkheer', 'Dona'], 'Rare')\n",
    "\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "    \n",
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset['Title'].map(title_mapping)\n",
    "    dataset['Title'] = dataset['Title'].fillna(0)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make name length feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "train_df['Name_Len'] = train_df['Name'].apply(lambda x: len(x))\n",
    "test_df['Name_Len'] = test_df['Name'].apply(lambda x: len(x))\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df[\"Name_Len\"].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.groupby(\"Name_Len\").Survived.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## map value to Sex "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for dataset in combine:\n",
    "    dataset[\"Sex\"] = dataset[\"Sex\"].map({'female':1, 'male':0}).astype(int)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make Age_Null_Flag if the Age is nulll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "train_df['Age_Null_Flag'] = train_df['Age'].apply(lambda x: 1 if pd.isnull(x) else 0)\n",
    "test_df['Age_Null_Flag'] = test_df['Age'].apply(lambda x: 1 if pd.isnull(x) else 0)\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df[\"Age_Null_Flag\"].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_df[\"Age_Null_Flag\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fill na value"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.isna().any()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_df.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fill na of Age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### by Sex and Pclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuki/.local/lib/python3.6/site-packages/pandas/core/indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "guess_ages = np.zeros((2,3))\n",
    "\n",
    "for dataset in combine:\n",
    "    for i in range(0, 2):\n",
    "        for j in range(0, 3):\n",
    "            guess_df = dataset[(dataset['Sex'] == i) & \\\n",
    "                                  (dataset['Pclass'] == j+1)]['Age'].dropna()\n",
    "\n",
    "            # age_mean = guess_df.mean()\n",
    "            # age_std = guess_df.std()\n",
    "            # age_guess = rnd.uniform(age_mean - age_std, age_mean + age_std)\n",
    "\n",
    "            age_guess = guess_df.median()\n",
    "\n",
    "            # Convert random age float to nearest .5 age\n",
    "            guess_ages[i,j] = int( age_guess/0.5 + 0.5 ) * 0.5\n",
    "            \n",
    "    for i in range(0, 2):\n",
    "        for j in range(0, 3):\n",
    "            dataset.loc[ (dataset.Age.isnull()) & (dataset.Sex == i) & (dataset.Pclass == j+1),\\\n",
    "                    'Age'] = guess_ages[i,j]\n",
    "\n",
    "    dataset['Age'] = dataset['Age'].astype(int)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tried keep Age feature and don't add AgeBand numerical feature\n",
    "if both are there, it is duplicate information\n",
    "\n",
    "#### 2018/03/17 tried Age instead of Age band. But AgeBand is better score for almost all models.\n",
    "svc score was same of little bit better.\n",
    "random forest score became worse.\n",
    "so AgeBand is better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add age band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "train_df['AgeBand'] = pd.cut(train_df['Age'], 5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overwrite AgeBand number on Age. means, drop Age and AgeBand text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuki/.local/lib/python3.6/site-packages/pandas/core/indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "for dataset in combine:\n",
    "    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n",
    "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
    "    dataset.loc[ dataset['Age'] > 64, 'Age'] = 4\n",
    "train_df = train_df.drop(['AgeBand'], axis=1)\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new feature \"FamilySize\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in combine:\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset['IsAlone'] = 0\n",
    "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset['Age*Class'] = dataset.Age * dataset.Pclass"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### select family related feature\n",
    "Parch, SibSp, FaimilySize, IsAlone\n",
    "\n",
    "2018/03/18 Parch and SibSp only was best for almost all models"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# drop Parch, SibSp, FaimilySize\n",
    "\n",
    "train_df = train_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\n",
    "test_df = test_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\n",
    "combine = [train_df, test_df]\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep Parch, SibSp only. this was best amoung familly related features\n",
    "\n",
    "train_df = train_df.drop(['FamilySize', 'IsAlone'], axis=1)\n",
    "test_df = test_df.drop(['FamilySize', 'IsAlone'], axis=1)\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# keep FamilySize only\n",
    "\n",
    "train_df = train_df.drop(['Parch', 'SibSp', 'IsAlone'], axis=1)\n",
    "test_df = test_df.drop(['Parch', 'SibSp', 'IsAlone'], axis=1)\n",
    "combine = [train_df, test_df]\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fill missing Embarked "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_port = train_df.Embarked.dropna().mode()[0]\n",
    "for dataset in combine:\n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna(freq_port)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Embarked categorical feature to numeric"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for dataset in combine:\n",
    "    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## try one hot encoding for Embarked categorical feature\n",
    "2018/03/18 this is better than using converting categorical to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 44) (418, 43)\n",
      "(1309, 44)\n",
      "(891, 46) (418, 45)\n"
     ]
    }
   ],
   "source": [
    "# try one hote encoding for Embarked\n",
    "#\n",
    "# concat train and test data. and apply get_dummies for Title. \n",
    "# then split to original size. also drop Survived column from test_df\n",
    "print(train_df.shape, test_df.shape)\n",
    "\n",
    "# concat train and test data\n",
    "#   test_df's Survived column is filled with NaN\n",
    "train_test_df = pd.concat((train_df, test_df))\n",
    "\n",
    "print(train_test_df.shape)\n",
    "\n",
    "# apply get_dummies for Title\n",
    "train_test_df = pd.get_dummies(train_test_df, columns=[\"Embarked\"])\n",
    "\n",
    "#train_test_df.head()\n",
    "train_df = train_test_df.iloc[:train_df.shape[0]]\n",
    "test_df = train_test_df.iloc[train_df.shape[0]:]\n",
    "\n",
    "# drop added Survived column from test_df\n",
    "test_df = test_df.drop(\"Survived\", axis=1)\n",
    "print(train_df.shape, test_df.shape)\n",
    "\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fill na of test data Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Fare'].fillna(test_df['Fare'].dropna().median(), inplace=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make Fareband feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/yuki/.local/lib/python3.6/site-packages/pandas/core/indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train_df['FareBand'] = pd.qcut(train_df['Fare'], 4)\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
    "    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "\n",
    "train_df = train_df.drop(['FareBand'], axis=1)\n",
    "\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try more fare band number\n",
    "\n",
    "- no difference\n",
    "\n",
    "### keep Fare feature and add FareBand numerical feature¶\n",
    "\n",
    "- not good result"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fareband = pd.qcut(train_df['Fare'], 6)\n",
    "fareband.unique()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df['FareBand'] = pd.qcut(train_df['Fare'], 6)\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset.loc[ dataset['Fare'] <= 7.775, 'Fare'] = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.775) & (dataset['Fare'] <= 8.662), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 8.662) & (dataset['Fare'] <= 14.454), 'Fare']   = 2\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 26.0), 'Fare']   = 3\n",
    "    dataset.loc[(dataset['Fare'] > 26.0) & (dataset['Fare'] <= 52.369), 'Fare']   = 4\n",
    "    \n",
    "    dataset.loc[ dataset['Fare'] > 52.369, 'Fare'] = 5\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "\n",
    "train_df = train_df.drop(['FareBand'], axis=1)\n",
    "\n",
    "combine = [train_df, test_df]\n",
    "    \n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## drop Name, PassengerId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(['Name', 'PassengerId'], axis=1)\n",
    "test_df = test_df.drop(['Name'], axis=1)\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## final check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Age*Class</th>\n",
       "      <th>Age_Null_Flag</th>\n",
       "      <th>Cabin_Letter_0</th>\n",
       "      <th>Cabin_Letter_A</th>\n",
       "      <th>Cabin_Letter_B</th>\n",
       "      <th>Cabin_Letter_C</th>\n",
       "      <th>Cabin_Letter_D</th>\n",
       "      <th>Cabin_Letter_E</th>\n",
       "      <th>Cabin_Letter_F</th>\n",
       "      <th>...</th>\n",
       "      <th>Title_Mlle</th>\n",
       "      <th>Title_Mme</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Ms</th>\n",
       "      <th>Title_Rev</th>\n",
       "      <th>Title_Sir</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Age*Class  Age_Null_Flag  Cabin_Letter_0  Cabin_Letter_A  \\\n",
       "0    1          3              0               1               0   \n",
       "1    2          2              0               0               0   \n",
       "2    1          3              0               1               0   \n",
       "3    2          2              0               0               0   \n",
       "4    2          6              0               1               0   \n",
       "\n",
       "   Cabin_Letter_B  Cabin_Letter_C  Cabin_Letter_D  Cabin_Letter_E  \\\n",
       "0               0               0               0               0   \n",
       "1               0               1               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               1               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   Cabin_Letter_F     ...      Title_Mlle  Title_Mme  Title_Mr  Title_Mrs  \\\n",
       "0               0     ...               0          0         1          0   \n",
       "1               0     ...               0          0         0          1   \n",
       "2               0     ...               0          0         0          0   \n",
       "3               0     ...               0          0         0          1   \n",
       "4               0     ...               0          0         1          0   \n",
       "\n",
       "   Title_Ms  Title_Rev  Title_Sir  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0         0          0          0           0           0           1  \n",
       "1         0          0          0           1           0           0  \n",
       "2         0          0          0           0           0           1  \n",
       "3         0          0          0           0           0           1  \n",
       "4         0          0          0           0           0           1  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Age*Class</th>\n",
       "      <th>Age_Null_Flag</th>\n",
       "      <th>Cabin_Letter_0</th>\n",
       "      <th>Cabin_Letter_A</th>\n",
       "      <th>Cabin_Letter_B</th>\n",
       "      <th>Cabin_Letter_C</th>\n",
       "      <th>Cabin_Letter_D</th>\n",
       "      <th>Cabin_Letter_E</th>\n",
       "      <th>Cabin_Letter_F</th>\n",
       "      <th>...</th>\n",
       "      <th>Title_Mlle</th>\n",
       "      <th>Title_Mme</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Ms</th>\n",
       "      <th>Title_Rev</th>\n",
       "      <th>Title_Sir</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Age*Class  Age_Null_Flag  Cabin_Letter_0  Cabin_Letter_A  \\\n",
       "0    2          6              0               1               0   \n",
       "1    2          6              0               1               0   \n",
       "2    3          6              0               1               0   \n",
       "3    1          3              0               1               0   \n",
       "4    1          3              0               1               0   \n",
       "\n",
       "   Cabin_Letter_B  Cabin_Letter_C  Cabin_Letter_D  Cabin_Letter_E  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   Cabin_Letter_F     ...      Title_Mlle  Title_Mme  Title_Mr  Title_Mrs  \\\n",
       "0               0     ...               0          0         1          0   \n",
       "1               0     ...               0          0         0          1   \n",
       "2               0     ...               0          0         1          0   \n",
       "3               0     ...               0          0         1          0   \n",
       "4               0     ...               0          0         0          1   \n",
       "\n",
       "   Title_Ms  Title_Rev  Title_Sir  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0         0          0          0           0           1           0  \n",
       "1         0          0          0           0           0           1  \n",
       "2         0          0          0           0           1           0  \n",
       "3         0          0          0           0           0           1  \n",
       "4         0          0          0           0           0           1  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model and estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = train_df.drop(\"Survived\", axis=1)\n",
    "y_train_df = train_df[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/test data shape (596, 43) (295, 43)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train_df, y_train_df, test_size=0.33, random_state=42)\n",
    "print(\"train/test data shape\", X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validated score of the best_estimator:  0.8154362416107382\n",
      "best parameters: {'C': 100, 'gamma': 0.001}\n",
      "test:  0.8406779661016949\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff32d7be9e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make wide the ranges\n",
    "\n",
    "param_grid = {'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "              'gamma': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]}\n",
    "\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5, n_jobs=3)\n",
    "\n",
    "# no meaning to use cross_val for grid_search model because it is incluced in grid search\n",
    "#scores = cross_val_score(grid_search, X_train, y_train, cv=5, n_jobs=6)\n",
    "#print(\"mean of train scores\", scores.mean())\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "plt.matshow(grid_search.cv_results_['mean_test_score'].reshape(8, -1),\n",
    "            vmin=0, cmap=\"viridis\")\n",
    "plt.xlabel(\"C\")\n",
    "plt.ylabel(\"gamma\")\n",
    "plt.xticks(range(len(param_grid['C'])), param_grid['C'])\n",
    "plt.yticks(range(len(param_grid['gamma'])), param_grid['gamma'])\n",
    "plt.colorbar()\n",
    "\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-100.        , -100.        , -100.        , -100.        ,\n",
       "        -100.        , -100.        , -100.        , -100.        ,\n",
       "          -7.43975181, -100.        , -100.        , -100.        ,\n",
       "        -100.        , -100.        , -100.        ,  -31.28392538,\n",
       "        -100.        , -100.        , -100.        , -100.        ,\n",
       "        -100.        , -100.        ,  -73.88202569, -100.        ,\n",
       "        -100.        , -100.        , -100.        , -100.        ,\n",
       "        -100.        ,  -10.88303604,  -35.23619089,  -86.70386171,\n",
       "         -94.02726709, -100.        , -100.        , -100.        ,\n",
       "        -100.        , -100.        , -100.        ,  -19.26225998,\n",
       "        -100.        , -100.        , -100.        , -100.        ,\n",
       "        -100.        , -100.        ,   -9.01054356, -100.        ,\n",
       "        -100.        , -100.        , -100.        ,  -94.83747243,\n",
       "        -100.        , -100.        , -100.        , -100.        ,\n",
       "        -100.        , -100.        , -100.        , -100.        ,\n",
       "        -100.        ,  -31.24566843, -100.        , -100.        ,\n",
       "         -52.40074752,  -99.10699356,   -8.0880365 , -100.        ,\n",
       "        -100.        , -100.        , -100.        , -100.        ,\n",
       "        -100.        , -100.        , -100.        , -100.        ,\n",
       "         -42.46152489, -100.        , -100.        , -100.        ,\n",
       "        -100.        , -100.        ,  -35.75064402,   -5.78784299,\n",
       "        -100.        , -100.        , -100.        , -100.        ,\n",
       "        -100.        , -100.        , -100.        ,   -2.33500363,\n",
       "        -100.        , -100.        , -100.        , -100.        ,\n",
       "        -100.        , -100.        ,  -24.75931184, -100.        ,\n",
       "        -100.        , -100.        , -100.        , -100.        ,\n",
       "         -43.74712701, -100.        , -100.        , -100.        ,\n",
       "        -100.        , -100.        ,  -56.76983482,  -14.85357759,\n",
       "        -100.        , -100.        , -100.        , -100.        ,\n",
       "        -100.        , -100.        , -100.        , -100.        ,\n",
       "        -100.        , -100.        , -100.        , -100.        ,\n",
       "        -100.        ,  -83.65750054, -100.        , -100.        ,\n",
       "        -100.        , -100.        ,  -54.05756418,  -23.73457049,\n",
       "        -100.        , -100.        , -100.        ,  -78.13252262,\n",
       "        -100.        , -100.        ,  -93.81784638, -100.        ,\n",
       "        -100.        ,  100.        ,  100.        ,  100.        ,\n",
       "         100.        ,  100.        ,   73.02801956,  100.        ,\n",
       "         100.        ,  100.        ,  100.        ,  100.        ,\n",
       "         100.        ,  100.        ,  100.        ,  100.        ,\n",
       "         100.        ,  100.        ,  100.        ,  100.        ,\n",
       "         100.        ,  100.        ,  100.        ,  100.        ,\n",
       "          97.68153083,  100.        ,  100.        ,   91.16100679,\n",
       "          74.14165732,  100.        ,  100.        ,  100.        ,\n",
       "         100.        ,  100.        ,  100.        ,  100.        ,\n",
       "         100.        ,  100.        ,   65.4984026 ,   55.50153505,\n",
       "         100.        ,    1.41767138,  100.        ,  100.        ,\n",
       "         100.        ,  100.        ,  100.        ,   92.19874759,\n",
       "         100.        ,   26.54548229,  100.        ,  100.        ,\n",
       "         100.        ,  100.        ,  100.        ,  100.        ,\n",
       "         100.        ,  100.        ,  100.        ,  100.        ,\n",
       "         100.        ,  100.        ,   63.87784028,  100.        ,\n",
       "         100.        ,  100.        ,  100.        ,  100.        ,\n",
       "          81.76051938,   76.99303707,  100.        ,  100.        ,\n",
       "         100.        ,  100.        ,  100.        ,  100.        ,\n",
       "         100.        ,  100.        ,   90.35761551,  100.        ,\n",
       "         100.        ,  100.        ,  100.        ,  100.        ,\n",
       "         100.        ,  100.        ,  100.        ,   13.2118079 ,\n",
       "         100.        ,  100.        ,  100.        ,  100.        ,\n",
       "         100.        ,  100.        ,  100.        ,  100.        ,\n",
       "          48.13651051,  100.        ,  100.        ,  100.        ,\n",
       "         100.        ,  100.        ,  100.        ,  100.        ,\n",
       "         100.        ,  100.        ,  100.        ,  100.        ,\n",
       "         100.        ,  100.        ,  100.        ,  100.        ,\n",
       "          85.40908417,  100.        ,  100.        ,  100.        ,\n",
       "         100.        ,   85.91712739,  100.        ,   39.7645928 ,\n",
       "         100.        ,  100.        ,  100.        ,  100.        ,\n",
       "         100.        ,  100.        ,  100.        ,  100.        ,\n",
       "         100.        ,  100.        ,  100.        ,   50.67046321,\n",
       "         100.        ,  100.        ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_.dual_coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random forest result for compare"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "param_grid = {'randomforestclassifier__n_estimators': [5, 10, 20, 30, 50, 100, 200, 300, 400, 500],\n",
    "              'randomforestclassifier__max_features': [1, 'auto', None],\n",
    "             'randomforestclassifier__max_depth':[1, 5, 10, 20, 30, None],\n",
    "             'randomforestclassifier__min_samples_leaf': [1,2,4],\n",
    "             \"randomforestclassifier__min_samples_split\" : [2, 5, 10, 13, 16]}\n",
    "\n",
    "pipe = make_pipeline(RandomForestClassifier())\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=6)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## output of upper code\n",
    "\n",
    "Mean cross-validated score of the best_estimator:  0.8389261744966443\n",
    "best parameters: {'randomforestclassifier__max_depth': 10, 'randomforestclassifier__max_features': 1, 'randomforestclassifier__min_samples_leaf': 1, 'randomforestclassifier__min_samples_split': 13, 'randomforestclassifier__n_estimators': 300}\n",
    "test:  0.8271186440677966"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test:  0.8203389830508474\n",
      "mean of cross val score:  0.8226711560044894\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(RandomForestClassifier(max_depth=10, \n",
    "                                            max_features=1,\n",
    "                                            min_samples_leaf=1, \n",
    "                                            min_samples_split=13, \n",
    "                                            n_estimators=300))\n",
    "pipe.fit(X_train, y_train)\n",
    "print(\"test: \", pipe.score(X_test, y_test))\n",
    "\n",
    "scores = cross_val_score(pipe, X_train_df, y_train_df, n_jobs=3)\n",
    "print(\"mean of cross val score: \", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Title_Mr</td>\n",
       "      <td>0.328918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Pclass</td>\n",
       "      <td>0.146335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Name_Len</td>\n",
       "      <td>0.123196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Sex</td>\n",
       "      <td>0.081773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Ticket_Len</td>\n",
       "      <td>0.045910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Fare</td>\n",
       "      <td>0.038713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Embarked_S</td>\n",
       "      <td>0.036164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SibSp</td>\n",
       "      <td>0.035131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cabin_Letter_0</td>\n",
       "      <td>0.026572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Age*Class</td>\n",
       "      <td>0.025016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.013945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Parch</td>\n",
       "      <td>0.013825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Title_Master</td>\n",
       "      <td>0.011654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cabin_Letter_E</td>\n",
       "      <td>0.008428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Embarked_C</td>\n",
       "      <td>0.008292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Cabin_num_(1.999, 28.667]</td>\n",
       "      <td>0.008143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Title_Miss</td>\n",
       "      <td>0.007649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cabin_Letter_C</td>\n",
       "      <td>0.007427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Title_Rev</td>\n",
       "      <td>0.006649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Age_Null_Flag</td>\n",
       "      <td>0.005671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cabin_Letter_D</td>\n",
       "      <td>0.004715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Cabin_num_(65.667, 148.0]</td>\n",
       "      <td>0.003594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Cabin_num_(28.667, 65.667]</td>\n",
       "      <td>0.003072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Title_Mrs</td>\n",
       "      <td>0.002870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Title_Dr</td>\n",
       "      <td>0.002572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cabin_Letter_B</td>\n",
       "      <td>0.001970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Embarked_Q</td>\n",
       "      <td>0.001794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Title_Mme</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cabin_Letter_F</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Title_Sir</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cabin_Letter_G</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Title_Ms</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Cabin_Letter_T</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cabin_Letter_A</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Title_Mlle</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Title_Capt</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Title_Major</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Title_Lady</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Title_Jonkheer</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Title_Dona</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Title_Countess</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Title_Col</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Title_Don</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      variable  importance\n",
       "35                    Title_Mr    0.328918\n",
       "18                      Pclass    0.146335\n",
       "16                    Name_Len    0.123196\n",
       "19                         Sex    0.081773\n",
       "21                  Ticket_Len    0.045910\n",
       "15                        Fare    0.038713\n",
       "42                  Embarked_S    0.036164\n",
       "20                       SibSp    0.035131\n",
       "3               Cabin_Letter_0    0.026572\n",
       "1                    Age*Class    0.025016\n",
       "0                          Age    0.013945\n",
       "17                       Parch    0.013825\n",
       "31                Title_Master    0.011654\n",
       "8               Cabin_Letter_E    0.008428\n",
       "40                  Embarked_C    0.008292\n",
       "12   Cabin_num_(1.999, 28.667]    0.008143\n",
       "32                  Title_Miss    0.007649\n",
       "6               Cabin_Letter_C    0.007427\n",
       "38                   Title_Rev    0.006649\n",
       "2                Age_Null_Flag    0.005671\n",
       "7               Cabin_Letter_D    0.004715\n",
       "14   Cabin_num_(65.667, 148.0]    0.003594\n",
       "13  Cabin_num_(28.667, 65.667]    0.003072\n",
       "36                   Title_Mrs    0.002870\n",
       "27                    Title_Dr    0.002572\n",
       "5               Cabin_Letter_B    0.001970\n",
       "41                  Embarked_Q    0.001794\n",
       "34                   Title_Mme    0.000000\n",
       "9               Cabin_Letter_F    0.000000\n",
       "39                   Title_Sir    0.000000\n",
       "10              Cabin_Letter_G    0.000000\n",
       "37                    Title_Ms    0.000000\n",
       "11              Cabin_Letter_T    0.000000\n",
       "4               Cabin_Letter_A    0.000000\n",
       "33                  Title_Mlle    0.000000\n",
       "22                  Title_Capt    0.000000\n",
       "30                 Title_Major    0.000000\n",
       "29                  Title_Lady    0.000000\n",
       "28              Title_Jonkheer    0.000000\n",
       "26                  Title_Dona    0.000000\n",
       "24              Title_Countess    0.000000\n",
       "23                   Title_Col    0.000000\n",
       "25                   Title_Don    0.000000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat((pd.DataFrame(X_train.columns, columns = ['variable']), \n",
    "           pd.DataFrame(pipe.named_steps[\"randomforestclassifier\"].feature_importances_, columns = ['importance'])), \n",
    "          axis = 1).sort_values(by='importance', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "AdaBoostClassifier(base_estimator=None, n_estimators=50,\n",
    "                   learning_rate=1.0, algorithm='SAMME.R',\n",
    "                   random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/home/yuki/anaconda3/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/home/yuki/anaconda3/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x7ff3493f1390, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/yuki/anaconda3/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/yuki/a.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7ff3493f1390, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/yuki/anaconda3/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/yuki/a.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/home/yuki/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    481         if self.poller is not None:\n    482             self.poller.start()\n    483         self.kernel.start()\n    484         self.io_loop = ioloop.IOLoop.current()\n    485         try:\n--> 486             self.io_loop.start()\n        self.io_loop.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    487         except KeyboardInterrupt:\n    488             pass\n    489 \n    490 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/yuki/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/home/yuki/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 5\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/home/yuki/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 5), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 5)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/yuki/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=5)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/home/yuki/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/home/yuki/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/home/yuki/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'param_grid = {\\'learning_rate\\': [0.001, 0.01, 0.1...rint(\"test: \", grid_search.score(X_test, y_test))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 3, 22, 22, 34, 29, 789330, tzinfo=tzutc()), 'msg_id': '1ea580e23447b3fe299833922ab84be4', 'msg_type': 'execute_request', 'session': 'b15e2f0d7eee1ed2d0a091f17000e414', 'username': '', 'version': '5.2'}, 'metadata': {}, 'msg_id': '1ea580e23447b3fe299833922ab84be4', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'b15e2f0d7eee1ed2d0a091f17000e414']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'param_grid = {\\'learning_rate\\': [0.001, 0.01, 0.1...rint(\"test: \", grid_search.score(X_test, y_test))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 3, 22, 22, 34, 29, 789330, tzinfo=tzutc()), 'msg_id': '1ea580e23447b3fe299833922ab84be4', 'msg_type': 'execute_request', 'session': 'b15e2f0d7eee1ed2d0a091f17000e414', 'username': '', 'version': '5.2'}, 'metadata': {}, 'msg_id': '1ea580e23447b3fe299833922ab84be4', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\n/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'b15e2f0d7eee1ed2d0a091f17000e414'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'param_grid = {\\'learning_rate\\': [0.001, 0.01, 0.1...rint(\"test: \", grid_search.score(X_test, y_test))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 3, 22, 22, 34, 29, 789330, tzinfo=tzutc()), 'msg_id': '1ea580e23447b3fe299833922ab84be4', 'msg_type': 'execute_request', 'session': 'b15e2f0d7eee1ed2d0a091f17000e414', 'username': '', 'version': '5.2'}, 'metadata': {}, 'msg_id': '1ea580e23447b3fe299833922ab84be4', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='param_grid = {\\'learning_rate\\': [0.001, 0.01, 0.1...rint(\"test: \", grid_search.score(X_test, y_test))', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'param_grid = {\\'learning_rate\\': [0.001, 0.01, 0.1...rint(\"test: \", grid_search.score(X_test, y_test))'\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\n/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('param_grid = {\\'learning_rate\\': [0.001, 0.01, 0.1...rint(\"test: \", grid_search.score(X_test, y_test))',), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('param_grid = {\\'learning_rate\\': [0.001, 0.01, 0.1...rint(\"test: \", grid_search.score(X_test, y_test))',)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\n/home/yuki/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='param_grid = {\\'learning_rate\\': [0.001, 0.01, 0.1...rint(\"test: \", grid_search.score(X_test, y_test))', store_history=True, silent=False, shell_futures=True)\n   2723                 self.displayhook.exec_result = result\n   2724 \n   2725                 # Execute the user code\n   2726                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2727                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2728                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2729                 \n   2730                 self.last_execution_succeeded = not has_raised\n   2731                 self.last_execution_result = result\n   2732 \n\n...........................................................................\n/home/yuki/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>], cell_name='<ipython-input-37-a11ccfbd15df>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7ff2f9355a58, executi..._before_exec=None error_in_exec=None result=None>)\n   2845 \n   2846         try:\n   2847             for i, node in enumerate(to_run_exec):\n   2848                 mod = ast.Module([node])\n   2849                 code = compiler(mod, cell_name, \"exec\")\n-> 2850                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7ff32e0ebf60, file \"<ipython-input-37-a11ccfbd15df>\", line 9>\n        result = <ExecutionResult object at 7ff2f9355a58, executi..._before_exec=None error_in_exec=None result=None>\n   2851                     return True\n   2852 \n   2853             for i, node in enumerate(to_run_interactive):\n   2854                 mod = ast.Interactive([node])\n\n...........................................................................\n/home/yuki/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7ff32e0ebf60, file \"<ipython-input-37-a11ccfbd15df>\", line 9>, result=<ExecutionResult object at 7ff2f9355a58, executi..._before_exec=None error_in_exec=None result=None>)\n   2905         outflag = True  # happens in more places, so it's easier as default\n   2906         try:\n   2907             try:\n   2908                 self.hooks.pre_run_code_hook()\n   2909                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2910                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7ff32e0ebf60, file \"<ipython-input-37-a11ccfbd15df>\", line 9>\n        self.user_global_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import time\\n\\n# data analysis and wrangling\\nimpor...omModel\\nfrom sklearn.feature_selection import RFE', \"train_df = pd.read_csv('../input/train.csv')\\ntes...../input/test.csv')\\ncombine = [train_df, test_df]\", \"train_df['Ticket_Len'] = train_df['Ticket'].appl...y(lambda x: len(x))\\ncombine = [train_df, test_df]\", 'train_df[\"Cabin_Letter\"] = train_df[\"Cabin\"].fil...ply(lambda x: x[0])\\ncombine = [train_df, test_df]', 'train_test_df = pd.concat((train_df, test_df))\\n\\n...pe, test_df.shape)\\n\\ncombine = [train_df, test_df]', \"for i in [train_df, test_df]:\\n    i['Cabin_num1'...'Cabin_num'] = pd.qcut(train_df['Cabin_num1'], 3)\", \"train_df = pd.concat((train_df, pd.get_dummies(t...f['Cabin_num'], prefix = 'Cabin_num')), axis = 1)\", \"del train_df['Cabin_num']\\ndel test_df['Cabin_num... train_df['Cabin_num1']\\ndel test_df['Cabin_num1']\", 'train_df.columns', \"# del Ticket, Cabin columns\\ntrain_df = train_df...., 'Cabin'], axis=1)\\ncombine = [train_df, test_df]\", \"# add title\\nfor dataset in combine:\\n    dataset[....Name.str.extract(' ([A-Za-z]+)\\\\.', expand=False)\", '# try one hote encoding without delete rare titl...pe, test_df.shape)\\n\\ncombine = [train_df, test_df]', 'train_df.columns', \"train_df['Name_Len'] = train_df['Name'].apply(la...y(lambda x: len(x))\\ncombine = [train_df, test_df]\", 'for dataset in combine:\\n    dataset[\"Sex\"] = dataset[\"Sex\"].map({\\'female\\':1, \\'male\\':0}).astype(int)', \"train_df['Age_Null_Flag'] = train_df['Age'].appl...d.isnull(x) else 0)\\ncombine = [train_df, test_df]\", \"guess_ages = np.zeros((2,3))\\n\\nfor dataset in com...\\n\\n    dataset['Age'] = dataset['Age'].astype(int)\", \"train_df['AgeBand'] = pd.cut(train_df['Age'], 5)\", \"for dataset in combine:\\n    dataset.loc[ dataset...'AgeBand'], axis=1)\\ncombine = [train_df, test_df]\", ...], 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'LinearSVC': <class 'sklearn.svm.classes.LinearSVC'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MinMaxScaler': <class 'sklearn.preprocessing.data.MinMaxScaler'>, ...}\n        self.user_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import time\\n\\n# data analysis and wrangling\\nimpor...omModel\\nfrom sklearn.feature_selection import RFE', \"train_df = pd.read_csv('../input/train.csv')\\ntes...../input/test.csv')\\ncombine = [train_df, test_df]\", \"train_df['Ticket_Len'] = train_df['Ticket'].appl...y(lambda x: len(x))\\ncombine = [train_df, test_df]\", 'train_df[\"Cabin_Letter\"] = train_df[\"Cabin\"].fil...ply(lambda x: x[0])\\ncombine = [train_df, test_df]', 'train_test_df = pd.concat((train_df, test_df))\\n\\n...pe, test_df.shape)\\n\\ncombine = [train_df, test_df]', \"for i in [train_df, test_df]:\\n    i['Cabin_num1'...'Cabin_num'] = pd.qcut(train_df['Cabin_num1'], 3)\", \"train_df = pd.concat((train_df, pd.get_dummies(t...f['Cabin_num'], prefix = 'Cabin_num')), axis = 1)\", \"del train_df['Cabin_num']\\ndel test_df['Cabin_num... train_df['Cabin_num1']\\ndel test_df['Cabin_num1']\", 'train_df.columns', \"# del Ticket, Cabin columns\\ntrain_df = train_df...., 'Cabin'], axis=1)\\ncombine = [train_df, test_df]\", \"# add title\\nfor dataset in combine:\\n    dataset[....Name.str.extract(' ([A-Za-z]+)\\\\.', expand=False)\", '# try one hote encoding without delete rare titl...pe, test_df.shape)\\n\\ncombine = [train_df, test_df]', 'train_df.columns', \"train_df['Name_Len'] = train_df['Name'].apply(la...y(lambda x: len(x))\\ncombine = [train_df, test_df]\", 'for dataset in combine:\\n    dataset[\"Sex\"] = dataset[\"Sex\"].map({\\'female\\':1, \\'male\\':0}).astype(int)', \"train_df['Age_Null_Flag'] = train_df['Age'].appl...d.isnull(x) else 0)\\ncombine = [train_df, test_df]\", \"guess_ages = np.zeros((2,3))\\n\\nfor dataset in com...\\n\\n    dataset['Age'] = dataset['Age'].astype(int)\", \"train_df['AgeBand'] = pd.cut(train_df['Age'], 5)\", \"for dataset in combine:\\n    dataset.loc[ dataset...'AgeBand'], axis=1)\\ncombine = [train_df, test_df]\", ...], 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'LinearSVC': <class 'sklearn.svm.classes.LinearSVC'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MinMaxScaler': <class 'sklearn.preprocessing.data.MinMaxScaler'>, ...}\n   2911             finally:\n   2912                 # Reset our crash handler in place\n   2913                 sys.excepthook = old_excepthook\n   2914         except SystemExit as e:\n\n...........................................................................\n/home/yuki/github/test/kaggle/titanic/src/<ipython-input-37-a11ccfbd15df> in <module>()\n      4               'min_samples_leaf': [1, 3, 5, 9, 17],\n      5               'max_depth':[1,2,3,4,5,6],\n      6               'max_features': [1, 'auto', 'sqrt', 'log2', 0.5, 0,7, 0.9],}\n      7 \n      8 grid_search = GridSearchCV(GradientBoostingClassifier(), param_grid, cv=5, n_jobs=3)\n----> 9 grid_search.fit(X_train, y_train)\n     10 \n     11 plt.matshow(grid_search.cv_results_['mean_test_score'].reshape(6, -1),\n     12             vmin=0, cmap=\"viridis\")\n     13 plt.xlabel(\"n_estimators\")\n\n...........................................................................\n/home/yuki/.local/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=5, error_score='raise',\n       e...ain_score='warn',\n       scoring=None, verbose=0), X=     Age  Age*Class  Age_Null_Flag  Cabin_Letter...         0           1  \n\n[596 rows x 43 columns], y=6      0.0\n718    0.0\n685    0.0\n73     0.0\n882 ...  0.0\nName: Survived, Length: 596, dtype: float64, groups=None, **fit_params={})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=5, random_state=None, shuffle=False)>\n        X =      Age  Age*Class  Age_Null_Flag  Cabin_Letter...         0           1  \n\n[596 rows x 43 columns]\n        y = 6      0.0\n718    0.0\n685    0.0\n73     0.0\n882 ...  0.0\nName: Survived, Length: 596, dtype: float64\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\n/home/yuki/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=3), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=3)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Fri Mar 23 07:47:09 2018\nPID: 8686                     Python 3.6.4: /home/yuki/anaconda3/bin/python\n...........................................................................\n/home/yuki/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (GradientBoostingClassifier(criterion='friedman_m...e=1.0, verbose=0,\n              warm_start=False),      Age  Age*Class  Age_Null_Flag  Cabin_Letter...         0           1  \n\n[596 rows x 43 columns], 6      0.0\n718    0.0\n685    0.0\n73     0.0\n882 ...  0.0\nName: Survived, Length: 596, dtype: float64, {'score': <function _passthrough_scorer>}, array([  0,   1,   2,   3,   4,   5,   6,   7,  ...70, 472, 473, 475, 476, 477, 478, 479, 482, 484]), array([468, 469, 471, 474, 480, 481, 483, 485, 4..., 588, 589, 590, 591, 592, 593, 594,\n       595]), 0, {'learning_rate': 0.001, 'max_depth': 1, 'max_features': 0.5, 'min_samples_leaf': 17, 'min_samples_split': 5, 'n_estimators': 1000}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}), (<function _fit_and_score>, (GradientBoostingClassifier(criterion='friedman_m...e=1.0, verbose=0,\n              warm_start=False),      Age  Age*Class  Age_Null_Flag  Cabin_Letter...         0           1  \n\n[596 rows x 43 columns], 6      0.0\n718    0.0\n685    0.0\n73     0.0\n882 ...  0.0\nName: Survived, Length: 596, dtype: float64, {'score': <function _passthrough_scorer>}, array([113, 117, 118, 120, 121, 125, 126, 127, 1...,\n       588, 589, 590, 591, 592, 593, 594, 595]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 112, 114, 115, 116, 119,\n       122, 123, 124]), 0, {'learning_rate': 0.001, 'max_depth': 1, 'max_features': 0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 3}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}), (<function _fit_and_score>, (GradientBoostingClassifier(criterion='friedman_m...e=1.0, verbose=0,\n              warm_start=False),      Age  Age*Class  Age_Null_Flag  Cabin_Letter...         0           1  \n\n[596 rows x 43 columns], 6      0.0\n718    0.0\n685    0.0\n73     0.0\n882 ...  0.0\nName: Survived, Length: 596, dtype: float64, {'score': <function _passthrough_scorer>}, array([  0,   1,   2,   3,   4,   5,   6,   7,  ...,\n       588, 589, 590, 591, 592, 593, 594, 595]), array([113, 117, 118, 120, 121, 125, 126, 127, 1..., 232, 233, 234, 235, 237,\n       238, 239, 240]), 0, {'learning_rate': 0.001, 'max_depth': 1, 'max_features': 0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 3}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}), (<function _fit_and_score>, (GradientBoostingClassifier(criterion='friedman_m...e=1.0, verbose=0,\n              warm_start=False),      Age  Age*Class  Age_Null_Flag  Cabin_Letter...         0           1  \n\n[596 rows x 43 columns], 6      0.0\n718    0.0\n685    0.0\n73     0.0\n882 ...  0.0\nName: Survived, Length: 596, dtype: float64, {'score': <function _passthrough_scorer>}, array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    587, 588, 589, 590, 591, 592, 593, 594, 595]), array([236, 241, 242, 243, 244, 245, 246, 247, 2..., 351, 352, 353, 355, 357, 359,\n       360, 361]), 0, {'learning_rate': 0.001, 'max_depth': 1, 'max_features': 0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 3}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/yuki/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (GradientBoostingClassifier(criterion='friedman_m...e=1.0, verbose=0,\n              warm_start=False),      Age  Age*Class  Age_Null_Flag  Cabin_Letter...         0           1  \n\n[596 rows x 43 columns], 6      0.0\n718    0.0\n685    0.0\n73     0.0\n882 ...  0.0\nName: Survived, Length: 596, dtype: float64, {'score': <function _passthrough_scorer>}, array([113, 117, 118, 120, 121, 125, 126, 127, 1...,\n       588, 589, 590, 591, 592, 593, 594, 595]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 112, 114, 115, 116, 119,\n       122, 123, 124]), 0, {'learning_rate': 0.001, 'max_depth': 1, 'max_features': 0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 3})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/yuki/.local/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=GradientBoostingClassifier(criterion='friedman_m...e=1.0, verbose=0,\n              warm_start=False), X=     Age  Age*Class  Age_Null_Flag  Cabin_Letter...         0           1  \n\n[596 rows x 43 columns], y=6      0.0\n718    0.0\n685    0.0\n73     0.0\n882 ...  0.0\nName: Survived, Length: 596, dtype: float64, scorer={'score': <function _passthrough_scorer>}, train=array([113, 117, 118, 120, 121, 125, 126, 127, 1...,\n       588, 589, 590, 591, 592, 593, 594, 595]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 112, 114, 115, 116, 119,\n       122, 123, 124]), verbose=0, parameters={'learning_rate': 0.001, 'max_depth': 1, 'max_features': 0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 3}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method BaseGradientBoosting.fit of Gradie...=1.0, verbose=0,\n              warm_start=False)>\n        X_train =      Age  Age*Class  Age_Null_Flag  Cabin_Letter...         0           1  \n\n[476 rows x 43 columns]\n        y_train = 506    1.0\n530    1.0\n9      1.0\n22     1.0\n356 ...  0.0\nName: Survived, Length: 476, dtype: float64\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\n/home/yuki/.local/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py in fit(self=GradientBoostingClassifier(criterion='friedman_m...e=1.0, verbose=0,\n              warm_start=False), X=array([[2., 4., 0., ..., 0., 0., 1.],\n       [0....   [1., 1., 0., ..., 0., 0., 1.]], dtype=float32), y=array([1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1,...       1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0]), sample_weight=array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1...1., 1., 1., 1., 1., 1., 1.],\n      dtype=float32), monitor=None)\n   1029                 X_idx_sorted = np.asfortranarray(np.argsort(X, axis=0),\n   1030                                                  dtype=np.int32)\n   1031 \n   1032         # fit the boosting stages\n   1033         n_stages = self._fit_stages(X, y, y_pred, sample_weight, random_state,\n-> 1034                                     begin_at_stage, monitor, X_idx_sorted)\n        begin_at_stage = 0\n        monitor = None\n        X_idx_sorted = array([[ 58, 336,   0, ...,   0,   0, 237],\n    ... 48, 231, 167, ..., 237, 280, 475]], dtype=int32)\n   1035         # change shape of arrays after fit (early-stopping or additional ests)\n   1036         if n_stages != self.estimators_.shape[0]:\n   1037             self.estimators_ = self.estimators_[:n_stages]\n   1038             self.train_score_ = self.train_score_[:n_stages]\n\n...........................................................................\n/home/yuki/.local/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py in _fit_stages(self=GradientBoostingClassifier(criterion='friedman_m...e=1.0, verbose=0,\n              warm_start=False), X=array([[2., 4., 0., ..., 0., 0., 1.],\n       [0....   [1., 1., 0., ..., 0., 0., 1.]], dtype=float32), y=array([1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1,...       1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0]), y_pred=array([[-0.52429384],\n       [-0.52429384],\n    ...84],\n       [-0.52429384],\n       [-0.52429384]]), sample_weight=array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1...1., 1., 1., 1., 1., 1., 1.],\n      dtype=float32), random_state=<mtrand.RandomState object>, begin_at_stage=0, monitor=None, X_idx_sorted=array([[ 58, 336,   0, ...,   0,   0, 237],\n    ... 48, 231, 167, ..., 237, 280, 475]], dtype=int32))\n   1084                                       sample_weight[~sample_mask])\n   1085 \n   1086             # fit next stage of trees\n   1087             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n   1088                                      sample_mask, random_state, X_idx_sorted,\n-> 1089                                      X_csc, X_csr)\n        X_csc = None\n        X_csr = None\n   1090 \n   1091             # track deviance (= loss)\n   1092             if do_oob:\n   1093                 self.train_score_[i] = loss_(y[sample_mask],\n\n...........................................................................\n/home/yuki/.local/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py in _fit_stage(self=GradientBoostingClassifier(criterion='friedman_m...e=1.0, verbose=0,\n              warm_start=False), i=0, X=array([[2., 4., 0., ..., 0., 0., 1.],\n       [0....   [1., 1., 0., ..., 0., 0., 1.]], dtype=float32), y=array([1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1,...       1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0]), y_pred=array([[-0.52429384],\n       [-0.52429384],\n    ...84],\n       [-0.52429384],\n       [-0.52429384]]), sample_weight=array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1...1., 1., 1., 1., 1., 1., 1.],\n      dtype=float32), sample_mask=array([ True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True]), random_state=<mtrand.RandomState object>, X_idx_sorted=array([[ 58, 336,   0, ...,   0,   0, 237],\n    ... 48, 231, 167, ..., 237, 280, 475]], dtype=int32), X_csc=None, X_csr=None)\n    783             if X_csc is not None:\n    784                 tree.fit(X_csc, residual, sample_weight=sample_weight,\n    785                          check_input=False, X_idx_sorted=X_idx_sorted)\n    786             else:\n    787                 tree.fit(X, residual, sample_weight=sample_weight,\n--> 788                          check_input=False, X_idx_sorted=X_idx_sorted)\n        X_idx_sorted = array([[ 58, 336,   0, ...,   0,   0, 237],\n    ... 48, 231, 167, ..., 237, 280, 475]], dtype=int32)\n    789 \n    790             # update tree leaves\n    791             if X_csr is not None:\n    792                 loss.update_terminal_regions(tree.tree_, X_csr, y, residual, y_pred,\n\n...........................................................................\n/home/yuki/.local/lib/python3.6/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeRegressor(criterion='friedman_mse', ...t at 0x7ff30d7aa2d0>,\n           splitter='best'), X=array([[2., 4., 0., ..., 0., 0., 1.],\n       [0....   [1., 1., 0., ..., 0., 0., 1.]], dtype=float32), y=array([ 0.62815126,  0.62815126,  0.62815126,  0...4, -0.37184874,  0.62815126,\n       -0.37184874]), sample_weight=array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1...1., 1., 1., 1., 1., 1., 1.],\n      dtype=float32), check_input=False, X_idx_sorted=array([[ 58, 336,   0, ...,   0,   0, 237],\n    ... 48, 231, 167, ..., 237, 280, 475]], dtype=int32))\n   1119 \n   1120         super(DecisionTreeRegressor, self).fit(\n   1121             X, y,\n   1122             sample_weight=sample_weight,\n   1123             check_input=check_input,\n-> 1124             X_idx_sorted=X_idx_sorted)\n        X_idx_sorted = array([[ 58, 336,   0, ...,   0,   0, 237],\n    ... 48, 231, 167, ..., 237, 280, 475]], dtype=int32)\n   1125         return self\n   1126 \n   1127 \n   1128 class ExtraTreeClassifier(DecisionTreeClassifier):\n\n...........................................................................\n/home/yuki/.local/lib/python3.6/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeRegressor(criterion='friedman_mse', ...t at 0x7ff30d7aa2d0>,\n           splitter='best'), X=array([[2., 4., 0., ..., 0., 0., 1.],\n       [0....   [1., 1., 0., ..., 0., 0., 1.]], dtype=float32), y=array([[ 0.62815126],\n       [ 0.62815126],\n    ...74],\n       [ 0.62815126],\n       [-0.37184874]]), sample_weight=array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1...1., 1., 1., 1., 1., 1., 1.],\n      dtype=float32), check_input=False, X_idx_sorted=array([[ 58, 336,   0, ...,   0,   0, 237],\n    ... 48, 231, 167, ..., 237, 280, 475]], dtype=int32))\n    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:\n    238             raise ValueError(\"min_weight_fraction_leaf must in [0, 0.5]\")\n    239         if max_depth <= 0:\n    240             raise ValueError(\"max_depth must be greater than zero. \")\n    241         if not (0 < max_features <= self.n_features_):\n--> 242             raise ValueError(\"max_features must be in (0, n_features]\")\n    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):\n    244             raise ValueError(\"max_leaf_nodes must be integral number but was \"\n    245                              \"%r\" % max_leaf_nodes)\n    246         if -1 < max_leaf_nodes < 2:\n\nValueError: max_features must be in (0, n_features]\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/yuki/.local/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"/home/yuki/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/home/yuki/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/home/yuki/.local/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 458, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/yuki/.local/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py\", line 1034, in fit\n    begin_at_stage, monitor, X_idx_sorted)\n  File \"/home/yuki/.local/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py\", line 1089, in _fit_stages\n    X_csc, X_csr)\n  File \"/home/yuki/.local/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py\", line 788, in _fit_stage\n    check_input=False, X_idx_sorted=X_idx_sorted)\n  File \"/home/yuki/.local/lib/python3.6/site-packages/sklearn/tree/tree.py\", line 1124, in fit\n    X_idx_sorted=X_idx_sorted)\n  File \"/home/yuki/.local/lib/python3.6/site-packages/sklearn/tree/tree.py\", line 242, in fit\n    raise ValueError(\"max_features must be in (0, n_features]\")\nValueError: max_features must be in (0, n_features]\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/yuki/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/yuki/.local/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nValueError                                         Fri Mar 23 07:47:09 2018\nPID: 8686                     Python 3.6.4: /home/yuki/anaconda3/bin/python\n...........................................................................\n/home/yuki/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (GradientBoostingClassifier(criterion='friedman_m...e=1.0, verbose=0,\n              warm_start=False),      Age  Age*Class  Age_Null_Flag  Cabin_Letter...         0           1  \n\n[596 rows x 43 columns], 6      0.0\n718    0.0\n685    0.0\n73     0.0\n882 ...  0.0\nName: Survived, Length: 596, dtype: float64, {'score': <function _passthrough_scorer>}, array([  0,   1,   2,   3,   4,   5,   6,   7,  ...70, 472, 473, 475, 476, 477, 478, 479, 482, 484]), array([468, 469, 471, 474, 480, 481, 483, 485, 4..., 588, 589, 590, 591, 592, 593, 594,\n       595]), 0, {'learning_rate': 0.001, 'max_depth': 1, 'max_features': 0.5, 'min_samples_leaf': 17, 'min_samples_split': 5, 'n_estimators': 1000}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}), (<function _fit_and_score>, (GradientBoostingClassifier(criterion='friedman_m...e=1.0, verbose=0,\n              warm_start=False),      Age  Age*Class  Age_Null_Flag  Cabin_Letter...         0           1  \n\n[596 rows x 43 columns], 6      0.0\n718    0.0\n685    0.0\n73     0.0\n882 ...  0.0\nName: Survived, Length: 596, dtype: float64, {'score': <function _passthrough_scorer>}, array([113, 117, 118, 120, 121, 125, 126, 127, 1...,\n       588, 589, 590, 591, 592, 593, 594, 595]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 112, 114, 115, 116, 119,\n       122, 123, 124]), 0, {'learning_rate': 0.001, 'max_depth': 1, 'max_features': 0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 3}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}), (<function _fit_and_score>, (GradientBoostingClassifier(criterion='friedman_m...e=1.0, verbose=0,\n              warm_start=False),      Age  Age*Class  Age_Null_Flag  Cabin_Letter...         0           1  \n\n[596 rows x 43 columns], 6      0.0\n718    0.0\n685    0.0\n73     0.0\n882 ...  0.0\nName: Survived, Length: 596, dtype: float64, {'score': <function _passthrough_scorer>}, array([  0,   1,   2,   3,   4,   5,   6,   7,  ...,\n       588, 589, 590, 591, 592, 593, 594, 595]), array([113, 117, 118, 120, 121, 125, 126, 127, 1..., 232, 233, 234, 235, 237,\n       238, 239, 240]), 0, {'learning_rate': 0.001, 'max_depth': 1, 'max_features': 0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 3}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}), (<function _fit_and_score>, (GradientBoostingClassifier(criterion='friedman_m...e=1.0, verbose=0,\n              warm_start=False),      Age  Age*Class  Age_Null_Flag  Cabin_Letter...         0           1  \n\n[596 rows x 43 columns], 6      0.0\n718    0.0\n685    0.0\n73     0.0\n882 ...  0.0\nName: Survived, Length: 596, dtype: float64, {'score': <function _passthrough_scorer>}, array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    587, 588, 589, 590, 591, 592, 593, 594, 595]), array([236, 241, 242, 243, 244, 245, 246, 247, 2..., 351, 352, 353, 355, 357, 359,\n       360, 361]), 0, {'learning_rate': 0.001, 'max_depth': 1, 'max_features': 0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 3}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/yuki/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (GradientBoostingClassifier(criterion='friedman_m...e=1.0, verbose=0,\n              warm_start=False),      Age  Age*Class  Age_Null_Flag  Cabin_Letter...         0           1  \n\n[596 rows x 43 columns], 6      0.0\n718    0.0\n685    0.0\n73     0.0\n882 ...  0.0\nName: Survived, Length: 596, dtype: float64, {'score': <function _passthrough_scorer>}, array([113, 117, 118, 120, 121, 125, 126, 127, 1...,\n       588, 589, 590, 591, 592, 593, 594, 595]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 112, 114, 115, 116, 119,\n       122, 123, 124]), 0, {'learning_rate': 0.001, 'max_depth': 1, 'max_features': 0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 3})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/yuki/.local/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=GradientBoostingClassifier(criterion='friedman_m...e=1.0, verbose=0,\n              warm_start=False), X=     Age  Age*Class  Age_Null_Flag  Cabin_Letter...         0           1  \n\n[596 rows x 43 columns], y=6      0.0\n718    0.0\n685    0.0\n73     0.0\n882 ...  0.0\nName: Survived, Length: 596, dtype: float64, scorer={'score': <function _passthrough_scorer>}, train=array([113, 117, 118, 120, 121, 125, 126, 127, 1...,\n       588, 589, 590, 591, 592, 593, 594, 595]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 112, 114, 115, 116, 119,\n       122, 123, 124]), verbose=0, parameters={'learning_rate': 0.001, 'max_depth': 1, 'max_features': 0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 3}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method BaseGradientBoosting.fit of Gradie...=1.0, verbose=0,\n              warm_start=False)>\n        X_train =      Age  Age*Class  Age_Null_Flag  Cabin_Letter...         0           1  \n\n[476 rows x 43 columns]\n        y_train = 506    1.0\n530    1.0\n9      1.0\n22     1.0\n356 ...  0.0\nName: Survived, Length: 476, dtype: float64\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\n/home/yuki/.local/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py in fit(self=GradientBoostingClassifier(criterion='friedman_m...e=1.0, verbose=0,\n              warm_start=False), X=array([[2., 4., 0., ..., 0., 0., 1.],\n       [0....   [1., 1., 0., ..., 0., 0., 1.]], dtype=float32), y=array([1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1,...       1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0]), sample_weight=array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1...1., 1., 1., 1., 1., 1., 1.],\n      dtype=float32), monitor=None)\n   1029                 X_idx_sorted = np.asfortranarray(np.argsort(X, axis=0),\n   1030                                                  dtype=np.int32)\n   1031 \n   1032         # fit the boosting stages\n   1033         n_stages = self._fit_stages(X, y, y_pred, sample_weight, random_state,\n-> 1034                                     begin_at_stage, monitor, X_idx_sorted)\n        begin_at_stage = 0\n        monitor = None\n        X_idx_sorted = array([[ 58, 336,   0, ...,   0,   0, 237],\n    ... 48, 231, 167, ..., 237, 280, 475]], dtype=int32)\n   1035         # change shape of arrays after fit (early-stopping or additional ests)\n   1036         if n_stages != self.estimators_.shape[0]:\n   1037             self.estimators_ = self.estimators_[:n_stages]\n   1038             self.train_score_ = self.train_score_[:n_stages]\n\n...........................................................................\n/home/yuki/.local/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py in _fit_stages(self=GradientBoostingClassifier(criterion='friedman_m...e=1.0, verbose=0,\n              warm_start=False), X=array([[2., 4., 0., ..., 0., 0., 1.],\n       [0....   [1., 1., 0., ..., 0., 0., 1.]], dtype=float32), y=array([1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1,...       1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0]), y_pred=array([[-0.52429384],\n       [-0.52429384],\n    ...84],\n       [-0.52429384],\n       [-0.52429384]]), sample_weight=array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1...1., 1., 1., 1., 1., 1., 1.],\n      dtype=float32), random_state=<mtrand.RandomState object>, begin_at_stage=0, monitor=None, X_idx_sorted=array([[ 58, 336,   0, ...,   0,   0, 237],\n    ... 48, 231, 167, ..., 237, 280, 475]], dtype=int32))\n   1084                                       sample_weight[~sample_mask])\n   1085 \n   1086             # fit next stage of trees\n   1087             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n   1088                                      sample_mask, random_state, X_idx_sorted,\n-> 1089                                      X_csc, X_csr)\n        X_csc = None\n        X_csr = None\n   1090 \n   1091             # track deviance (= loss)\n   1092             if do_oob:\n   1093                 self.train_score_[i] = loss_(y[sample_mask],\n\n...........................................................................\n/home/yuki/.local/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py in _fit_stage(self=GradientBoostingClassifier(criterion='friedman_m...e=1.0, verbose=0,\n              warm_start=False), i=0, X=array([[2., 4., 0., ..., 0., 0., 1.],\n       [0....   [1., 1., 0., ..., 0., 0., 1.]], dtype=float32), y=array([1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1,...       1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0]), y_pred=array([[-0.52429384],\n       [-0.52429384],\n    ...84],\n       [-0.52429384],\n       [-0.52429384]]), sample_weight=array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1...1., 1., 1., 1., 1., 1., 1.],\n      dtype=float32), sample_mask=array([ True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True]), random_state=<mtrand.RandomState object>, X_idx_sorted=array([[ 58, 336,   0, ...,   0,   0, 237],\n    ... 48, 231, 167, ..., 237, 280, 475]], dtype=int32), X_csc=None, X_csr=None)\n    783             if X_csc is not None:\n    784                 tree.fit(X_csc, residual, sample_weight=sample_weight,\n    785                          check_input=False, X_idx_sorted=X_idx_sorted)\n    786             else:\n    787                 tree.fit(X, residual, sample_weight=sample_weight,\n--> 788                          check_input=False, X_idx_sorted=X_idx_sorted)\n        X_idx_sorted = array([[ 58, 336,   0, ...,   0,   0, 237],\n    ... 48, 231, 167, ..., 237, 280, 475]], dtype=int32)\n    789 \n    790             # update tree leaves\n    791             if X_csr is not None:\n    792                 loss.update_terminal_regions(tree.tree_, X_csr, y, residual, y_pred,\n\n...........................................................................\n/home/yuki/.local/lib/python3.6/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeRegressor(criterion='friedman_mse', ...t at 0x7ff30d7aa2d0>,\n           splitter='best'), X=array([[2., 4., 0., ..., 0., 0., 1.],\n       [0....   [1., 1., 0., ..., 0., 0., 1.]], dtype=float32), y=array([ 0.62815126,  0.62815126,  0.62815126,  0...4, -0.37184874,  0.62815126,\n       -0.37184874]), sample_weight=array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1...1., 1., 1., 1., 1., 1., 1.],\n      dtype=float32), check_input=False, X_idx_sorted=array([[ 58, 336,   0, ...,   0,   0, 237],\n    ... 48, 231, 167, ..., 237, 280, 475]], dtype=int32))\n   1119 \n   1120         super(DecisionTreeRegressor, self).fit(\n   1121             X, y,\n   1122             sample_weight=sample_weight,\n   1123             check_input=check_input,\n-> 1124             X_idx_sorted=X_idx_sorted)\n        X_idx_sorted = array([[ 58, 336,   0, ...,   0,   0, 237],\n    ... 48, 231, 167, ..., 237, 280, 475]], dtype=int32)\n   1125         return self\n   1126 \n   1127 \n   1128 class ExtraTreeClassifier(DecisionTreeClassifier):\n\n...........................................................................\n/home/yuki/.local/lib/python3.6/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeRegressor(criterion='friedman_mse', ...t at 0x7ff30d7aa2d0>,\n           splitter='best'), X=array([[2., 4., 0., ..., 0., 0., 1.],\n       [0....   [1., 1., 0., ..., 0., 0., 1.]], dtype=float32), y=array([[ 0.62815126],\n       [ 0.62815126],\n    ...74],\n       [ 0.62815126],\n       [-0.37184874]]), sample_weight=array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1...1., 1., 1., 1., 1., 1., 1.],\n      dtype=float32), check_input=False, X_idx_sorted=array([[ 58, 336,   0, ...,   0,   0, 237],\n    ... 48, 231, 167, ..., 237, 280, 475]], dtype=int32))\n    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:\n    238             raise ValueError(\"min_weight_fraction_leaf must in [0, 0.5]\")\n    239         if max_depth <= 0:\n    240             raise ValueError(\"max_depth must be greater than zero. \")\n    241         if not (0 < max_features <= self.n_features_):\n--> 242             raise ValueError(\"max_features must be in (0, n_features]\")\n    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):\n    244             raise ValueError(\"max_leaf_nodes must be integral number but was \"\n    245                              \"%r\" % max_leaf_nodes)\n    246         if -1 < max_leaf_nodes < 2:\n\nValueError: max_features must be in (0, n_features]\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Fri Mar 23 07:47:09 2018\nPID: 8686                     Python 3.6.4: /home/yuki/anaconda3/bin/python\n...........................................................................\n/home/yuki/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (GradientBoostingClassifier(criterion='friedman_m...e=1.0, verbose=0,\n              warm_start=False),      Age  Age*Class  Age_Null_Flag  Cabin_Letter...         0           1  \n\n[596 rows x 43 columns], 6      0.0\n718    0.0\n685    0.0\n73     0.0\n882 ...  0.0\nName: Survived, Length: 596, dtype: float64, {'score': <function _passthrough_scorer>}, array([  0,   1,   2,   3,   4,   5,   6,   7,  ...70, 472, 473, 475, 476, 477, 478, 479, 482, 484]), array([468, 469, 471, 474, 480, 481, 483, 485, 4..., 588, 589, 590, 591, 592, 593, 594,\n       595]), 0, {'learning_rate': 0.001, 'max_depth': 1, 'max_features': 0.5, 'min_samples_leaf': 17, 'min_samples_split': 5, 'n_estimators': 1000}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}), (<function _fit_and_score>, (GradientBoostingClassifier(criterion='friedman_m...e=1.0, verbose=0,\n              warm_start=False),      Age  Age*Class  Age_Null_Flag  Cabin_Letter...         0           1  \n\n[596 rows x 43 columns], 6      0.0\n718    0.0\n685    0.0\n73     0.0\n882 ...  0.0\nName: Survived, Length: 596, dtype: float64, {'score': <function _passthrough_scorer>}, array([113, 117, 118, 120, 121, 125, 126, 127, 1...,\n       588, 589, 590, 591, 592, 593, 594, 595]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 112, 114, 115, 116, 119,\n       122, 123, 124]), 0, {'learning_rate': 0.001, 'max_depth': 1, 'max_features': 0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 3}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}), (<function _fit_and_score>, (GradientBoostingClassifier(criterion='friedman_m...e=1.0, verbose=0,\n              warm_start=False),      Age  Age*Class  Age_Null_Flag  Cabin_Letter...         0           1  \n\n[596 rows x 43 columns], 6      0.0\n718    0.0\n685    0.0\n73     0.0\n882 ...  0.0\nName: Survived, Length: 596, dtype: float64, {'score': <function _passthrough_scorer>}, array([  0,   1,   2,   3,   4,   5,   6,   7,  ...,\n       588, 589, 590, 591, 592, 593, 594, 595]), array([113, 117, 118, 120, 121, 125, 126, 127, 1..., 232, 233, 234, 235, 237,\n       238, 239, 240]), 0, {'learning_rate': 0.001, 'max_depth': 1, 'max_features': 0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 3}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}), (<function _fit_and_score>, (GradientBoostingClassifier(criterion='friedman_m...e=1.0, verbose=0,\n              warm_start=False),      Age  Age*Class  Age_Null_Flag  Cabin_Letter...         0           1  \n\n[596 rows x 43 columns], 6      0.0\n718    0.0\n685    0.0\n73     0.0\n882 ...  0.0\nName: Survived, Length: 596, dtype: float64, {'score': <function _passthrough_scorer>}, array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    587, 588, 589, 590, 591, 592, 593, 594, 595]), array([236, 241, 242, 243, 244, 245, 246, 247, 2..., 351, 352, 353, 355, 357, 359,\n       360, 361]), 0, {'learning_rate': 0.001, 'max_depth': 1, 'max_features': 0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 3}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/yuki/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (GradientBoostingClassifier(criterion='friedman_m...e=1.0, verbose=0,\n              warm_start=False),      Age  Age*Class  Age_Null_Flag  Cabin_Letter...         0           1  \n\n[596 rows x 43 columns], 6      0.0\n718    0.0\n685    0.0\n73     0.0\n882 ...  0.0\nName: Survived, Length: 596, dtype: float64, {'score': <function _passthrough_scorer>}, array([113, 117, 118, 120, 121, 125, 126, 127, 1...,\n       588, 589, 590, 591, 592, 593, 594, 595]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 112, 114, 115, 116, 119,\n       122, 123, 124]), 0, {'learning_rate': 0.001, 'max_depth': 1, 'max_features': 0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 3})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/yuki/.local/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=GradientBoostingClassifier(criterion='friedman_m...e=1.0, verbose=0,\n              warm_start=False), X=     Age  Age*Class  Age_Null_Flag  Cabin_Letter...         0           1  \n\n[596 rows x 43 columns], y=6      0.0\n718    0.0\n685    0.0\n73     0.0\n882 ...  0.0\nName: Survived, Length: 596, dtype: float64, scorer={'score': <function _passthrough_scorer>}, train=array([113, 117, 118, 120, 121, 125, 126, 127, 1...,\n       588, 589, 590, 591, 592, 593, 594, 595]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 112, 114, 115, 116, 119,\n       122, 123, 124]), verbose=0, parameters={'learning_rate': 0.001, 'max_depth': 1, 'max_features': 0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 3}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method BaseGradientBoosting.fit of Gradie...=1.0, verbose=0,\n              warm_start=False)>\n        X_train =      Age  Age*Class  Age_Null_Flag  Cabin_Letter...         0           1  \n\n[476 rows x 43 columns]\n        y_train = 506    1.0\n530    1.0\n9      1.0\n22     1.0\n356 ...  0.0\nName: Survived, Length: 476, dtype: float64\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\n/home/yuki/.local/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py in fit(self=GradientBoostingClassifier(criterion='friedman_m...e=1.0, verbose=0,\n              warm_start=False), X=array([[2., 4., 0., ..., 0., 0., 1.],\n       [0....   [1., 1., 0., ..., 0., 0., 1.]], dtype=float32), y=array([1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1,...       1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0]), sample_weight=array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1...1., 1., 1., 1., 1., 1., 1.],\n      dtype=float32), monitor=None)\n   1029                 X_idx_sorted = np.asfortranarray(np.argsort(X, axis=0),\n   1030                                                  dtype=np.int32)\n   1031 \n   1032         # fit the boosting stages\n   1033         n_stages = self._fit_stages(X, y, y_pred, sample_weight, random_state,\n-> 1034                                     begin_at_stage, monitor, X_idx_sorted)\n        begin_at_stage = 0\n        monitor = None\n        X_idx_sorted = array([[ 58, 336,   0, ...,   0,   0, 237],\n    ... 48, 231, 167, ..., 237, 280, 475]], dtype=int32)\n   1035         # change shape of arrays after fit (early-stopping or additional ests)\n   1036         if n_stages != self.estimators_.shape[0]:\n   1037             self.estimators_ = self.estimators_[:n_stages]\n   1038             self.train_score_ = self.train_score_[:n_stages]\n\n...........................................................................\n/home/yuki/.local/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py in _fit_stages(self=GradientBoostingClassifier(criterion='friedman_m...e=1.0, verbose=0,\n              warm_start=False), X=array([[2., 4., 0., ..., 0., 0., 1.],\n       [0....   [1., 1., 0., ..., 0., 0., 1.]], dtype=float32), y=array([1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1,...       1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0]), y_pred=array([[-0.52429384],\n       [-0.52429384],\n    ...84],\n       [-0.52429384],\n       [-0.52429384]]), sample_weight=array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1...1., 1., 1., 1., 1., 1., 1.],\n      dtype=float32), random_state=<mtrand.RandomState object>, begin_at_stage=0, monitor=None, X_idx_sorted=array([[ 58, 336,   0, ...,   0,   0, 237],\n    ... 48, 231, 167, ..., 237, 280, 475]], dtype=int32))\n   1084                                       sample_weight[~sample_mask])\n   1085 \n   1086             # fit next stage of trees\n   1087             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n   1088                                      sample_mask, random_state, X_idx_sorted,\n-> 1089                                      X_csc, X_csr)\n        X_csc = None\n        X_csr = None\n   1090 \n   1091             # track deviance (= loss)\n   1092             if do_oob:\n   1093                 self.train_score_[i] = loss_(y[sample_mask],\n\n...........................................................................\n/home/yuki/.local/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py in _fit_stage(self=GradientBoostingClassifier(criterion='friedman_m...e=1.0, verbose=0,\n              warm_start=False), i=0, X=array([[2., 4., 0., ..., 0., 0., 1.],\n       [0....   [1., 1., 0., ..., 0., 0., 1.]], dtype=float32), y=array([1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1,...       1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0]), y_pred=array([[-0.52429384],\n       [-0.52429384],\n    ...84],\n       [-0.52429384],\n       [-0.52429384]]), sample_weight=array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1...1., 1., 1., 1., 1., 1., 1.],\n      dtype=float32), sample_mask=array([ True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True]), random_state=<mtrand.RandomState object>, X_idx_sorted=array([[ 58, 336,   0, ...,   0,   0, 237],\n    ... 48, 231, 167, ..., 237, 280, 475]], dtype=int32), X_csc=None, X_csr=None)\n    783             if X_csc is not None:\n    784                 tree.fit(X_csc, residual, sample_weight=sample_weight,\n    785                          check_input=False, X_idx_sorted=X_idx_sorted)\n    786             else:\n    787                 tree.fit(X, residual, sample_weight=sample_weight,\n--> 788                          check_input=False, X_idx_sorted=X_idx_sorted)\n        X_idx_sorted = array([[ 58, 336,   0, ...,   0,   0, 237],\n    ... 48, 231, 167, ..., 237, 280, 475]], dtype=int32)\n    789 \n    790             # update tree leaves\n    791             if X_csr is not None:\n    792                 loss.update_terminal_regions(tree.tree_, X_csr, y, residual, y_pred,\n\n...........................................................................\n/home/yuki/.local/lib/python3.6/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeRegressor(criterion='friedman_mse', ...t at 0x7ff30d7aa2d0>,\n           splitter='best'), X=array([[2., 4., 0., ..., 0., 0., 1.],\n       [0....   [1., 1., 0., ..., 0., 0., 1.]], dtype=float32), y=array([ 0.62815126,  0.62815126,  0.62815126,  0...4, -0.37184874,  0.62815126,\n       -0.37184874]), sample_weight=array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1...1., 1., 1., 1., 1., 1., 1.],\n      dtype=float32), check_input=False, X_idx_sorted=array([[ 58, 336,   0, ...,   0,   0, 237],\n    ... 48, 231, 167, ..., 237, 280, 475]], dtype=int32))\n   1119 \n   1120         super(DecisionTreeRegressor, self).fit(\n   1121             X, y,\n   1122             sample_weight=sample_weight,\n   1123             check_input=check_input,\n-> 1124             X_idx_sorted=X_idx_sorted)\n        X_idx_sorted = array([[ 58, 336,   0, ...,   0,   0, 237],\n    ... 48, 231, 167, ..., 237, 280, 475]], dtype=int32)\n   1125         return self\n   1126 \n   1127 \n   1128 class ExtraTreeClassifier(DecisionTreeClassifier):\n\n...........................................................................\n/home/yuki/.local/lib/python3.6/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeRegressor(criterion='friedman_mse', ...t at 0x7ff30d7aa2d0>,\n           splitter='best'), X=array([[2., 4., 0., ..., 0., 0., 1.],\n       [0....   [1., 1., 0., ..., 0., 0., 1.]], dtype=float32), y=array([[ 0.62815126],\n       [ 0.62815126],\n    ...74],\n       [ 0.62815126],\n       [-0.37184874]]), sample_weight=array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1...1., 1., 1., 1., 1., 1., 1.],\n      dtype=float32), check_input=False, X_idx_sorted=array([[ 58, 336,   0, ...,   0,   0, 237],\n    ... 48, 231, 167, ..., 237, 280, 475]], dtype=int32))\n    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:\n    238             raise ValueError(\"min_weight_fraction_leaf must in [0, 0.5]\")\n    239         if max_depth <= 0:\n    240             raise ValueError(\"max_depth must be greater than zero. \")\n    241         if not (0 < max_features <= self.n_features_):\n--> 242             raise ValueError(\"max_features must be in (0, n_features]\")\n    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):\n    244             raise ValueError(\"max_leaf_nodes must be integral number but was \"\n    245                              \"%r\" % max_leaf_nodes)\n    246         if -1 < max_leaf_nodes < 2:\n\nValueError: max_features must be in (0, n_features]\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-a11ccfbd15df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGradientBoostingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m plt.matshow(grid_search.cv_results_['mean_test_score'].reshape(6, -1),\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/home/yuki/anaconda3/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/home/yuki/anaconda3/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x7ff3493f1390, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/yuki/anaconda3/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/yuki/a.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7ff3493f1390, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/yuki/anaconda3/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/yuki/a.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/home/yuki/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    481         if self.poller is not None:\n    482             self.poller.start()\n    483         self.kernel.start()\n    484         self.io_loop = ioloop.IOLoop.current()\n    485         try:\n--> 486             self.io_loop.start()\n        self.io_loop.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    487         except KeyboardInterrupt:\n    488             pass\n    489 \n    490 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/yuki/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/home/yuki/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 5\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/home/yuki/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 5), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 5)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/yuki/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=5)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/home/yuki/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/home/yuki/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/home/yuki/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'param_grid = {\\'learning_rate\\': [0.001, 0.01, 0.1...rint(\"test: \", grid_search.score(X_test, y_test))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 3, 22, 22, 34, 29, 789330, tzinfo=tzutc()), 'msg_id': '1ea580e23447b3fe299833922ab84be4', 'msg_type': 'execute_request', 'session': 'b15e2f0d7eee1ed2d0a091f17000e414', 'username': '', 'version': '5.2'}, 'metadata': {}, 'msg_id': '1ea580e23447b3fe299833922ab84be4', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'b15e2f0d7eee1ed2d0a091f17000e414']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'param_grid = {\\'learning_rate\\': [0.001, 0.01, 0.1...rint(\"test: \", grid_search.score(X_test, y_test))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 3, 22, 22, 34, 29, 789330, tzinfo=tzutc()), 'msg_id': '1ea580e23447b3fe299833922ab84be4', 'msg_type': 'execute_request', 'session': 'b15e2f0d7eee1ed2d0a091f17000e414', 'username': '', 'version': '5.2'}, 'metadata': {}, 'msg_id': '1ea580e23447b3fe299833922ab84be4', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\n/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'b15e2f0d7eee1ed2d0a091f17000e414'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'param_grid = {\\'learning_rate\\': [0.001, 0.01, 0.1...rint(\"test: \", grid_search.score(X_test, y_test))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 3, 22, 22, 34, 29, 789330, tzinfo=tzutc()), 'msg_id': '1ea580e23447b3fe299833922ab84be4', 'msg_type': 'execute_request', 'session': 'b15e2f0d7eee1ed2d0a091f17000e414', 'username': '', 'version': '5.2'}, 'metadata': {}, 'msg_id': '1ea580e23447b3fe299833922ab84be4', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='param_grid = {\\'learning_rate\\': [0.001, 0.01, 0.1...rint(\"test: \", grid_search.score(X_test, y_test))', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'param_grid = {\\'learning_rate\\': [0.001, 0.01, 0.1...rint(\"test: \", grid_search.score(X_test, y_test))'\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\n/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('param_grid = {\\'learning_rate\\': [0.001, 0.01, 0.1...rint(\"test: \", grid_search.score(X_test, y_test))',), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('param_grid = {\\'learning_rate\\': [0.001, 0.01, 0.1...rint(\"test: \", grid_search.score(X_test, y_test))',)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\n/home/yuki/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='param_grid = {\\'learning_rate\\': [0.001, 0.01, 0.1...rint(\"test: \", grid_search.score(X_test, y_test))', store_history=True, silent=False, shell_futures=True)\n   2723                 self.displayhook.exec_result = result\n   2724 \n   2725                 # Execute the user code\n   2726                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2727                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2728                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2729                 \n   2730                 self.last_execution_succeeded = not has_raised\n   2731                 self.last_execution_result = result\n   2732 \n\n...........................................................................\n/home/yuki/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>], cell_name='<ipython-input-37-a11ccfbd15df>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7ff2f9355a58, executi..._before_exec=None error_in_exec=None result=None>)\n   2845 \n   2846         try:\n   2847             for i, node in enumerate(to_run_exec):\n   2848                 mod = ast.Module([node])\n   2849                 code = compiler(mod, cell_name, \"exec\")\n-> 2850                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7ff32e0ebf60, file \"<ipython-input-37-a11ccfbd15df>\", line 9>\n        result = <ExecutionResult object at 7ff2f9355a58, executi..._before_exec=None error_in_exec=None result=None>\n   2851                     return True\n   2852 \n   2853             for i, node in enumerate(to_run_interactive):\n   2854                 mod = ast.Interactive([node])\n\n...........................................................................\n/home/yuki/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7ff32e0ebf60, file \"<ipython-input-37-a11ccfbd15df>\", line 9>, result=<ExecutionResult object at 7ff2f9355a58, executi..._before_exec=None error_in_exec=None result=None>)\n   2905         outflag = True  # happens in more places, so it's easier as default\n   2906         try:\n   2907             try:\n   2908                 self.hooks.pre_run_code_hook()\n   2909                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2910                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7ff32e0ebf60, file \"<ipython-input-37-a11ccfbd15df>\", line 9>\n        self.user_global_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import time\\n\\n# data analysis and wrangling\\nimpor...omModel\\nfrom sklearn.feature_selection import RFE', \"train_df = pd.read_csv('../input/train.csv')\\ntes...../input/test.csv')\\ncombine = [train_df, test_df]\", \"train_df['Ticket_Len'] = train_df['Ticket'].appl...y(lambda x: len(x))\\ncombine = [train_df, test_df]\", 'train_df[\"Cabin_Letter\"] = train_df[\"Cabin\"].fil...ply(lambda x: x[0])\\ncombine = [train_df, test_df]', 'train_test_df = pd.concat((train_df, test_df))\\n\\n...pe, test_df.shape)\\n\\ncombine = [train_df, test_df]', \"for i in [train_df, test_df]:\\n    i['Cabin_num1'...'Cabin_num'] = pd.qcut(train_df['Cabin_num1'], 3)\", \"train_df = pd.concat((train_df, pd.get_dummies(t...f['Cabin_num'], prefix = 'Cabin_num')), axis = 1)\", \"del train_df['Cabin_num']\\ndel test_df['Cabin_num... train_df['Cabin_num1']\\ndel test_df['Cabin_num1']\", 'train_df.columns', \"# del Ticket, Cabin columns\\ntrain_df = train_df...., 'Cabin'], axis=1)\\ncombine = [train_df, test_df]\", \"# add title\\nfor dataset in combine:\\n    dataset[....Name.str.extract(' ([A-Za-z]+)\\\\.', expand=False)\", '# try one hote encoding without delete rare titl...pe, test_df.shape)\\n\\ncombine = [train_df, test_df]', 'train_df.columns', \"train_df['Name_Len'] = train_df['Name'].apply(la...y(lambda x: len(x))\\ncombine = [train_df, test_df]\", 'for dataset in combine:\\n    dataset[\"Sex\"] = dataset[\"Sex\"].map({\\'female\\':1, \\'male\\':0}).astype(int)', \"train_df['Age_Null_Flag'] = train_df['Age'].appl...d.isnull(x) else 0)\\ncombine = [train_df, test_df]\", \"guess_ages = np.zeros((2,3))\\n\\nfor dataset in com...\\n\\n    dataset['Age'] = dataset['Age'].astype(int)\", \"train_df['AgeBand'] = pd.cut(train_df['Age'], 5)\", \"for dataset in combine:\\n    dataset.loc[ dataset...'AgeBand'], axis=1)\\ncombine = [train_df, test_df]\", ...], 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'LinearSVC': <class 'sklearn.svm.classes.LinearSVC'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MinMaxScaler': <class 'sklearn.preprocessing.data.MinMaxScaler'>, ...}\n        self.user_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import time\\n\\n# data analysis and wrangling\\nimpor...omModel\\nfrom sklearn.feature_selection import RFE', \"train_df = pd.read_csv('../input/train.csv')\\ntes...../input/test.csv')\\ncombine = [train_df, test_df]\", \"train_df['Ticket_Len'] = train_df['Ticket'].appl...y(lambda x: len(x))\\ncombine = [train_df, test_df]\", 'train_df[\"Cabin_Letter\"] = train_df[\"Cabin\"].fil...ply(lambda x: x[0])\\ncombine = [train_df, test_df]', 'train_test_df = pd.concat((train_df, test_df))\\n\\n...pe, test_df.shape)\\n\\ncombine = [train_df, test_df]', \"for i in [train_df, test_df]:\\n    i['Cabin_num1'...'Cabin_num'] = pd.qcut(train_df['Cabin_num1'], 3)\", \"train_df = pd.concat((train_df, pd.get_dummies(t...f['Cabin_num'], prefix = 'Cabin_num')), axis = 1)\", \"del train_df['Cabin_num']\\ndel test_df['Cabin_num... train_df['Cabin_num1']\\ndel test_df['Cabin_num1']\", 'train_df.columns', \"# del Ticket, Cabin columns\\ntrain_df = train_df...., 'Cabin'], axis=1)\\ncombine = [train_df, test_df]\", \"# add title\\nfor dataset in combine:\\n    dataset[....Name.str.extract(' ([A-Za-z]+)\\\\.', expand=False)\", '# try one hote encoding without delete rare titl...pe, test_df.shape)\\n\\ncombine = [train_df, test_df]', 'train_df.columns', \"train_df['Name_Len'] = train_df['Name'].apply(la...y(lambda x: len(x))\\ncombine = [train_df, test_df]\", 'for dataset in combine:\\n    dataset[\"Sex\"] = dataset[\"Sex\"].map({\\'female\\':1, \\'male\\':0}).astype(int)', \"train_df['Age_Null_Flag'] = train_df['Age'].appl...d.isnull(x) else 0)\\ncombine = [train_df, test_df]\", \"guess_ages = np.zeros((2,3))\\n\\nfor dataset in com...\\n\\n    dataset['Age'] = dataset['Age'].astype(int)\", \"train_df['AgeBand'] = pd.cut(train_df['Age'], 5)\", \"for dataset in combine:\\n    dataset.loc[ dataset...'AgeBand'], axis=1)\\ncombine = [train_df, test_df]\", ...], 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'LinearSVC': <class 'sklearn.svm.classes.LinearSVC'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MinMaxScaler': <class 'sklearn.preprocessing.data.MinMaxScaler'>, ...}\n   2911             finally:\n   2912                 # Reset our crash handler in place\n   2913                 sys.excepthook = old_excepthook\n   2914         except SystemExit as e:\n\n...........................................................................\n/home/yuki/github/test/kaggle/titanic/src/<ipython-input-37-a11ccfbd15df> in <module>()\n      4               'min_samples_leaf': [1, 3, 5, 9, 17],\n      5               'max_depth':[1,2,3,4,5,6],\n      6               'max_features': [1, 'auto', 'sqrt', 'log2', 0.5, 0,7, 0.9],}\n      7 \n      8 grid_search = GridSearchCV(GradientBoostingClassifier(), param_grid, cv=5, n_jobs=3)\n----> 9 grid_search.fit(X_train, y_train)\n     10 \n     11 plt.matshow(grid_search.cv_results_['mean_test_score'].reshape(6, -1),\n     12             vmin=0, cmap=\"viridis\")\n     13 plt.xlabel(\"n_estimators\")\n\n...........................................................................\n/home/yuki/.local/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=5, error_score='raise',\n       e...ain_score='warn',\n       scoring=None, verbose=0), X=     Age  Age*Class  Age_Null_Flag  Cabin_Letter...         0           1  \n\n[596 rows x 43 columns], y=6      0.0\n718    0.0\n685    0.0\n73     0.0\n882 ...  0.0\nName: Survived, Length: 596, dtype: float64, groups=None, **fit_params={})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=5, random_state=None, shuffle=False)>\n        X =      Age  Age*Class  Age_Null_Flag  Cabin_Letter...         0           1  \n\n[596 rows x 43 columns]\n        y = 6      0.0\n718    0.0\n685    0.0\n73     0.0\n882 ...  0.0\nName: Survived, Length: 596, dtype: float64\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\n/home/yuki/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=3), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=3)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Fri Mar 23 07:47:09 2018\nPID: 8686                     Python 3.6.4: /home/yuki/anaconda3/bin/python\n...........................................................................\n/home/yuki/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (GradientBoostingClassifier(criterion='friedman_m...e=1.0, verbose=0,\n              warm_start=False),      Age  Age*Class  Age_Null_Flag  Cabin_Letter...         0           1  \n\n[596 rows x 43 columns], 6      0.0\n718    0.0\n685    0.0\n73     0.0\n882 ...  0.0\nName: Survived, Length: 596, dtype: float64, {'score': <function _passthrough_scorer>}, array([  0,   1,   2,   3,   4,   5,   6,   7,  ...70, 472, 473, 475, 476, 477, 478, 479, 482, 484]), array([468, 469, 471, 474, 480, 481, 483, 485, 4..., 588, 589, 590, 591, 592, 593, 594,\n       595]), 0, {'learning_rate': 0.001, 'max_depth': 1, 'max_features': 0.5, 'min_samples_leaf': 17, 'min_samples_split': 5, 'n_estimators': 1000}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}), (<function _fit_and_score>, (GradientBoostingClassifier(criterion='friedman_m...e=1.0, verbose=0,\n              warm_start=False),      Age  Age*Class  Age_Null_Flag  Cabin_Letter...         0           1  \n\n[596 rows x 43 columns], 6      0.0\n718    0.0\n685    0.0\n73     0.0\n882 ...  0.0\nName: Survived, Length: 596, dtype: float64, {'score': <function _passthrough_scorer>}, array([113, 117, 118, 120, 121, 125, 126, 127, 1...,\n       588, 589, 590, 591, 592, 593, 594, 595]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 112, 114, 115, 116, 119,\n       122, 123, 124]), 0, {'learning_rate': 0.001, 'max_depth': 1, 'max_features': 0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 3}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}), (<function _fit_and_score>, (GradientBoostingClassifier(criterion='friedman_m...e=1.0, verbose=0,\n              warm_start=False),      Age  Age*Class  Age_Null_Flag  Cabin_Letter...         0           1  \n\n[596 rows x 43 columns], 6      0.0\n718    0.0\n685    0.0\n73     0.0\n882 ...  0.0\nName: Survived, Length: 596, dtype: float64, {'score': <function _passthrough_scorer>}, array([  0,   1,   2,   3,   4,   5,   6,   7,  ...,\n       588, 589, 590, 591, 592, 593, 594, 595]), array([113, 117, 118, 120, 121, 125, 126, 127, 1..., 232, 233, 234, 235, 237,\n       238, 239, 240]), 0, {'learning_rate': 0.001, 'max_depth': 1, 'max_features': 0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 3}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}), (<function _fit_and_score>, (GradientBoostingClassifier(criterion='friedman_m...e=1.0, verbose=0,\n              warm_start=False),      Age  Age*Class  Age_Null_Flag  Cabin_Letter...         0           1  \n\n[596 rows x 43 columns], 6      0.0\n718    0.0\n685    0.0\n73     0.0\n882 ...  0.0\nName: Survived, Length: 596, dtype: float64, {'score': <function _passthrough_scorer>}, array([  0,   1,   2,   3,   4,   5,   6,   7,  ...    587, 588, 589, 590, 591, 592, 593, 594, 595]), array([236, 241, 242, 243, 244, 245, 246, 247, 2..., 351, 352, 353, 355, 357, 359,\n       360, 361]), 0, {'learning_rate': 0.001, 'max_depth': 1, 'max_features': 0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 3}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/yuki/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (GradientBoostingClassifier(criterion='friedman_m...e=1.0, verbose=0,\n              warm_start=False),      Age  Age*Class  Age_Null_Flag  Cabin_Letter...         0           1  \n\n[596 rows x 43 columns], 6      0.0\n718    0.0\n685    0.0\n73     0.0\n882 ...  0.0\nName: Survived, Length: 596, dtype: float64, {'score': <function _passthrough_scorer>}, array([113, 117, 118, 120, 121, 125, 126, 127, 1...,\n       588, 589, 590, 591, 592, 593, 594, 595]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 112, 114, 115, 116, 119,\n       122, 123, 124]), 0, {'learning_rate': 0.001, 'max_depth': 1, 'max_features': 0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 3})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/yuki/.local/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=GradientBoostingClassifier(criterion='friedman_m...e=1.0, verbose=0,\n              warm_start=False), X=     Age  Age*Class  Age_Null_Flag  Cabin_Letter...         0           1  \n\n[596 rows x 43 columns], y=6      0.0\n718    0.0\n685    0.0\n73     0.0\n882 ...  0.0\nName: Survived, Length: 596, dtype: float64, scorer={'score': <function _passthrough_scorer>}, train=array([113, 117, 118, 120, 121, 125, 126, 127, 1...,\n       588, 589, 590, 591, 592, 593, 594, 595]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 112, 114, 115, 116, 119,\n       122, 123, 124]), verbose=0, parameters={'learning_rate': 0.001, 'max_depth': 1, 'max_features': 0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 3}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method BaseGradientBoosting.fit of Gradie...=1.0, verbose=0,\n              warm_start=False)>\n        X_train =      Age  Age*Class  Age_Null_Flag  Cabin_Letter...         0           1  \n\n[476 rows x 43 columns]\n        y_train = 506    1.0\n530    1.0\n9      1.0\n22     1.0\n356 ...  0.0\nName: Survived, Length: 476, dtype: float64\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\n/home/yuki/.local/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py in fit(self=GradientBoostingClassifier(criterion='friedman_m...e=1.0, verbose=0,\n              warm_start=False), X=array([[2., 4., 0., ..., 0., 0., 1.],\n       [0....   [1., 1., 0., ..., 0., 0., 1.]], dtype=float32), y=array([1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1,...       1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0]), sample_weight=array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1...1., 1., 1., 1., 1., 1., 1.],\n      dtype=float32), monitor=None)\n   1029                 X_idx_sorted = np.asfortranarray(np.argsort(X, axis=0),\n   1030                                                  dtype=np.int32)\n   1031 \n   1032         # fit the boosting stages\n   1033         n_stages = self._fit_stages(X, y, y_pred, sample_weight, random_state,\n-> 1034                                     begin_at_stage, monitor, X_idx_sorted)\n        begin_at_stage = 0\n        monitor = None\n        X_idx_sorted = array([[ 58, 336,   0, ...,   0,   0, 237],\n    ... 48, 231, 167, ..., 237, 280, 475]], dtype=int32)\n   1035         # change shape of arrays after fit (early-stopping or additional ests)\n   1036         if n_stages != self.estimators_.shape[0]:\n   1037             self.estimators_ = self.estimators_[:n_stages]\n   1038             self.train_score_ = self.train_score_[:n_stages]\n\n...........................................................................\n/home/yuki/.local/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py in _fit_stages(self=GradientBoostingClassifier(criterion='friedman_m...e=1.0, verbose=0,\n              warm_start=False), X=array([[2., 4., 0., ..., 0., 0., 1.],\n       [0....   [1., 1., 0., ..., 0., 0., 1.]], dtype=float32), y=array([1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1,...       1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0]), y_pred=array([[-0.52429384],\n       [-0.52429384],\n    ...84],\n       [-0.52429384],\n       [-0.52429384]]), sample_weight=array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1...1., 1., 1., 1., 1., 1., 1.],\n      dtype=float32), random_state=<mtrand.RandomState object>, begin_at_stage=0, monitor=None, X_idx_sorted=array([[ 58, 336,   0, ...,   0,   0, 237],\n    ... 48, 231, 167, ..., 237, 280, 475]], dtype=int32))\n   1084                                       sample_weight[~sample_mask])\n   1085 \n   1086             # fit next stage of trees\n   1087             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n   1088                                      sample_mask, random_state, X_idx_sorted,\n-> 1089                                      X_csc, X_csr)\n        X_csc = None\n        X_csr = None\n   1090 \n   1091             # track deviance (= loss)\n   1092             if do_oob:\n   1093                 self.train_score_[i] = loss_(y[sample_mask],\n\n...........................................................................\n/home/yuki/.local/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py in _fit_stage(self=GradientBoostingClassifier(criterion='friedman_m...e=1.0, verbose=0,\n              warm_start=False), i=0, X=array([[2., 4., 0., ..., 0., 0., 1.],\n       [0....   [1., 1., 0., ..., 0., 0., 1.]], dtype=float32), y=array([1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1,...       1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0]), y_pred=array([[-0.52429384],\n       [-0.52429384],\n    ...84],\n       [-0.52429384],\n       [-0.52429384]]), sample_weight=array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1...1., 1., 1., 1., 1., 1., 1.],\n      dtype=float32), sample_mask=array([ True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True]), random_state=<mtrand.RandomState object>, X_idx_sorted=array([[ 58, 336,   0, ...,   0,   0, 237],\n    ... 48, 231, 167, ..., 237, 280, 475]], dtype=int32), X_csc=None, X_csr=None)\n    783             if X_csc is not None:\n    784                 tree.fit(X_csc, residual, sample_weight=sample_weight,\n    785                          check_input=False, X_idx_sorted=X_idx_sorted)\n    786             else:\n    787                 tree.fit(X, residual, sample_weight=sample_weight,\n--> 788                          check_input=False, X_idx_sorted=X_idx_sorted)\n        X_idx_sorted = array([[ 58, 336,   0, ...,   0,   0, 237],\n    ... 48, 231, 167, ..., 237, 280, 475]], dtype=int32)\n    789 \n    790             # update tree leaves\n    791             if X_csr is not None:\n    792                 loss.update_terminal_regions(tree.tree_, X_csr, y, residual, y_pred,\n\n...........................................................................\n/home/yuki/.local/lib/python3.6/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeRegressor(criterion='friedman_mse', ...t at 0x7ff30d7aa2d0>,\n           splitter='best'), X=array([[2., 4., 0., ..., 0., 0., 1.],\n       [0....   [1., 1., 0., ..., 0., 0., 1.]], dtype=float32), y=array([ 0.62815126,  0.62815126,  0.62815126,  0...4, -0.37184874,  0.62815126,\n       -0.37184874]), sample_weight=array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1...1., 1., 1., 1., 1., 1., 1.],\n      dtype=float32), check_input=False, X_idx_sorted=array([[ 58, 336,   0, ...,   0,   0, 237],\n    ... 48, 231, 167, ..., 237, 280, 475]], dtype=int32))\n   1119 \n   1120         super(DecisionTreeRegressor, self).fit(\n   1121             X, y,\n   1122             sample_weight=sample_weight,\n   1123             check_input=check_input,\n-> 1124             X_idx_sorted=X_idx_sorted)\n        X_idx_sorted = array([[ 58, 336,   0, ...,   0,   0, 237],\n    ... 48, 231, 167, ..., 237, 280, 475]], dtype=int32)\n   1125         return self\n   1126 \n   1127 \n   1128 class ExtraTreeClassifier(DecisionTreeClassifier):\n\n...........................................................................\n/home/yuki/.local/lib/python3.6/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeRegressor(criterion='friedman_mse', ...t at 0x7ff30d7aa2d0>,\n           splitter='best'), X=array([[2., 4., 0., ..., 0., 0., 1.],\n       [0....   [1., 1., 0., ..., 0., 0., 1.]], dtype=float32), y=array([[ 0.62815126],\n       [ 0.62815126],\n    ...74],\n       [ 0.62815126],\n       [-0.37184874]]), sample_weight=array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1...1., 1., 1., 1., 1., 1., 1.],\n      dtype=float32), check_input=False, X_idx_sorted=array([[ 58, 336,   0, ...,   0,   0, 237],\n    ... 48, 231, 167, ..., 237, 280, 475]], dtype=int32))\n    237         if not 0 <= self.min_weight_fraction_leaf <= 0.5:\n    238             raise ValueError(\"min_weight_fraction_leaf must in [0, 0.5]\")\n    239         if max_depth <= 0:\n    240             raise ValueError(\"max_depth must be greater than zero. \")\n    241         if not (0 < max_features <= self.n_features_):\n--> 242             raise ValueError(\"max_features must be in (0, n_features]\")\n    243         if not isinstance(max_leaf_nodes, (numbers.Integral, np.integer)):\n    244             raise ValueError(\"max_leaf_nodes must be integral number but was \"\n    245                              \"%r\" % max_leaf_nodes)\n    246         if -1 < max_leaf_nodes < 2:\n\nValueError: max_features must be in (0, n_features]\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "param_grid = {'learning_rate': [0.001, 0.01, 0.1, 1, 10],\n",
    "              'n_estimators': [3, 5, 7, 10, 50, 100, 200, 400, 500, 600, 700, 800, 1000],\n",
    "              'min_samples_split':[2, 3, 4, 5],\n",
    "              'min_samples_leaf': [1, 3, 5, 9, 17],\n",
    "              'max_depth':[1,2,3,4,5,6],\n",
    "              'max_features': [1, 'auto', 'sqrt', 'log2', 0.5, 0,7, 0.9],}\n",
    "\n",
    "grid_search = GridSearchCV(GradientBoostingClassifier(), param_grid, cv=5, n_jobs=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "plt.matshow(grid_search.cv_results_['mean_test_score'].reshape(6, -1),\n",
    "            vmin=0, cmap=\"viridis\")\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.ylabel(\"learning_rate\")\n",
    "plt.xticks(range(len(param_grid['n_estimators'])), param_grid['n_estimators'])\n",
    "plt.yticks(range(len(param_grid['learning_rate'])), param_grid['learning_rate'])\n",
    "plt.colorbar()\n",
    "\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# output of upper code\n",
    "\n",
    "Mean cross-validated score of the best_estimator:  0.828859060403\n",
    "best parameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200}\n",
    "test:  0.837288135593"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(GradientBoostingClassifier(learning_rate=0.1, \n",
    "                                            max_depth=2,\n",
    "                                            n_estimators=700))\n",
    "pipe.fit(X_train, y_train)\n",
    "print(\"test: \", pipe.score(X_test, y_test))\n",
    "\n",
    "scores = cross_val_score(pipe, X_train_df, y_train_df, n_jobs=3)\n",
    "print(\"mean of cross val score for X_train_df: \", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat((pd.DataFrame(X_train.columns, columns = ['variable']), \n",
    "           pd.DataFrame(pipe.named_steps[\"gradientboostingclassifier\"].feature_importances_, columns = ['importance'])), \n",
    "          axis = 1).sort_values(by='importance', ascending = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
