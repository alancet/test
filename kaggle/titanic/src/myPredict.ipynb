{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# data analysis and wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# train, test, validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "\n",
    "# scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "# decomposition\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "# feature engineering\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# feature selection\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    \"\"\"Utility function to report best scores\n",
    "    \"\"\"\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Rank: {0}\".format(i))\n",
    "            print(\"Score: {0:f} (std: {1:f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Pars: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "            \n",
    "\n",
    "def report2(results, n_top=3):\n",
    "    \"\"\"Utility function to report best scores\n",
    "    \"\"\"\n",
    "    print(\"Rank|Score(std)|Params\", list(results['params'][0].keys()))\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"{0}|\".format(i), end=\"\")\n",
    "            print(\"{0:f}(std:{1:f})|\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]), end=\"\")\n",
    "            print(\"{0}\".format(list(results['params'][candidate].values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../input/train.csv')\n",
    "test_df = pd.read_csv('../input/test.csv')\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# modify features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make ticket length feature\n",
    "https://www.kaggle.com/yuanxuan/titanic-random-forest-82-78/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Ticket_Len'] = train_df['Ticket'].apply(lambda x: len(x))\n",
    "test_df['Ticket_Len'] = test_df['Ticket'].apply(lambda x: len(x))\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.barplot(data=train_df, x=\"Ticket_Len\", y=\"Survived\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df['Ticket_Len'].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_df['Ticket_Len'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make Cabin First character feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Cabin_Letter\"] = train_df[\"Cabin\"].fillna('0').apply(lambda x: x[0])\n",
    "test_df[\"Cabin_Letter\"] = test_df[\"Cabin\"].fillna('0').apply(lambda x: x[0])\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.barplot(data=train_df, x=\"Cabin_Letter\", y=\"Survived\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.groupby(\"Cabin_Letter\").Survived.value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df[\"Cabin_Letter\"].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.barplot(data=train_df, x=\"Cabin_Letter\", y=\"Survived\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_df[\"Cabin_Letter\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make one Cabin_Letter feature by numerical"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_test_df = pd.concat((train_df, test_df))\n",
    "train_test_df.Cabin_Letter.value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cabin_letter_map = {'0': 0, 'A': 1, 'B': 2,\n",
    "                   'C':3, 'D':4, 'E':5,\n",
    "                   'F':6, 'G':7, 'T':8}\n",
    "for dataset in combine:\n",
    "    dataset['Cabin_Letter'] = dataset['Cabin_Letter'].map(cabin_letter_map).astype(int)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make dummy variable for Cabin_Letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1309, 14)\n",
      "(891, 22) (418, 21)\n"
     ]
    }
   ],
   "source": [
    "train_test_df = pd.concat((train_df, test_df))\n",
    "\n",
    "print(train_test_df.shape)\n",
    "\n",
    "# apply get_dummies for Cabin_Letter\n",
    "train_test_df = pd.get_dummies(train_test_df, columns=[\"Cabin_Letter\"])\n",
    "\n",
    "#train_test_df.head()\n",
    "train_df = train_test_df.iloc[:train_df.shape[0]]\n",
    "test_df = train_test_df.iloc[train_df.shape[0]:]\n",
    "\n",
    "# drop added Survived column from test_df\n",
    "test_df = test_df.drop(\"Survived\", axis=1)\n",
    "print(train_df.shape, test_df.shape)\n",
    "\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**if you made Cabin_num features too, duplicate feature for NaN. delete one of these**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df = train_df.drop(\"Cabin_Letter_0\", axis=1)\n",
    "test_df = test_df.drop(\"Cabin_Letter_0\", axis=1)\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>...</th>\n",
       "      <th>Ticket_Len</th>\n",
       "      <th>Cabin_Letter_0</th>\n",
       "      <th>Cabin_Letter_A</th>\n",
       "      <th>Cabin_Letter_B</th>\n",
       "      <th>Cabin_Letter_C</th>\n",
       "      <th>Cabin_Letter_D</th>\n",
       "      <th>Cabin_Letter_E</th>\n",
       "      <th>Cabin_Letter_F</th>\n",
       "      <th>Cabin_Letter_G</th>\n",
       "      <th>Cabin_Letter_T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age Cabin Embarked     Fare  \\\n",
       "0  22.0   NaN        S   7.2500   \n",
       "1  38.0   C85        C  71.2833   \n",
       "2  26.0   NaN        S   7.9250   \n",
       "3  35.0  C123        S  53.1000   \n",
       "4  35.0   NaN        S   8.0500   \n",
       "\n",
       "                                                Name  Parch  PassengerId  \\\n",
       "0                            Braund, Mr. Owen Harris      0            1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...      0            2   \n",
       "2                             Heikkinen, Miss. Laina      0            3   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)      0            4   \n",
       "4                           Allen, Mr. William Henry      0            5   \n",
       "\n",
       "   Pclass     Sex  SibSp       ...        Ticket_Len Cabin_Letter_0  \\\n",
       "0       3    male      1       ...                 9              1   \n",
       "1       1  female      1       ...                 8              0   \n",
       "2       3  female      0       ...                16              1   \n",
       "3       1  female      1       ...                 6              0   \n",
       "4       3    male      0       ...                 6              1   \n",
       "\n",
       "   Cabin_Letter_A  Cabin_Letter_B  Cabin_Letter_C  Cabin_Letter_D  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               1               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               1               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   Cabin_Letter_E  Cabin_Letter_F  Cabin_Letter_G  Cabin_Letter_T  \n",
       "0               0               0               0               0  \n",
       "1               0               0               0               0  \n",
       "2               0               0               0               0  \n",
       "3               0               0               0               0  \n",
       "4               0               0               0               0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 691,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Cabin', 'Embarked', 'Fare', 'Name', 'Parch', 'PassengerId',\n",
       "       'Pclass', 'Sex', 'SibSp', 'Survived', 'Ticket', 'Ticket_Len',\n",
       "       'Cabin_Letter_0', 'Cabin_Letter_A', 'Cabin_Letter_B', 'Cabin_Letter_C',\n",
       "       'Cabin_Letter_D', 'Cabin_Letter_E', 'Cabin_Letter_F', 'Cabin_Letter_G',\n",
       "       'Cabin_Letter_T'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 692,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>...</th>\n",
       "      <th>Ticket_Len</th>\n",
       "      <th>Cabin_Letter_0</th>\n",
       "      <th>Cabin_Letter_A</th>\n",
       "      <th>Cabin_Letter_B</th>\n",
       "      <th>Cabin_Letter_C</th>\n",
       "      <th>Cabin_Letter_D</th>\n",
       "      <th>Cabin_Letter_E</th>\n",
       "      <th>Cabin_Letter_F</th>\n",
       "      <th>Cabin_Letter_G</th>\n",
       "      <th>Cabin_Letter_T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>0</td>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>0</td>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>0</td>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>0</td>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>1</td>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age Cabin Embarked     Fare                                          Name  \\\n",
       "0  34.5   NaN        Q   7.8292                              Kelly, Mr. James   \n",
       "1  47.0   NaN        S   7.0000              Wilkes, Mrs. James (Ellen Needs)   \n",
       "2  62.0   NaN        Q   9.6875                     Myles, Mr. Thomas Francis   \n",
       "3  27.0   NaN        S   8.6625                              Wirz, Mr. Albert   \n",
       "4  22.0   NaN        S  12.2875  Hirvonen, Mrs. Alexander (Helga E Lindqvist)   \n",
       "\n",
       "   Parch  PassengerId  Pclass     Sex  SibSp       ...       Ticket_Len  \\\n",
       "0      0          892       3    male      0       ...                6   \n",
       "1      0          893       3  female      1       ...                6   \n",
       "2      0          894       2    male      0       ...                6   \n",
       "3      0          895       3    male      0       ...                6   \n",
       "4      1          896       3  female      1       ...                7   \n",
       "\n",
       "   Cabin_Letter_0  Cabin_Letter_A  Cabin_Letter_B  Cabin_Letter_C  \\\n",
       "0               1               0               0               0   \n",
       "1               1               0               0               0   \n",
       "2               1               0               0               0   \n",
       "3               1               0               0               0   \n",
       "4               1               0               0               0   \n",
       "\n",
       "   Cabin_Letter_D  Cabin_Letter_E  Cabin_Letter_F  Cabin_Letter_G  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   Cabin_Letter_T  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 693,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make CabinBool feature\n",
    "**I think the idea here is that people with recorded cabin numbers are of higher socioeconomic class, and thus more likely to survive. **\n",
    "https://www.kaggle.com/nadintamer/titanic-survival-predictions-beginner\n",
    "\n",
    "- I tried it\n",
    "  - but gradient boosting result became worse. from 0.79904 to 0.77990\n",
    "  - more than cabinbool is necessary? should i use first letter of cabin name?\n",
    "\n",
    "**CabinBool is inclueded in Cabin letter and cabin number**\n",
    "**no need to use**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df[\"CabinBool\"] = (train_df[\"Cabin\"].notnull().astype('int'))\n",
    "test_df[\"CabinBool\"] = (test_df[\"Cabin\"].notnull().astype('int'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make Cabin number feature\n",
    "https://www.kaggle.com/yuanxuan/titanic-random-forest-82-78/notebook"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df['Cabin'].apply(lambda x: str(x).split(' ')[-1][1:]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/yuki/.local/lib/python3.6/site-packages/pandas/core/generic.py:4619: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "for i in [train_df, test_df]:\n",
    "    i['Cabin_num1'] = i['Cabin'].apply(lambda x: str(x).split(' ')[-1][1:])\n",
    "    i['Cabin_num1'].replace('an', np.NaN, inplace = True)\n",
    "    i['Cabin_num1'] = i['Cabin_num1'].apply(lambda x: int(x) if not pd.isnull(x) and x != '' else np.NaN)\n",
    "    i['Cabin_num'] = pd.qcut(train_df['Cabin_num1'], 3)\n",
    "    i['Cabin_num'] = i['Cabin_num'].cat.add_categories([\"nan_category\"])\n",
    "    i['Cabin_num'] = i['Cabin_num'].fillna(\"nan_category\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat((train_df, pd.get_dummies(train_df['Cabin_num'], prefix='Cabin_num')), axis = 1)\n",
    "test_df = pd.concat((test_df, pd.get_dummies(test_df['Cabin_num'], prefix='Cabin_num')), axis = 1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.barplot(data=train_df, x=\"Cabin_num\", y=\"Survived\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.groupby([\"Cabin_num\"])[\"Survived\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_df['Cabin_num']\n",
    "del test_df['Cabin_num']\n",
    "del train_df['Cabin_num1']\n",
    "del test_df['Cabin_num1']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df[['Cabin_num_(1.999, 28.667]', \n",
    "          'Cabin_num_(28.667, 65.667]',\n",
    "          'Cabin_num_(65.667, 148.0]']].head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df[[\"Cabin_Letter_0\", \"Cabin_num_nan_category\"]].head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## del Ticket, Cabin columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del Ticket, Cabin columns\n",
    "train_df = train_df.drop(['Ticket', 'Cabin'], axis=1)\n",
    "test_df = test_df.drop(['Ticket', 'Cabin'], axis=1)\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add title\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.barplot(data=train_df, x=\"Title\", y=\"Survived\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.Title.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make name length feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Name_Len'] = train_df['Name'].apply(lambda x: len(x))\n",
    "test_df['Name_Len'] = test_df['Name'].apply(lambda x: len(x))\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df[\"Name_Len\"].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.barplot(data=train_df, x=\"Name_Len\", y=\"Survived\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.groupby(\"Name_Len\").Survived.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## map value to Sex "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in combine:\n",
    "    dataset[\"Sex\"] = dataset[\"Sex\"].map({'female':1, 'male':0}).astype(int)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make Age_Null_Flag if the Age is nulll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Age_Null_Flag'] = train_df['Age'].apply(lambda x: 1 if pd.isnull(x) else 0)\n",
    "test_df['Age_Null_Flag'] = test_df['Age'].apply(lambda x: 1 if pd.isnull(x) else 0)\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.barplot(data=train_df, x=\"Age_Null_Flag\", y=\"Survived\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df[\"Age_Null_Flag\"].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_df[\"Age_Null_Flag\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fill na of Age\n",
    "\n",
    "options\n",
    "\n",
    "- by Sex and Pclass\n",
    "- by Title and Pclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### by Sex and Pclass"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "guess_ages = np.zeros((2,3))\n",
    "\n",
    "for dataset in combine:\n",
    "    for i in range(0, 2):\n",
    "        for j in range(0, 3):\n",
    "            guess_df = dataset[(dataset['Sex'] == i) & \\\n",
    "                                  (dataset['Pclass'] == j+1)]['Age'].dropna()\n",
    "\n",
    "            # age_mean = guess_df.mean()\n",
    "            # age_std = guess_df.std()\n",
    "            # age_guess = rnd.uniform(age_mean - age_std, age_mean + age_std)\n",
    "\n",
    "            age_guess = guess_df.median()\n",
    "\n",
    "            # Convert random age float to nearest .5 age\n",
    "            guess_ages[i,j] = int( age_guess/0.5 + 0.5 ) * 0.5\n",
    "            \n",
    "    for i in range(0, 2):\n",
    "        for j in range(0, 3):\n",
    "            dataset.loc[ (dataset.Age.isnull()) & (dataset.Sex == i) & (dataset.Pclass == j+1),\\\n",
    "                    'Age'] = guess_ages[i,j]\n",
    "\n",
    "    dataset['Age'] = dataset['Age'].astype(int)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.barplot(data=train_df, x=\"Age\", y=\"Survived\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fill nan of Age by Title and Pclass\n",
    "https://www.kaggle.com/yuanxuan/titanic-random-forest-82-78/notebook\n",
    "\n",
    "There is mistake in the original notebook.\n",
    "test_df was filled by train_df.\n",
    "So I modified."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "groupedAge_train = train_df.groupby(['Title', 'Pclass'])['Age']\n",
    "groupedAge_train.mean()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_test_df = pd.concat((train_df, test_df))\n",
    "groupedAge_train_test = train_test_df.groupby(['Title', 'Pclass'])['Age']\n",
    "filledAge = groupedAge_train_test.transform(lambda x:x.fillna(x.mean()))\n",
    "train_test_df[filledAge.isna()]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "groupedByTitleOnly_Age_train_test = train_test_df.groupby(['Title'])['Age']\n",
    "groupedByTitleOnly_Age_train_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_df = pd.concat((train_df, test_df))\n",
    "groupedAge_train_test = train_test_df.groupby(['Title', 'Pclass'])['Age']\n",
    "train_test_df.Age = groupedAge_train_test.transform(lambda x:x.fillna(x.mean()))\n",
    "\n",
    "groupedByTitleOnly_Age_train_test = train_test_df.groupby(['Title'])['Age']\n",
    "train_test_df.Age = groupedByTitleOnly_Age_train_test.transform(lambda x:x.fillna(x.mean()))\n",
    "\n",
    "train_df = train_test_df.iloc[:train_df.shape[0]]\n",
    "test_df = train_test_df.iloc[train_df.shape[0]:]\n",
    "\n",
    "combine = [train_df, test_df]\n",
    "test_df = test_df.drop([\"Survived\"], axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "groupedAge_train_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 703,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_df.Age.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((891, 27), (418, 26))"
      ]
     },
     "execution_count": 704,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head(30)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_df.head(30)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.isna().any()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_df.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tried keep Age feature and don't add AgeBand numerical feature\n",
    "if both are there, it is duplicate information\n",
    "\n",
    "#### 2018/03/17 tried Age instead of Age band. But AgeBand is better score for almost all models.\n",
    "svc score was same of little bit better.\n",
    "random forest score became worse.\n",
    "so AgeBand is better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add age band\n",
    "\n",
    "- 5 age band by pd.cut\n",
    "- 10 age band by pd.cut: this is better score.\n",
    "\n",
    "if i use pd.qcut, band become too short for young adult around 25."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pd.cut(train_df['Age'], 10).value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df['AgeBand'] = pd.cut(train_df['Age'], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "train_df['AgeBand'] = pd.cut(train_df['Age'], 10)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.barplot(x=\"AgeBand\", data=train_df, y=\"Survived\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overwrite AgeBand number on Age. means, drop Age and AgeBand text column"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 5 age band\n",
    "for dataset in combine:\n",
    "    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n",
    "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
    "    dataset.loc[ dataset['Age'] > 64, 'Age'] = 4\n",
    "train_df = train_df.drop(['AgeBand'], axis=1)\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuki/.local/lib/python3.6/site-packages/pandas/core/indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n(24.0, 32.0]    275\\n(16.0, 24.0]    220\\n(32.0, 40.0]    148\\n(40.0, 48.0]     68\\n(-0.08, 8.0]     54\\n(8.0, 16.0]      46\\n(48.0, 56.0]     45\\n(56.0, 64.0]     24\\n(64.0, 72.0]      9\\n(72.0, 80.0]      2\\n'"
      ]
     },
     "execution_count": 706,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10 age band\n",
    "for dataset in combine:\n",
    "    dataset.loc[ dataset['Age'] <= 8, 'Age'] = 0\n",
    "    dataset.loc[(dataset['Age'] > 8) & (dataset['Age'] <= 16), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 24), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 24) & (dataset['Age'] <= 32), 'Age'] = 3\n",
    "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 40), 'Age'] = 4\n",
    "    dataset.loc[(dataset['Age'] > 40) & (dataset['Age'] <= 48), 'Age'] = 5\n",
    "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 56), 'Age'] = 6\n",
    "    dataset.loc[(dataset['Age'] > 56) & (dataset['Age'] <= 64), 'Age'] = 7\n",
    "    dataset.loc[(dataset['Age'] > 64) & (dataset['Age'] <= 72), 'Age'] = 8\n",
    "    dataset.loc[ dataset['Age'] > 72, 'Age'] = 9\n",
    "train_df = train_df.drop(['AgeBand'], axis=1)\n",
    "combine = [train_df, test_df]\n",
    "\n",
    "\"\"\"\n",
    "(24.0, 32.0]    275\n",
    "(16.0, 24.0]    220\n",
    "(32.0, 40.0]    148\n",
    "(40.0, 48.0]     68\n",
    "(-0.08, 8.0]     54\n",
    "(8.0, 16.0]      46\n",
    "(48.0, 56.0]     45\n",
    "(56.0, 64.0]     24\n",
    "(64.0, 72.0]      9\n",
    "(72.0, 80.0]      2\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.barplot(data=train_df, x=\"Age\", y=\"Survived\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert Title to numerical or one hot encoding\n",
    "\n",
    "several options\n",
    "\n",
    "- one hot encoding, no deleting rare title\n",
    "- change rare title to \"Rare\" and map value\n",
    "- change rare title to \"Rare\" and one hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one hot encoding, no deleteing rare title"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# try one hote encoding without delete rare title\n",
    "#\n",
    "# concat train and test data. and apply get_dummies for Title. \n",
    "# then split to original size. also drop Survived column from test_df\n",
    "print(train_df.shape, test_df.shape)\n",
    "\n",
    "# concat train and test data\n",
    "#   test_df's Survived column is filled with NaN\n",
    "train_test_df = pd.concat((train_df, test_df))\n",
    "\n",
    "print(train_test_df.shape)\n",
    "\n",
    "# apply get_dummies for Title\n",
    "train_test_df = pd.get_dummies(train_test_df, columns=[\"Title\"])\n",
    "\n",
    "#train_test_df.head()\n",
    "train_df = train_test_df.iloc[:train_df.shape[0]]\n",
    "test_df = train_test_df.iloc[train_df.shape[0]:]\n",
    "\n",
    "# drop added Survived column from test_df\n",
    "test_df = test_df.drop(\"Survived\", axis=1)\n",
    "print(train_df.shape, test_df.shape)\n",
    "\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OR change rare title to \"Rare\" and map value"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_test_df = pd.concat((train_df, test_df))\n",
    "print(train_test_df.Title.value_counts(dropna=False))\n",
    "\n",
    "f, ax = plt.subplots(figsize=(20, 6))\n",
    "sns.barplot(data=train_test_df, x=\"Title\", y=\"Survived\", ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**del rare title and map value**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# del rare title and map value\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\n",
    "                                                 'Don', 'Dr', 'Major', 'Rev', 'Sir',\n",
    "                                                 'Jonkheer', 'Dona'], 'Rare')\n",
    "\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "    \n",
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rave\": 5}\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset['Title'].map(title_mapping)\n",
    "    dataset['Title'] = dataset['Title'].fillna(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Replacing rare titles with more common ones**\n",
    "\n",
    "https://www.kaggle.com/konstantinmasich/titanic-0-82-0-83/"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mapping = {'Mlle': 'Miss', \n",
    "            'Major': 'Mr', \n",
    "            'Col': 'Mr', \n",
    "            'Sir': 'Mr',\n",
    "            'Don': 'Mr', \n",
    "            'Mme': 'Miss',\n",
    "            'Jonkheer': 'Mr',\n",
    "            'Lady': 'Mrs', \n",
    "            'Capt': 'Mr', \n",
    "            'Countess': 'Mrs',\n",
    "            'Ms': 'Miss',\n",
    "            'Dona': 'Mrs'}\n",
    "\n",
    "train_df.replace({'Title': mapping}, inplace=True)\n",
    "test_df.replace({'Title': mapping}, inplace=True)\n",
    "\n",
    "combine = [train_df, test_df]\n",
    "\n",
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rev\": 5, \"Dr\":6}\n",
    "\n",
    "train_df['Title'] = train_df['Title'].map(title_mapping)\n",
    "test_df['Title'] = test_df['Title'].map(title_mapping)\n",
    "\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.Title.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.countplot(data=train_df, x=\"Title\", hue=\"Survived\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### change rare title to \"Rare\" and one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 32) (418, 31)\n"
     ]
    }
   ],
   "source": [
    "mapping = {'Mlle': 'Miss', \n",
    "            'Major': 'Mr', \n",
    "            'Col': 'Mr', \n",
    "            'Sir': 'Mr',\n",
    "            'Don': 'Mr', \n",
    "            'Mme': 'Miss',\n",
    "            'Jonkheer': 'Mr',\n",
    "            'Lady': 'Mrs', \n",
    "            'Capt': 'Mr', \n",
    "            'Countess': 'Mrs',\n",
    "            'Ms': 'Miss',\n",
    "            'Dona': 'Mrs'}\n",
    "\n",
    "train_df.replace({'Title': mapping}, inplace=True)\n",
    "test_df.replace({'Title': mapping}, inplace=True)\n",
    "\n",
    "combine = [train_df, test_df]\n",
    "\n",
    "train_test_df = pd.concat((train_df, test_df))\n",
    "train_test_df = pd.get_dummies(train_test_df, columns=[\"Title\"])\n",
    "\n",
    "train_df = train_test_df.iloc[:train_df.shape[0]]\n",
    "test_df = train_test_df.iloc[train_df.shape[0]:]\n",
    "\n",
    "test_df = test_df.drop(\"Survived\", axis=1)\n",
    "print(train_df.shape, test_df.shape)\n",
    "\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Age_Null_Flag', 'Cabin_Letter_0', 'Cabin_Letter_A',\n",
       "       'Cabin_Letter_B', 'Cabin_Letter_C', 'Cabin_Letter_D', 'Cabin_Letter_E',\n",
       "       'Cabin_Letter_F', 'Cabin_Letter_G', 'Cabin_Letter_T',\n",
       "       'Cabin_num_(1.999, 28.667]', 'Cabin_num_(28.667, 65.667]',\n",
       "       'Cabin_num_(65.667, 148.0]', 'Cabin_num_nan_category', 'Embarked',\n",
       "       'Fare', 'Name', 'Name_Len', 'Parch', 'PassengerId', 'Pclass', 'Sex',\n",
       "       'SibSp', 'Survived', 'Ticket_Len', 'Title_Dr', 'Title_Master',\n",
       "       'Title_Miss', 'Title_Mr', 'Title_Mrs', 'Title_Rev'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 708,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new feature \"FamilySize\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/home/yuki/.local/lib/python3.6/site-packages/pandas/core/indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "for dataset in combine:\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset['IsAlone'] = 0\n",
    "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset['Age*Class'] = dataset.Age * dataset.Pclass"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.barplot(data=train_df, x=\"FamilySize\", y=\"Survived\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.barplot(data=train_df, x=\"IsAlone\", y=\"Survived\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.countplot(data=train_df, x=\"Age*Class\", hue=\"Survived\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### select family related feature\n",
    "Parch, SibSp, FaimilySize, IsAlone\n",
    "\n",
    "2018/03/18 Parch and SibSp only was best for almost all models"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# keep all"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# keep Parch, SibSp only. this was best amoung familly related features\n",
    "\n",
    "train_df = train_df.drop(['FamilySize', 'IsAlone'], axis=1)\n",
    "test_df = test_df.drop(['FamilySize', 'IsAlone'], axis=1)\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Age_Null_Flag</th>\n",
       "      <th>Cabin_Letter_0</th>\n",
       "      <th>Cabin_Letter_A</th>\n",
       "      <th>Cabin_Letter_B</th>\n",
       "      <th>Cabin_Letter_C</th>\n",
       "      <th>Cabin_Letter_D</th>\n",
       "      <th>Cabin_Letter_E</th>\n",
       "      <th>Cabin_Letter_F</th>\n",
       "      <th>Cabin_Letter_G</th>\n",
       "      <th>...</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Ticket_Len</th>\n",
       "      <th>Title_Dr</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Rev</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Age*Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Age_Null_Flag  Cabin_Letter_0  Cabin_Letter_A  Cabin_Letter_B  \\\n",
       "0  2.0              0               1               0               0   \n",
       "1  4.0              0               0               0               0   \n",
       "2  3.0              0               1               0               0   \n",
       "3  4.0              0               0               0               0   \n",
       "4  4.0              0               1               0               0   \n",
       "\n",
       "   Cabin_Letter_C  Cabin_Letter_D  Cabin_Letter_E  Cabin_Letter_F  \\\n",
       "0               0               0               0               0   \n",
       "1               1               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               1               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   Cabin_Letter_G    ...      Survived  Ticket_Len  Title_Dr  Title_Master  \\\n",
       "0               0    ...           0.0           9         0             0   \n",
       "1               0    ...           1.0           8         0             0   \n",
       "2               0    ...           1.0          16         0             0   \n",
       "3               0    ...           1.0           6         0             0   \n",
       "4               0    ...           0.0           6         0             0   \n",
       "\n",
       "   Title_Miss Title_Mr  Title_Mrs Title_Rev  FamilySize  Age*Class  \n",
       "0           0        1          0         0           2        6.0  \n",
       "1           0        0          1         0           2        4.0  \n",
       "2           1        0          0         0           1        9.0  \n",
       "3           0        0          1         0           2        4.0  \n",
       "4           0        1          0         0           1       12.0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 710,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep FamilySize only\n",
    "\n",
    "train_df = train_df.drop(['Parch', 'SibSp', 'IsAlone'], axis=1)\n",
    "test_df = test_df.drop(['Parch', 'SibSp', 'IsAlone'], axis=1)\n",
    "combine = [train_df, test_df]\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# keep IsAlone only (drop Parch, SibSp, FaimilySize)\n",
    "\n",
    "train_df = train_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\n",
    "test_df = test_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\n",
    "combine = [train_df, test_df]\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fill missing Embarked "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_port = train_df.Embarked.dropna().mode()[0]\n",
    "for dataset in combine:\n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna(freq_port)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Embarked categorical feature to numeric"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for dataset in combine:\n",
    "    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## try one hot encoding for Embarked categorical feature\n",
    "2018/03/18 this is better than using converting categorical to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 32) (418, 31)\n",
      "(1309, 32)\n",
      "(891, 34) (418, 34)\n"
     ]
    }
   ],
   "source": [
    "# try one hote encoding for Embarked\n",
    "#\n",
    "# concat train and test data. and apply get_dummies for Title. \n",
    "# then split to original size. also drop Survived column from test_df\n",
    "print(train_df.shape, test_df.shape)\n",
    "\n",
    "# concat train and test data\n",
    "#   test_df's Survived column is filled with NaN\n",
    "train_test_df = pd.concat((train_df, test_df))\n",
    "\n",
    "print(train_test_df.shape)\n",
    "\n",
    "# apply get_dummies for Title\n",
    "train_test_df = pd.get_dummies(train_test_df, columns=[\"Embarked\"])\n",
    "\n",
    "#train_test_df.head()\n",
    "train_df = train_test_df.iloc[:train_df.shape[0]]\n",
    "test_df = train_test_df.iloc[train_df.shape[0]:]\n",
    "\n",
    "print(train_df.shape, test_df.shape)\n",
    "\n",
    "# drop added Survived column from test_df\n",
    "test_df = test_df.drop(\"Survived\", axis=1)\n",
    "\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Age*Class</th>\n",
       "      <th>Age_Null_Flag</th>\n",
       "      <th>Cabin_Letter_0</th>\n",
       "      <th>Cabin_Letter_A</th>\n",
       "      <th>Cabin_Letter_B</th>\n",
       "      <th>Cabin_Letter_C</th>\n",
       "      <th>Cabin_Letter_D</th>\n",
       "      <th>Cabin_Letter_E</th>\n",
       "      <th>Cabin_Letter_F</th>\n",
       "      <th>...</th>\n",
       "      <th>Ticket_Len</th>\n",
       "      <th>Title_Dr</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Rev</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Age*Class  Age_Null_Flag  Cabin_Letter_0  Cabin_Letter_A  \\\n",
       "0  2.0        6.0              0               1               0   \n",
       "1  4.0        4.0              0               0               0   \n",
       "2  3.0        9.0              0               1               0   \n",
       "3  4.0        4.0              0               0               0   \n",
       "4  4.0       12.0              0               1               0   \n",
       "\n",
       "   Cabin_Letter_B  Cabin_Letter_C  Cabin_Letter_D  Cabin_Letter_E  \\\n",
       "0               0               0               0               0   \n",
       "1               0               1               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               1               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   Cabin_Letter_F     ...      Ticket_Len  Title_Dr  Title_Master  Title_Miss  \\\n",
       "0               0     ...               9         0             0           0   \n",
       "1               0     ...               8         0             0           0   \n",
       "2               0     ...              16         0             0           1   \n",
       "3               0     ...               6         0             0           0   \n",
       "4               0     ...               6         0             0           0   \n",
       "\n",
       "   Title_Mr  Title_Mrs  Title_Rev  Embarked_C Embarked_Q  Embarked_S  \n",
       "0         1          0          0           0          0           1  \n",
       "1         0          1          0           1          0           0  \n",
       "2         0          0          0           0          0           1  \n",
       "3         0          1          0           0          0           1  \n",
       "4         1          0          0           0          0           1  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 713,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fill na of test data Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Fare'].fillna(test_df['Fare'].dropna().median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Age*Class</th>\n",
       "      <th>Age_Null_Flag</th>\n",
       "      <th>Cabin_Letter_0</th>\n",
       "      <th>Cabin_Letter_A</th>\n",
       "      <th>Cabin_Letter_B</th>\n",
       "      <th>Cabin_Letter_C</th>\n",
       "      <th>Cabin_Letter_D</th>\n",
       "      <th>Cabin_Letter_E</th>\n",
       "      <th>Cabin_Letter_F</th>\n",
       "      <th>...</th>\n",
       "      <th>Ticket_Len</th>\n",
       "      <th>Title_Dr</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Rev</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.5</td>\n",
       "      <td>103.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Age*Class  Age_Null_Flag  Cabin_Letter_0  Cabin_Letter_A  \\\n",
       "0  34.5      103.5              0               1               0   \n",
       "1  47.0      141.0              0               1               0   \n",
       "2  62.0      124.0              0               1               0   \n",
       "3  27.0       81.0              0               1               0   \n",
       "4  22.0       66.0              0               1               0   \n",
       "\n",
       "   Cabin_Letter_B  Cabin_Letter_C  Cabin_Letter_D  Cabin_Letter_E  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   Cabin_Letter_F     ...      Ticket_Len  Title_Dr  Title_Master  Title_Miss  \\\n",
       "0               0     ...               6         0             0           0   \n",
       "1               0     ...               6         0             0           0   \n",
       "2               0     ...               6         0             0           0   \n",
       "3               0     ...               6         0             0           0   \n",
       "4               0     ...               7         0             0           0   \n",
       "\n",
       "   Title_Mr  Title_Mrs  Title_Rev  Embarked_C Embarked_Q  Embarked_S  \n",
       "0         1          0          0           0          1           0  \n",
       "1         0          1          0           0          0           1  \n",
       "2         1          0          0           0          1           0  \n",
       "3         1          0          0           0          0           1  \n",
       "4         0          1          0           0          0           1  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 715,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 716,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.Fare.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make Fareband feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/yuki/.local/lib/python3.6/site-packages/pandas/core/indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "train_df['FareBand'] = pd.qcut(train_df['Fare'], 4)\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
    "    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n",
    "    #print(dataset['Fare'].value_counts())\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "\n",
    "train_df = train_df.drop(['FareBand'], axis=1)\n",
    "\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try more fare band number\n",
    "\n",
    "- no difference\n",
    "\n",
    "### keep Fare feature and add FareBand numerical feature¶\n",
    "\n",
    "- not good result"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fareband = pd.qcut(train_df['Fare'], 6)\n",
    "fareband.unique()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df['FareBand'] = pd.qcut(train_df['Fare'], 6)\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset.loc[ dataset['Fare'] <= 7.775, 'Fare'] = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.775) & (dataset['Fare'] <= 8.662), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 8.662) & (dataset['Fare'] <= 14.454), 'Fare']   = 2\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 26.0), 'Fare']   = 3\n",
    "    dataset.loc[(dataset['Fare'] > 26.0) & (dataset['Fare'] <= 52.369), 'Fare']   = 4\n",
    "    \n",
    "    dataset.loc[ dataset['Fare'] > 52.369, 'Fare'] = 5\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "\n",
    "train_df = train_df.drop(['FareBand'], axis=1)\n",
    "\n",
    "combine = [train_df, test_df]\n",
    "    \n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## drop Name, PassengerId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(['Name', 'PassengerId'], axis=1)\n",
    "test_df = test_df.drop(['Name'], axis=1)\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## final check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Age*Class</th>\n",
       "      <th>Age_Null_Flag</th>\n",
       "      <th>Cabin_Letter_0</th>\n",
       "      <th>Cabin_Letter_A</th>\n",
       "      <th>Cabin_Letter_B</th>\n",
       "      <th>Cabin_Letter_C</th>\n",
       "      <th>Cabin_Letter_D</th>\n",
       "      <th>Cabin_Letter_E</th>\n",
       "      <th>Cabin_Letter_F</th>\n",
       "      <th>...</th>\n",
       "      <th>Ticket_Len</th>\n",
       "      <th>Title_Dr</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Rev</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Age*Class  Age_Null_Flag  Cabin_Letter_0  Cabin_Letter_A  \\\n",
       "0  2.0        6.0              0               1               0   \n",
       "1  4.0        4.0              0               0               0   \n",
       "2  3.0        9.0              0               1               0   \n",
       "3  4.0        4.0              0               0               0   \n",
       "4  4.0       12.0              0               1               0   \n",
       "\n",
       "   Cabin_Letter_B  Cabin_Letter_C  Cabin_Letter_D  Cabin_Letter_E  \\\n",
       "0               0               0               0               0   \n",
       "1               0               1               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               1               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   Cabin_Letter_F     ...      Ticket_Len  Title_Dr  Title_Master  Title_Miss  \\\n",
       "0               0     ...               9         0             0           0   \n",
       "1               0     ...               8         0             0           0   \n",
       "2               0     ...              16         0             0           1   \n",
       "3               0     ...               6         0             0           0   \n",
       "4               0     ...               6         0             0           0   \n",
       "\n",
       "   Title_Mr  Title_Mrs  Title_Rev  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0         1          0          0           0           0           1  \n",
       "1         0          1          0           1           0           0  \n",
       "2         0          0          0           0           0           1  \n",
       "3         0          1          0           0           0           1  \n",
       "4         1          0          0           0           0           1  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 719,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Age*Class', 'Age_Null_Flag', 'Cabin_Letter_0', 'Cabin_Letter_A',\n",
       "       'Cabin_Letter_B', 'Cabin_Letter_C', 'Cabin_Letter_D', 'Cabin_Letter_E',\n",
       "       'Cabin_Letter_F', 'Cabin_Letter_G', 'Cabin_Letter_T',\n",
       "       'Cabin_num_(1.999, 28.667]', 'Cabin_num_(28.667, 65.667]',\n",
       "       'Cabin_num_(65.667, 148.0]', 'Cabin_num_nan_category', 'FamilySize',\n",
       "       'Fare', 'Name_Len', 'Pclass', 'Sex', 'Survived', 'Ticket_Len',\n",
       "       'Title_Dr', 'Title_Master', 'Title_Miss', 'Title_Mr', 'Title_Mrs',\n",
       "       'Title_Rev', 'Embarked_C', 'Embarked_Q', 'Embarked_S'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 720,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Age*Class</th>\n",
       "      <th>Age_Null_Flag</th>\n",
       "      <th>Cabin_Letter_0</th>\n",
       "      <th>Cabin_Letter_A</th>\n",
       "      <th>Cabin_Letter_B</th>\n",
       "      <th>Cabin_Letter_C</th>\n",
       "      <th>Cabin_Letter_D</th>\n",
       "      <th>Cabin_Letter_E</th>\n",
       "      <th>Cabin_Letter_F</th>\n",
       "      <th>...</th>\n",
       "      <th>Ticket_Len</th>\n",
       "      <th>Title_Dr</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Rev</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.5</td>\n",
       "      <td>103.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Age*Class  Age_Null_Flag  Cabin_Letter_0  Cabin_Letter_A  \\\n",
       "0  34.5      103.5              0               1               0   \n",
       "1  47.0      141.0              0               1               0   \n",
       "2  62.0      124.0              0               1               0   \n",
       "3  27.0       81.0              0               1               0   \n",
       "4  22.0       66.0              0               1               0   \n",
       "\n",
       "   Cabin_Letter_B  Cabin_Letter_C  Cabin_Letter_D  Cabin_Letter_E  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   Cabin_Letter_F     ...      Ticket_Len  Title_Dr  Title_Master  Title_Miss  \\\n",
       "0               0     ...               6         0             0           0   \n",
       "1               0     ...               6         0             0           0   \n",
       "2               0     ...               6         0             0           0   \n",
       "3               0     ...               6         0             0           0   \n",
       "4               0     ...               7         0             0           0   \n",
       "\n",
       "   Title_Mr  Title_Mrs  Title_Rev  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0         1          0          0           0           1           0  \n",
       "1         0          1          0           0           0           1  \n",
       "2         1          0          0           0           1           0  \n",
       "3         1          0          0           0           0           1  \n",
       "4         0          1          0           0           0           1  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 721,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Age*Class', 'Age_Null_Flag', 'Cabin_Letter_0', 'Cabin_Letter_A',\n",
       "       'Cabin_Letter_B', 'Cabin_Letter_C', 'Cabin_Letter_D', 'Cabin_Letter_E',\n",
       "       'Cabin_Letter_F', 'Cabin_Letter_G', 'Cabin_Letter_T',\n",
       "       'Cabin_num_(1.999, 28.667]', 'Cabin_num_(28.667, 65.667]',\n",
       "       'Cabin_num_(65.667, 148.0]', 'Cabin_num_nan_category', 'FamilySize',\n",
       "       'Fare', 'Name_Len', 'PassengerId', 'Pclass', 'Sex', 'Ticket_Len',\n",
       "       'Title_Dr', 'Title_Master', 'Title_Miss', 'Title_Mr', 'Title_Mrs',\n",
       "       'Title_Rev', 'Embarked_C', 'Embarked_Q', 'Embarked_S'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 722,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.columns"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "colormap = plt.cm.viridis\n",
    "plt.figure(figsize=(30,30))\n",
    "plt.title('Pearson Correlation of Features', y=1.05, size=15)\n",
    "sns.heatmap(train_df.astype(float).corr(), \n",
    "            linewidths=0.1,vmax=1.0,\n",
    "            square=True, cmap=colormap, \n",
    "            linecolor='white', annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# try to delete some features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Age*Class is duplicated. Age and Pclass is enough, i think"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df = train_df.drop(['Age*Class'], axis=1)\n",
    "test_df = test_df.drop(['Age*Class'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Name_Len looks no meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(['Name_Len'], axis=1)\n",
    "test_df = test_df.drop(['Name_Len'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ticket_Len looks no meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(['Ticket_Len'], axis=1)\n",
    "test_df = test_df.drop(['Ticket_Len'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cabin_Num looks no meaning. Cabin null feature is included in Cabinb_Letter value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(['Cabin_num_(1.999, 28.667]', 'Cabin_num_(28.667, 65.667]',\n",
    "                          'Cabin_num_(65.667, 148.0]', 'Cabin_num_nan_category'], axis=1)\n",
    "test_df = test_df.drop(['Cabin_num_(1.999, 28.667]', 'Cabin_num_(28.667, 65.667]',\n",
    "                        'Cabin_num_(65.667, 148.0]', 'Cabin_num_nan_category'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 26) (418, 26)\n",
      "Index(['Age', 'Age*Class', 'Age_Null_Flag', 'Cabin_Letter_0', 'Cabin_Letter_A',\n",
      "       'Cabin_Letter_B', 'Cabin_Letter_C', 'Cabin_Letter_D', 'Cabin_Letter_E',\n",
      "       'Cabin_Letter_F', 'Cabin_Letter_G', 'Cabin_Letter_T', 'FamilySize',\n",
      "       'Fare', 'Pclass', 'Sex', 'Survived', 'Title_Dr', 'Title_Master',\n",
      "       'Title_Miss', 'Title_Mr', 'Title_Mrs', 'Title_Rev', 'Embarked_C',\n",
      "       'Embarked_Q', 'Embarked_S'],\n",
      "      dtype='object') Index(['Age', 'Age*Class', 'Age_Null_Flag', 'Cabin_Letter_0', 'Cabin_Letter_A',\n",
      "       'Cabin_Letter_B', 'Cabin_Letter_C', 'Cabin_Letter_D', 'Cabin_Letter_E',\n",
      "       'Cabin_Letter_F', 'Cabin_Letter_G', 'Cabin_Letter_T', 'FamilySize',\n",
      "       'Fare', 'PassengerId', 'Pclass', 'Sex', 'Title_Dr', 'Title_Master',\n",
      "       'Title_Miss', 'Title_Mr', 'Title_Mrs', 'Title_Rev', 'Embarked_C',\n",
      "       'Embarked_Q', 'Embarked_S'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape, test_df.shape)\n",
    "print(train_df.columns, test_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Age*Class</th>\n",
       "      <th>Age_Null_Flag</th>\n",
       "      <th>Cabin_Letter_0</th>\n",
       "      <th>Cabin_Letter_A</th>\n",
       "      <th>Cabin_Letter_B</th>\n",
       "      <th>Cabin_Letter_C</th>\n",
       "      <th>Cabin_Letter_D</th>\n",
       "      <th>Cabin_Letter_E</th>\n",
       "      <th>Cabin_Letter_F</th>\n",
       "      <th>...</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Title_Dr</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Rev</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Age*Class  Age_Null_Flag  Cabin_Letter_0  Cabin_Letter_A  \\\n",
       "0  2.0        6.0              0               1               0   \n",
       "1  4.0        4.0              0               0               0   \n",
       "2  3.0        9.0              0               1               0   \n",
       "3  4.0        4.0              0               0               0   \n",
       "4  4.0       12.0              0               1               0   \n",
       "\n",
       "   Cabin_Letter_B  Cabin_Letter_C  Cabin_Letter_D  Cabin_Letter_E  \\\n",
       "0               0               0               0               0   \n",
       "1               0               1               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               1               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   Cabin_Letter_F     ...      Survived  Title_Dr  Title_Master  Title_Miss  \\\n",
       "0               0     ...           0.0         0             0           0   \n",
       "1               0     ...           1.0         0             0           0   \n",
       "2               0     ...           1.0         0             0           1   \n",
       "3               0     ...           1.0         0             0           0   \n",
       "4               0     ...           0.0         0             0           0   \n",
       "\n",
       "   Title_Mr  Title_Mrs  Title_Rev  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0         1          0          0           0           0           1  \n",
       "1         0          1          0           1           0           0  \n",
       "2         0          0          0           0           0           1  \n",
       "3         0          1          0           0           0           1  \n",
       "4         1          0          0           0           0           1  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 727,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Age*Class</th>\n",
       "      <th>Age_Null_Flag</th>\n",
       "      <th>Cabin_Letter_0</th>\n",
       "      <th>Cabin_Letter_A</th>\n",
       "      <th>Cabin_Letter_B</th>\n",
       "      <th>Cabin_Letter_C</th>\n",
       "      <th>Cabin_Letter_D</th>\n",
       "      <th>Cabin_Letter_E</th>\n",
       "      <th>Cabin_Letter_F</th>\n",
       "      <th>...</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Title_Dr</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Rev</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.5</td>\n",
       "      <td>103.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Age*Class  Age_Null_Flag  Cabin_Letter_0  Cabin_Letter_A  \\\n",
       "0  34.5      103.5              0               1               0   \n",
       "1  47.0      141.0              0               1               0   \n",
       "2  62.0      124.0              0               1               0   \n",
       "3  27.0       81.0              0               1               0   \n",
       "4  22.0       66.0              0               1               0   \n",
       "\n",
       "   Cabin_Letter_B  Cabin_Letter_C  Cabin_Letter_D  Cabin_Letter_E  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   Cabin_Letter_F     ...      Sex  Title_Dr  Title_Master  Title_Miss  \\\n",
       "0               0     ...        0         0             0           0   \n",
       "1               0     ...        1         0             0           0   \n",
       "2               0     ...        0         0             0           0   \n",
       "3               0     ...        0         0             0           0   \n",
       "4               0     ...        1         0             0           0   \n",
       "\n",
       "   Title_Mr  Title_Mrs  Title_Rev  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0         1          0          0           0           1           0  \n",
       "1         0          1          0           0           0           1  \n",
       "2         1          0          0           0           1           0  \n",
       "3         1          0          0           0           0           1  \n",
       "4         0          1          0           0           0           1  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 728,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model and estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = train_df.drop(\"Survived\", axis=1)\n",
    "y_train_df = train_df[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/test data shape (668, 25) (223, 25)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train_df, y_train_df, test_size=0.25, random_state=42)\n",
    "print(\"train/test data shape\", X_train.shape, X_test.shape)\n",
    "# 33, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done 386 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=3)]: Done 1200 out of 1200 | elapsed:    9.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'svc__C': 10, 'svc__gamma': 0.04}\n",
      "Mean cross-validated score of the best_estimator:  0.8293413173652695\n",
      "test:  0.8295964125560538\n",
      "confusion matrix:  [[118  16]\n",
      " [ 22  67]]\n",
      "\n",
      "Rank|Score(std)|Params ['svc__C', 'svc__gamma']\n",
      "1|0.829341(std:0.032070)|[10, 0.04]\n",
      "2|0.826347(std:0.032878)|[1, 0.008]\n",
      "2|0.826347(std:0.032878)|[1, 0.04]\n",
      "2|0.826347(std:0.034092)|[90, 0.001]\n",
      "2|0.826347(std:0.034092)|[100, 0.001]\n",
      "2|0.826347(std:0.027579)|[500, 0.008]\n",
      "7|0.824850(std:0.033657)|[1, 0.01]\n",
      "7|0.824850(std:0.032236)|[10, 0.01]\n",
      "7|0.824850(std:0.032172)|[30, 0.005]\n",
      "7|0.824850(std:0.036045)|[70, 0.001]\n",
      "7|0.824850(std:0.036045)|[80, 0.001]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2a6cdc7198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "param_grid = {'svc__C': [0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 30, 50, 70, 80, 90, 100, 500, 1000],\n",
    "              'svc__gamma': [0.001, 0.005, 0.008, 0.01, 0.03, 0.04, 0.05, 0.1, 1, 10, 100, 1000, 10000, 100000, 1000000]}\n",
    "\n",
    "pipe = make_pipeline(SVC())\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv=5, n_jobs=3, verbose=1)\n",
    "\n",
    "# no meaning to use cross_val for grid_search model because it is incluced in grid search\n",
    "#scores = cross_val_score(grid_search, X_train, y_train, cv=5, n_jobs=6)\n",
    "#print(\"mean of train scores\", scores.mean())\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "plt.matshow(grid_search.cv_results_['mean_test_score'].reshape(16, -1),\n",
    "            vmin=0, cmap=\"viridis\")\n",
    "plt.xlabel(\"C\")\n",
    "plt.ylabel(\"gamma\")\n",
    "plt.xticks(range(len(param_grid['svc__C'])), param_grid['svc__C'])\n",
    "plt.yticks(range(len(param_grid['svc__gamma'])), param_grid['svc__C'])\n",
    "plt.colorbar()\n",
    "\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))\n",
    "print(\"confusion matrix: \", confusion_matrix(y_test, grid_search.best_estimator_.predict(X_test)))\n",
    "print(\"\")\n",
    "report2(grid_search.cv_results_, n_top=10)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# if age band is 5\n",
    "Mean cross-validated score of the best_estimator:  0.8154362416107382\n",
    "best parameters: {'C': 100, 'gamma': 0.001}\n",
    "test:  0.8338983050847457\n",
    "\n",
    "\n",
    "# if age band is 10\n",
    "Mean cross-validated score of the best_estimator:  0.8137583892617449\n",
    "best parameters: {'C': 100, 'gamma': 0.001}\n",
    "test:  0.8372881355932204\n",
    "\n",
    "\n",
    "# OR change rare title to \"Rare\" and map value\n",
    "Mean cross-validated score of the best_estimator:  0.8070469798657718\n",
    "best parameters: {'C': 10, 'gamma': 0.01}\n",
    "test:  0.8135593220338984\n",
    "\n",
    "# 5 age band and filled age by mean of group(title, pclass)\n",
    "Mean cross-validated score of the best_estimator:  0.8120805369127517\n",
    "best parameters: {'C': 100, 'gamma': 0.001}\n",
    "test:  0.8305084745762712\n",
    "\n",
    "# 10 age band, parch, sibsp\n",
    "best parameters: {'C': 1000, 'gamma': 0.001}\n",
    "Mean cross-validated score of the best_estimator:  0.81711409396\n",
    "test:  0.84406779661\n",
    "\n",
    "\n",
    "# 10 age band, parch&sibsp, embarked num category\n",
    "best parameters: {'C': 100, 'gamma': 0.001}\n",
    "Mean cross-validated score of the best_estimator:  0.815436241611\n",
    "test:  0.840677966102\n",
    "\n",
    "# 10 age band, parch&sibsp, embarked num category, rare title&map value\n",
    "best parameters: {'C': 1000, 'gamma': 0.001}\n",
    "Mean cross-validated score of the best_estimator:  0.803691275168\n",
    "test:  0.840677966102\n",
    "\n",
    "# 10 age band, familysize, embarked num category, rare title&map value, no Name_Len, no Ticket_Len, one Cabin_Letter feature\n",
    "\n",
    "best parameters: {'C': 70, 'gamma': 0.03}\n",
    "Mean cross-validated score of the best_estimator:  0.8271812080536913\n",
    "test:  0.8101694915254237\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "grid_search.best_estimator_.support_vectors_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "grid_search.best_estimator_.dual_coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### svc, minmax scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done 386 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=3)]: Done 1200 out of 1200 | elapsed:    9.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'svc__C': 1000, 'svc__gamma': 0.05}\n",
      "Mean cross-validated score of the best_estimator:  0.8353293413173652\n",
      "test:  0.820627802690583\n",
      "confusion matrix:  [[116  18]\n",
      " [ 22  67]]\n",
      "\n",
      "Rank|Score(std)|Params ['svc__C', 'svc__gamma']\n",
      "1|0.835329(std:0.021357)|[1000, 0.05]\n",
      "2|0.833832(std:0.024668)|[100, 0.03]\n",
      "2|0.833832(std:0.012557)|[500, 0.1]\n",
      "4|0.832335(std:0.022849)|[50, 0.04]\n",
      "4|0.832335(std:0.025779)|[50, 0.05]\n",
      "4|0.832335(std:0.027729)|[50, 0.1]\n",
      "4|0.832335(std:0.025779)|[70, 0.04]\n",
      "4|0.832335(std:0.025779)|[80, 0.04]\n",
      "4|0.832335(std:0.022849)|[90, 0.03]\n",
      "10|0.830838(std:0.027511)|[10, 0.1]\n",
      "10|0.830838(std:0.028960)|[30, 0.1]\n",
      "10|0.830838(std:0.024095)|[70, 0.03]\n",
      "10|0.830838(std:0.027835)|[90, 0.04]\n",
      "10|0.830838(std:0.025959)|[1000, 0.008]\n",
      "10|0.830838(std:0.027835)|[1000, 0.01]\n",
      "10|0.830838(std:0.030261)|[1000, 0.04]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2a6c1698d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "param_grid = {'svc__C': [0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 30, 50, 70, 80, 90, 100, 500, 1000],\n",
    "              'svc__gamma': [0.001, 0.005, 0.008, 0.01, 0.03, 0.04, 0.05, 0.1, 1, 10, 100, 1000, 10000, 100000, 1000000]}\n",
    "\n",
    "pipe = make_pipeline(MinMaxScaler(), SVC())\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv=5, n_jobs=3, verbose=1)\n",
    "\n",
    "# no meaning to use cross_val for grid_search model because it is incluced in grid search\n",
    "#scores = cross_val_score(grid_search, X_train, y_train, cv=5, n_jobs=6)\n",
    "#print(\"mean of train scores\", scores.mean())\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "plt.matshow(grid_search.cv_results_['mean_test_score'].reshape(16, -1),\n",
    "            vmin=0, cmap=\"viridis\")\n",
    "plt.xlabel(\"C\")\n",
    "plt.ylabel(\"gamma\")\n",
    "plt.xticks(range(len(param_grid['svc__C'])), param_grid['svc__C'])\n",
    "plt.yticks(range(len(param_grid['svc__gamma'])), param_grid['svc__C'])\n",
    "plt.colorbar()\n",
    "\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))\n",
    "print(\"confusion matrix: \", confusion_matrix(y_test, grid_search.best_estimator_.predict(X_test)))\n",
    "print(\"\")\n",
    "report2(grid_search.cv_results_, n_top=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### svc, robust scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done 386 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=3)]: Done 1200 out of 1200 | elapsed:    9.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'svc__C': 1000, 'svc__gamma': 0.05}\n",
      "Mean cross-validated score of the best_estimator:  0.8353293413173652\n",
      "test:  0.820627802690583\n",
      "confusion matrix:  [[116  18]\n",
      " [ 22  67]]\n",
      "\n",
      "Rank|Score(std)|Params ['svc__C', 'svc__gamma']\n",
      "1|0.835329(std:0.021357)|[1000, 0.05]\n",
      "2|0.833832(std:0.024668)|[100, 0.03]\n",
      "2|0.833832(std:0.012557)|[500, 0.1]\n",
      "4|0.832335(std:0.022849)|[50, 0.04]\n",
      "4|0.832335(std:0.025779)|[50, 0.05]\n",
      "4|0.832335(std:0.027729)|[50, 0.1]\n",
      "4|0.832335(std:0.025779)|[70, 0.04]\n",
      "4|0.832335(std:0.025779)|[80, 0.04]\n",
      "4|0.832335(std:0.022849)|[90, 0.03]\n",
      "10|0.830838(std:0.027511)|[10, 0.1]\n",
      "10|0.830838(std:0.028960)|[30, 0.1]\n",
      "10|0.830838(std:0.024095)|[70, 0.03]\n",
      "10|0.830838(std:0.027835)|[90, 0.04]\n",
      "10|0.830838(std:0.025959)|[1000, 0.008]\n",
      "10|0.830838(std:0.027835)|[1000, 0.01]\n",
      "10|0.830838(std:0.030261)|[1000, 0.04]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASYAAAEFCAYAAABO/EpCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJztnXv4VWWZ9z9fTuIpFfCAYIpJJZlSIjJT+eYZmwaaybqgk5VFzUhl1tur15QlM11v+k7ZOGNNlI7aNYrkm0UNiU46OTNvIaCI4BFRFPIEiqQmwu93v388z4bFZh+exW/v31r7t+/PdT3X3nutZ93r3muvde/ndN+3zAzHcZwyMahoBRzHcapxw+Q4Tulww+Q4Tulww+Q4Tulww+Q4Tulww+Q4Tulww+Q4Tulww+Q4Tulww+Q4TukYUrQCjuP0L2eevLdtfL4nqe6yFVsWmdnUNqu0C26YHKfL2PB8D4sXjU2qO3T0o6ParE5N3DA5Ttdh9Fhv0Uo0xA2T43QZBvRSbud9N0yO04X04i0mx3FKhGH0lDzckRsmx+lCyt6V83VMjtNlGNCDJZUUJE2V9JCk1ZIurLH/9ZLukHSPpBWS3tNMphsmx+lCerGk0gxJg4ErgbOACcBMSROqqn0VmG9mbwNmAN9rJte7co7TZRi0coxpMrDazNYASJoHTAfurzrl6+L7/YDfNxPqhslxugzD2Jo+xjRK0tLM57lmNjfzeQzwZObzOuDEKhnfAG6V9Dlgb+C0Zicd0F05SVdLelbSyrz1JR0v6b7Yb75CkmKdqZKekfRafL0sbs/Wfzi+Lpb0XUnrJS2XtFHStnjsVZnzZvvo92aOvTi+N0kb4nHPSTqzhs4vZo47Iu4bGeX1StpUp/9/kqS7o15n572GtfZLGiHpNkmPxNcD4vbhku6KOq2SdEncPi7qvVrSjZKGZWQ9Hq/r8soDUku+pDfFOpWyWdL59XSJcr4Y9Vgp6YaoX01dJH0h1lsl6fwaeqyPv03KdVDUb4ukP0q6v5G8WP8KSWsk/UHSEzXkXRF1XiHp7RkdzonyHpF0DgAGPYkF2GBmkzIla5RSmQlcY2ZjgfcAP5bU0PYMaMMEXAPk8fPJ1v8+8GlgfCxTFfrTVwGrgRHA08CCqvrfAYYDnwMuJ/w7XA58BNgHOCaWj0g6Rjv30f+B8A80LR7zDuAMoAfYGM+5AfhhPK6i81VAj5kdFY+7NO57DRgFXAxcT+3+/xPAx+P+Ztckdf+FwK/NbDzw6/gZYAtwipkdB0wkXNMpUd/Lo/4vAOdWyTvZzCaa2aR68s3soVhnInA88Apwcz1dJI0BPg9MMrNjgMGE8Y9ddJF0DOG3nQwcB7xX0lFVsn8B/FvidTiL0FsZA5wM/KFG/ay8swj34E3AdcBTNeRV7tNZhHsRSSOArxNaMJOBr0s6ICywTCsJrAcOy3weG7dlOReYD2BmvyU8Hw1dXQa0YTKzO4Hns9skvUHSLZKWSfpPSW+uUX8I8Doz+x1wJHAo4YZYBgwDvm5mLwHzgHdJGp2pPx34EfA+wo10ZBR/HrDWzB40s4eBtXFbto/+XuAnUcZNhAfsYEIffX4853XAq/G4is5/SniIiMedKkkEA7iS0LzujfpOr7pGj5vZCurch7WuYcL+6cC18f218VpggZfi9qGxGHBK1Hun+g2oKT/DqcCjZra2Sd0hwJ6ShgB7ER74WrocDSw2s1fMbBvwG+Avq2RfArwrUc/pwMsA8Z7ZP95D9eRNJ/zu04G/A/YHflUl77p4fbPyzgRuM7PnzewF4DZgKoiexJLAEmB8bGkOIxj3BVV1niD8Jkg6mmCYnmskdEAbpjrMBT5nZscDX6b2DMEQwsNcqf8tYDHhwd6PYIwWAx8D3kb456vUH0MwBmPiTfwq4Z/5w8C+ma7E74Ej2LmPPgZ4IHPsi8CbCQ9v5V9oHbAt1q1wCLAVIHPcSGr3/7PHtYuDzeyp+P5pgnEFwiyOpOXAs4QH5VFgU9S7lo5GGJ9YJmlWM/mRGcANjeqa2Xrg7wkPzVOEa7asji4rCb/5SEl7Ebojh9WQfWDidRhD+L1ulbSM8KcwpoG8yu9Y2b+OYNQPrtpfoaJ3ze0G9FpaaUa8VrOBRYR7d76ZrZI0R9K0WO1LwKcl3Uv4XT5uTRJadtXgt6R9CK2Ln4QGBQB7JNR/PXAQ8BaCMR8BTCF0kb4EXNbgtJsJrZtrCdOp3wY+2Zfv0UmYmUmyzOceYKKk/QldrTfXPTjwTjNbL+kg4DZJDzaSH/+1pwEXNdIl/kFMB8YBmwgt1ZpdVjN7QNKlwK2Els5yQve6rh6Nzh35azP7WfxejxL+4JLlVao12V+XxNZQEma2EFhYte3izPv7CcMSyXRbi2kQ4R9xYqYcXfkXj//kXyS0SMZW6hMM0DzgQ/Hzz4B7gM8QjPsfY30ILZtjgPWxi7APodn6OOFmnhzrHRq3Zfvo6wndhsqx+wEPAmJHK2JsPGe2H/804R+UzHEbSev/t4NnYleC+PpsdQUz2wTcAfwJoetR+ZPcScfYssHMniUYsslN5J8F3G1mzzTR5TTgMTN7zsy2Aj8lPDw1dTGzq8zseDM7idBtfriG7A2J12E9sGfme22J56onr/I7VvaPJbS4nq3aX6Gid83tYYFly7pybaGrDJOZbQYek/QB2D6bcZyZ9WQGTi8nGKbNhBbOY8BXgJ8T+tODCf+0kwnN/xcJazY2x4HcBcCnYv2zgf8Xm63fJ7S81kp6I3A4oRu5vY9OGOz8QJRxNnB73C/gg7EF9zHCTX1X5qv9O1DpIp4N3B7PuYQwIDqK8FvX6v+3gwXAOfH9OYRrgaQDY0sJSXsCpxOa/3dEvavr7y1p38p7wkTAynryIzPZ0Y2rqwuhCzdF0l5xPO5Uwu9YT5eD4uvrCeNL19eQfVvKdSB0ez4R7793E1rtv20gbwHhd19AWKz4IsEA/zy7P8qbArwYu3yLgDMUZi0PiNdvEUCvKakUhpkN2EK4QZ8i/LusI8wOjANuAe4l3IgX16n/DOEfZ20slfr/SjBaWwjjRKcAc4ALCA/NGsKs3WqC8bgZuA9YQXgYthJmy66J55xDGOh8OB57X+bYS6LePbH0ElpfZ8XjpmV07iUY1DXAkZnv9Ezm2BcJxnYOMC3uPyGe42VCK2tVs2uYcI1HEmaNHiEYzRGx7rGEluaKeK0ujtuPjN93NaFLtUdm+72xrAL+Jm6vJ3/v+B32y+hXs27cdwmhRboS+DHBQNTT5T/j738vcGoN2U/HknIdjiS0hrYQxiC/lyDvdsKf5EuE+ygrT4SZ3UcJ98+kzHf8JDvux0+YGUe/dagtW3tYUgGWFvHsykruZew4Tms5+tg97Lpfjk6qO/nwtctsxzKNfqOrBr8dxwkU2k1LwA2T43QZlcHvMuOGyXG6DtFj5Z73csPkOF2GAVsZ3LRekZTbbBZEZoVxS+u6bJddBtlmocWUUorCDVNt8vzQuW4Kl+2ySyCbXpRUisK7co7TZYTB73K3Sbp6HdMe+w+3fUbvu8v2Vze9yvD9hyfJyFPXZbvsvsoet/fhu2xbtmzZS2a2641ch/Fv3cu+8/OjkupOe8N9vo6pv9ln9L6c+S/NImw4Tnm4fsoPd9km6aE8MkI8pnK3mPpdO+WMKll1bM2oknHf5yQ9qBBhsJG3v+N0PT2mpFIURZjNa8gXVTLLLlElASSdTHCsPc7M3kKIs+M4Tg0M0cOgpFIU/X5myxlVMlNne5TI6Dl/HTsi+P0V8C0z2xLPsUuYDcdxdtBrg5JKUZSlo5kSVTIbJRJ2jnT4RmJUSUm/kXRCvRNJmiVpqaSlr256tUXqO07nUJmVK3OLqfDB77xRJeswhB1RJU8A5ks60mpMOVrI8jAXYOTRB3bvlKTTtRjFjh+lULhhIhNVMrtRIQvIsvhxAWF8aWymSjbS4Trgp9EQ3SWplxAcrWHAc8fpVnxWrgmWEFXSzC62EJFvs6QpcTbuY+yI4PczQhocYnTIYewa5tRxHMCMlrqkaOe8iLVyF16uHfn+Hpa0qZnMfm8xSboBeDchw+c6Qt6rDwPfl/RVQuzqeYRIgdX8NWFWb09C+ppfxe1XA1fHJQivAefU6sY5jhO6clutNU682pEX8XRCz2WJpAUWEhCE85l9MVP/c1QlXqhFvxsmM5tZZ1fTJQRmtpQQ6L96+2uEhJKO4yTQwoHtbF5EJFVyF95fp/5MQmOkIWUYY3Icpx8xciUaGKWYmj0y13ZOE14rd92JtQRJOpwQc//2Zid1w+Q4XUiOFtOGFvrKzQBuspBbsCFumBynywiZeFvWlcuTu3AGcF6K0AHhKyfpG5LWZ0b+39N6zR1noJCW7DIxLvj2vIgKWZBr5i6M3hwHEPLnNWVA+MpFLs8sL1hY82jHcba3mFrhkmJm24DZhESaDwDzzWyVpDmSpmWqzgDmpc6WFzErd6ekI7LbJL2BMOV4IPAK8Gkze7CqznZfufi54iv3KxzHyUUrs6TEhsDCqm0XV33+Rh6ZhS+wjPTVVw5gtqQVsat4AHVwXzmn2zGTO/E2o8pXbjnwAyAtTegOvg+8AZhISFf97XoVzWyumU0ys0l5Igo6zkCi7MkIyjAr12dfOTN7JnPcD4FftlNhx+lkQgRLd+JtiJltlvSYpA+Y2U/iTNuxZnYvoQW0HUmbJU0BFhN85f4xbh8dfekA/gLIPePnON2DJ7zchTb5yl0maSLhz+Bx4DPt+waO09mEWTlvMe1Em3zlPtpXvRynmyh7+qbCu3KO4/QvhtjWougC7cINk+N0GSEeU7m7cm1tzyUEkNpD0o1x/+LswktJF8XtD0k6s5lMSbPjNpM0qp3fy3E6nV5TUimKthmmTACps4AJwExJE6qqnQu8YGZHAZcDl8ZjJxCWsL+FMPb0PUmDm8j8b+A0YG27vpPjDARC2JPuXWC5PYBUDORWCSCVZTpwbXx/E3BqXC4wneBXs8XMHgNWR3l1ZZrZPWb2eBu/j+MMGFroxNsW2mmYagWQGlOvTnQGfBEY2eDYFJkNcZcUp9upLBcoc1eu6wa/PX2T46jQbloK7TRMKQGkKnXWSRoC7AdsbHJsalAqx3HqUHaXlHaazZQAUguAc+L7s4HbY7yWBcCMOGs3jhB76a5EmY7jNKCyXCClFEXbWkxmtk1SJYDUYODqSgApYKmZLQCuAn4saTXwPMHQEOvNJ2Ra2AacV4kTXEtm3P554CvAIcAKSQvN7FPt+n6O08l0c1euaQApM3sV+ECdY78JfDNFZtx+BXBFH1V2nAFPziwphdB1g9+O45R/jMkNk+N0GR5dwHGc8mFiW2+5nXgLGQFrkw/dbqeFcpxuohLBMqWk0Ox5jnU+KOl+SaskXd9MZhF55VruQxePuYbdTwvlOF1Fq1Z+pzzPksYDFwHvMLO3AOc3k1tEi6kdPnSY2Z2EJQeO4zSgxS4pKc/zp4ErzewFADN7tpnQIgxTO3zoknFfOcfJZZhGVZ6XWGZViUp5Jt8IvFHSf0v6naSmPZuuG/x2Xzmn28m5jmmDmU3q4ymHELw33k1wI7tT0lvNbFO9A4poMeXxoSOHD53jOIm0cPA75ZlcBywws61xCOZhgqGqSxGGqR0+dI7jpGItHWNKeZ5/RmgtEaPLvhFY00hovxumOGZU8Xd7AJhf8aGTNC1WuwoYGX3oLgAujMeuAio+dLewsw/dDcBvgTdJWifp3P78Xo7TKbRy8DvxeV4EbJR0P3AH8D/NbGMjuYWMMbXJh65eWijHcapo5crvhOfZCA2MC1Jldt3gt+N0O+7E6zhOKbGSG6ZSBWXZXVcVSSMl3SHpJUn/1N96O06n0UqXlHZQGsPUF1cV4FXga8CX+0ldx+lYzKCnd1BSKYrSGCb64KpiZi+b2X8RDJTjOA1Jm5EbkAkvd4O+uKok4y4pjhPGmFJKUZTJMPULZjbXzCaZ2aTh+w8vWh3H6Xc6Ia9cmQxTX1xVHMdJxcI4U0opijIZpr64qjiOk4Oyz8qVZh1TX9I9AUh6HHgdMEzS+4AzzOz+/v4ejlN2jPKvYyqNYYI+u6oc0VblHGfA4Cu/nTZw0aG/ylV/L/W0SRMYnOP+HjEo3+32hXWnJdfd0uu3ch7KPgDiv6bjdCHelXMcp1SEGbdyG6Yyzco1JMGP7iRJd0vaJunsInR0nE7B1zG1gEQ/uieAjwNNc1Y5TrdT9nVMndKV2+5HByCp4ke3fTmAmT0e9/UWoaDjdAqG6C3QQTeFcmu3gz6nbargvnKOE9cyJZSi6BTD1DLcV87pesydeFuFp21ynFbSwiZTwsTUxyU9J2l5LJ9qJrNTxpi2+9ERDNIM4EPFquQ4nUurWkOZianTCUMsSyQtqOEOdqOZzU6V2xEtppQUMZJOkLSO4LLyA0mritPYccpNC2flUgI85qZTWkwpfnRLCF28tnHJmF+2U3wyPTm9vts5Tbm30nXZQ0Nzyf7Hsbcn171rS77xwuWvvj5X/YFETifeUZKWZj7PNbO5mc+1JqZOrCHn/ZJOImTh/aKZPVmjznY6xjA5jtMiDEg3TBvMbFIfz/gL4AYz2yLpM4Tw2Kc0OqAjunKO47SWFnblmk5MmdlGM9sSP/4IOL6Z0AFlmCRdLelZSSuL1sVxSk3rZuWaBniUNDrzcRphnLghA8owAdcAU4tWwnHKTdoappRxqJSJKeDzklZJuhf4PMF1rCEDaozJzO6sJMF0HKcBLVzWnTAxdRFwUR6ZA8owpSBpFjALYK9D9ilYG8cpAA97Uj7cJcVxKL2zXNe1mBzHIc9ygUJIajFJmiJpiaSXJL0mqUfS5nYr5zhOmyh5iym1K/dPwEzgEWBP4FME/5hSIekG4LfAmyStk3Ru0To5TumoLLBMKQWR3JUzs9WSBptZD/Avku4h50h7uzGzmUXr4DidwEDJkvJKXDy1XNJlwFMMgIHzQ4duapv/29CcfzbDc/icDc3pK5fHR603p2fdnhqWq34eNvS+llx3UBv1GJCU3DClGpePErLjzgZeJixBf3+7lHIcp80MhK6cma2Nb/8IXNI+dRzH6Q80EFpMkt4r6R5Jz0vaLOkPRc3K1fKHkzRC0m2SHomvBxShm+N0BKkzch0wK/dd4BxgpJm9zsz2NbPXtVGvRlzDrv5wFwK/NrPxwK/jZ8dxapLYjeuAmN9PAivNih/LN7M7geerNk8nxHghvr6vX5VynE6j5C2m1Fm5rwALJf0GqMRVwcy+0xat8nOwmT0V3z8NHFyvYtZX7tAxHT+x6Di7R+FNjMakPpnfBF4BhgP7ZkrpiK26upc96ys3YoQbJqdLGSAtpkPN7Ji2atI3npE02syeikGpni1aIccpLflC6xZCapNhoaQz2qpJ31hAGJwnvv68QF0cp/SoN60URaph+ivgFkl/LMFygVr+cN8CTpf0CHBa/Ow4ToeSusCyNONJDfzhTs0tC+VKhVSWIamhyqfIUA1OrjuojZFwNve+2jbZTj7KvsAy+S6UdCxwRPYYM/tpG3RyHKfdlHyMKckwSboaOBZYxY78iQa4YXKcTqPgGbcUUltMU8xsQls1cRyn/2ihYZI0FfgHgqP/j8ys5hivpPcDNwEnmNnSWnUqpA5W/FZSKQyTpOGS7pJ0b0wJc0ncPk7SYkmrJd0Yw7Q4jlMDWVppKkcaTAgaeRYwAZhZy1ZI2hf4ArA4Rb9Uw3QdwTg9JGmFpPskrUg8ttVsAU4xs+OAicBUSVOAS4HLzewo4AXAo1c6Tj1at8ByMrDazNaY2WvAPIKLWDV/S3hGk2ZAUg3TVYSYTFOBPwfeG1/7HQu8FD8OjcUIudBvitvdX85xGpFumEZJWpops6okjSH40lZYF7dtR9LbgcPM7N9S1UsdY3rOzBY0r9Y/xObjMuAoQjPyUWBTzAoKNS5O5tiMr1z6NLrjDBRSu2mRDWY2abfPJQ0CvkNC9t0sqYbpHknXA79gZyfeQmblYtzxiZL2B24G3pzj2LnAXIBjjh1W8rkJx2kTrVsusJ4Q0bbC2Litwr7AMcB/KISPPgRYIGlaowHwVMO0J8EgZd1SCl8uYGabJN0B/Amwv6QhsdVUfXEcx8nSur/kJcB4SeMIz9wM4EPbT2P2IjCq8lnSfwBfbjYrl7ry+xO7oXBbkHQgsDUapT2B0wmDancAZxMG39xfznEa0KqV32a2TdJsYBFhucDVZrZK0hxg6e4OAaUusBxOmOV6CyH0SUWpT+7OSfvIaODaOM40CJhvZr+UdD8wT9LfAfcQBuwdx6nGWuuga2YLgYVV2y6uU/fdKTJTu3I/Bh4EzgTmAB8GHkg8tqWY2QrgbTW2ryFMXSYjjME52rS9Ofzq8rrV5blP8vi+7U79djEoR4oqoPSrkzuakl/b1OfnKDP7GvCymV0L/BlwYvvUchynrQyQQHFb4+smSccQwtce1B6VHMdpNwMlusDcmBLpq4SgbPsAX2ubVk2Q9DjwB6AH2GZmkySNAG4kREB4HPigmb1QlI6O4+w+qV25/YBPAJMICxovBbZJmtguxRI42cwmZhZ/eQonx0ml5F25VMN0PPBZwmrqQwkrp6cCP5T0lTbplhdP4eQ4KSQ68BbZ3Us1TGOBt5vZl8zsSwRDdRBwEjmXmrcIA26VtCzju5OUwknSrIrfz/PPFxjU2HGKpOQtptQxpoPIuKIQBsMPNrM/StpS55h28k4zWy/pIOA2SQ9md5qZSbXtfdYl5a3HDi35EKDjtImS3/mphulfgcWSKqup/xy4XtLewP1t0awBZrY+vj4r6WbC+iVP4eQ4CYjyz8oldeXM7G8J40qbYvmsmc0xs5fN7MPtVLAaSXvHoFNEw3gGsBJP4eQ46QyQrhzR6a6h410/cTBwc/RUHgJcb2a3SFoCzI/pnNYCHyxQR8cpLwUPbKfQvlw9bSK6nhxXY/tGdiOFk+N0JW6Yyk0en7Y8dfPO9w3N4Yc3hPb5vm21nrbJdkqEGybHccpGkem/U3DD5DjdRgfklStJ0ut0JL1J0vJM2SzpfEkjJN0m6ZH4ekDRujpOWRkoK79Lg5k9FH3kJhJWoL9CiPvtvnKOk0rJlwt0nGGq4lTgUTNbi/vKOU4y3mJqLzOAG+J795VznFS8xdQeYgrwacBPqveZWd3LamZzzWySmU0aMaJjv77j7D6pRinRMEmaGrN0r5a0yxCKpM/G7N3LJf1XrRTi1XTyk3kWcLeZPRM/PxN95HBfOcepj3KUprJCUpArCc/jBGBmDcNzvZm9NY4LX0ZIgNmQTjZMM9nRjQP3lXOcdFrXYpoMrDazNWb2GiF92vSdTmW2OfNx7xTJHbmOKTrvng58JrP5W7ivnOMkkWNge5SkrI/s3Bg6qMIY4MnM53XUSFQi6TzgAmAYcEqzk3akYTKzl4GRVdty+8oJGJwjo1CeofJ2NkV7c45KliN5k1Mq0m+hDZnw1bt/OrMrgSslfYiQO+CcRvU7uSvnOM7u0rqu3HrgsMznsXFbPeaRsJTHDZPjdButjfm9BBgvaVycKZ9BGO/djqTxmY9/BjzSTGhHduUkfRH4FMGm30fI4DKaYI1HAsuAj8bBOMdxqmiVE6+ZbZM0G1hEGDW42sxWSZoDLDWzBcBsSacRQnK/QJNuHHSgYZI0Bvg8MCHGHJ9PsNLvAS43s3mS/hk4F/h+gao6Tnlp4eJJM1sILKzadnHm/RfyyuzUrtwQYE9JQ4C9gKcII/03xf3ukuI4DXCXlBYTExH8PfAEwSC9SOi6bTKzbbHaOsI05i5kXVI2ukuK0420eOV3O+g4wxTDmUwHxhGSb+5NSL6ZRNYlZaS7pDjdSskNU8eNMQGnAY+Z2XMAkn4KvAPYX9KQ2GpqNmXpOF3LgEnfVDKeAKZI2kshVcqphNx2dwBnxzrukuI4jSh5i6njDJOZLSYMct9NWCowiJBZ938BF0haTVgycFVhSjpOyZFZUimKTuzKYWZfB75etXkNwaHQcZxGFNwaSqEjDVMraVeTcXCOdEx5Gap83m895rOPzs6UfYyp6w2T43QlbpgcxykbZW8xddzgN4CkL0haKWmVpPPjNk/f5Dip+Kxca5F0DPBpwkD3ccB7JR2Fp29ynDQsOPGmlKLoOMMEHA0sNrNX4mLK3wB/iadvcpwkKgss3VeutawE3iVppKS9CFEFDsPTNzlOOmZppSA6bvDbzB6QdClwK/AysBzoqapjUm17H+MVzwU49tihJR8CdJz24IPfbcDMrjKz483sJELgqYfx9E2Ok4ZHF2gPkg6Kr68njC9dj6dvcpxkyj743XFducj/lTSSEKrzPDPbJMnTNzlOKiXvynWkYTKzd9XYlj99k8QwpbuO9OQYDByaQ26ZGNRGV5q89JT84elkyj7G1JGGyXGcPmAUOuOWQkeOMTmO0zdauY5J0lRJD0laLWmXhc2SLpB0v6QVkn4t6fBmMktrmCRdLelZSSsz22q6nShwRbwwKyS9vTjNHacDaNGsnKTBwJXAWcAEYKakCVXV7gEmmdmxhFhqlzWTW1rDBFzDrrG867mdnAWMj2UWnrbJcerS4pXfk4HVZrYm5nGcR/DC2I6Z3WFmr8SPvyOEvm5IaQ2Tmd0JPF+1uZ7byXTgOgv8jhD/e3T/aOo4HUbqqu8wDjWq4ikRy6wqaWOAJzOf62YoipwL/KqZip02+F3P7aTexXmKKuKFnQUwZky+gGuOM1DIsUZpg5lNask5pY8Ak4D/0axuaVtMzTCz3VqbulP6ppEd+/Udp0+0sCu3nuCrWqFmhqKYIvxvgGlmtqWZ0E57Muu5nSRdHMdxCH/nvZZWmrMEGC9pnKRhwAyCF8Z2JL0N+AHBKCW5inWaYarndrIA+FicnZsCvJjp8jmOU02LZuVi6KHZwCLgAWC+ma2SNEfStFjt/wD7AD+RtFzSgjritlPaMSZJNwDvJgy+rSNkRanndrKQEP5kNfAK8Il+V9hxOohWrvw2s4WEZzC77eLM+9PyyiytYTKzmXV27eJ2EsebzmuvRo4zgCj5yu/SGqZ+wSyX/9u+g9IvV94US4Ny9Kq3Wk/zSjvJTvd/6805n5Dne277zllUAAAEz0lEQVTp9cB8ZcF95RzHKRcFx1pKwQ2T43QZYeV3uS1TqWflJD0u6b44kr80bnN/OcfpK72JpSBKbZgiJ5vZxMzqU/eXc5w+IrOkUhSdYJiqcX85x+kLHvO7zxhwq6RlGefBvP5yO5FN37TR0zc5XUkuJ95CKPvg9zvNbH1MPnCbpAezOxulaapHNn3TcZ6+yelSfLlAHzCz9fH1WUk3E2K/PCNptJk95f5yjrMbGKjkAdVL25WTtLekfSvvgTMIWXjdX85x+op35Xabg4GbFbKNDAGuN7NbJC3B/eUcp2+Uu8FUXsNkZmuA42psr5mmqT/85fK4XwyhM4PQ5XWlean31eS6r5V8UV83UfYFlqU1TI7jtBE3TI7jlAqj0FXdKbhhcpwuQxS7qjsFN0yO0424YXIcp3S4YXIcp1R0wBhTaRdYOo7TPloZXUDSVEkPxZBDF9bYf5KkuyVtk3R2ikw3TI7TjbRo5bekwcCVhLBDE4CZkiZUVXsC+Dhwfap63pVznK6jpe4mk4HVcUE0kuYRQhDdv/1sZo/HfckdSDdMjtNtGJDuxDuqEj02MjdG6KhQK9zQiX1T0A2T43QlOdYxbchEj+03utowrbhv24axhz29tsauUcCGRDF56rrs0she3UbZfa5bt/6XaqfielMOuYHWdeXaEm6oqw2TmR1Ya7ukpan/EnnqumyX3S7ZqXKBuFygZYZpCTBe0jiCQZoBfKivQn1WznG6jtaF1jWzbcBsYBHwADDfzFZJmiNpGoCkEyStAz4A/EDSqmZyu7rF5DhdSwtXfpvZQkI8tOy2izPvlxC6eMm4YarN3OZVdquuy3bZZZBdepcUWckVdDoTSYcA3wVOADYBzwDnm9nDhSrmsN8eh9ifjvlIUt1bHvv2Mp+VcwYECvGQbwauNbMZcdtxhHDJbpgKx8DK7SznhslpBycDW83snysbzOzeAvVxqil5T8kNk9MOjgGWFa2EU4fWLhdoC26YHKcbKXmLydcxOe1gFXB80Uo4DSh5Xjk3TE47uB3YQ9KsygZJx0p6V4E6ORXMoKcnrRSEGyan5cQcf38BnCbp0bjS938DTxermbOdkreYfIzJaQtm9nt2ZEl2ykbJx5jcMDlO12E+K+c4TskwMF9g6ThO6fAWk+M4pcPHmBzHKRVm0OtdOcdxyoa3mBzHKRvmLSbHccpFsYsnU3DD5DjdhkcXcBynlJR8HZP7yjlOl2GA9VpSSUHSVEkPSVot6cIa+/eQdGPcv1jSEc1kumFynG7DDOvpSSrNkDQYuBI4C5gAzJQ0oaraucALZnYUcDlwaTO5bpgcpxux3rTSnMnAajNbY2avAfOA6VV1pgPXxvc3AafGuPB18TEmx+ky/sALi/7dbhqVWH14VabfuWaWTRc1Bngy83kdcGKVjO11zGybpBeBkTRIme6GyXG6DDObWrQOzfCunOM4fWE9cFjm89i4rWYdSUOA/YCNjYS6YXIcpy8sAcZLGidpGDADWFBVZwFwTnx/NnC7Ncm06105x3F2mzhmNBtYBAwGrjazVZLmAEvNbAFwFfBjSauB5wnGqyGeItxxnNLhXTnHcUqHGybHcUqHGybHcUqHGybHcUqHGybHcUqHGybHcUqHGybHcUrH/wdVSFnILnfWLAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2a6cda8320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "param_grid = {'svc__C': [0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 30, 50, 70, 80, 90, 100, 500, 1000],\n",
    "              'svc__gamma': [0.001, 0.005, 0.008, 0.01, 0.03, 0.04, 0.05, 0.1, 1, 10, 100, 1000, 10000, 100000, 1000000]}\n",
    "\n",
    "pipe = make_pipeline(MinMaxScaler(), SVC())\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv=5, n_jobs=3, verbose=1)\n",
    "\n",
    "# no meaning to use cross_val for grid_search model because it is incluced in grid search\n",
    "#scores = cross_val_score(grid_search, X_train, y_train, cv=5, n_jobs=6)\n",
    "#print(\"mean of train scores\", scores.mean())\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "plt.matshow(grid_search.cv_results_['mean_test_score'].reshape(16, -1),\n",
    "            vmin=0, cmap=\"viridis\")\n",
    "plt.xlabel(\"C\")\n",
    "plt.ylabel(\"gamma\")\n",
    "plt.xticks(range(len(param_grid['svc__C'])), param_grid['svc__C'])\n",
    "plt.yticks(range(len(param_grid['svc__gamma'])), param_grid['svc__C'])\n",
    "plt.colorbar()\n",
    "\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))\n",
    "print(\"confusion matrix: \", confusion_matrix(y_test, grid_search.best_estimator_.predict(X_test)))\n",
    "print(\"\")\n",
    "report2(grid_search.cv_results_, n_top=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n",
      "best parameters: {'kneighborsclassifier__n_neighbors': 3}\n",
      "Mean cross-validated score of the best_estimator:  0.7979041916167665\n",
      "test:  0.820627802690583\n",
      "confusion matrix:  [[114  20]\n",
      " [ 20  69]]\n",
      "\n",
      "Rank|Score(std)|Params ['kneighborsclassifier__n_neighbors']\n",
      "1|0.797904(std:0.037606)|[3]\n",
      "2|0.794910(std:0.034435)|[4]\n",
      "3|0.790419(std:0.033305)|[5]\n",
      "4|0.787425(std:0.045020)|[7]\n",
      "5|0.785928(std:0.043933)|[6]\n",
      "6|0.784431(std:0.039757)|[9]\n",
      "7|0.781437(std:0.039525)|[2]\n",
      "8|0.778443(std:0.043845)|[15]\n",
      "9|0.775449(std:0.040502)|[8]\n",
      "10|0.772455(std:0.034110)|[10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done  55 out of  55 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "# no cale\n",
    "param_grid = {'kneighborsclassifier__n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20]}\n",
    "\n",
    "pipe = make_pipeline(KNeighborsClassifier())\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv=5, n_jobs=3, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))\n",
    "print(\"confusion matrix: \", confusion_matrix(y_test, grid_search.best_estimator_.predict(X_test)))\n",
    "print(\"\")\n",
    "report2(grid_search.cv_results_, n_top=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n",
      "best parameters: {'kneighborsclassifier__n_neighbors': 8}\n",
      "Mean cross-validated score of the best_estimator:  0.8293413173652695\n",
      "test:  0.8116591928251121\n",
      "confusion matrix:  [[117  17]\n",
      " [ 25  64]]\n",
      "\n",
      "Rank|Score(std)|Params ['kneighborsclassifier__n_neighbors']\n",
      "1|0.829341(std:0.024227)|[8]\n",
      "1|0.829341(std:0.025162)|[9]\n",
      "3|0.826347(std:0.023000)|[10]\n",
      "4|0.824850(std:0.026713)|[7]\n",
      "5|0.821856(std:0.023662)|[5]\n",
      "6|0.820359(std:0.026612)|[3]\n",
      "7|0.815868(std:0.020314)|[15]\n",
      "8|0.814371(std:0.018015)|[6]\n",
      "8|0.814371(std:0.030705)|[20]\n",
      "10|0.809880(std:0.015750)|[4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done  55 out of  55 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "# minmax scaler\n",
    "param_grid = {'kneighborsclassifier__n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20]}\n",
    "\n",
    "pipe = make_pipeline(MinMaxScaler(), KNeighborsClassifier())\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv=5, n_jobs=3, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))\n",
    "print(\"confusion matrix: \", confusion_matrix(y_test, grid_search.best_estimator_.predict(X_test)))\n",
    "print(\"\")\n",
    "report2(grid_search.cv_results_, n_top=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n",
      "best parameters: {'kneighborsclassifier__n_neighbors': 8}\n",
      "Mean cross-validated score of the best_estimator:  0.8293413173652695\n",
      "test:  0.8116591928251121\n",
      "confusion matrix:  [[117  17]\n",
      " [ 25  64]]\n",
      "\n",
      "Rank|Score(std)|Params ['kneighborsclassifier__n_neighbors']\n",
      "1|0.829341(std:0.024227)|[8]\n",
      "1|0.829341(std:0.025162)|[9]\n",
      "3|0.826347(std:0.023000)|[10]\n",
      "4|0.824850(std:0.026713)|[7]\n",
      "5|0.821856(std:0.023662)|[5]\n",
      "6|0.820359(std:0.026612)|[3]\n",
      "7|0.815868(std:0.020314)|[15]\n",
      "8|0.814371(std:0.018015)|[6]\n",
      "8|0.814371(std:0.030705)|[20]\n",
      "10|0.809880(std:0.015750)|[4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done  55 out of  55 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "# robust scaler\n",
    "param_grid = {'kneighborsclassifier__n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20]}\n",
    "\n",
    "pipe = make_pipeline(MinMaxScaler(), KNeighborsClassifier())\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv=5, n_jobs=3, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))\n",
    "print(\"confusion matrix: \", confusion_matrix(y_test, grid_search.best_estimator_.predict(X_test)))\n",
    "print(\"\")\n",
    "report2(grid_search.cv_results_, n_top=10)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 5 age band\n",
    "Mean cross-validated score of the best_estimator:  0.837248322147651\n",
    "best parameters: {'kneighborsclassifier__n_neighbors': 8}\n",
    "test:  0.823728813559322\n",
    "\n",
    "# if age band is 10\n",
    "Mean cross-validated score of the best_estimator:  0.8355704697986577\n",
    "best parameters: {'kneighborsclassifier__n_neighbors': 8}\n",
    "test:  0.8271186440677966\n",
    "\n",
    "# OR change rare title to \"Rare\" and map value\n",
    "Mean cross-validated score of the best_estimator:  0.8087248322147651\n",
    "best parameters: {'kneighborsclassifier__n_neighbors': 10}\n",
    "test:  0.7830508474576271\n",
    "\n",
    "\n",
    "# 5 age band and filled age by mean of group(title, pclass)\n",
    "Mean cross-validated score of the best_estimator:  0.837248322147651\n",
    "best parameters: {'kneighborsclassifier__n_neighbors': 8}\n",
    "test:  0.823728813559322\n",
    "\n",
    "# 10 age band, parch, sibsp\n",
    "best parameters: {'kneighborsclassifier__n_neighbors': 8}\n",
    "Mean cross-validated score of the best_estimator:  0.835570469799\n",
    "test:  0.827118644068\n",
    "\n",
    "\n",
    "# 10 age band, parch&sibsp, embarked num category\n",
    "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n",
    "best parameters: {'kneighborsclassifier__n_neighbors': 8}\n",
    "Mean cross-validated score of the best_estimator:  0.840604026846\n",
    "test:  0.813559322034\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## try several SVC, KNeighborsClassifier models and preprocessing conbinations"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "param_grid = dict(scaling=[None, MinMaxScaler(), RobustScaler()],\n",
    "                  reduce_dim=[None, PCA(), PCA(5)],\n",
    "                  clf=[SVC(C=100, gamma=0.01), KNeighborsClassifier(n_neighbors=8)]\n",
    "                 )\n",
    "pipe = Pipeline([('scaling', StandardScaler()), ('reduce_dim', PCA()), ('clf', SVC())]) \n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=3, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))\n",
    "print(\"confusion matrix: \", confusion_matrix(y_test, grid_search.best_estimator_.predict(X_test)))\n",
    "print(\"\")\n",
    "report2(grid_search.cv_results_, n_top=10)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 5 age band\n",
    "\n",
    "Mean cross-validated score of the best_estimator:  0.8422818791946308\n",
    "best parameters: {'clf': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "           metric_params=None, n_jobs=1, n_neighbors=8, p=2,\n",
    "           weights='uniform'), 'reduce_dim': PCA(copy=True, iterated_power='auto', n_components=15, random_state=None,\n",
    "  svd_solver='auto', tol=0.0, whiten=False), 'scaling': MinMaxScaler(copy=True, feature_range=(0, 1))}\n",
    "test:  0.8101694915254237\n",
    "\n",
    "# 10 age band\n",
    "\n",
    "Mean cross-validated score of the best_estimator:  0.8422818791946308\n",
    "best parameters: {'clf': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "           metric_params=None, n_jobs=1, n_neighbors=8, p=2,\n",
    "           weights='uniform'), 'reduce_dim': PCA(copy=True, iterated_power='auto', n_components=15, random_state=None,\n",
    "  svd_solver='auto', tol=0.0, whiten=False), 'scaling': MinMaxScaler(copy=True, feature_range=(0, 1))}\n",
    "test:  0.8101694915254237\n",
    "\n",
    "# OR change rare title to \"Rare\" and map value\n",
    "Mean cross-validated score of the best_estimator:  0.8154362416107382\n",
    "best parameters: {'clf': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "           metric_params=None, n_jobs=1, n_neighbors=8, p=2,\n",
    "           weights='uniform'), 'reduce_dim': PCA(copy=True, iterated_power='auto', n_components=15, random_state=None,\n",
    "  svd_solver='auto', tol=0.0, whiten=False), 'scaling': MinMaxScaler(copy=True, feature_range=(0, 1))}\n",
    "test:  0.7898305084745763\n",
    "\n",
    "\n",
    "\n",
    "# 5 age band and filled age by mean of group(title, pclass)\n",
    "Mean cross-validated score of the best_estimator:  0.8439597315436241\n",
    "best parameters: {'clf': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "           metric_params=None, n_jobs=1, n_neighbors=8, p=2,\n",
    "           weights='uniform'), 'reduce_dim': PCA(copy=True, iterated_power='auto', n_components=15, random_state=None,\n",
    "  svd_solver='auto', tol=0.0, whiten=False), 'scaling': MinMaxScaler(copy=True, feature_range=(0, 1))}\n",
    "test:  0.8067796610169492\n",
    "\n",
    "\n",
    "# 10 age band, parch, sibsp\n",
    "best parameters: {'clf': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "           metric_params=None, n_jobs=1, n_neighbors=8, p=2,\n",
    "           weights='uniform'), 'reduce_dim': PCA(copy=True, iterated_power='auto', n_components=15, random_state=None,\n",
    "  svd_solver='auto', tol=0.0, whiten=False), 'scaling': MinMaxScaler(copy=True, feature_range=(0, 1))}\n",
    "Mean cross-validated score of the best_estimator:  0.8439597315436241\n",
    "test:  0.8067796610169492\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random forest result for compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**just trial of PolynomialFeatures(degree=2)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 675 candidates, totalling 3375 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 116 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=6)]: Done 716 tasks      | elapsed:   11.7s\n",
      "[Parallel(n_jobs=6)]: Done 1716 tasks      | elapsed:   28.7s\n",
      "[Parallel(n_jobs=6)]: Done 3116 tasks      | elapsed:   55.1s\n",
      "[Parallel(n_jobs=6)]: Done 3364 out of 3375 | elapsed:   59.9s remaining:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'randomforestclassifier__max_depth': 8, 'randomforestclassifier__max_features': 'log2', 'randomforestclassifier__min_samples_split': 7, 'randomforestclassifier__n_estimators': 40}\n",
      "Mean cross-validated score of the best_estimator:  0.8502994011976048\n",
      "test:  0.820627802690583\n",
      "confusion matrix:  [[117  17]\n",
      " [ 23  66]]\n",
      "\n",
      "Rank|Score(std)|Params ['randomforestclassifier__max_depth', 'randomforestclassifier__max_features', 'randomforestclassifier__min_samples_split', 'randomforestclassifier__n_estimators']\n",
      "1|0.850299(std:0.028153)|[8, 'log2', 7, 40]\n",
      "1|0.850299(std:0.030805)|[None, 'sqrt', 6, 40]\n",
      "3|0.848802(std:0.022352)|[20, 1, 5, 20]\n",
      "4|0.847305(std:0.025046)|[7, 'log2', 7, 60]\n",
      "4|0.847305(std:0.020712)|[8, 'log2', 3, 40]\n",
      "6|0.845808(std:0.031814)|[8, 1, 2, 20]\n",
      "6|0.845808(std:0.022244)|[8, 'log2', 7, 60]\n",
      "6|0.845808(std:0.021139)|[9, 'log2', 5, 60]\n",
      "6|0.845808(std:0.030166)|[20, 1, 5, 100]\n",
      "10|0.844311(std:0.031838)|[7, 'log2', 3, 20]\n",
      "10|0.844311(std:0.025359)|[8, 'log2', 2, 100]\n",
      "10|0.844311(std:0.020930)|[8, 'log2', 3, 20]\n",
      "10|0.844311(std:0.017710)|[9, 1, 2, 60]\n",
      "10|0.844311(std:0.026269)|[9, 'sqrt', 6, 20]\n",
      "10|0.844311(std:0.019907)|[9, 'log2', 5, 40]\n",
      "10|0.844311(std:0.024642)|[13, 'log2', 3, 60]\n",
      "10|0.844311(std:0.026206)|[13, 'log2', 5, 40]\n",
      "10|0.844311(std:0.027103)|[15, 'log2', 5, 40]\n",
      "10|0.844311(std:0.022680)|[20, 'sqrt', 3, 20]\n",
      "10|0.844311(std:0.021406)|[20, 'log2', 3, 30]\n",
      "10|0.844311(std:0.022470)|[25, 'log2', 6, 100]\n",
      "10|0.844311(std:0.020461)|[None, 1, 7, 30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 3375 out of 3375 | elapsed:  1.0min finished\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# too wide\n",
    "param_grid = {'randomforestclassifier__max_depth':[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 15, 20, 25 None],\n",
    "             'randomforestclassifier__max_features': [1, 'sqrt', 'log2', None],\n",
    "             'randomforestclassifier__min_samples_leaf': [1,2,3,4,5],\n",
    "             \"randomforestclassifier__min_samples_split\" : [2,3,4,5,6,7],\n",
    "             'randomforestclassifier__n_estimators': [10, 20, 30, 40, 50, 60, 70, 100],\n",
    "              }\n",
    "\"\"\"\n",
    "# narrow down\n",
    "param_grid = {'randomforestclassifier__max_depth':[5, 7, 8, 9,  13, 15, 20, 25, None],\n",
    "             'randomforestclassifier__max_features': [1, 'sqrt', 'log2'],\n",
    "#             'randomforestclassifier__min_samples_leaf': [1,2,3 ,5],\n",
    "             \"randomforestclassifier__min_samples_split\" : [2,3, 5,6,7],\n",
    "             'randomforestclassifier__n_estimators': [20, 30, 40,  60, 100],\n",
    "              }\n",
    "pipe = make_pipeline(PolynomialFeatures(degree=2), RandomForestClassifier())\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=6, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))\n",
    "print(\"confusion matrix: \", confusion_matrix(y_test, grid_search.best_estimator_.predict(X_test)))\n",
    "print(\"\")\n",
    "report2(grid_search.cv_results_, n_top=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 675 candidates, totalling 3375 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 272 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=6)]: Done 1772 tasks      | elapsed:   22.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'randomforestclassifier__max_depth': None, 'randomforestclassifier__max_features': 'sqrt', 'randomforestclassifier__min_samples_split': 6, 'randomforestclassifier__n_estimators': 30}\n",
      "Mean cross-validated score of the best_estimator:  0.8473053892215568\n",
      "test:  0.8116591928251121\n",
      "confusion matrix:  [[113  21]\n",
      " [ 21  68]]\n",
      "\n",
      "Rank|Score(std)|Params ['randomforestclassifier__max_depth', 'randomforestclassifier__max_features', 'randomforestclassifier__min_samples_split', 'randomforestclassifier__n_estimators']\n",
      "1|0.847305(std:0.027764)|[None, 'sqrt', 6, 30]\n",
      "2|0.845808(std:0.029138)|[8, 'log2', 3, 100]\n",
      "2|0.845808(std:0.025657)|[20, 'log2', 7, 20]\n",
      "4|0.844311(std:0.019098)|[15, 1, 5, 40]\n",
      "4|0.844311(std:0.030907)|[20, 'sqrt', 7, 100]\n",
      "4|0.844311(std:0.028818)|[20, 'log2', 3, 40]\n",
      "4|0.844311(std:0.027052)|[25, 1, 7, 40]\n",
      "4|0.844311(std:0.017068)|[None, 1, 5, 60]\n",
      "4|0.844311(std:0.025776)|[None, 1, 6, 30]\n",
      "4|0.844311(std:0.021525)|[None, 'log2', 6, 30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 3375 out of 3375 | elapsed:   45.1s finished\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# too wide\n",
    "param_grid = {'randomforestclassifier__max_depth':[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 15, 20, 25 None],\n",
    "             'randomforestclassifier__max_features': [1, 'sqrt', 'log2', None],\n",
    "             'randomforestclassifier__min_samples_leaf': [1,2,3,4,5],\n",
    "             \"randomforestclassifier__min_samples_split\" : [2,3,4,5,6,7],\n",
    "             'randomforestclassifier__n_estimators': [10, 20, 30, 40, 50, 60, 70, 100],\n",
    "              }\n",
    "\"\"\"\n",
    "# narrow down\n",
    "param_grid = {'randomforestclassifier__max_depth':[5, 7, 8, 9,  13, 15, 20, 25, None],\n",
    "             'randomforestclassifier__max_features': [1, 'sqrt', 'log2'],\n",
    "#             'randomforestclassifier__min_samples_leaf': [1,2,3 ,5],\n",
    "             \"randomforestclassifier__min_samples_split\" : [2,3, 5,6,7],\n",
    "             'randomforestclassifier__n_estimators': [20, 30, 40,  60, 100],\n",
    "              }\n",
    "pipe = make_pipeline(RandomForestClassifier())\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=6, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))\n",
    "print(\"confusion matrix: \", confusion_matrix(y_test, grid_search.best_estimator_.predict(X_test)))\n",
    "print(\"\")\n",
    "report2(grid_search.cv_results_, n_top=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X_train_df, y_train_df)\n",
    "\n",
    "test_df_noid = test_df.drop(\"PassengerId\", axis=1).copy()\n",
    "y_pred = pipe.predict(test_df_noid).astype(int)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": test_df[\"PassengerId\"].astype(int),\n",
    "        \"Survived\": y_pred\n",
    "    })\n",
    "submission.to_csv('../output/submission_randomforest.csv', index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "output of upper code\n",
    "\n",
    "# 5 age band\n",
    "Mean cross-validated score of the best_estimator:  0.8406040268456376\n",
    "best parameters: {'randomforestclassifier__max_depth': 7, 'randomforestclassifier__max_features': 'auto', 'randomforestclassifier__min_samples_leaf': 1, 'randomforestclassifier__min_samples_split': 2, 'randomforestclassifier__n_estimators': 100}\n",
    "test:  0.8203389830508474\n",
    "\n",
    "# if age band is 10\n",
    "Mean cross-validated score of the best_estimator:  0.8406040268456376\n",
    "best parameters: {'randomforestclassifier__max_depth': 7, 'randomforestclassifier__max_features': 'auto', 'randomforestclassifier__min_samples_leaf': 1, 'randomforestclassifier__min_samples_split': 3, 'randomforestclassifier__n_estimators': 100}\n",
    "test:  0.8271186440677966\n",
    "\n",
    "\n",
    "# OR change rare title to \"Rare\" and map value\n",
    "\n",
    "Mean cross-validated score of the best_estimator:  0.8305369127516778\n",
    "best parameters: {'randomforestclassifier__max_depth': 7, 'randomforestclassifier__max_features': 'auto', 'randomforestclassifier__min_samples_leaf': 1, 'randomforestclassifier__min_samples_split': 3, 'randomforestclassifier__n_estimators': 10}\n",
    "test:  0.8440677966101695\n",
    "\n",
    "test score was not bad score. but best estimager score is lower. it is better to not use Rare title\n",
    "\n",
    "\n",
    "## 10 age band, familysize, embarked num category, rare title&map value, no Name_Len, no Ticket_Len\n",
    "\n",
    "best parameters: {'randomforestclassifier__max_depth': 7, 'randomforestclassifier__max_features': 'auto', 'randomforestclassifier__min_samples_leaf': 2, 'randomforestclassifier__min_samples_split': 2, 'randomforestclassifier__n_estimators': 50}\n",
    "Mean cross-validated score of the best_estimator:  0.8506711409395973\n",
    "test:  0.8406779661016949\n",
    "\n",
    "\n",
    "## 10 age band, familysize, embarked num category, rare title&map value, no Name_Len, no Ticket_Len, one Cabin_Letter feature\n",
    "\n",
    "best parameters: {'randomforestclassifier__max_depth': 7, 'randomforestclassifier__max_features': 'auto', 'randomforestclassifier__min_samples_leaf': 1, 'randomforestclassifier__min_samples_split': 3, 'randomforestclassifier__n_estimators': 30}\n",
    "Mean cross-validated score of the best_estimator:  0.8506711409395973\n",
    "test:  0.8338983050847457\n",
    "\n",
    "\n",
    "## 10 age band, familysize, embarked num category, rare title&map value, no Name_Len, no Ticket_Len, one Cabin_Letter feature, del Cabin_Num features\n",
    "\n",
    "best parameters: {'randomforestclassifier__max_depth': 20, 'randomforestclassifier__max_features': 1, 'randomforestclassifier__min_samples_leaf': 2, 'randomforestclassifier__min_samples_split': 5, 'randomforestclassifier__n_estimators': 30}\n",
    "Mean cross-validated score of the best_estimator:  0.8456375838926175\n",
    "test:  0.8305084745762712\n",
    "\n",
    "Rank|Score(std)|Params ['randomforestclassifier__max_depth', 'randomforestclassifier__max_features', 'randomforestclassifier__min_samples_leaf', 'randomforestclassifier__min_samples_split', 'randomforestclassifier__n_estimators']\n",
    "1|0.845638(std:0.022761)|[20, 1, 2, 5, 30]\n",
    "2|0.843960(std:0.030146)|[9, 1, 2, 3, 40]\n",
    "3|0.842282(std:0.030799)|[5, 1, 1, 2, 60]\n",
    "3|0.842282(std:0.026623)|[7, 'auto', 3, 6, 60]\n",
    "3|0.842282(std:0.019193)|[13, 'auto', 2, 2, 30]\n",
    "6|0.840604(std:0.029149)|[7, 'auto', 2, 4, 20]\n",
    "6|0.840604(std:0.029776)|[7, 'auto', 2, 6, 30]\n",
    "6|0.840604(std:0.031222)|[8, 'auto', 1, 7, 40]\n",
    "6|0.840604(std:0.027545)|[15, 1, 5, 5, 60]\n",
    "6|0.840604(std:0.032248)|[20, 1, 5, 6, 100]\n",
    "\n",
    "\n",
    "## 10 age band, familysize, embarked num category, rare title&map value, no Name_Len, no Ticket_Len, one Cabin_Letter feature, del Cabin_Num features, activate Age*Class again\n",
    "\n",
    "best parameters: {'randomforestclassifier__max_depth': 25, 'randomforestclassifier__max_features': 'sqrt', 'randomforestclassifier__min_samples_leaf': 2, 'randomforestclassifier__min_samples_split': 2, 'randomforestclassifier__n_estimators': 30}\n",
    "Mean cross-validated score of the best_estimator:  0.8456375838926175\n",
    "test:  0.8542372881355932\n",
    "\n",
    "Rank|Score(std)|Params ['randomforestclassifier__max_depth', 'randomforestclassifier__max_features', 'randomforestclassifier__min_samples_leaf', 'randomforestclassifier__min_samples_split', 'randomforestclassifier__n_estimators']\n",
    "1|0.845638(std:0.024877)|[25, 'sqrt', 2, 2, 30]\n",
    "2|0.843960(std:0.026350)|[15, 'log2', 1, 6, 30]\n",
    "3|0.842282(std:0.031656)|[13, 1, 1, 3, 100]\n",
    "3|0.842282(std:0.024657)|[13, 'log2', 1, 5, 20]\n",
    "3|0.842282(std:0.026438)|[25, 1, 1, 7, 100]\n",
    "3|0.842282(std:0.027839)|[25, 'log2', 1, 6, 60]\n",
    "3|0.842282(std:0.036636)|[None, 'log2', 1, 5, 60]\n",
    "3|0.842282(std:0.029715)|[None, 'log2', 3, 7, 30]\n",
    "9|0.840604(std:0.031981)|[7, 1, 1, 5, 40]\n",
    "9|0.840604(std:0.029960)|[7, 'sqrt', 2, 2, 20]\n",
    "9|0.840604(std:0.032309)|[7, 'sqrt', 2, 6, 20]\n",
    "9|0.840604(std:0.035593)|[8, 'log2', 3, 2, 30]\n",
    "9|0.840604(std:0.036326)|[13, 'sqrt', 3, 2, 30]\n",
    "9|0.840604(std:0.024657)|[20, 'sqrt', 1, 6, 100]\n",
    "9|0.840604(std:0.023780)|[25, 1, 3, 2, 40]\n",
    "9|0.840604(std:0.037120)|[None, 'log2', 1, 3, 100]\n",
    "\n",
    "\n",
    "\n",
    "## 1\n",
    "\n",
    "\n",
    "- 10 age band\n",
    "- familysize\n",
    "- embarked num category\n",
    "- rare title&map value\n",
    "- no Name_Len\n",
    "- no Ticket_Len\n",
    "- one Cabin_Letter feature\n",
    "- del Cabin_Num features\n",
    "- activate Age*Class again\n",
    "- try another title mapping. from 5 category(inc. rare) to 6 category(complete map rare to other title)\n",
    "\n",
    "\n",
    "best parameters: {'randomforestclassifier__max_depth': None, 'randomforestclassifier__max_features': 1, 'randomforestclassifier__min_samples_leaf': 1, 'randomforestclassifier__min_samples_split': 6, 'randomforestclassifier__n_estimators': 100}\n",
    "Mean cross-validated score of the best_estimator:  0.8502994011976048\n",
    "test:  0.8385650224215246\n",
    "confusion matrix:  [[117  17]\n",
    " [ 19  70]]\n",
    "\n",
    "Rank|Score(std)|Params ['randomforestclassifier__max_depth', 'randomforestclassifier__max_features', 'randomforestclassifier__min_samples_leaf', 'randomforestclassifier__min_samples_split', 'randomforestclassifier__n_estimators']\n",
    "1|0.850299(std:0.035294)|[None, 1, 1, 6, 100]\n",
    "2|0.848802(std:0.036812)|[9, 'log2', 1, 6, 40]\n",
    "3|0.845808(std:0.033851)|[20, 'sqrt', 1, 3, 40]\n",
    "3|0.845808(std:0.021297)|[None, 1, 1, 5, 20]\n",
    "5|0.844311(std:0.029206)|[5, 'sqrt', 2, 5, 40]\n",
    "5|0.844311(std:0.028656)|[8, 1, 1, 5, 20]\n",
    "5|0.844311(std:0.032142)|[13, 1, 1, 6, 100]\n",
    "5|0.844311(std:0.046218)|[13, 'log2', 1, 5, 30]\n",
    "5|0.844311(std:0.037751)|[13, 'log2', 1, 6, 100]\n",
    "5|0.844311(std:0.031668)|[13, 'log2', 2, 5, 20]\n",
    "5|0.844311(std:0.024326)|[20, 1, 1, 2, 40]\n",
    "5|0.844311(std:0.039814)|[None, 'log2', 1, 5, 40]\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test:  0.852017937219731\n",
      "mean of cross val score:  0.840628507295174\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(RandomForestClassifier(max_depth=7, \n",
    "                                            max_features=\"auto\",\n",
    "                                            min_samples_leaf=1, \n",
    "                                            min_samples_split=3, \n",
    "                                            n_estimators=100))\n",
    "pipe.fit(X_train, y_train)\n",
    "print(\"test: \", pipe.score(X_test, y_test))\n",
    "\n",
    "scores = cross_val_score(pipe, X_train_df, y_train_df, n_jobs=3)\n",
    "print(\"mean of cross val score: \", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Sex</td>\n",
       "      <td>0.189988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Title_Mr</td>\n",
       "      <td>0.176171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Pclass</td>\n",
       "      <td>0.097738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Age*Class</td>\n",
       "      <td>0.079561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Title_Mrs</td>\n",
       "      <td>0.074967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>FamilySize</td>\n",
       "      <td>0.070322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Fare</td>\n",
       "      <td>0.052259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.051101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Title_Miss</td>\n",
       "      <td>0.045023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cabin_Letter_0</td>\n",
       "      <td>0.040111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Embarked_C</td>\n",
       "      <td>0.017657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Embarked_S</td>\n",
       "      <td>0.016106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cabin_Letter_B</td>\n",
       "      <td>0.013357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Age_Null_Flag</td>\n",
       "      <td>0.012215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cabin_Letter_E</td>\n",
       "      <td>0.011768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Embarked_Q</td>\n",
       "      <td>0.010021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Title_Master</td>\n",
       "      <td>0.009216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cabin_Letter_C</td>\n",
       "      <td>0.008383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Title_Rev</td>\n",
       "      <td>0.006012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cabin_Letter_D</td>\n",
       "      <td>0.004855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Title_Dr</td>\n",
       "      <td>0.004050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cabin_Letter_F</td>\n",
       "      <td>0.003797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cabin_Letter_A</td>\n",
       "      <td>0.002637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cabin_Letter_G</td>\n",
       "      <td>0.002582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Cabin_Letter_T</td>\n",
       "      <td>0.000101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          variable  importance\n",
       "15             Sex    0.189988\n",
       "19        Title_Mr    0.176171\n",
       "14          Pclass    0.097738\n",
       "1        Age*Class    0.079561\n",
       "20       Title_Mrs    0.074967\n",
       "12      FamilySize    0.070322\n",
       "13            Fare    0.052259\n",
       "0              Age    0.051101\n",
       "18      Title_Miss    0.045023\n",
       "3   Cabin_Letter_0    0.040111\n",
       "22      Embarked_C    0.017657\n",
       "24      Embarked_S    0.016106\n",
       "5   Cabin_Letter_B    0.013357\n",
       "2    Age_Null_Flag    0.012215\n",
       "8   Cabin_Letter_E    0.011768\n",
       "23      Embarked_Q    0.010021\n",
       "17    Title_Master    0.009216\n",
       "6   Cabin_Letter_C    0.008383\n",
       "21       Title_Rev    0.006012\n",
       "7   Cabin_Letter_D    0.004855\n",
       "16        Title_Dr    0.004050\n",
       "9   Cabin_Letter_F    0.003797\n",
       "4   Cabin_Letter_A    0.002637\n",
       "10  Cabin_Letter_G    0.002582\n",
       "11  Cabin_Letter_T    0.000101"
      ]
     },
     "execution_count": 741,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat((pd.DataFrame(X_train.columns, columns = ['variable']), \n",
    "           pd.DataFrame(pipe.named_steps[\"randomforestclassifier\"].feature_importances_, columns = ['importance'])), \n",
    "          axis = 1).sort_values(by='importance', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try several scaling and feature selections for random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done  40 out of  45 | elapsed:    2.9s remaining:    0.4s\n",
      "[Parallel(n_jobs=3)]: Done  45 out of  45 | elapsed:    3.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'clf': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=7, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=3,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False), 'reduce_dim': PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), 'scaling': RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
      "       with_scaling=True)}\n",
      "Mean cross-validated score of the best_estimator:  0.8383233532934131\n",
      "test:  0.8340807174887892\n",
      "confusion matrix:  [[119  15]\n",
      " [ 22  67]]\n",
      "\n",
      "Rank|Score(std)|Params ['clf', 'reduce_dim', 'scaling']\n",
      "1|0.838323(std:0.023627)|[RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=7, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=3,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False), PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
      "       with_scaling=True)]\n",
      "1|0.838323(std:0.033190)|[RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=7, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=3,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False), PCA(copy=True, iterated_power='auto', n_components=5, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), MinMaxScaler(copy=True, feature_range=(0, 1))]\n",
      "3|0.835329(std:0.026370)|[RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=7, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=3,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False), PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), None]\n",
      "4|0.833832(std:0.036643)|[RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=7, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=3,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False), None, MinMaxScaler(copy=True, feature_range=(0, 1))]\n",
      "5|0.832335(std:0.026911)|[RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=7, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=3,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False), PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), MinMaxScaler(copy=True, feature_range=(0, 1))]\n",
      "6|0.830838(std:0.029996)|[RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=7, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=3,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False), None, None]\n",
      "7|0.826347(std:0.031899)|[RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=7, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=3,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False), PCA(copy=True, iterated_power='auto', n_components=5, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), None]\n",
      "8|0.824850(std:0.025881)|[RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=7, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=3,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False), None, RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
      "       with_scaling=True)]\n",
      "9|0.820359(std:0.027244)|[RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=7, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=3,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False), PCA(copy=True, iterated_power='auto', n_components=5, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
      "       with_scaling=True)]\n"
     ]
    }
   ],
   "source": [
    "param_grid = dict(scaling=[None, MinMaxScaler(), RobustScaler()],\n",
    "                  reduce_dim=[None, PCA(), PCA(5)],\n",
    "                  clf=[RandomForestClassifier(max_depth=7, \n",
    "                                            max_features=\"auto\",\n",
    "                                            min_samples_leaf=1, \n",
    "                                            min_samples_split=3, \n",
    "                                            n_estimators=100)]\n",
    "                 )\n",
    "pipe = Pipeline([('scaling', StandardScaler()), ('reduce_dim', PCA()), ('clf', RandomForestClassifier())]) \n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=3, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))\n",
    "print(\"confusion matrix: \", confusion_matrix(y_test, grid_search.best_estimator_.predict(X_test)))\n",
    "print(\"\")\n",
    "report2(grid_search.cv_results_, n_top=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**try scaling for random forest**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# RobustScaler(), \n",
    "pipe = make_pipeline(RobustScaler(), RandomForestClassifier(max_depth=10, \n",
    "                                            max_features=1,\n",
    "                                            min_samples_leaf=1, \n",
    "                                            min_samples_split=13, \n",
    "                                            n_estimators=300))\n",
    "pipe.fit(X_train, y_train)\n",
    "print(\"test: \", pipe.score(X_test, y_test))\n",
    "\n",
    "scores = cross_val_score(pipe, X_train_df, y_train_df, n_jobs=3)\n",
    "print(\"mean of cross val score: \", scores.mean())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# MinMaxScaler(), \n",
    "pipe = make_pipeline(MinMaxScaler(), RandomForestClassifier(max_depth=10, \n",
    "                                            max_features=1,\n",
    "                                            min_samples_leaf=1, \n",
    "                                            min_samples_split=13, \n",
    "                                            n_estimators=300))\n",
    "pipe.fit(X_train, y_train)\n",
    "print(\"test: \", pipe.score(X_test, y_test))\n",
    "\n",
    "scores = cross_val_score(pipe, X_train_df, y_train_df, n_jobs=3)\n",
    "print(\"mean of cross val score: \", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**try feature selection**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#pca\n",
    "param_grid = {'pca__n_components':[5, 10, 15, 20, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 40]}\n",
    "\n",
    "pipe = make_pipeline(PCA(n_components=30), RandomForestClassifier(max_depth=10, \n",
    "                                            max_features=1,\n",
    "                                            min_samples_leaf=1, \n",
    "                                            min_samples_split=13, \n",
    "                                            n_estimators=300))\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=6)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pipe = make_pipeline(PCA(n_components=15), RandomForestClassifier(max_depth=10, \n",
    "                                            max_features=1,\n",
    "                                            min_samples_leaf=1, \n",
    "                                            min_samples_split=13, \n",
    "                                            n_estimators=300))\n",
    "pipe.fit(X_train, y_train)\n",
    "print(\"test: \", pipe.score(X_test, y_test))\n",
    "\n",
    "scores = cross_val_score(pipe, X_train_df, y_train_df, n_jobs=3)\n",
    "print(\"mean of cross val score: \", scores.mean())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test:  0.840677966102\n",
    "mean of cross val score:  0.82379349046"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "param_grid = {'max_depth': [0,1,2,3,4,5,6,7],\n",
    "              'min_child_weight':[0.8,0.9, 1],\n",
    "              'gamma':[0, 0.1, 0.2],\n",
    "            'subsample': [0.5, 0.7, 0.95],\n",
    "            'colsample_bytree': [1.0]}\n",
    "    \n",
    "grid_search = GridSearchCV(xgb.XGBClassifier(), param_grid, cv=5, n_jobs=6, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "AdaBoostClassifier(base_estimator=None, n_estimators=50,\n",
    "                   learning_rate=1.0, algorithm='SAMME.R',\n",
    "                   random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4200 candidates, totalling 21000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 366 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=6)]: Done 859 tasks      | elapsed:   23.5s\n",
      "[Parallel(n_jobs=6)]: Done 1359 tasks      | elapsed:   41.9s\n",
      "[Parallel(n_jobs=6)]: Done 1970 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=6)]: Done 2557 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=6)]: Done 3157 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=6)]: Done 4457 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=6)]: Done 5421 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=6)]: Done 6484 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=6)]: Done 8134 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=6)]: Done 9347 tasks      | elapsed:  7.7min\n",
      "[Parallel(n_jobs=6)]: Done 11286 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=6)]: Done 13015 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=6)]: Done 14801 tasks      | elapsed: 11.8min\n",
      "[Parallel(n_jobs=6)]: Done 17162 tasks      | elapsed: 13.4min\n",
      "[Parallel(n_jobs=6)]: Done 19700 tasks      | elapsed: 15.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'learning_rate': 0.2, 'max_depth': 4, 'max_features': 'log2', 'min_samples_split': 6, 'n_estimators': 7}\n",
      "Mean cross-validated score of the best_estimator:  0.8413173652694611\n",
      "test:  0.820627802690583\n",
      "confusion matrix:  [[120  14]\n",
      " [ 26  63]]\n",
      "\n",
      "Rank|Score(std)|Params ['learning_rate', 'max_depth', 'max_features', 'min_samples_split', 'n_estimators']\n",
      "1|0.841317(std:0.020392)|[0.2, 4, 'log2', 6, 7]\n",
      "2|0.838323(std:0.029889)|[0.005, 6, 'log2', 5, 500]\n",
      "2|0.838323(std:0.023627)|[0.05, 5, 'log2', 6, 50]\n",
      "2|0.838323(std:0.029022)|[0.05, 5, 'log2', 6, 100]\n",
      "2|0.838323(std:0.026800)|[0.1, 4, 'sqrt', 6, 10]\n",
      "2|0.838323(std:0.025506)|[0.2, 4, 'log2', 6, 10]\n",
      "2|0.838323(std:0.017545)|[0.2, 5, 'log2', 6, 10]\n",
      "8|0.836826(std:0.025457)|[0.005, 6, 'log2', 6, 500]\n",
      "8|0.836826(std:0.023403)|[0.1, 4, 'sqrt', 4, 500]\n",
      "8|0.836826(std:0.041012)|[0.2, 3, 'sqrt', 3, 400]\n",
      "8|0.836826(std:0.031987)|[0.2, 3, 'log2', 6, 300]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 21000 out of 21000 | elapsed: 16.5min finished\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# too wide\n",
    "param_grid = {'learning_rate': [0.001, 0.005, 0.007, 0.01, 0.02, 0.05, 0.1, 0.2],\n",
    "              'max_depth':[1,2,3,4,5,6,7,8],\n",
    "              'max_features': [None, 'sqrt', 'log2'],\n",
    "              'min_samples_leaf': [1, 2, 3, 4, 5, 6],\n",
    "              'min_samples_split':[2, 3, 4, 5, 6],\n",
    "              'n_estimators': [3, 5, 7, 10, 50, 100, 200, 300, 400, 500],\n",
    "              }\n",
    "\"\"\"\n",
    "\n",
    "# narrow in specific region\n",
    "param_grid = {'learning_rate': [0.005, 0.007, 0.01, 0.02, 0.05, 0.1, 0.2],\n",
    "              'max_depth':[3,4,5,6,7],\n",
    "              'max_features': [None, 'sqrt', 'log2'],\n",
    "#              'min_samples_leaf': [1, 2, 3, 4, 5],\n",
    "              'min_samples_split':[2, 3, 4, 5, 6],\n",
    "              'n_estimators': [7, 10, 50, 100, 200, 300, 400, 500],\n",
    "              }\n",
    "\n",
    "grid_search = GridSearchCV(GradientBoostingClassifier(), param_grid, cv=5, n_jobs=6, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))\n",
    "print(\"confusion matrix: \", confusion_matrix(y_test, grid_search.best_estimator_.predict(X_test)))\n",
    "print(\"\")\n",
    "report2(grid_search.cv_results_, n_top=10)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# output of upper code\n",
    "\n",
    "Mean cross-validated score of the best_estimator:  0.843959731544\n",
    "best parameters: {'learning_rate': 0.01, 'max_depth': 6, 'max_features': 'sqrt', 'min_samples_leaf': 3, 'min_samples_split': 3, 'n_estimators': 200}\n",
    "test:  0.830508474576\n",
    "\n",
    "\n",
    "# 10 age band, parch, sibsp\n",
    "\n",
    "best parameters: {'learning_rate': 0.02, 'max_depth': 6, 'max_features': 'log2', 'min_samples_leaf': 3, 'min_samples_split': 3, 'n_estimators': 100}\n",
    "Mean cross-validated score of the best_estimator:  0.845637583893\n",
    "test:  0.820338983051\n",
    "\n",
    "\n",
    "\n",
    "# 10 age band, parch&sibsp, embarked num category\n",
    "\n",
    "best parameters: {'learning_rate': 0.02, 'max_depth': 4, 'max_features': 'log2', 'min_samples_leaf': 3, 'min_samples_split': 4, 'n_estimators': 200}\n",
    "Mean cross-validated score of the best_estimator:  0.843959731544\n",
    "test:  0.833898305085\n",
    "\n",
    "\n",
    "# 10 age band, parch&sibsp, embarked num category, rare title&map value\n",
    "\n",
    "best parameters: {'learning_rate': 0.05, 'max_depth': 4, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
    "Mean cross-validated score of the best_estimator:  0.842281879195\n",
    "test:  0.827118644068\n",
    "\n",
    "\n",
    "# 10 age band, familysize, embarked num category, rare title&map value\n",
    "\n",
    "best parameters: {'learning_rate': 0.05, 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 100}\n",
    "Mean cross-validated score of the best_estimator:  0.838926174497\n",
    "test:  0.84406779661\n",
    "\n",
    "\n",
    "\n",
    "# 10 age band, familysize, embarked num category, rare title&map value, no Name_Len\n",
    "\n",
    "best parameters: {'learning_rate': 0.007, 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
    "Mean cross-validated score of the best_estimator:  0.845637583893\n",
    "test:  0.833898305085\n",
    "\n",
    "\n",
    "# 10 age band, familysize, embarked num category, rare title&map value, no Name_Len, no Ticket_Len\n",
    "\n",
    "best parameters: {'learning_rate': 0.01, 'max_depth': 4, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}\n",
    "Mean cross-validated score of the best_estimator:  0.845637583893\n",
    "test:  0.837288135593\n",
    "\n",
    "\n",
    "## 10 age band, familysize, embarked num category, rare title&map value, no Name_Len, no Ticket_Len, one Cabin_Letter feature\n",
    "\n",
    "best parameters: {'learning_rate': 0.1, 'max_depth': 4, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 50}\n",
    "Mean cross-validated score of the best_estimator:  0.8489932885906041\n",
    "test:  0.8305084745762712\n",
    "\n",
    "\n",
    "## 10 age band, familysize, embarked num category, rare title&map value, no Name_Len, no Ticket_Len, one Cabin_Letter feature, del Cabin_Num features\n",
    "\n",
    "best parameters: {'learning_rate': 0.1, 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 50}\n",
    "Mean cross-validated score of the best_estimator:  0.8422818791946308\n",
    "test:  0.8305084745762712\n",
    "\n",
    "Rank|Score(std)|Params ['learning_rate', 'max_depth', 'max_features', 'min_samples_leaf', 'min_samples_split', 'n_estimators']\n",
    "1|0.842282(std:0.039318)|[0.1, 3, 'log2', 5, 2, 50]\n",
    "2|0.838926(std:0.037329)|[0.007, 4, 'log2', 5, 2, 400]\n",
    "2|0.838926(std:0.041292)|[0.02, 3, 'sqrt', 4, 6, 400]\n",
    "2|0.838926(std:0.038219)|[0.1, 3, 'sqrt', 4, 5, 50]\n",
    "2|0.838926(std:0.033613)|[0.1, 3, 'log2', 1, 5, 50]\n",
    "2|0.838926(std:0.041584)|[0.1, 3, 'log2', 4, 4, 50]\n",
    "2|0.838926(std:0.028890)|[0.1, 4, 'sqrt', 5, 4, 50]\n",
    "8|0.837248(std:0.040103)|[0.02, 3, 'sqrt', 5, 4, 300]\n",
    "8|0.837248(std:0.036323)|[0.02, 4, 'sqrt', 4, 4, 200]\n",
    "8|0.837248(std:0.028291)|[0.05, 3, None, 1, 2, 200]\n",
    "8|0.837248(std:0.028291)|[0.05, 3, None, 1, 4, 200]\n",
    "8|0.837248(std:0.033345)|[0.05, 5, 'log2', 5, 5, 50]\n",
    "8|0.837248(std:0.037624)|[0.1, 3, 'log2', 1, 4, 100]\n",
    "8|0.837248(std:0.025055)|[0.1, 3, 'log2', 1, 6, 200]\n",
    "8|0.837248(std:0.041710)|[0.1, 4, 'sqrt', 1, 3, 50]\n",
    "8|0.837248(std:0.030870)|[0.1, 4, 'log2', 5, 3, 50]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## GradientBoostingClassifier: 10 age band, familysize, embarked num category, rare title&map value, no Name_Len, no Ticket_Len, one Cabin_Letter feature, del Cabin_Num features, activate Age*Class again\n",
    "\n",
    "best parameters: {'learning_rate': 0.2, 'max_depth': 4, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 3, 'n_estimators': 10}\n",
    "Mean cross-validated score of the best_estimator:  0.8406040268456376\n",
    "test:  0.8406779661016949\n",
    "\n",
    "Rank|Score(std)|Params ['learning_rate', 'max_depth', 'max_features', 'min_samples_leaf', 'min_samples_split', 'n_estimators']\n",
    "1|0.840604(std:0.039600)|[0.2, 4, 'sqrt', 2, 3, 10]\n",
    "2|0.838926(std:0.044443)|[0.01, 3, 'log2', 4, 2, 400]\n",
    "2|0.838926(std:0.044709)|[0.02, 3, 'sqrt', 4, 4, 200]\n",
    "2|0.838926(std:0.044443)|[0.02, 3, 'sqrt', 4, 5, 200]\n",
    "2|0.838926(std:0.041648)|[0.02, 4, 'log2', 5, 4, 100]\n",
    "2|0.838926(std:0.043104)|[0.05, 3, 'sqrt', 4, 3, 100]\n",
    "2|0.838926(std:0.044903)|[0.1, 3, 'log2', 1, 2, 50]\n",
    "2|0.838926(std:0.025955)|[0.2, 6, 'sqrt', 4, 3, 7]\n",
    "9|0.837248(std:0.044516)|[0.01, 3, 'log2', 4, 4, 400]\n",
    "9|0.837248(std:0.043828)|[0.02, 3, 'sqrt', 4, 6, 300]\n",
    "9|0.837248(std:0.044516)|[0.02, 3, 'log2', 4, 6, 200]\n",
    "9|0.837248(std:0.043383)|[0.02, 4, 'sqrt', 1, 5, 200]\n",
    "9|0.837248(std:0.046819)|[0.05, 3, 'sqrt', 4, 4, 100]\n",
    "9|0.837248(std:0.031411)|[0.05, 3, 'sqrt', 5, 6, 100]\n",
    "9|0.837248(std:0.044677)|[0.05, 3, 'log2', 2, 5, 100]\n",
    "9|0.837248(std:0.043704)|[0.05, 3, 'log2', 4, 4, 100]\n",
    "9|0.837248(std:0.044711)|[0.05, 3, 'log2', 4, 6, 100]\n",
    "9|0.837248(std:0.032774)|[0.05, 5, 'log2', 4, 5, 50]\n",
    "9|0.837248(std:0.041284)|[0.1, 3, 'log2', 5, 2, 50]\n",
    "9|0.837248(std:0.040684)|[0.2, 4, 'sqrt', 5, 4, 7]\n",
    "\n",
    "\n",
    "### change ration of train/test split from 0.33 to 0.25\n",
    "\n",
    "best parameters: {'learning_rate': 0.2, 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 200}\n",
    "Mean cross-validated score of the best_estimator:  0.8473053892215568\n",
    "test:  0.8116591928251121\n",
    "confusion matrix:  [[114  20]\n",
    " [ 22  67]]\n",
    "\n",
    "Rank|Score(std)|Params ['learning_rate', 'max_depth', 'max_features', 'min_samples_leaf', 'min_samples_split', 'n_estimators']\n",
    "1|0.847305(std:0.032881)|[0.2, 5, 'log2', 5, 3, 200]\n",
    "2|0.845808(std:0.043098)|[0.05, 5, 'log2', 4, 6, 300]\n",
    "2|0.845808(std:0.041714)|[0.2, 6, 'sqrt', 4, 4, 50]\n",
    "4|0.844311(std:0.038319)|[0.1, 4, 'log2', 1, 5, 200]\n",
    "4|0.844311(std:0.036937)|[0.1, 4, 'log2', 5, 5, 400]\n",
    "4|0.844311(std:0.039819)|[0.2, 3, 'sqrt', 5, 5, 400]\n",
    "4|0.844311(std:0.028865)|[0.2, 4, 'sqrt', 3, 6, 300]\n",
    "4|0.844311(std:0.032183)|[0.2, 4, 'sqrt', 4, 3, 300]\n",
    "4|0.844311(std:0.027152)|[0.2, 4, 'sqrt', 4, 6, 200]\n",
    "4|0.844311(std:0.033087)|[0.2, 4, 'log2', 4, 3, 400]\n",
    "4|0.844311(std:0.032808)|[0.2, 4, 'log2', 5, 2, 400]\n",
    "4|0.844311(std:0.031058)|[0.2, 4, 'log2', 5, 3, 300]\n",
    "4|0.844311(std:0.040603)|[0.2, 5, 'sqrt', 5, 4, 400]\n",
    "4|0.844311(std:0.033699)|[0.2, 5, 'log2', 2, 4, 50]\n",
    "4|0.844311(std:0.038369)|[0.2, 6, 'sqrt', 2, 6, 200]\n",
    "4|0.844311(std:0.040308)|[0.2, 7, 'log2', 4, 3, 300]\n",
    "\n",
    "\n",
    "\n",
    "# 1 GradientBoostingClassifier\n",
    "\n",
    "- 10 age band\n",
    "- familysize\n",
    "- embarked num category\n",
    "- rare title&map value\n",
    "- no Name_Len\n",
    "- no Ticket_Len\n",
    "- one Cabin_Letter feature\n",
    "- del Cabin_Num features\n",
    "- activate Age*Class again\n",
    "- try another title mapping. from 5 category(inc. rare) to 6 category(complete map rare to other title)\n",
    "\n",
    "mapping = {'Mlle': 'Miss', \n",
    "            'Major': 'Mr', \n",
    "            'Col': 'Mr', \n",
    "            'Sir': 'Mr',\n",
    "            'Don': 'Mr', \n",
    "            'Mme': 'Miss',\n",
    "            'Jonkheer': 'Mr',\n",
    "            'Lady': 'Mrs', \n",
    "            'Capt': 'Mr', \n",
    "            'Countess': 'Mrs',\n",
    "            'Ms': 'Miss',\n",
    "            'Dona': 'Mrs'}\n",
    "titles = ['Dr', 'Master', 'Miss', 'Mr', 'Mrs', 'Rev']\n",
    "\n",
    "\n",
    "\n",
    "best parameters: {'learning_rate': 0.2, 'max_depth': 4, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 300}\n",
    "Mean cross-validated score of the best_estimator:  0.8473053892215568\n",
    "test:  0.8026905829596412\n",
    "confusion matrix:  [[113  21]\n",
    " [ 23  66]]\n",
    "\n",
    "Rank|Score(std)|Params ['learning_rate', 'max_depth', 'max_features', 'min_samples_leaf', 'min_samples_split', 'n_estimators']\n",
    "1|0.847305(std:0.023510)|[0.2, 4, 'log2', 4, 5, 300]\n",
    "2|0.844311(std:0.035000)|[0.2, 5, 'log2', 5, 3, 400]\n",
    "2|0.844311(std:0.024509)|[0.2, 6, 'sqrt', 4, 2, 50]\n",
    "4|0.842814(std:0.027134)|[0.1, 5, 'log2', 4, 3, 400]\n",
    "4|0.842814(std:0.028805)|[0.2, 4, 'log2', 5, 4, 400]\n",
    "4|0.842814(std:0.035875)|[0.2, 6, 'log2', 5, 6, 300]\n",
    "4|0.842814(std:0.029787)|[0.2, 7, 'sqrt', 3, 2, 300]\n",
    "8|0.841317(std:0.034481)|[0.01, 4, 'sqrt', 3, 5, 200]\n",
    "8|0.841317(std:0.042157)|[0.1, 4, 'sqrt', 1, 4, 200]\n",
    "8|0.841317(std:0.039613)|[0.1, 4, 'log2', 5, 6, 400]\n",
    "8|0.841317(std:0.042075)|[0.1, 5, 'sqrt', 1, 4, 100]\n",
    "8|0.841317(std:0.029249)|[0.1, 5, 'log2', 4, 5, 400]\n",
    "8|0.841317(std:0.030651)|[0.1, 5, 'log2', 4, 6, 400]\n",
    "8|0.841317(std:0.035506)|[0.1, 6, 'sqrt', 1, 2, 100]\n",
    "8|0.841317(std:0.040615)|[0.1, 6, 'log2', 1, 6, 100]\n",
    "8|0.841317(std:0.026786)|[0.1, 7, 'log2', 5, 5, 300]\n",
    "8|0.841317(std:0.039613)|[0.2, 3, 'sqrt', 4, 4, 400]\n",
    "8|0.841317(std:0.039354)|[0.2, 3, 'log2', 2, 2, 400]\n",
    "8|0.841317(std:0.035071)|[0.2, 3, 'log2', 5, 2, 400]\n",
    "8|0.841317(std:0.026313)|[0.2, 4, 'sqrt', 4, 4, 200]\n",
    "8|0.841317(std:0.027297)|[0.2, 4, 'sqrt', 4, 4, 300]\n",
    "8|0.841317(std:0.028622)|[0.2, 4, 'sqrt', 4, 5, 400]\n",
    "8|0.841317(std:0.031055)|[0.2, 4, 'log2', 2, 5, 300]\n",
    "8|0.841317(std:0.028887)|[0.2, 4, 'log2', 5, 6, 400]\n",
    "8|0.841317(std:0.031810)|[0.2, 6, 'sqrt', 2, 2, 400]\n",
    "8|0.841317(std:0.028887)|[0.2, 6, 'sqrt', 5, 2, 400]\n",
    "8|0.841317(std:0.034788)|[0.2, 6, 'log2', 1, 2, 100]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 3 GradientBoostingClassifier\n",
    "\n",
    "\n",
    "- age\n",
    "  - [ ] 5 age band\n",
    "  - [x] 10 age band\n",
    "- family\n",
    "  - [x] familysize\n",
    "  - [ ] parch,sib\n",
    "  - [ ] isalone\n",
    "- embarked\n",
    "  - [ ] integer encoding\n",
    "  - [x] one hot encoding\n",
    "- Title\n",
    "  - [ ] keep rare title and integer encoding\n",
    "  - [ ] change rare title to \"Rare\" and integer encoding\n",
    "  - [ ] change rare title to \"Rare\" and one hot encoding\n",
    "  - [x] change some rare title to usual title, other rare title to \"Rare\" and one hot encoding\n",
    "- [ ] Name_Len\n",
    "- [ ] Ticket_Len\n",
    "- Cabin_Letter\n",
    "  - [x] integer encoding\n",
    "  - [ ] one hot encoding\n",
    "- Cabin_Num\n",
    "  - [x] no\n",
    "  - [ ] integer encoding\n",
    "  - [ ] one hot encoding\n",
    "- [x] Age*Class\n",
    "\n",
    "\n",
    "best parameters: {'learning_rate': 0.05, 'max_depth': 4, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 50}\n",
    "Mean cross-validated score of the best_estimator:  0.8413173652694611\n",
    "test:  0.8295964125560538\n",
    "confusion matrix:  [[121  13]\n",
    " [ 25  64]]\n",
    "\n",
    "Rank|Score(std)|Params ['learning_rate', 'max_depth', 'max_features', 'min_samples_split', 'n_estimators']\n",
    "1|0.841317(std:0.032879)|[0.05, 4, 'log2', 2, 50]\n",
    "1|0.841317(std:0.031308)|[0.1, 4, 'sqrt', 4, 300]\n",
    "1|0.841317(std:0.028452)|[0.2, 3, 'sqrt', 2, 500]\n",
    "1|0.841317(std:0.037397)|[0.2, 4, 'sqrt', 4, 100]\n",
    "5|0.839820(std:0.036424)|[0.02, 4, 'sqrt', 6, 100]\n",
    "5|0.839820(std:0.028735)|[0.05, 4, 'log2', 4, 100]\n",
    "5|0.839820(std:0.028186)|[0.1, 5, 'sqrt', 5, 10]\n",
    "8|0.838323(std:0.032153)|[0.005, 4, 'sqrt', 2, 400]\n",
    "8|0.838323(std:0.036036)|[0.02, 6, 'sqrt', 6, 400]\n",
    "8|0.838323(std:0.028844)|[0.1, 4, 'log2', 4, 200]\n",
    "8|0.838323(std:0.030687)|[0.1, 4, 'log2', 5, 10]\n",
    "8|0.838323(std:0.038513)|[0.1, 4, 'log2', 6, 200]\n",
    "8|0.838323(std:0.032141)|[0.2, 3, 'sqrt', 2, 400]\n",
    "8|0.838323(std:0.029254)|[0.2, 4, 'log2', 3, 200]\n",
    "8|0.838323(std:0.036152)|[0.2, 4, 'log2', 3, 300]\n",
    "\n",
    "\n",
    "\n",
    "## 4 GradientBoostingClassifier\n",
    "\n",
    "\n",
    "- age\n",
    "  - [ ] 5 age band\n",
    "  - [x] 10 age band\n",
    "- family\n",
    "  - [x] familysize\n",
    "  - [ ] parch,sib\n",
    "  - [ ] isalone\n",
    "- embarked\n",
    "  - [ ] integer encoding\n",
    "  - [x] one hot encoding\n",
    "- Title\n",
    "  - [ ] keep rare title and integer encoding\n",
    "  - [ ] change rare title to \"Rare\" and integer encoding\n",
    "  - [ ] change rare title to \"Rare\" and one hot encoding\n",
    "  - [x] change some rare title to usual title, other rare title to \"Rare\" and one hot encoding\n",
    "- [ ] Name_Len\n",
    "- [ ] Ticket_Len\n",
    "- Cabin_Letter\n",
    "  - [ ] integer encoding\n",
    "  - [x] one hot encoding\n",
    "- Cabin_Num\n",
    "  - [x] no\n",
    "  - [ ] integer encoding\n",
    "  - [ ] one hot encoding\n",
    "- [x] Age*Class\n",
    "\n",
    "\n",
    "\n",
    "best parameters: {'learning_rate': 0.2, 'max_depth': 4, 'max_features': 'log2', 'min_samples_split': 6, 'n_estimators': 7}\n",
    "Mean cross-validated score of the best_estimator:  0.8413173652694611\n",
    "test:  0.820627802690583\n",
    "confusion matrix:  [[120  14]\n",
    " [ 26  63]]\n",
    "\n",
    "Rank|Score(std)|Params ['learning_rate', 'max_depth', 'max_features', 'min_samples_split', 'n_estimators']\n",
    "1|0.841317(std:0.020392)|[0.2, 4, 'log2', 6, 7]\n",
    "2|0.838323(std:0.029889)|[0.005, 6, 'log2', 5, 500]\n",
    "2|0.838323(std:0.023627)|[0.05, 5, 'log2', 6, 50]\n",
    "2|0.838323(std:0.029022)|[0.05, 5, 'log2', 6, 100]\n",
    "2|0.838323(std:0.026800)|[0.1, 4, 'sqrt', 6, 10]\n",
    "2|0.838323(std:0.025506)|[0.2, 4, 'log2', 6, 10]\n",
    "2|0.838323(std:0.017545)|[0.2, 5, 'log2', 6, 10]\n",
    "8|0.836826(std:0.025457)|[0.005, 6, 'log2', 6, 500]\n",
    "8|0.836826(std:0.023403)|[0.1, 4, 'sqrt', 4, 500]\n",
    "8|0.836826(std:0.041012)|[0.2, 3, 'sqrt', 3, 400]\n",
    "8|0.836826(std:0.031987)|[0.2, 3, 'log2', 6, 300]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test:  0.8430493273542601\n",
      "confusion matrix:  [[120  14]\n",
      " [ 21  68]]\n",
      "mean of cross val score for X_train_df:  0.8159371492704826\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(GradientBoostingClassifier(learning_rate=0.2,\n",
    "                                                max_depth=4,\n",
    "                                                max_features=\"sqrt\",\n",
    "                                                min_samples_leaf=2,\n",
    "                                                min_samples_split=3,\n",
    "                                                n_estimators=10))\n",
    "pipe.fit(X_train, y_train)\n",
    "print(\"test: \", pipe.score(X_test, y_test))\n",
    "print(\"confusion matrix: \", confusion_matrix(y_test, pipe.predict(X_test)))\n",
    "\n",
    "scores = cross_val_score(pipe, X_train_df, y_train_df, n_jobs=3)\n",
    "print(\"mean of cross val score for X_train_df: \", scores.mean())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 5 age band\n",
    "test:  0.823728813559322\n",
    "mean of cross val score for X_train_df:  0.8237934904601572\n",
    "    \n",
    "# 10 age band\n",
    "test:  0.823728813559322\n",
    "mean of cross val score for X_train_df:  0.8282828282828283\n",
    "\n",
    "# 10 age band, keep all family features\n",
    "test:  0.8338983050847457\n",
    "mean of cross val score for X_train_df:  0.8260381593714926\n",
    "\n",
    "# 10 age band, parch, siblib, use embarked column\n",
    "test:  0.8338983050847457\n",
    "mean of cross val score for X_train_df:  0.8271604938271605\n",
    "\n",
    "# 10 age band, parch, sibsp\n",
    "test:  0.823728813559\n",
    "mean of cross val score for X_train_df:  0.822671156004\n",
    "\n",
    "# 10 age band, parch&sibsp, embarked num category\n",
    "test:  0.830508474576\n",
    "mean of cross val score for X_train_df:  0.827160493827\n",
    "\n",
    "\n",
    "# 10 age band, parch&sibsp, embarked num category, rare title&map value\n",
    "test:  0.833898305085\n",
    "mean of cross val score for X_train_df:  0.83164983165\n",
    "\n",
    "\n",
    "# 10 age band, familysize, embarked num category, rare title&map value\n",
    "\n",
    "test:  0.827118644068\n",
    "mean of cross val score for X_train_df:  0.828282828283\n",
    "\n",
    "\n",
    "# 10 age band, familysize, embarked num category, rare title&map value, no Name_Len\n",
    "\n",
    "test:  0.830508474576\n",
    "mean of cross val score for X_train_df:  0.822671156004\n",
    "\n",
    "\n",
    "# 10 age band, familysize, embarked num category, rare title&map value, no Name_Len, no Ticket_Len\n",
    "\n",
    "test:  0.833898305085\n",
    "mean of cross val score for X_train_df:  0.832772166105\n",
    "\n",
    "\n",
    "# 10 age band, familysize, embarked num category, rare title&map value, no Name_Len, no Ticket_Len, one Cabin_Letter feature\n",
    "test:  0.8305084745762712\n",
    "mean of cross val score for X_train_df:  0.8226711560044894\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Sex</td>\n",
       "      <td>0.221882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Title_Mr</td>\n",
       "      <td>0.174780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Age*Class</td>\n",
       "      <td>0.093106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>FamilySize</td>\n",
       "      <td>0.090351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Pclass</td>\n",
       "      <td>0.077312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Title_Mrs</td>\n",
       "      <td>0.068876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Title_Master</td>\n",
       "      <td>0.067857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Title_Miss</td>\n",
       "      <td>0.048855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Fare</td>\n",
       "      <td>0.027326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cabin_Letter_0</td>\n",
       "      <td>0.025859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cabin_Letter_E</td>\n",
       "      <td>0.024547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.018467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Embarked_C</td>\n",
       "      <td>0.017884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Embarked_S</td>\n",
       "      <td>0.011290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cabin_Letter_F</td>\n",
       "      <td>0.006049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cabin_Letter_D</td>\n",
       "      <td>0.005540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cabin_Letter_B</td>\n",
       "      <td>0.005201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Title_Rev</td>\n",
       "      <td>0.004871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cabin_Letter_C</td>\n",
       "      <td>0.003751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Embarked_Q</td>\n",
       "      <td>0.003212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Age_Null_Flag</td>\n",
       "      <td>0.002880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cabin_Letter_G</td>\n",
       "      <td>0.000104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Cabin_Letter_T</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Title_Dr</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cabin_Letter_A</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          variable  importance\n",
       "15             Sex    0.221882\n",
       "19        Title_Mr    0.174780\n",
       "1        Age*Class    0.093106\n",
       "12      FamilySize    0.090351\n",
       "14          Pclass    0.077312\n",
       "20       Title_Mrs    0.068876\n",
       "17    Title_Master    0.067857\n",
       "18      Title_Miss    0.048855\n",
       "13            Fare    0.027326\n",
       "3   Cabin_Letter_0    0.025859\n",
       "8   Cabin_Letter_E    0.024547\n",
       "0              Age    0.018467\n",
       "22      Embarked_C    0.017884\n",
       "24      Embarked_S    0.011290\n",
       "9   Cabin_Letter_F    0.006049\n",
       "7   Cabin_Letter_D    0.005540\n",
       "5   Cabin_Letter_B    0.005201\n",
       "21       Title_Rev    0.004871\n",
       "6   Cabin_Letter_C    0.003751\n",
       "23      Embarked_Q    0.003212\n",
       "2    Age_Null_Flag    0.002880\n",
       "10  Cabin_Letter_G    0.000104\n",
       "11  Cabin_Letter_T    0.000000\n",
       "16        Title_Dr    0.000000\n",
       "4   Cabin_Letter_A    0.000000"
      ]
     },
     "execution_count": 745,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat((pd.DataFrame(X_train.columns, columns = ['variable']), \n",
    "           pd.DataFrame(pipe.named_steps[\"gradientboostingclassifier\"].feature_importances_, columns = ['importance'])), \n",
    "          axis = 1).sort_values(by='importance', ascending = False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X_train_df, y_train_df)\n",
    "\n",
    "test_df_noid = test_df.drop(\"PassengerId\", axis=1).copy()\n",
    "y_pred = pipe.predict(test_df_noid).astype(int)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": test_df[\"PassengerId\"].astype(int),\n",
    "        \"Survived\": y_pred\n",
    "    })\n",
    "submission.to_csv('../output/submission_gradientboosting.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Title_Mr</td>\n",
       "      <td>0.181305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Sex</td>\n",
       "      <td>0.166517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Age*Class</td>\n",
       "      <td>0.155921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Pclass</td>\n",
       "      <td>0.137609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>FamilySize</td>\n",
       "      <td>0.093685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cabin_Letter_0</td>\n",
       "      <td>0.067282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Title_Miss</td>\n",
       "      <td>0.055454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Title_Mrs</td>\n",
       "      <td>0.032763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Fare</td>\n",
       "      <td>0.027612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.018740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Title_Master</td>\n",
       "      <td>0.015683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cabin_Letter_E</td>\n",
       "      <td>0.011870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Embarked_S</td>\n",
       "      <td>0.010173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cabin_Letter_B</td>\n",
       "      <td>0.006063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cabin_Letter_C</td>\n",
       "      <td>0.005896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cabin_Letter_D</td>\n",
       "      <td>0.005096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Embarked_C</td>\n",
       "      <td>0.003339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Age_Null_Flag</td>\n",
       "      <td>0.002082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Embarked_Q</td>\n",
       "      <td>0.001863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cabin_Letter_G</td>\n",
       "      <td>0.001048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Cabin_Letter_T</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cabin_Letter_F</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Title_Dr</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cabin_Letter_A</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Title_Rev</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          variable  importance\n",
       "19        Title_Mr    0.181305\n",
       "15             Sex    0.166517\n",
       "1        Age*Class    0.155921\n",
       "14          Pclass    0.137609\n",
       "12      FamilySize    0.093685\n",
       "3   Cabin_Letter_0    0.067282\n",
       "18      Title_Miss    0.055454\n",
       "20       Title_Mrs    0.032763\n",
       "13            Fare    0.027612\n",
       "0              Age    0.018740\n",
       "17    Title_Master    0.015683\n",
       "8   Cabin_Letter_E    0.011870\n",
       "24      Embarked_S    0.010173\n",
       "5   Cabin_Letter_B    0.006063\n",
       "6   Cabin_Letter_C    0.005896\n",
       "7   Cabin_Letter_D    0.005096\n",
       "22      Embarked_C    0.003339\n",
       "2    Age_Null_Flag    0.002082\n",
       "23      Embarked_Q    0.001863\n",
       "10  Cabin_Letter_G    0.001048\n",
       "11  Cabin_Letter_T    0.000000\n",
       "9   Cabin_Letter_F    0.000000\n",
       "16        Title_Dr    0.000000\n",
       "4   Cabin_Letter_A    0.000000\n",
       "21       Title_Rev    0.000000"
      ]
     },
     "execution_count": 747,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat((pd.DataFrame(X_train.columns, columns = ['variable']), \n",
    "           pd.DataFrame(pipe.named_steps[\"gradientboostingclassifier\"].feature_importances_, columns = ['importance'])), \n",
    "          axis = 1).sort_values(by='importance', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try scaling and feature selection"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "param_grid = dict(scaling=[None, MinMaxScaler(), RobustScaler()],\n",
    "                  reduce_dim=[None, PCA(), PCA(5), PCA(10), PCA(15), PCA(20), PCA(25), PCA(30)],\n",
    "                  clf=[GradientBoostingClassifier(learning_rate=0.01,\n",
    "                                                max_depth=6,\n",
    "                                                max_features=\"sqrt\",\n",
    "                                                min_samples_leaf=3,\n",
    "                                                min_samples_split=3,\n",
    "                                                n_estimators=200)]\n",
    "                 )\n",
    "pipe = Pipeline([('scaling', StandardScaler()), ('reduce_dim', PCA()), ('clf', RandomForestClassifier())]) \n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=3, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**try scaling for Gradient boosting**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# RobustScaler\n",
    "pipe = make_pipeline(RobustScaler(), GradientBoostingClassifier(learning_rate=0.01,\n",
    "                                                max_depth=6,\n",
    "                                                max_features=\"sqrt\",\n",
    "                                                min_samples_leaf=3,\n",
    "                                                min_samples_split=3,\n",
    "                                                n_estimators=200))\n",
    "pipe.fit(X_train, y_train)\n",
    "print(\"test: \", pipe.score(X_test, y_test))\n",
    "\n",
    "scores = cross_val_score(pipe, X_train_df, y_train_df, n_jobs=3)\n",
    "print(\"mean of cross val score for X_train_df: \", scores.mean())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pd.concat((pd.DataFrame(X_train.columns, columns = ['variable']), \n",
    "           pd.DataFrame(pipe.named_steps[\"gradientboostingclassifier\"].feature_importances_, columns = ['importance'])), \n",
    "          axis = 1).sort_values(by='importance', ascending = False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# MinMaxScaler\n",
    "pipe = make_pipeline(MinMaxScaler(), GradientBoostingClassifier(learning_rate=0.01,\n",
    "                                                max_depth=6,\n",
    "                                                max_features=\"sqrt\",\n",
    "                                                min_samples_leaf=3,\n",
    "                                                min_samples_split=3,\n",
    "                                                n_estimators=200))\n",
    "pipe.fit(X_train, y_train)\n",
    "print(\"test: \", pipe.score(X_test, y_test))\n",
    "\n",
    "scores = cross_val_score(pipe, X_train_df, y_train_df, n_jobs=3)\n",
    "print(\"mean of cross val score for X_train_df: \", scores.mean())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pd.concat((pd.DataFrame(X_train.columns, columns = ['variable']), \n",
    "           pd.DataFrame(pipe.named_steps[\"gradientboostingclassifier\"].feature_importances_, columns = ['importance'])), \n",
    "          axis = 1).sort_values(by='importance', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**try feature selection**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#PCA\n",
    "param_grid = {'pca__n_components':[5, 10, 15, 20, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 40]}\n",
    "\n",
    "pipe = make_pipeline(PCA(n_components=30), GradientBoostingClassifier(learning_rate=0.01,\n",
    "                                                max_depth=6,\n",
    "                                                max_features=\"sqrt\",\n",
    "                                                min_samples_leaf=3,\n",
    "                                                min_samples_split=3,\n",
    "                                                n_estimators=200))\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv=5, n_jobs=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pipe = make_pipeline(PCA(n_components=20), GradientBoostingClassifier(learning_rate=0.01,\n",
    "                                                max_depth=6,\n",
    "                                                max_features=\"sqrt\",\n",
    "                                                min_samples_leaf=3,\n",
    "                                                min_samples_split=3,\n",
    "                                                n_estimators=200))\n",
    "pipe.fit(X_train, y_train)\n",
    "print(\"test: \", pipe.score(X_test, y_test))\n",
    "\n",
    "scores = cross_val_score(pipe, X_train_df, y_train_df, n_jobs=3)\n",
    "print(\"mean of cross val score for X_train_df: \", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "param_grid = [\n",
    "{'classifier': [SVC()], \n",
    " 'preprocessing': [StandardScaler(), None], \n",
    " 'classifier__gamma': [0.001, 0.01, 0.1, 1, 10, 100], \n",
    " 'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100]},\n",
    "{'classifier': [RandomForestClassifier(n_estimators=100)], \n",
    " 'preprocessing': [None], \n",
    " 'classifier__max_features': [1, 2, 3]}]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Individual steps may also be replaced as parameters, and non-final steps may be ignored by setting them to None:\n",
    "# http://scikit-learn.org/stable/modules/pipeline.html\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "param_grid = dict(reduce_dim=[None, PCA(5), PCA(10)],\n",
    "                   clf=[SVC(), LogisticRegression()],\n",
    "                   clf__C=[0.1, 10, 100])\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
