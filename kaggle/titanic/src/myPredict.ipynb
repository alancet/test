{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# data analysis and wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# train, test, validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "\n",
    "\n",
    "# scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "# decomposition\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "# feature engineering\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# feature selection\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../input/train.csv')\n",
    "test_df = pd.read_csv('../input/test.csv')\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# modify features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make ticket length feature\n",
    "https://www.kaggle.com/yuanxuan/titanic-random-forest-82-78/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Ticket_Len'] = train_df['Ticket'].apply(lambda x: len(x))\n",
    "test_df['Ticket_Len'] = test_df['Ticket'].apply(lambda x: len(x))\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.barplot(data=train_df, x=\"Ticket_Len\", y=\"Survived\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df['Ticket_Len'].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_df['Ticket_Len'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make Cabin First character feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Cabin_Letter\"] = train_df[\"Cabin\"].fillna('0').apply(lambda x: x[0])\n",
    "test_df[\"Cabin_Letter\"] = test_df[\"Cabin\"].fillna('0').apply(lambda x: x[0])\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.barplot(data=train_df, x=\"Cabin_Letter\", y=\"Survived\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.groupby(\"Cabin_Letter\").Survived.value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df[\"Cabin_Letter\"].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.barplot(data=train_df, x=\"Cabin_Letter\", y=\"Survived\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_df[\"Cabin_Letter\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make dummy variable for Cabin_Letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1309, 14)\n",
      "(891, 22) (418, 21)\n"
     ]
    }
   ],
   "source": [
    "train_test_df = pd.concat((train_df, test_df))\n",
    "\n",
    "print(train_test_df.shape)\n",
    "\n",
    "# apply get_dummies for Cabin_Letter\n",
    "train_test_df = pd.get_dummies(train_test_df, columns=[\"Cabin_Letter\"])\n",
    "\n",
    "#train_test_df.head()\n",
    "train_df = train_test_df.iloc[:train_df.shape[0]]\n",
    "test_df = train_test_df.iloc[train_df.shape[0]:]\n",
    "\n",
    "# drop added Survived column from test_df\n",
    "test_df = test_df.drop(\"Survived\", axis=1)\n",
    "print(train_df.shape, test_df.shape)\n",
    "\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make CabinBool feature\n",
    "**I think the idea here is that people with recorded cabin numbers are of higher socioeconomic class, and thus more likely to survive. **\n",
    "https://www.kaggle.com/nadintamer/titanic-survival-predictions-beginner\n",
    "\n",
    "- I tried it\n",
    "  - but gradient boosting result became worse. from 0.79904 to 0.77990\n",
    "  - more than cabinbool is necessary? should i use first letter of cabin name?\n",
    "\n",
    "**CabinBool is inclueded in Cabin letter and cabin number**\n",
    "**no need to use**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df[\"CabinBool\"] = (train_df[\"Cabin\"].notnull().astype('int'))\n",
    "test_df[\"CabinBool\"] = (test_df[\"Cabin\"].notnull().astype('int'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make Cabin number feature\n",
    "https://www.kaggle.com/yuanxuan/titanic-random-forest-82-78/notebook"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df['Cabin'].apply(lambda x: str(x).split(' ')[-1][1:]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:4619: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "for i in [train_df, test_df]:\n",
    "    i['Cabin_num1'] = i['Cabin'].apply(lambda x: str(x).split(' ')[-1][1:])\n",
    "    i['Cabin_num1'].replace('an', np.NaN, inplace = True)\n",
    "    i['Cabin_num1'] = i['Cabin_num1'].apply(lambda x: int(x) if not pd.isnull(x) and x != '' else np.NaN)\n",
    "    i['Cabin_num'] = pd.qcut(train_df['Cabin_num1'], 3)\n",
    "    i['Cabin_num'] = i['Cabin_num'].cat.add_categories([\"nan_category\"])\n",
    "    i['Cabin_num'] = i['Cabin_num'].fillna(\"nan_category\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat((train_df, pd.get_dummies(train_df['Cabin_num'], prefix='Cabin_num')), axis = 1)\n",
    "test_df = pd.concat((test_df, pd.get_dummies(test_df['Cabin_num'], prefix='Cabin_num')), axis = 1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.barplot(data=train_df, x=\"Cabin_num\", y=\"Survived\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.groupby([\"Cabin_num\"])[\"Survived\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_df['Cabin_num']\n",
    "del test_df['Cabin_num']\n",
    "del train_df['Cabin_num1']\n",
    "del test_df['Cabin_num1']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df[['Cabin_num_(1.999, 28.667]', \n",
    "          'Cabin_num_(28.667, 65.667]',\n",
    "          'Cabin_num_(65.667, 148.0]']].head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df[[\"Cabin_Letter_0\", \"Cabin_num_nan_category\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**duplicate feature. delete one of these**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(\"Cabin_Letter_0\", axis=1)\n",
    "test_df = test_df.drop(\"Cabin_Letter_0\", axis=1)\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## del Ticket, Cabin columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del Ticket, Cabin columns\n",
    "train_df = train_df.drop(['Ticket', 'Cabin'], axis=1)\n",
    "test_df = test_df.drop(['Ticket', 'Cabin'], axis=1)\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add title\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.barplot(data=train_df, x=\"Title\", y=\"Survived\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.Title.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make name length feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Name_Len'] = train_df['Name'].apply(lambda x: len(x))\n",
    "test_df['Name_Len'] = test_df['Name'].apply(lambda x: len(x))\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df[\"Name_Len\"].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.barplot(data=train_df, x=\"Name_Len\", y=\"Survived\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.groupby(\"Name_Len\").Survived.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## map value to Sex "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in combine:\n",
    "    dataset[\"Sex\"] = dataset[\"Sex\"].map({'female':1, 'male':0}).astype(int)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make Age_Null_Flag if the Age is nulll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Age_Null_Flag'] = train_df['Age'].apply(lambda x: 1 if pd.isnull(x) else 0)\n",
    "test_df['Age_Null_Flag'] = test_df['Age'].apply(lambda x: 1 if pd.isnull(x) else 0)\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.barplot(data=train_df, x=\"Age_Null_Flag\", y=\"Survived\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df[\"Age_Null_Flag\"].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_df[\"Age_Null_Flag\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fill na of Age\n",
    "\n",
    "options\n",
    "\n",
    "- by Sex and Pclass\n",
    "- by Title and Pclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### by Sex and Pclass"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "guess_ages = np.zeros((2,3))\n",
    "\n",
    "for dataset in combine:\n",
    "    for i in range(0, 2):\n",
    "        for j in range(0, 3):\n",
    "            guess_df = dataset[(dataset['Sex'] == i) & \\\n",
    "                                  (dataset['Pclass'] == j+1)]['Age'].dropna()\n",
    "\n",
    "            # age_mean = guess_df.mean()\n",
    "            # age_std = guess_df.std()\n",
    "            # age_guess = rnd.uniform(age_mean - age_std, age_mean + age_std)\n",
    "\n",
    "            age_guess = guess_df.median()\n",
    "\n",
    "            # Convert random age float to nearest .5 age\n",
    "            guess_ages[i,j] = int( age_guess/0.5 + 0.5 ) * 0.5\n",
    "            \n",
    "    for i in range(0, 2):\n",
    "        for j in range(0, 3):\n",
    "            dataset.loc[ (dataset.Age.isnull()) & (dataset.Sex == i) & (dataset.Pclass == j+1),\\\n",
    "                    'Age'] = guess_ages[i,j]\n",
    "\n",
    "    dataset['Age'] = dataset['Age'].astype(int)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.barplot(data=train_df, x=\"Age\", y=\"Survived\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fill nan of Age by Title and Pclass\n",
    "https://www.kaggle.com/yuanxuan/titanic-random-forest-82-78/notebook\n",
    "\n",
    "There is mistake in the original notebook.\n",
    "test_df was filled by train_df.\n",
    "So I modified."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "groupedAge_train = train_df.groupby(['Title', 'Pclass'])['Age']\n",
    "groupedAge_train.mean()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_test_df = pd.concat((train_df, test_df))\n",
    "groupedAge_train_test = train_test_df.groupby(['Title', 'Pclass'])['Age']\n",
    "filledAge = groupedAge_train_test.transform(lambda x:x.fillna(x.mean()))\n",
    "train_test_df[filledAge.isna()]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "groupedByTitleOnly_Age_train_test = train_test_df.groupby(['Title'])['Age']\n",
    "groupedByTitleOnly_Age_train_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_df = pd.concat((train_df, test_df))\n",
    "groupedAge_train_test = train_test_df.groupby(['Title', 'Pclass'])['Age']\n",
    "train_test_df.Age = groupedAge_train_test.transform(lambda x:x.fillna(x.mean()))\n",
    "\n",
    "groupedByTitleOnly_Age_train_test = train_test_df.groupby(['Title'])['Age']\n",
    "train_test_df.Age = groupedByTitleOnly_Age_train_test.transform(lambda x:x.fillna(x.mean()))\n",
    "\n",
    "train_df = train_test_df.iloc[:train_df.shape[0]]\n",
    "test_df = train_test_df.iloc[train_df.shape[0]:]\n",
    "\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "groupedAge_train_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_df.Age.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((891, 26), (418, 26))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head(30)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_df.head(30)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.isna().any()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_df.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tried keep Age feature and don't add AgeBand numerical feature\n",
    "if both are there, it is duplicate information\n",
    "\n",
    "#### 2018/03/17 tried Age instead of Age band. But AgeBand is better score for almost all models.\n",
    "svc score was same of little bit better.\n",
    "random forest score became worse.\n",
    "so AgeBand is better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add age band\n",
    "\n",
    "- 5 age band by pd.cut\n",
    "- 10 age band by pd.cut: this is better score.\n",
    "\n",
    "if i use pd.qcut, band become too short for young adult around 25."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pd.cut(train_df['Age'], 10).value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df['AgeBand'] = pd.cut(train_df['Age'], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "train_df['AgeBand'] = pd.cut(train_df['Age'], 10)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.barplot(x=\"AgeBand\", data=train_df, y=\"Survived\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overwrite AgeBand number on Age. means, drop Age and AgeBand text column"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 5 age band\n",
    "for dataset in combine:\n",
    "    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n",
    "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
    "    dataset.loc[ dataset['Age'] > 64, 'Age'] = 4\n",
    "train_df = train_df.drop(['AgeBand'], axis=1)\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n(24.0, 32.0]    275\\n(16.0, 24.0]    220\\n(32.0, 40.0]    148\\n(40.0, 48.0]     68\\n(-0.08, 8.0]     54\\n(8.0, 16.0]      46\\n(48.0, 56.0]     45\\n(56.0, 64.0]     24\\n(64.0, 72.0]      9\\n(72.0, 80.0]      2\\n'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10 age band\n",
    "for dataset in combine:\n",
    "    dataset.loc[ dataset['Age'] <= 8, 'Age'] = 0\n",
    "    dataset.loc[(dataset['Age'] > 8) & (dataset['Age'] <= 16), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 24), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 24) & (dataset['Age'] <= 32), 'Age'] = 3\n",
    "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 40), 'Age'] = 4\n",
    "    dataset.loc[(dataset['Age'] > 40) & (dataset['Age'] <= 48), 'Age'] = 5\n",
    "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 56), 'Age'] = 6\n",
    "    dataset.loc[(dataset['Age'] > 56) & (dataset['Age'] <= 64), 'Age'] = 7\n",
    "    dataset.loc[(dataset['Age'] > 64) & (dataset['Age'] <= 72), 'Age'] = 8\n",
    "    dataset.loc[ dataset['Age'] > 72, 'Age'] = 9\n",
    "train_df = train_df.drop(['AgeBand'], axis=1)\n",
    "combine = [train_df, test_df]\n",
    "\n",
    "\"\"\"\n",
    "(24.0, 32.0]    275\n",
    "(16.0, 24.0]    220\n",
    "(32.0, 40.0]    148\n",
    "(40.0, 48.0]     68\n",
    "(-0.08, 8.0]     54\n",
    "(8.0, 16.0]      46\n",
    "(48.0, 56.0]     45\n",
    "(56.0, 64.0]     24\n",
    "(64.0, 72.0]      9\n",
    "(72.0, 80.0]      2\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.barplot(data=train_df, x=\"Age\", y=\"Survived\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert Title to numerical or one hot encoding\n",
    "\n",
    "- one hot encoding, no deleting rare title\n",
    "- OR change rare title to \"Rare\" and map value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one hot encoding, no deleteing rare title"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# try one hote encoding without delete rare title\n",
    "#\n",
    "# concat train and test data. and apply get_dummies for Title. \n",
    "# then split to original size. also drop Survived column from test_df\n",
    "print(train_df.shape, test_df.shape)\n",
    "\n",
    "# concat train and test data\n",
    "#   test_df's Survived column is filled with NaN\n",
    "train_test_df = pd.concat((train_df, test_df))\n",
    "\n",
    "print(train_test_df.shape)\n",
    "\n",
    "# apply get_dummies for Title\n",
    "train_test_df = pd.get_dummies(train_test_df, columns=[\"Title\"])\n",
    "\n",
    "#train_test_df.head()\n",
    "train_df = train_test_df.iloc[:train_df.shape[0]]\n",
    "test_df = train_test_df.iloc[train_df.shape[0]:]\n",
    "\n",
    "# drop added Survived column from test_df\n",
    "test_df = test_df.drop(\"Survived\", axis=1)\n",
    "print(train_df.shape, test_df.shape)\n",
    "\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OR change rare title to \"Rare\" and map value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Age_Null_Flag</th>\n",
       "      <th>Cabin_Letter_A</th>\n",
       "      <th>Cabin_Letter_B</th>\n",
       "      <th>Cabin_Letter_C</th>\n",
       "      <th>Cabin_Letter_D</th>\n",
       "      <th>Cabin_Letter_E</th>\n",
       "      <th>Cabin_Letter_F</th>\n",
       "      <th>Cabin_Letter_G</th>\n",
       "      <th>Cabin_Letter_T</th>\n",
       "      <th>...</th>\n",
       "      <th>Name</th>\n",
       "      <th>Name_Len</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Ticket_Len</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Age_Null_Flag  Cabin_Letter_A  Cabin_Letter_B  Cabin_Letter_C  \\\n",
       "0  2.0              0               0               0               0   \n",
       "1  4.0              0               0               0               1   \n",
       "2  3.0              0               0               0               0   \n",
       "3  4.0              0               0               0               1   \n",
       "4  4.0              0               0               0               0   \n",
       "\n",
       "   Cabin_Letter_D  Cabin_Letter_E  Cabin_Letter_F  Cabin_Letter_G  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   Cabin_Letter_T  ...                                                 Name  \\\n",
       "0               0  ...                              Braund, Mr. Owen Harris   \n",
       "1               0  ...    Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2               0  ...                               Heikkinen, Miss. Laina   \n",
       "3               0  ...         Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4               0  ...                             Allen, Mr. William Henry   \n",
       "\n",
       "   Name_Len  Parch  PassengerId Pclass  Sex SibSp  Survived  Ticket_Len  Title  \n",
       "0        23      0            1      3    0     1       0.0           9      1  \n",
       "1        51      0            2      1    1     1       1.0           8      3  \n",
       "2        22      0            3      3    1     0       1.0          16      2  \n",
       "3        44      0            4      1    1     1       1.0           6      3  \n",
       "4        24      0            5      3    0     0       0.0           6      1  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# del rare title and map value\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\n",
    "                                                 'Don', 'Dr', 'Major', 'Rev', 'Sir',\n",
    "                                                 'Jonkheer', 'Dona'], 'Rare')\n",
    "\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "    \n",
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset['Title'].map(title_mapping)\n",
    "    dataset['Title'] = dataset['Title'].fillna(0)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.countplot(data=train_df, x=\"Title\", hue=\"Survived\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new feature \"FamilySize\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "for dataset in combine:\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset['IsAlone'] = 0\n",
    "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset['Age*Class'] = dataset.Age * dataset.Pclass"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.barplot(data=train_df, x=\"FamilySize\", y=\"Survived\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.barplot(data=train_df, x=\"IsAlone\", y=\"Survived\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.countplot(data=train_df, x=\"Age*Class\", hue=\"Survived\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### select family related feature\n",
    "Parch, SibSp, FaimilySize, IsAlone\n",
    "\n",
    "2018/03/18 Parch and SibSp only was best for almost all models"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# keep all"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# keep Parch, SibSp only. this was best amoung familly related features\n",
    "\n",
    "train_df = train_df.drop(['FamilySize', 'IsAlone'], axis=1)\n",
    "test_df = test_df.drop(['FamilySize', 'IsAlone'], axis=1)\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Age_Null_Flag</th>\n",
       "      <th>Cabin_Letter_A</th>\n",
       "      <th>Cabin_Letter_B</th>\n",
       "      <th>Cabin_Letter_C</th>\n",
       "      <th>Cabin_Letter_D</th>\n",
       "      <th>Cabin_Letter_E</th>\n",
       "      <th>Cabin_Letter_F</th>\n",
       "      <th>Cabin_Letter_G</th>\n",
       "      <th>Cabin_Letter_T</th>\n",
       "      <th>...</th>\n",
       "      <th>Name</th>\n",
       "      <th>Name_Len</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Ticket_Len</th>\n",
       "      <th>Title</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Age*Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Age_Null_Flag  Cabin_Letter_A  Cabin_Letter_B  Cabin_Letter_C  \\\n",
       "0  2.0              0               0               0               0   \n",
       "1  4.0              0               0               0               1   \n",
       "2  3.0              0               0               0               0   \n",
       "3  4.0              0               0               0               1   \n",
       "4  4.0              0               0               0               0   \n",
       "\n",
       "   Cabin_Letter_D  Cabin_Letter_E  Cabin_Letter_F  Cabin_Letter_G  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   Cabin_Letter_T    ...      \\\n",
       "0               0    ...       \n",
       "1               0    ...       \n",
       "2               0    ...       \n",
       "3               0    ...       \n",
       "4               0    ...       \n",
       "\n",
       "                                                Name  Name_Len  PassengerId  \\\n",
       "0                            Braund, Mr. Owen Harris        23            1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...        51            2   \n",
       "2                             Heikkinen, Miss. Laina        22            3   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)        44            4   \n",
       "4                           Allen, Mr. William Henry        24            5   \n",
       "\n",
       "   Pclass Sex  Survived Ticket_Len  Title  FamilySize  Age*Class  \n",
       "0       3   0       0.0          9      1           2        6.0  \n",
       "1       1   1       1.0          8      3           2        4.0  \n",
       "2       3   1       1.0         16      2           1        9.0  \n",
       "3       1   1       1.0          6      3           2        4.0  \n",
       "4       3   0       0.0          6      1           1       12.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep FamilySize only\n",
    "\n",
    "train_df = train_df.drop(['Parch', 'SibSp', 'IsAlone'], axis=1)\n",
    "test_df = test_df.drop(['Parch', 'SibSp', 'IsAlone'], axis=1)\n",
    "combine = [train_df, test_df]\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# keep IsAlone only (drop Parch, SibSp, FaimilySize)\n",
    "\n",
    "train_df = train_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\n",
    "test_df = test_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\n",
    "combine = [train_df, test_df]\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fill missing Embarked "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_port = train_df.Embarked.dropna().mode()[0]\n",
    "for dataset in combine:\n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna(freq_port)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Embarked categorical feature to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Age_Null_Flag</th>\n",
       "      <th>Cabin_Letter_A</th>\n",
       "      <th>Cabin_Letter_B</th>\n",
       "      <th>Cabin_Letter_C</th>\n",
       "      <th>Cabin_Letter_D</th>\n",
       "      <th>Cabin_Letter_E</th>\n",
       "      <th>Cabin_Letter_F</th>\n",
       "      <th>Cabin_Letter_G</th>\n",
       "      <th>Cabin_Letter_T</th>\n",
       "      <th>...</th>\n",
       "      <th>Name</th>\n",
       "      <th>Name_Len</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Ticket_Len</th>\n",
       "      <th>Title</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Age*Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Age_Null_Flag  Cabin_Letter_A  Cabin_Letter_B  Cabin_Letter_C  \\\n",
       "0  2.0              0               0               0               0   \n",
       "1  4.0              0               0               0               1   \n",
       "2  3.0              0               0               0               0   \n",
       "3  4.0              0               0               0               1   \n",
       "4  4.0              0               0               0               0   \n",
       "\n",
       "   Cabin_Letter_D  Cabin_Letter_E  Cabin_Letter_F  Cabin_Letter_G  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   Cabin_Letter_T    ...      \\\n",
       "0               0    ...       \n",
       "1               0    ...       \n",
       "2               0    ...       \n",
       "3               0    ...       \n",
       "4               0    ...       \n",
       "\n",
       "                                                Name  Name_Len  PassengerId  \\\n",
       "0                            Braund, Mr. Owen Harris        23            1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...        51            2   \n",
       "2                             Heikkinen, Miss. Laina        22            3   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)        44            4   \n",
       "4                           Allen, Mr. William Henry        24            5   \n",
       "\n",
       "   Pclass  Sex  Survived Ticket_Len  Title  FamilySize  Age*Class  \n",
       "0       3    0       0.0          9      1           2        6.0  \n",
       "1       1    1       1.0          8      3           2        4.0  \n",
       "2       3    1       1.0         16      2           1        9.0  \n",
       "3       1    1       1.0          6      3           2        4.0  \n",
       "4       3    0       0.0          6      1           1       12.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for dataset in combine:\n",
    "    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## try one hot encoding for Embarked categorical feature\n",
    "2018/03/18 this is better than using converting categorical to numeric"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# try one hote encoding for Embarked\n",
    "#\n",
    "# concat train and test data. and apply get_dummies for Title. \n",
    "# then split to original size. also drop Survived column from test_df\n",
    "print(train_df.shape, test_df.shape)\n",
    "\n",
    "# concat train and test data\n",
    "#   test_df's Survived column is filled with NaN\n",
    "train_test_df = pd.concat((train_df, test_df))\n",
    "\n",
    "print(train_test_df.shape)\n",
    "\n",
    "# apply get_dummies for Title\n",
    "train_test_df = pd.get_dummies(train_test_df, columns=[\"Embarked\"])\n",
    "\n",
    "#train_test_df.head()\n",
    "train_df = train_test_df.iloc[:train_df.shape[0]]\n",
    "test_df = train_test_df.iloc[train_df.shape[0]:]\n",
    "\n",
    "# drop added Survived column from test_df\n",
    "test_df = test_df.drop(\"Survived\", axis=1)\n",
    "print(train_df.shape, test_df.shape)\n",
    "\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fill na of test data Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Fare'].fillna(test_df['Fare'].dropna().median(), inplace=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make Fareband feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['FareBand'] = pd.qcut(train_df['Fare'], 4)\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
    "    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "\n",
    "train_df = train_df.drop(['FareBand'], axis=1)\n",
    "\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try more fare band number\n",
    "\n",
    "- no difference\n",
    "\n",
    "### keep Fare feature and add FareBand numerical feature¶\n",
    "\n",
    "- not good result"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fareband = pd.qcut(train_df['Fare'], 6)\n",
    "fareband.unique()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df['FareBand'] = pd.qcut(train_df['Fare'], 6)\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset.loc[ dataset['Fare'] <= 7.775, 'Fare'] = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.775) & (dataset['Fare'] <= 8.662), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 8.662) & (dataset['Fare'] <= 14.454), 'Fare']   = 2\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 26.0), 'Fare']   = 3\n",
    "    dataset.loc[(dataset['Fare'] > 26.0) & (dataset['Fare'] <= 52.369), 'Fare']   = 4\n",
    "    \n",
    "    dataset.loc[ dataset['Fare'] > 52.369, 'Fare'] = 5\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "\n",
    "train_df = train_df.drop(['FareBand'], axis=1)\n",
    "\n",
    "combine = [train_df, test_df]\n",
    "    \n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## drop Name, PassengerId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(['Name', 'PassengerId'], axis=1)\n",
    "test_df = test_df.drop(['Name'], axis=1)\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## drop Survived in test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.drop([\"Survived\"], axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## final check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Age_Null_Flag</th>\n",
       "      <th>Cabin_Letter_A</th>\n",
       "      <th>Cabin_Letter_B</th>\n",
       "      <th>Cabin_Letter_C</th>\n",
       "      <th>Cabin_Letter_D</th>\n",
       "      <th>Cabin_Letter_E</th>\n",
       "      <th>Cabin_Letter_F</th>\n",
       "      <th>Cabin_Letter_G</th>\n",
       "      <th>Cabin_Letter_T</th>\n",
       "      <th>...</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name_Len</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Ticket_Len</th>\n",
       "      <th>Title</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Age*Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Age_Null_Flag  Cabin_Letter_A  Cabin_Letter_B  Cabin_Letter_C  \\\n",
       "0  2.0              0               0               0               0   \n",
       "1  4.0              0               0               0               1   \n",
       "2  3.0              0               0               0               0   \n",
       "3  4.0              0               0               0               1   \n",
       "4  4.0              0               0               0               0   \n",
       "\n",
       "   Cabin_Letter_D  Cabin_Letter_E  Cabin_Letter_F  Cabin_Letter_G  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   Cabin_Letter_T    ...      Embarked  Fare  Name_Len  Pclass  Sex  Survived  \\\n",
       "0               0    ...             0     0        23       3    0       0.0   \n",
       "1               0    ...             1     3        51       1    1       1.0   \n",
       "2               0    ...             0     1        22       3    1       1.0   \n",
       "3               0    ...             0     3        44       1    1       1.0   \n",
       "4               0    ...             0     1        24       3    0       0.0   \n",
       "\n",
       "   Ticket_Len  Title  FamilySize  Age*Class  \n",
       "0           9      1           2        6.0  \n",
       "1           8      3           2        4.0  \n",
       "2          16      2           1        9.0  \n",
       "3           6      3           2        4.0  \n",
       "4           6      1           1       12.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Age_Null_Flag', 'Cabin_Letter_A', 'Cabin_Letter_B',\n",
       "       'Cabin_Letter_C', 'Cabin_Letter_D', 'Cabin_Letter_E', 'Cabin_Letter_F',\n",
       "       'Cabin_Letter_G', 'Cabin_Letter_T', 'Cabin_num_(1.999, 28.667]',\n",
       "       'Cabin_num_(28.667, 65.667]', 'Cabin_num_(65.667, 148.0]',\n",
       "       'Cabin_num_nan_category', 'Embarked', 'Fare', 'Name_Len', 'Pclass',\n",
       "       'Sex', 'Survived', 'Ticket_Len', 'Title', 'FamilySize', 'Age*Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Age_Null_Flag</th>\n",
       "      <th>Cabin_Letter_A</th>\n",
       "      <th>Cabin_Letter_B</th>\n",
       "      <th>Cabin_Letter_C</th>\n",
       "      <th>Cabin_Letter_D</th>\n",
       "      <th>Cabin_Letter_E</th>\n",
       "      <th>Cabin_Letter_F</th>\n",
       "      <th>Cabin_Letter_G</th>\n",
       "      <th>Cabin_Letter_T</th>\n",
       "      <th>...</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name_Len</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ticket_Len</th>\n",
       "      <th>Title</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Age*Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Age_Null_Flag  Cabin_Letter_A  Cabin_Letter_B  Cabin_Letter_C  \\\n",
       "0  4.0              0               0               0               0   \n",
       "1  5.0              0               0               0               0   \n",
       "2  7.0              0               0               0               0   \n",
       "3  3.0              0               0               0               0   \n",
       "4  2.0              0               0               0               0   \n",
       "\n",
       "   Cabin_Letter_D  Cabin_Letter_E  Cabin_Letter_F  Cabin_Letter_G  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   Cabin_Letter_T    ...      Embarked  Fare  Name_Len  PassengerId  Pclass  \\\n",
       "0               0    ...             2     0        16          892       3   \n",
       "1               0    ...             0     0        32          893       3   \n",
       "2               0    ...             2     1        25          894       2   \n",
       "3               0    ...             0     1        16          895       3   \n",
       "4               0    ...             0     1        44          896       3   \n",
       "\n",
       "   Sex  Ticket_Len  Title  FamilySize  Age*Class  \n",
       "0    0           6      1           1       12.0  \n",
       "1    1           6      3           2       15.0  \n",
       "2    0           6      1           1       14.0  \n",
       "3    0           6      1           1        9.0  \n",
       "4    1           7      3           3        6.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Age_Null_Flag', 'Cabin_Letter_A', 'Cabin_Letter_B',\n",
       "       'Cabin_Letter_C', 'Cabin_Letter_D', 'Cabin_Letter_E', 'Cabin_Letter_F',\n",
       "       'Cabin_Letter_G', 'Cabin_Letter_T', 'Cabin_num_(1.999, 28.667]',\n",
       "       'Cabin_num_(28.667, 65.667]', 'Cabin_num_(65.667, 148.0]',\n",
       "       'Cabin_num_nan_category', 'Embarked', 'Fare', 'Name_Len', 'PassengerId',\n",
       "       'Pclass', 'Sex', 'Ticket_Len', 'Title', 'FamilySize', 'Age*Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.columns"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "colormap = plt.cm.viridis\n",
    "plt.figure(figsize=(30,30))\n",
    "plt.title('Pearson Correlation of Features', y=1.05, size=15)\n",
    "sns.heatmap(train_df.astype(float).corr(), \n",
    "            linewidths=0.1,vmax=1.0,\n",
    "            square=True, cmap=colormap, \n",
    "            linecolor='white', annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# try to delete some features\n",
    "\n",
    "- Age*Class is duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(['Age*Class'], axis=1)\n",
    "test_df = test_df.drop(['Age*Class'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Name_Len looks no meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(['Name_Len'], axis=1)\n",
    "test_df = test_df.drop(['Name_Len'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ticket_Len looks no meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(['Ticket_Len'], axis=1)\n",
    "test_df = test_df.drop(['Ticket_Len'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 21) (418, 21)\n",
      "Index(['Age', 'Age_Null_Flag', 'Cabin_Letter_A', 'Cabin_Letter_B',\n",
      "       'Cabin_Letter_C', 'Cabin_Letter_D', 'Cabin_Letter_E', 'Cabin_Letter_F',\n",
      "       'Cabin_Letter_G', 'Cabin_Letter_T', 'Cabin_num_(1.999, 28.667]',\n",
      "       'Cabin_num_(28.667, 65.667]', 'Cabin_num_(65.667, 148.0]',\n",
      "       'Cabin_num_nan_category', 'Embarked', 'Fare', 'Pclass', 'Sex',\n",
      "       'Survived', 'Title', 'FamilySize'],\n",
      "      dtype='object') Index(['Age', 'Age_Null_Flag', 'Cabin_Letter_A', 'Cabin_Letter_B',\n",
      "       'Cabin_Letter_C', 'Cabin_Letter_D', 'Cabin_Letter_E', 'Cabin_Letter_F',\n",
      "       'Cabin_Letter_G', 'Cabin_Letter_T', 'Cabin_num_(1.999, 28.667]',\n",
      "       'Cabin_num_(28.667, 65.667]', 'Cabin_num_(65.667, 148.0]',\n",
      "       'Cabin_num_nan_category', 'Embarked', 'Fare', 'PassengerId', 'Pclass',\n",
      "       'Sex', 'Title', 'FamilySize'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape, test_df.shape)\n",
    "print(train_df.columns, test_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Age_Null_Flag</th>\n",
       "      <th>Cabin_Letter_A</th>\n",
       "      <th>Cabin_Letter_B</th>\n",
       "      <th>Cabin_Letter_C</th>\n",
       "      <th>Cabin_Letter_D</th>\n",
       "      <th>Cabin_Letter_E</th>\n",
       "      <th>Cabin_Letter_F</th>\n",
       "      <th>Cabin_Letter_G</th>\n",
       "      <th>Cabin_Letter_T</th>\n",
       "      <th>...</th>\n",
       "      <th>Cabin_num_(28.667, 65.667]</th>\n",
       "      <th>Cabin_num_(65.667, 148.0]</th>\n",
       "      <th>Cabin_num_nan_category</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Title</th>\n",
       "      <th>FamilySize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Age_Null_Flag  Cabin_Letter_A  Cabin_Letter_B  Cabin_Letter_C  \\\n",
       "0  2.0              0               0               0               0   \n",
       "1  4.0              0               0               0               1   \n",
       "2  3.0              0               0               0               0   \n",
       "3  4.0              0               0               0               1   \n",
       "4  4.0              0               0               0               0   \n",
       "\n",
       "   Cabin_Letter_D  Cabin_Letter_E  Cabin_Letter_F  Cabin_Letter_G  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   Cabin_Letter_T     ...      Cabin_num_(28.667, 65.667]  \\\n",
       "0               0     ...                               0   \n",
       "1               0     ...                               0   \n",
       "2               0     ...                               0   \n",
       "3               0     ...                               0   \n",
       "4               0     ...                               0   \n",
       "\n",
       "   Cabin_num_(65.667, 148.0]  Cabin_num_nan_category  Embarked  Fare  Pclass  \\\n",
       "0                          0                       1         0     0       3   \n",
       "1                          1                       0         1     3       1   \n",
       "2                          0                       1         0     1       3   \n",
       "3                          1                       0         0     3       1   \n",
       "4                          0                       1         0     1       3   \n",
       "\n",
       "   Sex  Survived  Title  FamilySize  \n",
       "0    0       0.0      1           2  \n",
       "1    1       1.0      3           2  \n",
       "2    1       1.0      2           1  \n",
       "3    1       1.0      3           2  \n",
       "4    0       0.0      1           1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Age_Null_Flag</th>\n",
       "      <th>Cabin_Letter_A</th>\n",
       "      <th>Cabin_Letter_B</th>\n",
       "      <th>Cabin_Letter_C</th>\n",
       "      <th>Cabin_Letter_D</th>\n",
       "      <th>Cabin_Letter_E</th>\n",
       "      <th>Cabin_Letter_F</th>\n",
       "      <th>Cabin_Letter_G</th>\n",
       "      <th>Cabin_Letter_T</th>\n",
       "      <th>...</th>\n",
       "      <th>Cabin_num_(28.667, 65.667]</th>\n",
       "      <th>Cabin_num_(65.667, 148.0]</th>\n",
       "      <th>Cabin_num_nan_category</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Title</th>\n",
       "      <th>FamilySize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Age_Null_Flag  Cabin_Letter_A  Cabin_Letter_B  Cabin_Letter_C  \\\n",
       "0  4.0              0               0               0               0   \n",
       "1  5.0              0               0               0               0   \n",
       "2  7.0              0               0               0               0   \n",
       "3  3.0              0               0               0               0   \n",
       "4  2.0              0               0               0               0   \n",
       "\n",
       "   Cabin_Letter_D  Cabin_Letter_E  Cabin_Letter_F  Cabin_Letter_G  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   Cabin_Letter_T     ...      Cabin_num_(28.667, 65.667]  \\\n",
       "0               0     ...                               0   \n",
       "1               0     ...                               0   \n",
       "2               0     ...                               0   \n",
       "3               0     ...                               0   \n",
       "4               0     ...                               0   \n",
       "\n",
       "   Cabin_num_(65.667, 148.0]  Cabin_num_nan_category  Embarked  Fare  \\\n",
       "0                          0                       1         2     0   \n",
       "1                          1                       0         0     0   \n",
       "2                          0                       1         2     1   \n",
       "3                          1                       0         0     1   \n",
       "4                          0                       1         0     1   \n",
       "\n",
       "   PassengerId  Pclass  Sex  Title  FamilySize  \n",
       "0          892       3    0      1           1  \n",
       "1          893       3    1      3           2  \n",
       "2          894       2    0      1           1  \n",
       "3          895       3    0      1           1  \n",
       "4          896       3    1      3           3  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model and estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = train_df.drop(\"Survived\", axis=1)\n",
    "y_train_df = train_df[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/test data shape (596, 20) (295, 20)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train_df, y_train_df, test_size=0.33, random_state=42)\n",
    "print(\"train/test data shape\", X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done 185 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=3)]: Done 320 out of 320 | elapsed:    5.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'C': 100, 'gamma': 0.01}\n",
      "Mean cross-validated score of the best_estimator:  0.823825503356\n",
      "test:  0.840677966102\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make wide the ranges\n",
    "\n",
    "param_grid = {'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "              'gamma': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]}\n",
    "\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5, n_jobs=3, verbose=1)\n",
    "\n",
    "# no meaning to use cross_val for grid_search model because it is incluced in grid search\n",
    "#scores = cross_val_score(grid_search, X_train, y_train, cv=5, n_jobs=6)\n",
    "#print(\"mean of train scores\", scores.mean())\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "plt.matshow(grid_search.cv_results_['mean_test_score'].reshape(8, -1),\n",
    "            vmin=0, cmap=\"viridis\")\n",
    "plt.xlabel(\"C\")\n",
    "plt.ylabel(\"gamma\")\n",
    "plt.xticks(range(len(param_grid['C'])), param_grid['C'])\n",
    "plt.yticks(range(len(param_grid['gamma'])), param_grid['gamma'])\n",
    "plt.colorbar()\n",
    "\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# if age band is 5\n",
    "Mean cross-validated score of the best_estimator:  0.8154362416107382\n",
    "best parameters: {'C': 100, 'gamma': 0.001}\n",
    "test:  0.8338983050847457\n",
    "\n",
    "\n",
    "# if age band is 10\n",
    "Mean cross-validated score of the best_estimator:  0.8137583892617449\n",
    "best parameters: {'C': 100, 'gamma': 0.001}\n",
    "test:  0.8372881355932204\n",
    "\n",
    "\n",
    "# OR change rare title to \"Rare\" and map value\n",
    "Mean cross-validated score of the best_estimator:  0.8070469798657718\n",
    "best parameters: {'C': 10, 'gamma': 0.01}\n",
    "test:  0.8135593220338984\n",
    "\n",
    "# 5 age band and filled age by mean of group(title, pclass)\n",
    "Mean cross-validated score of the best_estimator:  0.8120805369127517\n",
    "best parameters: {'C': 100, 'gamma': 0.001}\n",
    "test:  0.8305084745762712\n",
    "\n",
    "# 10 age band, parch, sibsp\n",
    "best parameters: {'C': 1000, 'gamma': 0.001}\n",
    "Mean cross-validated score of the best_estimator:  0.81711409396\n",
    "test:  0.84406779661\n",
    "\n",
    "\n",
    "# 10 age band, parch&sibsp, embarked num category\n",
    "best parameters: {'C': 100, 'gamma': 0.001}\n",
    "Mean cross-validated score of the best_estimator:  0.815436241611\n",
    "test:  0.840677966102\n",
    "\n",
    "# 10 age band, parch&sibsp, embarked num category, rare title&map value\n",
    "best parameters: {'C': 1000, 'gamma': 0.001}\n",
    "Mean cross-validated score of the best_estimator:  0.803691275168\n",
    "test:  0.840677966102"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "grid_search.best_estimator_.support_vectors_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "grid_search.best_estimator_.dual_coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "param_grid = {'kneighborsclassifier__n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20]}\n",
    "\n",
    "pipe = make_pipeline(MinMaxScaler(), KNeighborsClassifier())\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv=5, n_jobs=3, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 5 age band\n",
    "Mean cross-validated score of the best_estimator:  0.837248322147651\n",
    "best parameters: {'kneighborsclassifier__n_neighbors': 8}\n",
    "test:  0.823728813559322\n",
    "\n",
    "# if age band is 10\n",
    "Mean cross-validated score of the best_estimator:  0.8355704697986577\n",
    "best parameters: {'kneighborsclassifier__n_neighbors': 8}\n",
    "test:  0.8271186440677966\n",
    "\n",
    "# OR change rare title to \"Rare\" and map value\n",
    "Mean cross-validated score of the best_estimator:  0.8087248322147651\n",
    "best parameters: {'kneighborsclassifier__n_neighbors': 10}\n",
    "test:  0.7830508474576271\n",
    "\n",
    "\n",
    "# 5 age band and filled age by mean of group(title, pclass)\n",
    "Mean cross-validated score of the best_estimator:  0.837248322147651\n",
    "best parameters: {'kneighborsclassifier__n_neighbors': 8}\n",
    "test:  0.823728813559322\n",
    "\n",
    "# 10 age band, parch, sibsp\n",
    "best parameters: {'kneighborsclassifier__n_neighbors': 8}\n",
    "Mean cross-validated score of the best_estimator:  0.835570469799\n",
    "test:  0.827118644068\n",
    "\n",
    "\n",
    "# 10 age band, parch&sibsp, embarked num category\n",
    "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n",
    "best parameters: {'kneighborsclassifier__n_neighbors': 8}\n",
    "Mean cross-validated score of the best_estimator:  0.840604026846\n",
    "test:  0.813559322034\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## try several SVC, KNeighborsClassifier models and preprocessing conbinations"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "param_grid = dict(scaling=[None, MinMaxScaler(), RobustScaler()],\n",
    "                  reduce_dim=[None, PCA(), PCA(5), PCA(10), PCA(15), PCA(20), PCA(25)],\n",
    "                  clf=[SVC(C=100, gamma=0.001), KNeighborsClassifier(n_neighbors=8)]\n",
    "                 )\n",
    "pipe = Pipeline([('scaling', StandardScaler()), ('reduce_dim', PCA()), ('clf', SVC())]) \n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=3, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 5 age band\n",
    "\n",
    "Mean cross-validated score of the best_estimator:  0.8422818791946308\n",
    "best parameters: {'clf': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "           metric_params=None, n_jobs=1, n_neighbors=8, p=2,\n",
    "           weights='uniform'), 'reduce_dim': PCA(copy=True, iterated_power='auto', n_components=15, random_state=None,\n",
    "  svd_solver='auto', tol=0.0, whiten=False), 'scaling': MinMaxScaler(copy=True, feature_range=(0, 1))}\n",
    "test:  0.8101694915254237\n",
    "\n",
    "# 10 age band\n",
    "\n",
    "Mean cross-validated score of the best_estimator:  0.8422818791946308\n",
    "best parameters: {'clf': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "           metric_params=None, n_jobs=1, n_neighbors=8, p=2,\n",
    "           weights='uniform'), 'reduce_dim': PCA(copy=True, iterated_power='auto', n_components=15, random_state=None,\n",
    "  svd_solver='auto', tol=0.0, whiten=False), 'scaling': MinMaxScaler(copy=True, feature_range=(0, 1))}\n",
    "test:  0.8101694915254237\n",
    "\n",
    "# OR change rare title to \"Rare\" and map value\n",
    "Mean cross-validated score of the best_estimator:  0.8154362416107382\n",
    "best parameters: {'clf': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "           metric_params=None, n_jobs=1, n_neighbors=8, p=2,\n",
    "           weights='uniform'), 'reduce_dim': PCA(copy=True, iterated_power='auto', n_components=15, random_state=None,\n",
    "  svd_solver='auto', tol=0.0, whiten=False), 'scaling': MinMaxScaler(copy=True, feature_range=(0, 1))}\n",
    "test:  0.7898305084745763\n",
    "\n",
    "\n",
    "\n",
    "# 5 age band and filled age by mean of group(title, pclass)\n",
    "Mean cross-validated score of the best_estimator:  0.8439597315436241\n",
    "best parameters: {'clf': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "           metric_params=None, n_jobs=1, n_neighbors=8, p=2,\n",
    "           weights='uniform'), 'reduce_dim': PCA(copy=True, iterated_power='auto', n_components=15, random_state=None,\n",
    "  svd_solver='auto', tol=0.0, whiten=False), 'scaling': MinMaxScaler(copy=True, feature_range=(0, 1))}\n",
    "test:  0.8067796610169492\n",
    "\n",
    "\n",
    "# 10 age band, parch, sibsp\n",
    "best parameters: {'clf': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "           metric_params=None, n_jobs=1, n_neighbors=8, p=2,\n",
    "           weights='uniform'), 'reduce_dim': PCA(copy=True, iterated_power='auto', n_components=15, random_state=None,\n",
    "  svd_solver='auto', tol=0.0, whiten=False), 'scaling': MinMaxScaler(copy=True, feature_range=(0, 1))}\n",
    "Mean cross-validated score of the best_estimator:  0.8439597315436241\n",
    "test:  0.8067796610169492\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random forest result for compare"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "param_grid = {'randomforestclassifier__n_estimators': [10, 50, 100, 300, 500],\n",
    "              'randomforestclassifier__max_features': [1, 'auto', None],\n",
    "             'randomforestclassifier__max_depth':[1, 3, 5, 7, 9, 13,  None],\n",
    "             'randomforestclassifier__min_samples_leaf': [1,2,4, 7],\n",
    "             \"randomforestclassifier__min_samples_split\" : [2, 3, 4, 7]}\n",
    "\"\"\"\n",
    "# very narrow range\n",
    "param_grid = {'randomforestclassifier__n_estimators': [10,  100,  500, 1000],\n",
    "              'randomforestclassifier__max_features': [1, 'auto', None],\n",
    "             'randomforestclassifier__max_depth':[1, 3, 5, 7, None],\n",
    "             'randomforestclassifier__min_samples_leaf': [1,2,4],\n",
    "             \"randomforestclassifier__min_samples_split\" : [2, 3, 4]}\n",
    "\"\"\"\n",
    "\n",
    "pipe = make_pipeline(RandomForestClassifier())\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=3, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "output of upper code\n",
    "\n",
    "# 5 age band\n",
    "Mean cross-validated score of the best_estimator:  0.8406040268456376\n",
    "best parameters: {'randomforestclassifier__max_depth': 7, 'randomforestclassifier__max_features': 'auto', 'randomforestclassifier__min_samples_leaf': 1, 'randomforestclassifier__min_samples_split': 2, 'randomforestclassifier__n_estimators': 100}\n",
    "test:  0.8203389830508474\n",
    "\n",
    "# if age band is 10\n",
    "Mean cross-validated score of the best_estimator:  0.8406040268456376\n",
    "best parameters: {'randomforestclassifier__max_depth': 7, 'randomforestclassifier__max_features': 'auto', 'randomforestclassifier__min_samples_leaf': 1, 'randomforestclassifier__min_samples_split': 3, 'randomforestclassifier__n_estimators': 100}\n",
    "test:  0.8271186440677966\n",
    "\n",
    "\n",
    "# OR change rare title to \"Rare\" and map value\n",
    "\n",
    "Mean cross-validated score of the best_estimator:  0.8305369127516778\n",
    "best parameters: {'randomforestclassifier__max_depth': 7, 'randomforestclassifier__max_features': 'auto', 'randomforestclassifier__min_samples_leaf': 1, 'randomforestclassifier__min_samples_split': 3, 'randomforestclassifier__n_estimators': 10}\n",
    "test:  0.8440677966101695\n",
    "\n",
    "test score was not bad score. but best estimager score is lower. it is better to not use Rare title\n",
    "\n",
    "\n",
    "# 5 age band and filled age by mean of group(title, pclass)\n",
    "?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test:  0.827118644068\n",
      "mean of cross val score:  0.828282828283\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(RandomForestClassifier(max_depth=7, \n",
    "                                            max_features=\"auto\",\n",
    "                                            min_samples_leaf=1, \n",
    "                                            min_samples_split=3, \n",
    "                                            n_estimators=100))\n",
    "pipe.fit(X_train, y_train)\n",
    "print(\"test: \", pipe.score(X_test, y_test))\n",
    "\n",
    "scores = cross_val_score(pipe, X_train_df, y_train_df, n_jobs=3)\n",
    "print(\"mean of cross val score: \", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Title</td>\n",
       "      <td>0.238899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sex</td>\n",
       "      <td>0.227569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Pclass</td>\n",
       "      <td>0.097440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>FamilySize</td>\n",
       "      <td>0.084691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.067344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Fare</td>\n",
       "      <td>0.062499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Cabin_num_nan_category</td>\n",
       "      <td>0.051990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Embarked</td>\n",
       "      <td>0.041883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cabin_num_(1.999, 28.667]</td>\n",
       "      <td>0.020235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cabin_Letter_E</td>\n",
       "      <td>0.018795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Cabin_num_(28.667, 65.667]</td>\n",
       "      <td>0.015793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cabin_Letter_B</td>\n",
       "      <td>0.013955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Cabin_num_(65.667, 148.0]</td>\n",
       "      <td>0.013585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Age_Null_Flag</td>\n",
       "      <td>0.012566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cabin_Letter_D</td>\n",
       "      <td>0.011889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cabin_Letter_C</td>\n",
       "      <td>0.011074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cabin_Letter_A</td>\n",
       "      <td>0.003655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cabin_Letter_G</td>\n",
       "      <td>0.003398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cabin_Letter_F</td>\n",
       "      <td>0.002572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cabin_Letter_T</td>\n",
       "      <td>0.000168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      variable  importance\n",
       "18                       Title    0.238899\n",
       "17                         Sex    0.227569\n",
       "16                      Pclass    0.097440\n",
       "19                  FamilySize    0.084691\n",
       "0                          Age    0.067344\n",
       "15                        Fare    0.062499\n",
       "13      Cabin_num_nan_category    0.051990\n",
       "14                    Embarked    0.041883\n",
       "10   Cabin_num_(1.999, 28.667]    0.020235\n",
       "6               Cabin_Letter_E    0.018795\n",
       "11  Cabin_num_(28.667, 65.667]    0.015793\n",
       "3               Cabin_Letter_B    0.013955\n",
       "12   Cabin_num_(65.667, 148.0]    0.013585\n",
       "1                Age_Null_Flag    0.012566\n",
       "5               Cabin_Letter_D    0.011889\n",
       "4               Cabin_Letter_C    0.011074\n",
       "2               Cabin_Letter_A    0.003655\n",
       "8               Cabin_Letter_G    0.003398\n",
       "7               Cabin_Letter_F    0.002572\n",
       "9               Cabin_Letter_T    0.000168"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat((pd.DataFrame(X_train.columns, columns = ['variable']), \n",
    "           pd.DataFrame(pipe.named_steps[\"randomforestclassifier\"].feature_importances_, columns = ['importance'])), \n",
    "          axis = 1).sort_values(by='importance', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try several scaling and feature selections for random forest"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "param_grid = dict(scaling=[None, MinMaxScaler(), RobustScaler()],\n",
    "                  reduce_dim=[None, PCA(), PCA(5), PCA(10), PCA(15), PCA(20), PCA(25)],\n",
    "                  clf=[RandomForestClassifier(max_depth=7, \n",
    "                                            max_features=\"auto\",\n",
    "                                            min_samples_leaf=1, \n",
    "                                            min_samples_split=3, \n",
    "                                            n_estimators=100)]\n",
    "                 )\n",
    "pipe = Pipeline([('scaling', StandardScaler()), ('reduce_dim', PCA()), ('clf', RandomForestClassifier())]) \n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=3, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**try scaling for random forest**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# RobustScaler(), \n",
    "pipe = make_pipeline(RobustScaler(), RandomForestClassifier(max_depth=10, \n",
    "                                            max_features=1,\n",
    "                                            min_samples_leaf=1, \n",
    "                                            min_samples_split=13, \n",
    "                                            n_estimators=300))\n",
    "pipe.fit(X_train, y_train)\n",
    "print(\"test: \", pipe.score(X_test, y_test))\n",
    "\n",
    "scores = cross_val_score(pipe, X_train_df, y_train_df, n_jobs=3)\n",
    "print(\"mean of cross val score: \", scores.mean())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# MinMaxScaler(), \n",
    "pipe = make_pipeline(MinMaxScaler(), RandomForestClassifier(max_depth=10, \n",
    "                                            max_features=1,\n",
    "                                            min_samples_leaf=1, \n",
    "                                            min_samples_split=13, \n",
    "                                            n_estimators=300))\n",
    "pipe.fit(X_train, y_train)\n",
    "print(\"test: \", pipe.score(X_test, y_test))\n",
    "\n",
    "scores = cross_val_score(pipe, X_train_df, y_train_df, n_jobs=3)\n",
    "print(\"mean of cross val score: \", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**try feature selection**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#pca\n",
    "param_grid = {'pca__n_components':[5, 10, 15, 20, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 40]}\n",
    "\n",
    "pipe = make_pipeline(PCA(n_components=30), RandomForestClassifier(max_depth=10, \n",
    "                                            max_features=1,\n",
    "                                            min_samples_leaf=1, \n",
    "                                            min_samples_split=13, \n",
    "                                            n_estimators=300))\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=6)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pipe = make_pipeline(PCA(n_components=15), RandomForestClassifier(max_depth=10, \n",
    "                                            max_features=1,\n",
    "                                            min_samples_leaf=1, \n",
    "                                            min_samples_split=13, \n",
    "                                            n_estimators=300))\n",
    "pipe.fit(X_train, y_train)\n",
    "print(\"test: \", pipe.score(X_test, y_test))\n",
    "\n",
    "scores = cross_val_score(pipe, X_train_df, y_train_df, n_jobs=3)\n",
    "print(\"mean of cross val score: \", scores.mean())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test:  0.840677966102\n",
    "mean of cross val score:  0.82379349046"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "AdaBoostClassifier(base_estimator=None, n_estimators=50,\n",
    "                   learning_rate=1.0, algorithm='SAMME.R',\n",
    "                   random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12096 candidates, totalling 60480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=3)]: Done 1694 tasks      | elapsed:   16.0s\n",
      "[Parallel(n_jobs=3)]: Done 4194 tasks      | elapsed:   50.5s\n",
      "[Parallel(n_jobs=3)]: Done 6504 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 8754 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=3)]: Done 11504 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=3)]: Done 14754 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=3)]: Done 18504 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=3)]: Done 22754 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=3)]: Done 27504 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=3)]: Done 32754 tasks      | elapsed: 11.1min\n",
      "[Parallel(n_jobs=3)]: Done 38504 tasks      | elapsed: 13.1min\n",
      "[Parallel(n_jobs=3)]: Done 47079 tasks      | elapsed: 16.0min\n",
      "[Parallel(n_jobs=3)]: Done 55779 tasks      | elapsed: 18.9min\n",
      "[Parallel(n_jobs=3)]: Done 60475 out of 60480 | elapsed: 21.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=3)]: Done 60480 out of 60480 | elapsed: 21.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'learning_rate': 0.01, 'max_depth': 4, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Mean cross-validated score of the best_estimator:  0.845637583893\n",
      "test:  0.837288135593\n"
     ]
    }
   ],
   "source": [
    "#wide\n",
    "\"\"\"param_grid = {'learning_rate': [0.001, 0.005, 0.007, 0.01, 0.02, 0.05, 0.1],\n",
    "              'n_estimators': [3, 5, 7, 10, 50, 100, 200, 500],\n",
    "              'min_samples_split':[2, 3, 4, 5],\n",
    "              'min_samples_leaf': [1, 2, 3, 4, 5],\n",
    "              'max_depth':[1,2,3,4,5,6],\n",
    "              'max_features': ['auto', 'sqrt', 'log2'],}\n",
    "\"\"\"\n",
    "\n",
    "# min\n",
    "param_grid = {'learning_rate': [0.001, 0.005, 0.007, 0.01, 0.02, 0.05],\n",
    "              'n_estimators': [3, 5, 7, 10, 50, 100, 200],\n",
    "              'min_samples_split':[2, 3, 4, 5],\n",
    "              'min_samples_leaf': [1, 2, 3, 5],\n",
    "              'max_depth':[1,2,3,4,5,6],\n",
    "              'max_features': ['auto', 'sqrt', 'log2'],}\n",
    "\n",
    "grid_search = GridSearchCV(GradientBoostingClassifier(), param_grid, cv=5, n_jobs=3, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "\"\"\"\n",
    "plt.matshow(grid_search.cv_results_['mean_test_score'].reshape(6, -1),\n",
    "            vmin=0, cmap=\"viridis\")\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.ylabel(\"learning_rate\")\n",
    "plt.xticks(range(len(param_grid['n_estimators'])), param_grid['n_estimators'])\n",
    "plt.yticks(range(len(param_grid['learning_rate'])), param_grid['learning_rate'])\n",
    "plt.colorbar()\n",
    "\"\"\"\n",
    "\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# output of upper code\n",
    "\n",
    "Mean cross-validated score of the best_estimator:  0.843959731544\n",
    "best parameters: {'learning_rate': 0.01, 'max_depth': 6, 'max_features': 'sqrt', 'min_samples_leaf': 3, 'min_samples_split': 3, 'n_estimators': 200}\n",
    "test:  0.830508474576\n",
    "\n",
    "\n",
    "# 10 age band, parch, sibsp\n",
    "\n",
    "best parameters: {'learning_rate': 0.02, 'max_depth': 6, 'max_features': 'log2', 'min_samples_leaf': 3, 'min_samples_split': 3, 'n_estimators': 100}\n",
    "Mean cross-validated score of the best_estimator:  0.845637583893\n",
    "test:  0.820338983051\n",
    "\n",
    "\n",
    "\n",
    "# 10 age band, parch&sibsp, embarked num category\n",
    "\n",
    "best parameters: {'learning_rate': 0.02, 'max_depth': 4, 'max_features': 'log2', 'min_samples_leaf': 3, 'min_samples_split': 4, 'n_estimators': 200}\n",
    "Mean cross-validated score of the best_estimator:  0.843959731544\n",
    "test:  0.833898305085\n",
    "\n",
    "\n",
    "# 10 age band, parch&sibsp, embarked num category, rare title&map value\n",
    "\n",
    "best parameters: {'learning_rate': 0.05, 'max_depth': 4, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
    "Mean cross-validated score of the best_estimator:  0.842281879195\n",
    "test:  0.827118644068\n",
    "\n",
    "\n",
    "# 10 age band, familysize, embarked num category, rare title&map value\n",
    "\n",
    "best parameters: {'learning_rate': 0.05, 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 100}\n",
    "Mean cross-validated score of the best_estimator:  0.838926174497\n",
    "test:  0.84406779661\n",
    "\n",
    "\n",
    "\n",
    "# 10 age band, familysize, embarked num category, rare title&map value, no Name_Len\n",
    "\n",
    "best parameters: {'learning_rate': 0.007, 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
    "Mean cross-validated score of the best_estimator:  0.845637583893\n",
    "test:  0.833898305085\n",
    "\n",
    "\n",
    "# 10 age band, familysize, embarked num category, rare title&map value, no Name_Len, no Ticket_Len\n",
    "\n",
    "best parameters: {'learning_rate': 0.01, 'max_depth': 4, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}\n",
    "Mean cross-validated score of the best_estimator:  0.845637583893\n",
    "test:  0.837288135593\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test:  0.833898305085\n",
      "mean of cross val score for X_train_df:  0.832772166105\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(GradientBoostingClassifier(learning_rate=0.01,\n",
    "                                                max_depth=4,\n",
    "                                                max_features=\"sqrt\",\n",
    "                                                min_samples_leaf=2,\n",
    "                                                min_samples_split=5,\n",
    "                                                n_estimators=200))\n",
    "pipe.fit(X_train, y_train)\n",
    "print(\"test: \", pipe.score(X_test, y_test))\n",
    "\n",
    "scores = cross_val_score(pipe, X_train_df, y_train_df, n_jobs=3)\n",
    "print(\"mean of cross val score for X_train_df: \", scores.mean())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 5 age band\n",
    "test:  0.823728813559322\n",
    "mean of cross val score for X_train_df:  0.8237934904601572\n",
    "    \n",
    "# 10 age band\n",
    "test:  0.823728813559322\n",
    "mean of cross val score for X_train_df:  0.8282828282828283\n",
    "\n",
    "# 10 age band, keep all family features\n",
    "test:  0.8338983050847457\n",
    "mean of cross val score for X_train_df:  0.8260381593714926\n",
    "\n",
    "# 10 age band, parch, siblib, use embarked column\n",
    "test:  0.8338983050847457\n",
    "mean of cross val score for X_train_df:  0.8271604938271605\n",
    "\n",
    "# 10 age band, parch, sibsp\n",
    "test:  0.823728813559\n",
    "mean of cross val score for X_train_df:  0.822671156004\n",
    "\n",
    "# 10 age band, parch&sibsp, embarked num category\n",
    "test:  0.830508474576\n",
    "mean of cross val score for X_train_df:  0.827160493827\n",
    "\n",
    "\n",
    "# 10 age band, parch&sibsp, embarked num category, rare title&map value\n",
    "test:  0.833898305085\n",
    "mean of cross val score for X_train_df:  0.83164983165\n",
    "\n",
    "\n",
    "# 10 age band, familysize, embarked num category, rare title&map value\n",
    "\n",
    "test:  0.827118644068\n",
    "mean of cross val score for X_train_df:  0.828282828283\n",
    "\n",
    "\n",
    "# 10 age band, familysize, embarked num category, rare title&map value, no Name_Len\n",
    "\n",
    "test:  0.830508474576\n",
    "mean of cross val score for X_train_df:  0.822671156004\n",
    "\n",
    "\n",
    "# 10 age band, familysize, embarked num category, rare title&map value, no Name_Len, no Ticket_Len\n",
    "\n",
    "test:  0.833898305085\n",
    "mean of cross val score for X_train_df:  0.832772166105\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Title</td>\n",
       "      <td>0.265103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sex</td>\n",
       "      <td>0.233681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Pclass</td>\n",
       "      <td>0.115127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>FamilySize</td>\n",
       "      <td>0.084211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.060461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Fare</td>\n",
       "      <td>0.043397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Cabin_num_nan_category</td>\n",
       "      <td>0.043286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Embarked</td>\n",
       "      <td>0.039469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cabin_Letter_E</td>\n",
       "      <td>0.027275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cabin_num_(1.999, 28.667]</td>\n",
       "      <td>0.016824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cabin_Letter_B</td>\n",
       "      <td>0.015858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Cabin_num_(28.667, 65.667]</td>\n",
       "      <td>0.014687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cabin_Letter_D</td>\n",
       "      <td>0.012196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Cabin_num_(65.667, 148.0]</td>\n",
       "      <td>0.007358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Age_Null_Flag</td>\n",
       "      <td>0.005600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cabin_Letter_F</td>\n",
       "      <td>0.004696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cabin_Letter_C</td>\n",
       "      <td>0.004110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cabin_Letter_G</td>\n",
       "      <td>0.003737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cabin_Letter_A</td>\n",
       "      <td>0.002924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cabin_Letter_T</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      variable  importance\n",
       "18                       Title    0.265103\n",
       "17                         Sex    0.233681\n",
       "16                      Pclass    0.115127\n",
       "19                  FamilySize    0.084211\n",
       "0                          Age    0.060461\n",
       "15                        Fare    0.043397\n",
       "13      Cabin_num_nan_category    0.043286\n",
       "14                    Embarked    0.039469\n",
       "6               Cabin_Letter_E    0.027275\n",
       "10   Cabin_num_(1.999, 28.667]    0.016824\n",
       "3               Cabin_Letter_B    0.015858\n",
       "11  Cabin_num_(28.667, 65.667]    0.014687\n",
       "5               Cabin_Letter_D    0.012196\n",
       "12   Cabin_num_(65.667, 148.0]    0.007358\n",
       "1                Age_Null_Flag    0.005600\n",
       "7               Cabin_Letter_F    0.004696\n",
       "4               Cabin_Letter_C    0.004110\n",
       "8               Cabin_Letter_G    0.003737\n",
       "2               Cabin_Letter_A    0.002924\n",
       "9               Cabin_Letter_T    0.000000"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat((pd.DataFrame(X_train.columns, columns = ['variable']), \n",
    "           pd.DataFrame(pipe.named_steps[\"gradientboostingclassifier\"].feature_importances_, columns = ['importance'])), \n",
    "          axis = 1).sort_values(by='importance', ascending = False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X_train_df, y_train_df)\n",
    "\n",
    "test_df_noid = test_df.drop(\"PassengerId\", axis=1).copy()\n",
    "y_pred = pipe.predict(test_df_noid).astype(int)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": test_df[\"PassengerId\"].astype(int),\n",
    "        \"Survived\": y_pred\n",
    "    })\n",
    "submission.to_csv('../output/submission_gradientboosting.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Title</td>\n",
       "      <td>0.278140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sex</td>\n",
       "      <td>0.226206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Pclass</td>\n",
       "      <td>0.112216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>FamilySize</td>\n",
       "      <td>0.103962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.077115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Cabin_num_nan_category</td>\n",
       "      <td>0.057174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Fare</td>\n",
       "      <td>0.044871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Embarked</td>\n",
       "      <td>0.029050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cabin_num_(1.999, 28.667]</td>\n",
       "      <td>0.016268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cabin_Letter_E</td>\n",
       "      <td>0.012870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cabin_Letter_D</td>\n",
       "      <td>0.007998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Cabin_num_(28.667, 65.667]</td>\n",
       "      <td>0.007786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cabin_Letter_B</td>\n",
       "      <td>0.006281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Age_Null_Flag</td>\n",
       "      <td>0.004827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Cabin_num_(65.667, 148.0]</td>\n",
       "      <td>0.003983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cabin_Letter_C</td>\n",
       "      <td>0.003842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cabin_Letter_G</td>\n",
       "      <td>0.002954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cabin_Letter_A</td>\n",
       "      <td>0.002765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cabin_Letter_F</td>\n",
       "      <td>0.001694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cabin_Letter_T</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      variable  importance\n",
       "18                       Title    0.278140\n",
       "17                         Sex    0.226206\n",
       "16                      Pclass    0.112216\n",
       "19                  FamilySize    0.103962\n",
       "0                          Age    0.077115\n",
       "13      Cabin_num_nan_category    0.057174\n",
       "15                        Fare    0.044871\n",
       "14                    Embarked    0.029050\n",
       "10   Cabin_num_(1.999, 28.667]    0.016268\n",
       "6               Cabin_Letter_E    0.012870\n",
       "5               Cabin_Letter_D    0.007998\n",
       "11  Cabin_num_(28.667, 65.667]    0.007786\n",
       "3               Cabin_Letter_B    0.006281\n",
       "1                Age_Null_Flag    0.004827\n",
       "12   Cabin_num_(65.667, 148.0]    0.003983\n",
       "4               Cabin_Letter_C    0.003842\n",
       "8               Cabin_Letter_G    0.002954\n",
       "2               Cabin_Letter_A    0.002765\n",
       "7               Cabin_Letter_F    0.001694\n",
       "9               Cabin_Letter_T    0.000000"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat((pd.DataFrame(X_train.columns, columns = ['variable']), \n",
    "           pd.DataFrame(pipe.named_steps[\"gradientboostingclassifier\"].feature_importances_, columns = ['importance'])), \n",
    "          axis = 1).sort_values(by='importance', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try scaling and feature selection"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "param_grid = dict(scaling=[None, MinMaxScaler(), RobustScaler()],\n",
    "                  reduce_dim=[None, PCA(), PCA(5), PCA(10), PCA(15), PCA(20), PCA(25), PCA(30)],\n",
    "                  clf=[GradientBoostingClassifier(learning_rate=0.01,\n",
    "                                                max_depth=6,\n",
    "                                                max_features=\"sqrt\",\n",
    "                                                min_samples_leaf=3,\n",
    "                                                min_samples_split=3,\n",
    "                                                n_estimators=200)]\n",
    "                 )\n",
    "pipe = Pipeline([('scaling', StandardScaler()), ('reduce_dim', PCA()), ('clf', RandomForestClassifier())]) \n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=3, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**try scaling for Gradient boosting**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# RobustScaler\n",
    "pipe = make_pipeline(RobustScaler(), GradientBoostingClassifier(learning_rate=0.01,\n",
    "                                                max_depth=6,\n",
    "                                                max_features=\"sqrt\",\n",
    "                                                min_samples_leaf=3,\n",
    "                                                min_samples_split=3,\n",
    "                                                n_estimators=200))\n",
    "pipe.fit(X_train, y_train)\n",
    "print(\"test: \", pipe.score(X_test, y_test))\n",
    "\n",
    "scores = cross_val_score(pipe, X_train_df, y_train_df, n_jobs=3)\n",
    "print(\"mean of cross val score for X_train_df: \", scores.mean())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pd.concat((pd.DataFrame(X_train.columns, columns = ['variable']), \n",
    "           pd.DataFrame(pipe.named_steps[\"gradientboostingclassifier\"].feature_importances_, columns = ['importance'])), \n",
    "          axis = 1).sort_values(by='importance', ascending = False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# MinMaxScaler\n",
    "pipe = make_pipeline(MinMaxScaler(), GradientBoostingClassifier(learning_rate=0.01,\n",
    "                                                max_depth=6,\n",
    "                                                max_features=\"sqrt\",\n",
    "                                                min_samples_leaf=3,\n",
    "                                                min_samples_split=3,\n",
    "                                                n_estimators=200))\n",
    "pipe.fit(X_train, y_train)\n",
    "print(\"test: \", pipe.score(X_test, y_test))\n",
    "\n",
    "scores = cross_val_score(pipe, X_train_df, y_train_df, n_jobs=3)\n",
    "print(\"mean of cross val score for X_train_df: \", scores.mean())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pd.concat((pd.DataFrame(X_train.columns, columns = ['variable']), \n",
    "           pd.DataFrame(pipe.named_steps[\"gradientboostingclassifier\"].feature_importances_, columns = ['importance'])), \n",
    "          axis = 1).sort_values(by='importance', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**try feature selection**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#PCA\n",
    "param_grid = {'pca__n_components':[5, 10, 15, 20, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 40]}\n",
    "\n",
    "pipe = make_pipeline(PCA(n_components=30), GradientBoostingClassifier(learning_rate=0.01,\n",
    "                                                max_depth=6,\n",
    "                                                max_features=\"sqrt\",\n",
    "                                                min_samples_leaf=3,\n",
    "                                                min_samples_split=3,\n",
    "                                                n_estimators=200))\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv=5, n_jobs=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pipe = make_pipeline(PCA(n_components=20), GradientBoostingClassifier(learning_rate=0.01,\n",
    "                                                max_depth=6,\n",
    "                                                max_features=\"sqrt\",\n",
    "                                                min_samples_leaf=3,\n",
    "                                                min_samples_split=3,\n",
    "                                                n_estimators=200))\n",
    "pipe.fit(X_train, y_train)\n",
    "print(\"test: \", pipe.score(X_test, y_test))\n",
    "\n",
    "scores = cross_val_score(pipe, X_train_df, y_train_df, n_jobs=3)\n",
    "print(\"mean of cross val score for X_train_df: \", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "param_grid = [\n",
    "{'classifier': [SVC()], \n",
    " 'preprocessing': [StandardScaler(), None], \n",
    " 'classifier__gamma': [0.001, 0.01, 0.1, 1, 10, 100], \n",
    " 'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100]},\n",
    "{'classifier': [RandomForestClassifier(n_estimators=100)], \n",
    " 'preprocessing': [None], \n",
    " 'classifier__max_features': [1, 2, 3]}]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Individual steps may also be replaced as parameters, and non-final steps may be ignored by setting them to None:\n",
    "# http://scikit-learn.org/stable/modules/pipeline.html\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "param_grid = dict(reduce_dim=[None, PCA(5), PCA(10)],\n",
    "                   clf=[SVC(), LogisticRegression()],\n",
    "                   clf__C=[0.1, 10, 100])\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
