{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to <a href=#bookmark>my bookmark</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# data analysis and wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# train, test, validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "# decomposition\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "# feature engineering\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# feature selection\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../input/train.csv')\n",
    "test_df = pd.read_csv('../input/test.csv')\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del Ticket, Cabin columns\n",
    "train_df = train_df.drop(['Ticket', 'Cabin'], axis=1)\n",
    "test_df = test_df.drop(['Ticket', 'Cabin'], axis=1)\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr          517\n",
       "Miss        182\n",
       "Mrs         125\n",
       "Master       40\n",
       "Dr            7\n",
       "Rev           6\n",
       "Major         2\n",
       "Mlle          2\n",
       "Col           2\n",
       "Ms            1\n",
       "Don           1\n",
       "Countess      1\n",
       "Mme           1\n",
       "Jonkheer      1\n",
       "Capt          1\n",
       "Sir           1\n",
       "Lady          1\n",
       "Name: Title, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add title\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "train_df.Title.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## try one hote encoding without delete rare title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 11) (418, 10)\n",
      "(1309, 11)\n",
      "(891, 28) (418, 27)\n"
     ]
    }
   ],
   "source": [
    "# try one hote encoding without delete rare title\n",
    "#\n",
    "# concat train and test data. and apply get_dummies for Title. \n",
    "# then split to original size. also drop Survived column from test_df\n",
    "print(train_df.shape, test_df.shape)\n",
    "\n",
    "# concat train and test data\n",
    "#   test_df's Survived column is filled with NaN\n",
    "train_test_df = pd.concat((train_df, test_df))\n",
    "\n",
    "print(train_test_df.shape)\n",
    "\n",
    "# apply get_dummies for Title\n",
    "train_test_df = pd.get_dummies(train_test_df, columns=[\"Title\"])\n",
    "\n",
    "#train_test_df.head()\n",
    "train_df = train_test_df.iloc[:train_df.shape[0]]\n",
    "test_df = train_test_df.iloc[train_df.shape[0]:]\n",
    "\n",
    "# drop added Survived column from test_df\n",
    "test_df = test_df.drop(\"Survived\", axis=1)\n",
    "print(train_df.shape, test_df.shape)\n",
    "\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Title_Capt</th>\n",
       "      <th>...</th>\n",
       "      <th>Title_Major</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mlle</th>\n",
       "      <th>Title_Mme</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Ms</th>\n",
       "      <th>Title_Rev</th>\n",
       "      <th>Title_Sir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.5</td>\n",
       "      <td>Q</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>0</td>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47.0</td>\n",
       "      <td>S</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>0</td>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62.0</td>\n",
       "      <td>Q</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>0</td>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.0</td>\n",
       "      <td>S</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>0</td>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.0</td>\n",
       "      <td>S</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>1</td>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age Embarked     Fare                                          Name  \\\n",
       "0  34.5        Q   7.8292                              Kelly, Mr. James   \n",
       "1  47.0        S   7.0000              Wilkes, Mrs. James (Ellen Needs)   \n",
       "2  62.0        Q   9.6875                     Myles, Mr. Thomas Francis   \n",
       "3  27.0        S   8.6625                              Wirz, Mr. Albert   \n",
       "4  22.0        S  12.2875  Hirvonen, Mrs. Alexander (Helga E Lindqvist)   \n",
       "\n",
       "   Parch  PassengerId  Pclass     Sex  SibSp  Title_Capt    ...      \\\n",
       "0      0          892       3    male      0           0    ...       \n",
       "1      0          893       3  female      1           0    ...       \n",
       "2      0          894       2    male      0           0    ...       \n",
       "3      0          895       3    male      0           0    ...       \n",
       "4      1          896       3  female      1           0    ...       \n",
       "\n",
       "   Title_Major  Title_Master  Title_Miss  Title_Mlle  Title_Mme  Title_Mr  \\\n",
       "0            0             0           0           0          0         1   \n",
       "1            0             0           0           0          0         0   \n",
       "2            0             0           0           0          0         1   \n",
       "3            0             0           0           0          0         1   \n",
       "4            0             0           0           0          0         0   \n",
       "\n",
       "   Title_Mrs  Title_Ms  Title_Rev  Title_Sir  \n",
       "0          0         0          0          0  \n",
       "1          1         0          0          0  \n",
       "2          0         0          0          0  \n",
       "3          0         0          0          0  \n",
       "4          1         0          0          0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## del rare title and map value"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# del rare title and map value\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\n",
    "                                                 'Don', 'Dr', 'Major', 'Rev', 'Sir',\n",
    "                                                 'Jonkheer', 'Dona'], 'Rare')\n",
    "\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "    \n",
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset['Title'].map(title_mapping)\n",
    "    dataset['Title'] = dataset['Title'].fillna(0)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# drop Name, PassengerId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Title_Capt</th>\n",
       "      <th>Title_Col</th>\n",
       "      <th>...</th>\n",
       "      <th>Title_Major</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mlle</th>\n",
       "      <th>Title_Mme</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Ms</th>\n",
       "      <th>Title_Rev</th>\n",
       "      <th>Title_Sir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>S</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>C</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>S</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>S</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>S</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age Embarked     Fare  Parch  Pclass     Sex  SibSp  Survived  Title_Capt  \\\n",
       "0  22.0        S   7.2500      0       3    male      1       0.0           0   \n",
       "1  38.0        C  71.2833      0       1  female      1       1.0           0   \n",
       "2  26.0        S   7.9250      0       3  female      0       1.0           0   \n",
       "3  35.0        S  53.1000      0       1  female      1       1.0           0   \n",
       "4  35.0        S   8.0500      0       3    male      0       0.0           0   \n",
       "\n",
       "   Title_Col    ...      Title_Major  Title_Master  Title_Miss  Title_Mlle  \\\n",
       "0          0    ...                0             0           0           0   \n",
       "1          0    ...                0             0           0           0   \n",
       "2          0    ...                0             0           1           0   \n",
       "3          0    ...                0             0           0           0   \n",
       "4          0    ...                0             0           0           0   \n",
       "\n",
       "   Title_Mme  Title_Mr  Title_Mrs  Title_Ms  Title_Rev  Title_Sir  \n",
       "0          0         1          0         0          0          0  \n",
       "1          0         0          1         0          0          0  \n",
       "2          0         0          0         0          0          0  \n",
       "3          0         0          1         0          0          0  \n",
       "4          0         1          0         0          0          0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df.drop(['Name', 'PassengerId'], axis=1)\n",
    "test_df = test_df.drop(['Name'], axis=1)\n",
    "combine = [train_df, test_df]\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# map value to Sex "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Title_Capt</th>\n",
       "      <th>Title_Col</th>\n",
       "      <th>...</th>\n",
       "      <th>Title_Major</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mlle</th>\n",
       "      <th>Title_Mme</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Ms</th>\n",
       "      <th>Title_Rev</th>\n",
       "      <th>Title_Sir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>S</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>C</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>S</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>S</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>S</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age Embarked     Fare  Parch  Pclass  Sex  SibSp  Survived  Title_Capt  \\\n",
       "0  22.0        S   7.2500      0       3    0      1       0.0           0   \n",
       "1  38.0        C  71.2833      0       1    1      1       1.0           0   \n",
       "2  26.0        S   7.9250      0       3    1      0       1.0           0   \n",
       "3  35.0        S  53.1000      0       1    1      1       1.0           0   \n",
       "4  35.0        S   8.0500      0       3    0      0       0.0           0   \n",
       "\n",
       "   Title_Col    ...      Title_Major  Title_Master  Title_Miss  Title_Mlle  \\\n",
       "0          0    ...                0             0           0           0   \n",
       "1          0    ...                0             0           0           0   \n",
       "2          0    ...                0             0           1           0   \n",
       "3          0    ...                0             0           0           0   \n",
       "4          0    ...                0             0           0           0   \n",
       "\n",
       "   Title_Mme  Title_Mr  Title_Mrs  Title_Ms  Title_Rev  Title_Sir  \n",
       "0          0         1          0         0          0          0  \n",
       "1          0         0          1         0          0          0  \n",
       "2          0         0          0         0          0          0  \n",
       "3          0         0          1         0          0          0  \n",
       "4          0         1          0         0          0          0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for dataset in combine:\n",
    "    dataset[\"Sex\"] = dataset[\"Sex\"].map({'female':1, 'male':0}).astype(int)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fill na value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                True\n",
       "Embarked           True\n",
       "Fare              False\n",
       "Parch             False\n",
       "Pclass            False\n",
       "Sex               False\n",
       "SibSp             False\n",
       "Survived          False\n",
       "Title_Capt        False\n",
       "Title_Col         False\n",
       "Title_Countess    False\n",
       "Title_Don         False\n",
       "Title_Dona        False\n",
       "Title_Dr          False\n",
       "Title_Jonkheer    False\n",
       "Title_Lady        False\n",
       "Title_Major       False\n",
       "Title_Master      False\n",
       "Title_Miss        False\n",
       "Title_Mlle        False\n",
       "Title_Mme         False\n",
       "Title_Mr          False\n",
       "Title_Mrs         False\n",
       "Title_Ms          False\n",
       "Title_Rev         False\n",
       "Title_Sir         False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                True\n",
       "Embarked          False\n",
       "Fare               True\n",
       "Parch             False\n",
       "PassengerId       False\n",
       "Pclass            False\n",
       "Sex               False\n",
       "SibSp             False\n",
       "Title_Capt        False\n",
       "Title_Col         False\n",
       "Title_Countess    False\n",
       "Title_Don         False\n",
       "Title_Dona        False\n",
       "Title_Dr          False\n",
       "Title_Jonkheer    False\n",
       "Title_Lady        False\n",
       "Title_Major       False\n",
       "Title_Master      False\n",
       "Title_Miss        False\n",
       "Title_Mlle        False\n",
       "Title_Mme         False\n",
       "Title_Mr          False\n",
       "Title_Mrs         False\n",
       "Title_Ms          False\n",
       "Title_Rev         False\n",
       "Title_Sir         False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fill na of Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Title_Capt</th>\n",
       "      <th>Title_Col</th>\n",
       "      <th>...</th>\n",
       "      <th>Title_Major</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mlle</th>\n",
       "      <th>Title_Mme</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Ms</th>\n",
       "      <th>Title_Rev</th>\n",
       "      <th>Title_Sir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>S</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>C</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>S</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>S</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>S</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Embarked     Fare  Parch  Pclass  Sex  SibSp  Survived  Title_Capt  \\\n",
       "0   22        S   7.2500      0       3    0      1       0.0           0   \n",
       "1   38        C  71.2833      0       1    1      1       1.0           0   \n",
       "2   26        S   7.9250      0       3    1      0       1.0           0   \n",
       "3   35        S  53.1000      0       1    1      1       1.0           0   \n",
       "4   35        S   8.0500      0       3    0      0       0.0           0   \n",
       "\n",
       "   Title_Col    ...      Title_Major  Title_Master  Title_Miss  Title_Mlle  \\\n",
       "0          0    ...                0             0           0           0   \n",
       "1          0    ...                0             0           0           0   \n",
       "2          0    ...                0             0           1           0   \n",
       "3          0    ...                0             0           0           0   \n",
       "4          0    ...                0             0           0           0   \n",
       "\n",
       "   Title_Mme  Title_Mr  Title_Mrs  Title_Ms  Title_Rev  Title_Sir  \n",
       "0          0         1          0         0          0          0  \n",
       "1          0         0          1         0          0          0  \n",
       "2          0         0          0         0          0          0  \n",
       "3          0         0          1         0          0          0  \n",
       "4          0         1          0         0          0          0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guess_ages = np.zeros((2,3))\n",
    "\n",
    "for dataset in combine:\n",
    "    for i in range(0, 2):\n",
    "        for j in range(0, 3):\n",
    "            guess_df = dataset[(dataset['Sex'] == i) & \\\n",
    "                                  (dataset['Pclass'] == j+1)]['Age'].dropna()\n",
    "\n",
    "            # age_mean = guess_df.mean()\n",
    "            # age_std = guess_df.std()\n",
    "            # age_guess = rnd.uniform(age_mean - age_std, age_mean + age_std)\n",
    "\n",
    "            age_guess = guess_df.median()\n",
    "\n",
    "            # Convert random age float to nearest .5 age\n",
    "            guess_ages[i,j] = int( age_guess/0.5 + 0.5 ) * 0.5\n",
    "            \n",
    "    for i in range(0, 2):\n",
    "        for j in range(0, 3):\n",
    "            dataset.loc[ (dataset.Age.isnull()) & (dataset.Sex == i) & (dataset.Pclass == j+1),\\\n",
    "                    'Age'] = guess_ages[i,j]\n",
    "\n",
    "    dataset['Age'] = dataset['Age'].astype(int)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age               False\n",
       "Embarked           True\n",
       "Fare              False\n",
       "Parch             False\n",
       "Pclass            False\n",
       "Sex               False\n",
       "SibSp             False\n",
       "Survived          False\n",
       "Title_Capt        False\n",
       "Title_Col         False\n",
       "Title_Countess    False\n",
       "Title_Don         False\n",
       "Title_Dona        False\n",
       "Title_Dr          False\n",
       "Title_Jonkheer    False\n",
       "Title_Lady        False\n",
       "Title_Major       False\n",
       "Title_Master      False\n",
       "Title_Miss        False\n",
       "Title_Mlle        False\n",
       "Title_Mme         False\n",
       "Title_Mr          False\n",
       "Title_Mrs         False\n",
       "Title_Ms          False\n",
       "Title_Rev         False\n",
       "Title_Sir         False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tried keep Age feature and don't add AgeBand numerical feature\n",
    "if both are there, it is duplicate information\n",
    "\n",
    "### 2018/03/17 tried Age instead of Age band. But AgeBand is better score for almost all models.\n",
    "svc score was same of little bit better.\n",
    "random forest score became worse.\n",
    "so AgeBand is better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add age band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Title_Capt</th>\n",
       "      <th>Title_Col</th>\n",
       "      <th>...</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mlle</th>\n",
       "      <th>Title_Mme</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Ms</th>\n",
       "      <th>Title_Rev</th>\n",
       "      <th>Title_Sir</th>\n",
       "      <th>AgeBand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>S</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>C</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>S</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>S</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>S</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Embarked     Fare  Parch  Pclass  Sex  SibSp  Survived  Title_Capt  \\\n",
       "0   22        S   7.2500      0       3    0      1       0.0           0   \n",
       "1   38        C  71.2833      0       1    1      1       1.0           0   \n",
       "2   26        S   7.9250      0       3    1      0       1.0           0   \n",
       "3   35        S  53.1000      0       1    1      1       1.0           0   \n",
       "4   35        S   8.0500      0       3    0      0       0.0           0   \n",
       "\n",
       "   Title_Col      ...       Title_Master  Title_Miss  Title_Mlle  Title_Mme  \\\n",
       "0          0      ...                  0           0           0          0   \n",
       "1          0      ...                  0           0           0          0   \n",
       "2          0      ...                  0           1           0          0   \n",
       "3          0      ...                  0           0           0          0   \n",
       "4          0      ...                  0           0           0          0   \n",
       "\n",
       "   Title_Mr  Title_Mrs  Title_Ms  Title_Rev  Title_Sir       AgeBand  \n",
       "0         1          0         0          0          0  (16.0, 32.0]  \n",
       "1         0          1         0          0          0  (32.0, 48.0]  \n",
       "2         0          0         0          0          0  (16.0, 32.0]  \n",
       "3         0          1         0          0          0  (32.0, 48.0]  \n",
       "4         1          0         0          0          0  (32.0, 48.0]  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['AgeBand'] = pd.cut(train_df['Age'], 5)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overwrite AgeBand number on Age. means, drop Age and AgeBand text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Title_Capt</th>\n",
       "      <th>Title_Col</th>\n",
       "      <th>...</th>\n",
       "      <th>Title_Major</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mlle</th>\n",
       "      <th>Title_Mme</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Ms</th>\n",
       "      <th>Title_Rev</th>\n",
       "      <th>Title_Sir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>C</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>S</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>S</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Embarked     Fare  Parch  Pclass  Sex  SibSp  Survived  Title_Capt  \\\n",
       "0    1        S   7.2500      0       3    0      1       0.0           0   \n",
       "1    2        C  71.2833      0       1    1      1       1.0           0   \n",
       "2    1        S   7.9250      0       3    1      0       1.0           0   \n",
       "3    2        S  53.1000      0       1    1      1       1.0           0   \n",
       "4    2        S   8.0500      0       3    0      0       0.0           0   \n",
       "\n",
       "   Title_Col    ...      Title_Major  Title_Master  Title_Miss  Title_Mlle  \\\n",
       "0          0    ...                0             0           0           0   \n",
       "1          0    ...                0             0           0           0   \n",
       "2          0    ...                0             0           1           0   \n",
       "3          0    ...                0             0           0           0   \n",
       "4          0    ...                0             0           0           0   \n",
       "\n",
       "   Title_Mme  Title_Mr  Title_Mrs  Title_Ms  Title_Rev  Title_Sir  \n",
       "0          0         1          0         0          0          0  \n",
       "1          0         0          1         0          0          0  \n",
       "2          0         0          0         0          0          0  \n",
       "3          0         0          1         0          0          0  \n",
       "4          0         1          0         0          0          0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for dataset in combine:\n",
    "    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n",
    "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
    "    dataset.loc[ dataset['Age'] > 64, 'Age'] = 4\n",
    "train_df = train_df.drop(['AgeBand'], axis=1)\n",
    "combine = [train_df, test_df]\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Title_Capt</th>\n",
       "      <th>Title_Col</th>\n",
       "      <th>...</th>\n",
       "      <th>Title_Mlle</th>\n",
       "      <th>Title_Mme</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Ms</th>\n",
       "      <th>Title_Rev</th>\n",
       "      <th>Title_Sir</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>Age*Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>C</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>S</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>S</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Embarked     Fare  Parch  Pclass  Sex  SibSp  Survived  Title_Capt  \\\n",
       "0    1        S   7.2500      0       3    0      1       0.0           0   \n",
       "1    2        C  71.2833      0       1    1      1       1.0           0   \n",
       "2    1        S   7.9250      0       3    1      0       1.0           0   \n",
       "3    2        S  53.1000      0       1    1      1       1.0           0   \n",
       "4    2        S   8.0500      0       3    0      0       0.0           0   \n",
       "\n",
       "   Title_Col    ...      Title_Mlle  Title_Mme  Title_Mr  Title_Mrs  Title_Ms  \\\n",
       "0          0    ...               0          0         1          0         0   \n",
       "1          0    ...               0          0         0          1         0   \n",
       "2          0    ...               0          0         0          0         0   \n",
       "3          0    ...               0          0         0          1         0   \n",
       "4          0    ...               0          0         1          0         0   \n",
       "\n",
       "   Title_Rev  Title_Sir  FamilySize  IsAlone  Age*Class  \n",
       "0          0          0           2        0          3  \n",
       "1          0          0           2        0          2  \n",
       "2          0          0           1        1          3  \n",
       "3          0          0           2        0          2  \n",
       "4          0          0           1        1          6  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for dataset in combine:\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset['IsAlone'] = 0\n",
    "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset['Age*Class'] = dataset.Age * dataset.Pclass\n",
    "    \n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# select family related feature\n",
    "Parch, SibSp, FaimilySize, IsAlone\n",
    "\n",
    "2018/03/18 Parch and SibSp only was best for almost all models"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# drop Parch, SibSp, FaimilySize\n",
    "\n",
    "train_df = train_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\n",
    "test_df = test_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\n",
    "combine = [train_df, test_df]\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Title_Capt</th>\n",
       "      <th>Title_Col</th>\n",
       "      <th>...</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mlle</th>\n",
       "      <th>Title_Mme</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Ms</th>\n",
       "      <th>Title_Rev</th>\n",
       "      <th>Title_Sir</th>\n",
       "      <th>Age*Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>C</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>S</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>S</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Embarked     Fare  Parch  Pclass  Sex  SibSp  Survived  Title_Capt  \\\n",
       "0    1        S   7.2500      0       3    0      1       0.0           0   \n",
       "1    2        C  71.2833      0       1    1      1       1.0           0   \n",
       "2    1        S   7.9250      0       3    1      0       1.0           0   \n",
       "3    2        S  53.1000      0       1    1      1       1.0           0   \n",
       "4    2        S   8.0500      0       3    0      0       0.0           0   \n",
       "\n",
       "   Title_Col    ...      Title_Master  Title_Miss  Title_Mlle  Title_Mme  \\\n",
       "0          0    ...                 0           0           0          0   \n",
       "1          0    ...                 0           0           0          0   \n",
       "2          0    ...                 0           1           0          0   \n",
       "3          0    ...                 0           0           0          0   \n",
       "4          0    ...                 0           0           0          0   \n",
       "\n",
       "   Title_Mr  Title_Mrs  Title_Ms  Title_Rev  Title_Sir  Age*Class  \n",
       "0         1          0         0          0          0          3  \n",
       "1         0          1         0          0          0          2  \n",
       "2         0          0         0          0          0          3  \n",
       "3         0          1         0          0          0          2  \n",
       "4         1          0         0          0          0          6  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep Parch, SibSp only. this was best amoung familly related features\n",
    "\n",
    "train_df = train_df.drop(['FamilySize', 'IsAlone'], axis=1)\n",
    "test_df = test_df.drop(['FamilySize', 'IsAlone'], axis=1)\n",
    "combine = [train_df, test_df]\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# keep FamilySize only\n",
    "\n",
    "train_df = train_df.drop(['Parch', 'SibSp', 'IsAlone'], axis=1)\n",
    "test_df = test_df.drop(['Parch', 'SibSp', 'IsAlone'], axis=1)\n",
    "combine = [train_df, test_df]\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fill missing Embarked "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_port = train_df.Embarked.dropna().mode()[0]\n",
    "for dataset in combine:\n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna(freq_port)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Embarked categorical feature to numeric"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for dataset in combine:\n",
    "    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try one hot encoding for Embarked categorical feature\n",
    "2018/03/18 this is better than using converting categorical to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 27) (418, 27)\n",
      "(1309, 28)\n",
      "(891, 30) (418, 29)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Age*Class</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Title_Capt</th>\n",
       "      <th>...</th>\n",
       "      <th>Title_Mlle</th>\n",
       "      <th>Title_Mme</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Ms</th>\n",
       "      <th>Title_Rev</th>\n",
       "      <th>Title_Sir</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Age*Class     Fare  Parch  PassengerId  Pclass  Sex  SibSp  Survived  \\\n",
       "0    1          3   7.2500      0          NaN       3    0      1       0.0   \n",
       "1    2          2  71.2833      0          NaN       1    1      1       1.0   \n",
       "2    1          3   7.9250      0          NaN       3    1      0       1.0   \n",
       "3    2          2  53.1000      0          NaN       1    1      1       1.0   \n",
       "4    2          6   8.0500      0          NaN       3    0      0       0.0   \n",
       "\n",
       "   Title_Capt     ...      Title_Mlle  Title_Mme  Title_Mr  Title_Mrs  \\\n",
       "0           0     ...               0          0         1          0   \n",
       "1           0     ...               0          0         0          1   \n",
       "2           0     ...               0          0         0          0   \n",
       "3           0     ...               0          0         0          1   \n",
       "4           0     ...               0          0         1          0   \n",
       "\n",
       "   Title_Ms  Title_Rev  Title_Sir  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0         0          0          0           0           0           1  \n",
       "1         0          0          0           1           0           0  \n",
       "2         0          0          0           0           0           1  \n",
       "3         0          0          0           0           0           1  \n",
       "4         0          0          0           0           0           1  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try one hote encoding for Embarked\n",
    "#\n",
    "# concat train and test data. and apply get_dummies for Title. \n",
    "# then split to original size. also drop Survived column from test_df\n",
    "print(train_df.shape, test_df.shape)\n",
    "\n",
    "# concat train and test data\n",
    "#   test_df's Survived column is filled with NaN\n",
    "train_test_df = pd.concat((train_df, test_df))\n",
    "\n",
    "print(train_test_df.shape)\n",
    "\n",
    "# apply get_dummies for Title\n",
    "train_test_df = pd.get_dummies(train_test_df, columns=[\"Embarked\"])\n",
    "\n",
    "#train_test_df.head()\n",
    "train_df = train_test_df.iloc[:train_df.shape[0]]\n",
    "test_df = train_test_df.iloc[train_df.shape[0]:]\n",
    "\n",
    "# drop added Survived column from test_df\n",
    "test_df = test_df.drop(\"Survived\", axis=1)\n",
    "print(train_df.shape, test_df.shape)\n",
    "\n",
    "combine = [train_df, test_df]\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fill na of test data Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Age*Class</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Title_Capt</th>\n",
       "      <th>Title_Col</th>\n",
       "      <th>...</th>\n",
       "      <th>Title_Mlle</th>\n",
       "      <th>Title_Mme</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Ms</th>\n",
       "      <th>Title_Rev</th>\n",
       "      <th>Title_Sir</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>0</td>\n",
       "      <td>892.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>893.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>894.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0</td>\n",
       "      <td>895.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>896.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Age*Class     Fare  Parch  PassengerId  Pclass  Sex  SibSp  \\\n",
       "0    2          6   7.8292      0        892.0       3    0      0   \n",
       "1    2          6   7.0000      0        893.0       3    1      1   \n",
       "2    3          6   9.6875      0        894.0       2    0      0   \n",
       "3    1          3   8.6625      0        895.0       3    0      0   \n",
       "4    1          3  12.2875      1        896.0       3    1      1   \n",
       "\n",
       "   Title_Capt  Title_Col     ...      Title_Mlle  Title_Mme  Title_Mr  \\\n",
       "0           0          0     ...               0          0         1   \n",
       "1           0          0     ...               0          0         0   \n",
       "2           0          0     ...               0          0         1   \n",
       "3           0          0     ...               0          0         1   \n",
       "4           0          0     ...               0          0         0   \n",
       "\n",
       "   Title_Mrs  Title_Ms  Title_Rev  Title_Sir  Embarked_C  Embarked_Q  \\\n",
       "0          0         0          0          0           0           1   \n",
       "1          1         0          0          0           0           0   \n",
       "2          0         0          0          0           0           1   \n",
       "3          0         0          0          0           0           0   \n",
       "4          1         0          0          0           0           0   \n",
       "\n",
       "   Embarked_S  \n",
       "0           0  \n",
       "1           1  \n",
       "2           0  \n",
       "3           1  \n",
       "4           1  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['Fare'].fillna(test_df['Fare'].dropna().median(), inplace=True)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make Fareband feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/yuki/.local/lib/python3.6/site-packages/pandas/core/indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Age*Class</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Title_Capt</th>\n",
       "      <th>...</th>\n",
       "      <th>Title_Mlle</th>\n",
       "      <th>Title_Mme</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Ms</th>\n",
       "      <th>Title_Rev</th>\n",
       "      <th>Title_Sir</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Age*Class  Fare  Parch  PassengerId  Pclass  Sex  SibSp  Survived  \\\n",
       "0    1          3     0      0          NaN       3    0      1       0.0   \n",
       "1    2          2     3      0          NaN       1    1      1       1.0   \n",
       "2    1          3     1      0          NaN       3    1      0       1.0   \n",
       "3    2          2     3      0          NaN       1    1      1       1.0   \n",
       "4    2          6     1      0          NaN       3    0      0       0.0   \n",
       "5    1          3     1      0          NaN       3    0      0       0.0   \n",
       "6    3          3     3      0          NaN       1    0      0       0.0   \n",
       "7    0          0     2      1          NaN       3    0      3       0.0   \n",
       "8    1          3     1      2          NaN       3    1      0       1.0   \n",
       "9    0          0     2      0          NaN       2    1      1       1.0   \n",
       "\n",
       "   Title_Capt     ...      Title_Mlle  Title_Mme  Title_Mr  Title_Mrs  \\\n",
       "0           0     ...               0          0         1          0   \n",
       "1           0     ...               0          0         0          1   \n",
       "2           0     ...               0          0         0          0   \n",
       "3           0     ...               0          0         0          1   \n",
       "4           0     ...               0          0         1          0   \n",
       "5           0     ...               0          0         1          0   \n",
       "6           0     ...               0          0         1          0   \n",
       "7           0     ...               0          0         0          0   \n",
       "8           0     ...               0          0         0          1   \n",
       "9           0     ...               0          0         0          1   \n",
       "\n",
       "   Title_Ms  Title_Rev  Title_Sir  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0         0          0          0           0           0           1  \n",
       "1         0          0          0           1           0           0  \n",
       "2         0          0          0           0           0           1  \n",
       "3         0          0          0           0           0           1  \n",
       "4         0          0          0           0           0           1  \n",
       "5         0          0          0           0           1           0  \n",
       "6         0          0          0           0           0           1  \n",
       "7         0          0          0           0           0           1  \n",
       "8         0          0          0           0           0           1  \n",
       "9         0          0          0           1           0           0  \n",
       "\n",
       "[10 rows x 30 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['FareBand'] = pd.qcut(train_df['Fare'], 4)\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
    "    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "\n",
    "train_df = train_df.drop(['FareBand'], axis=1)\n",
    "\n",
    "combine = [train_df, test_df]\n",
    "    \n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## try more fare band number\n",
    "\n",
    "- no difference\n",
    "\n",
    "## keep Fare feature and add FareBand numerical feature¶\n",
    "\n",
    "- not good result"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fareband = pd.qcut(train_df['Fare'], 6)\n",
    "fareband.unique()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df['FareBand'] = pd.qcut(train_df['Fare'], 6)\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset.loc[ dataset['Fare'] <= 7.775, 'Fare'] = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.775) & (dataset['Fare'] <= 8.662), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 8.662) & (dataset['Fare'] <= 14.454), 'Fare']   = 2\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 26.0), 'Fare']   = 3\n",
    "    dataset.loc[(dataset['Fare'] > 26.0) & (dataset['Fare'] <= 52.369), 'Fare']   = 4\n",
    "    \n",
    "    dataset.loc[ dataset['Fare'] > 52.369, 'Fare'] = 5\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "\n",
    "train_df = train_df.drop(['FareBand'], axis=1)\n",
    "\n",
    "combine = [train_df, test_df]\n",
    "    \n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# final check data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## passengerid is existing again in train_df because test_df inclues it. also they are convied several times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Age*Class</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Title_Capt</th>\n",
       "      <th>Title_Col</th>\n",
       "      <th>...</th>\n",
       "      <th>Title_Mlle</th>\n",
       "      <th>Title_Mme</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Ms</th>\n",
       "      <th>Title_Rev</th>\n",
       "      <th>Title_Sir</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Age*Class  Fare  Parch  Pclass  Sex  SibSp  Survived  Title_Capt  \\\n",
       "0    1          3     0      0       3    0      1       0.0           0   \n",
       "1    2          2     3      0       1    1      1       1.0           0   \n",
       "2    1          3     1      0       3    1      0       1.0           0   \n",
       "3    2          2     3      0       1    1      1       1.0           0   \n",
       "4    2          6     1      0       3    0      0       0.0           0   \n",
       "\n",
       "   Title_Col     ...      Title_Mlle  Title_Mme  Title_Mr  Title_Mrs  \\\n",
       "0          0     ...               0          0         1          0   \n",
       "1          0     ...               0          0         0          1   \n",
       "2          0     ...               0          0         0          0   \n",
       "3          0     ...               0          0         0          1   \n",
       "4          0     ...               0          0         1          0   \n",
       "\n",
       "   Title_Ms  Title_Rev  Title_Sir  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0         0          0          0           0           0           1  \n",
       "1         0          0          0           1           0           0  \n",
       "2         0          0          0           0           0           1  \n",
       "3         0          0          0           0           0           1  \n",
       "4         0          0          0           0           0           1  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df.drop(['PassengerId'], axis=1)\n",
    "combine = [train_df, test_df]\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Age*Class</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Title_Capt</th>\n",
       "      <th>Title_Col</th>\n",
       "      <th>...</th>\n",
       "      <th>Title_Mlle</th>\n",
       "      <th>Title_Mme</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Ms</th>\n",
       "      <th>Title_Rev</th>\n",
       "      <th>Title_Sir</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>892.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>893.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>894.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>895.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>896.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Age*Class  Fare  Parch  PassengerId  Pclass  Sex  SibSp  Title_Capt  \\\n",
       "0    2          6     0      0        892.0       3    0      0           0   \n",
       "1    2          6     0      0        893.0       3    1      1           0   \n",
       "2    3          6     1      0        894.0       2    0      0           0   \n",
       "3    1          3     1      0        895.0       3    0      0           0   \n",
       "4    1          3     1      1        896.0       3    1      1           0   \n",
       "\n",
       "   Title_Col     ...      Title_Mlle  Title_Mme  Title_Mr  Title_Mrs  \\\n",
       "0          0     ...               0          0         1          0   \n",
       "1          0     ...               0          0         0          1   \n",
       "2          0     ...               0          0         1          0   \n",
       "3          0     ...               0          0         1          0   \n",
       "4          0     ...               0          0         0          1   \n",
       "\n",
       "   Title_Ms  Title_Rev  Title_Sir  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0         0          0          0           0           1           0  \n",
       "1         0          0          0           0           0           1  \n",
       "2         0          0          0           0           1           0  \n",
       "3         0          0          0           0           0           1  \n",
       "4         0          0          0           0           0           1  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model and estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Age*Class</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Title_Capt</th>\n",
       "      <th>Title_Col</th>\n",
       "      <th>...</th>\n",
       "      <th>Title_Mlle</th>\n",
       "      <th>Title_Mme</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Ms</th>\n",
       "      <th>Title_Rev</th>\n",
       "      <th>Title_Sir</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Age*Class  Fare  Parch  Pclass  Sex  SibSp  Survived  Title_Capt  \\\n",
       "0    1          3     0      0       3    0      1       0.0           0   \n",
       "1    2          2     3      0       1    1      1       1.0           0   \n",
       "2    1          3     1      0       3    1      0       1.0           0   \n",
       "3    2          2     3      0       1    1      1       1.0           0   \n",
       "4    2          6     1      0       3    0      0       0.0           0   \n",
       "\n",
       "   Title_Col     ...      Title_Mlle  Title_Mme  Title_Mr  Title_Mrs  \\\n",
       "0          0     ...               0          0         1          0   \n",
       "1          0     ...               0          0         0          1   \n",
       "2          0     ...               0          0         0          0   \n",
       "3          0     ...               0          0         0          1   \n",
       "4          0     ...               0          0         1          0   \n",
       "\n",
       "   Title_Ms  Title_Rev  Title_Sir  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0         0          0          0           0           0           1  \n",
       "1         0          0          0           1           0           0  \n",
       "2         0          0          0           0           0           1  \n",
       "3         0          0          0           0           0           1  \n",
       "4         0          0          0           0           0           1  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age               False\n",
       "Age*Class         False\n",
       "Fare              False\n",
       "Parch             False\n",
       "Pclass            False\n",
       "Sex               False\n",
       "SibSp             False\n",
       "Survived          False\n",
       "Title_Capt        False\n",
       "Title_Col         False\n",
       "Title_Countess    False\n",
       "Title_Don         False\n",
       "Title_Dona        False\n",
       "Title_Dr          False\n",
       "Title_Jonkheer    False\n",
       "Title_Lady        False\n",
       "Title_Major       False\n",
       "Title_Master      False\n",
       "Title_Miss        False\n",
       "Title_Mlle        False\n",
       "Title_Mme         False\n",
       "Title_Mr          False\n",
       "Title_Mrs         False\n",
       "Title_Ms          False\n",
       "Title_Rev         False\n",
       "Title_Sir         False\n",
       "Embarked_C        False\n",
       "Embarked_Q        False\n",
       "Embarked_S        False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df <  0].any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    678\n",
       "1    118\n",
       "2     80\n",
       "5      5\n",
       "3      5\n",
       "4      4\n",
       "6      1\n",
       "Name: Parch, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"Parch\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## try several models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = train_df.drop(\"Survived\", axis=1)\n",
    "y_train_df = train_df[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.823832261089224"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "scores = cross_val_score(logreg, X_train_df, y_train_df, cv=5)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# cannnot get model attribute because of cross_val_score use\n",
    "\"\"\"\n",
    "coeff_df = pd.DataFrame(train_df.columns.delete(0))\n",
    "coeff_df.columns = ['Feature']\n",
    "coeff_df[\"Correlation\"] = pd.Series(logreg.coef_[0])\n",
    "\n",
    "coeff_df.sort_values(by='Correlation', ascending=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(C=10.0, kernel=\"rbf\")\n",
    "scores = cross_val_score(svc, X_train_df, y_train_df, cv=5)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussianNb = GaussianNB()\n",
    "scores = cross_val_score(gaussianNb, X_train_df, y_train_df, cv=5)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron = Perceptron()\n",
    "scores = cross_val_score(perceptron, X_train_df, y_train_df, cv=5)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_svc = LinearSVC()\n",
    "scores = cross_val_score(linear_svc, X_train_df, y_train_df, cv=5)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGDClassifier()\n",
    "scores = cross_val_score(sgd, X_train_df, y_train_df, cv=5)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = DecisionTreeClassifier()\n",
    "scores = cross_val_score(decision_tree, X_train_df, y_train_df, cv=5)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "scores = cross_val_score(random_forest, X_train_df, y_train_df, cv=5)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make train, test data set from train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/test data shape (596, 28) (295, 28)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train_df, y_train_df, test_size=0.33, random_state=42)\n",
    "print(\"train/test data shape\", X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "              'gamma': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "#param_grid = [{'kernel': ['rbf'],\n",
    "#               'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "#               'gamma': [0.001, 0.01, 0.1, 1, 10, 100]},\n",
    "#              {'kernel': ['linear'],\n",
    "#               'C': [0.001, 0.01, 0.1, 1, 10, 100]}]\n",
    "\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5, n_jobs=3)\n",
    "#grid_search.fit(X_train, y_train, grid_search)\n",
    "\n",
    "#scores = cross_val_score(grid_search, X_train, y_train, cv=5)\n",
    "#print(\"mean of train scores\", scores.mean())\n",
    "\n",
    "# cannot show grid_search attribute because using cross_val_score\n",
    "#print(grid_search.score(X_train, y_train))\n",
    "#print(grid_search.best_params_)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# to get cv_results_, need to fit with data once\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "plt.matshow(grid_search.cv_results_['mean_test_score'].reshape(6, -1),\n",
    "            vmin=0, cmap=\"viridis\")\n",
    "plt.xlabel(\"C\")\n",
    "plt.ylabel(\"gamma\")\n",
    "plt.xticks(range(len(param_grid['C'])), param_grid['C'])\n",
    "plt.yticks(range(len(param_grid['gamma'])), param_grid['gamma'])\n",
    "plt.colorbar()\n",
    "\n",
    "\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"best estimator:\", grid_search.best_estimator_)\n",
    "print(\"best parameters:\", grid_search.best_parameters)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make wide the ranges\n",
    "\n",
    "param_grid = {'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "              'gamma': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]}\n",
    "\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5, n_jobs=3)\n",
    "\n",
    "# no meaning to use cross_val for grid_search model because it is incluced in grid search\n",
    "#scores = cross_val_score(grid_search, X_train, y_train, cv=5, n_jobs=6)\n",
    "#print(\"mean of train scores\", scores.mean())\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "plt.matshow(grid_search.cv_results_['mean_test_score'].reshape(8, -1),\n",
    "            vmin=0, cmap=\"viridis\")\n",
    "plt.xlabel(\"C\")\n",
    "plt.ylabel(\"gamma\")\n",
    "plt.xticks(range(len(param_grid['C'])), param_grid['C'])\n",
    "plt.yticks(range(len(param_grid['gamma'])), param_grid['gamma'])\n",
    "plt.colorbar()\n",
    "\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# use randomized cv RandomizedSearchCV\n",
    "\n",
    "param_dist = {\"max_depth\": [3, None],                  #distribution\n",
    "              \"n_estimators\":[50,100,200,300,400,500],\n",
    "              \"max_features\": sp_randint(1, 11),\n",
    "              \"min_samples_split\": sp_randint(2, 11),\n",
    "              \"min_samples_leaf\": sp_randint(1, 11),\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "param_dist = {'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "              'gamma': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# reduce gamma range and wide other side \n",
    "\n",
    "param_grid = {'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "              'gamma': [1, 10, 100, 1000, 10000, 100000, 1000000, 10000000, 100000000]}\n",
    "\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5, n_jobs=3)\n",
    "\n",
    "#scores = cross_val_score(grid_search, X_train, y_train, cv=5)\n",
    "#print(\"mean of train scores\", scores.mean())\n",
    "\n",
    "\n",
    "# to get cv_results_, need to fit with data once\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "plt.matshow(grid_search.cv_results_['mean_test_score'].reshape(8, -1),\n",
    "            vmin=0, cmap=\"viridis\")\n",
    "plt.xlabel(\"C\")\n",
    "plt.ylabel(\"gamma\")\n",
    "plt.xticks(range(len(param_grid['C'])), param_grid['C'])\n",
    "plt.yticks(range(len(param_grid['gamma'])), param_grid['gamma'])\n",
    "plt.colorbar()\n",
    "\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# search where it looks good. but not good result\n",
    "\n",
    "param_grid = {'C': [0.0001, 0.0005, 0.001, 0.005, 0.01],\n",
    "              'gamma': [10000, 50000, 100000]}\n",
    "\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5, n_jobs=3)\n",
    "\n",
    "#scores = cross_val_score(grid_search, X_train, y_train, cv=5)\n",
    "#print(\"mean of train scores\", scores.mean())\n",
    "\n",
    "\n",
    "\n",
    "# to get cv_results_, need to fit with data once\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "plt.matshow(grid_search.cv_results_['mean_test_score'].reshape(5, -1),\n",
    "            vmin=0, cmap=\"viridis\")\n",
    "plt.xlabel(\"C\")\n",
    "plt.ylabel(\"gamma\")\n",
    "plt.xticks(range(len(param_grid['C'])), param_grid['C'])\n",
    "plt.yticks(range(len(param_grid['gamma'])), param_grid['gamma'])\n",
    "plt.colorbar()\n",
    "\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## univariate statistics: SelectPercentile(percentile=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SelectPercentile make worse. percentage is bigger, test score become better.**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# grid search for pipeline\n",
    "param_grid = {'svc__C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "              'svc__gamma': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000],\n",
    "             'selectpercentile__percentile':[30, 50, 70, 80, 90]}\n",
    "\n",
    "pipe = make_pipeline(SelectPercentile(), SVC())\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model-based selection: SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search for pipeline\n",
    "param_grid = {'svc__C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "              'svc__gamma': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]}\n",
    "\n",
    "pipe = make_pipeline(SelectFromModel(RandomForestClassifier(n_estimators=100, random_state=42), threshold=\"median\"), \n",
    "                     SVC())\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**no effect. test score is same as only SVC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature was decrease from 28 to 14\n",
    "X_train.shape, grid_search.best_estimator_.named_steps[\"selectfrommodel\"].transform(X_train).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RFE recursive feature elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search for pipeline\n",
    "param_grid = {'svc__C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "              'svc__gamma': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]}\n",
    "\n",
    "pipe = make_pipeline(RFE(RandomForestClassifier(n_estimators=100, random_state=42), n_features_to_select=14), \n",
    "                     SVC())\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**no effect. test score is same as only SVC**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# grid search for pipeline\n",
    "param_grid = {'svc__C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "              'svc__gamma': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000],\n",
    "             'rfe__n_features_to_select':[5, 10, 14, 16, 18, 20, 22, 24, 26]}\n",
    "\n",
    "pipe = make_pipeline(RFE(RandomForestClassifier(n_estimators=100, random_state=42), n_features_to_select=10), \n",
    "                     SVC())\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# apply preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min Max Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search for pipeline\n",
    "param_grid = {'svc__C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "              'svc__gamma': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]}\n",
    "pipe = make_pipeline(MinMaxScaler(), SVC())\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search for pipeline\n",
    "param_grid = {'svc__C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "              'svc__gamma': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]}\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(), SVC())\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search for pipeline\n",
    "param_grid = {'svc__C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "              'svc__gamma': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]}\n",
    "\n",
    "pipe = make_pipeline(RobustScaler(), SVC())\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search for pipeline\n",
    "param_grid = {'svc__C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "              'svc__gamma': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]}\n",
    "\n",
    "pipe = make_pipeline(Normalizer(), SVC())\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# watching wrong result\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "print(\"test\", pipe.score(X_test, y_test))\n",
    "\n",
    "#scores = cross_val_score(pipe, X_train_df, y_train_df, cv=5, n_jobs=3)\n",
    "#print(\"cross eval for all\", scores.mean())\n",
    "\n",
    "y_predicted = pipe.predict(X_test)\n",
    "\n",
    "confusion = confusion_matrix(y_test, y_predicted)\n",
    "print(\"Confusion matrix:\\n{}\".format(confusion))\n",
    "\n",
    "wrongResult = []\n",
    "for i, (y, y_pred) in enumerate(zip(y_test, y_predicted)):\n",
    "    if y != y_pred:\n",
    "        wrongResult.append([X_test.iloc[i,:], y, y_pred])\n",
    "\n",
    "print(wrongResult[0])\n",
    "print(wrongResult[1])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "param_grid = {'n_estimators': [3, 5, 7, 10, 50, 100, 200, 500, 1000],\n",
    "              'learning_rate': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "             'max_depth':[1,2,3,4,5,6]}\n",
    "\n",
    "grid_search = GridSearchCV(RobustScalerGradientBoostingClassifier(), param_grid, cv=5, n_jobs=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "plt.matshow(grid_search.cv_results_['mean_test_score'].reshape(6, -1),\n",
    "            vmin=0, cmap=\"viridis\")\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.ylabel(\"learning_rate\")\n",
    "plt.xticks(range(len(param_grid['n_estimators'])), param_grid['n_estimators'])\n",
    "plt.yticks(range(len(param_grid['learning_rate'])), param_grid['learning_rate'])\n",
    "plt.colorbar()\n",
    "\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search for pipeline\n",
    "param_grid = {'svc__C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "              'svc__gamma': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]}\n",
    "pipe = make_pipeline(PolynomialFeatures(degree=2), RobustScaler(), SVC())\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**as a result of grid, 2 degree was best. currently deactivating the grid because it take so much time**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# grid search for pipeline\n",
    "param_grid = {'svc__C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "              'svc__gamma': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000],\n",
    "             'polynomialfeatures__degree': [2, 3, 4]}\n",
    "pipe = make_pipeline(PolynomialFeatures(), RobustScaler(), SVC())\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**polynominal feature, robust scaler, pca, svc**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# polynominal feature, robust scaler, pca, svc\n",
    "param_grid = {'svc__C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "              'svc__gamma': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]}\n",
    "pipe = make_pipeline(PolynomialFeatures(degree=2), RobustScaler(), PCA(), SVC())\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### minmaxscaler, pca, svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min max scaler and PCA\n",
    "\n",
    "\"\"\"\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(X_scaled)\n",
    "# 最初の2つの主成分に対してデータポイントを変換\n",
    "X_pca = pca.transform(X_scaled)\n",
    "print(\"Original shape: {}\".format(str(X_scaled.shape)))\n",
    "print(\"Reduced shape: {}\".format(str(X_pca.shape)))\n",
    "\"\"\"\n",
    "\n",
    "param_grid = {'svc__C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "              'svc__gamma': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000],\n",
    "#             'pca__n_components':[2,4,6,8,10]}\n",
    "             'pca__n_components':[2,4,6,8,10, 12, 14, 16, 18, 20]}\n",
    "\n",
    "pipe = make_pipeline(MinMaxScaler(), PCA(), SVC())\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### robustscaler, pca, svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# robust scaler and PCA\n",
    "\n",
    "param_grid = {'svc__C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "              'svc__gamma': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000],\n",
    "#             'pca__n_components':[2,4,6,8,10]}\n",
    "             'pca__n_components':[2,4,6,8,10, 12, 14, 16, 18, 20]}\n",
    "\n",
    "pipe = make_pipeline(RobustScaler(), PCA(), SVC())\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search for pipeline\n",
    "param_grid = {'svc__C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "              'svc__gamma': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000],\n",
    "             'nmf__n_components':[5,10,14, 16, 18, 20, 22, 24]}\n",
    "\n",
    "pipe = make_pipeline(MinMaxScaler(), NMF(), SVC())\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RobustScaler make negative value. so NMF cannot be used**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "scaling = RobustScaler()\n",
    "scaling.fit(X_train)\n",
    "X_train_scaled = scaling.transform(X_train)\n",
    "X_train_scaled[:5]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# RobustScaler make negative value. so NMF cannot be used\n",
    "# grid search for pipeline\n",
    "param_grid = {'svc__C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "              'svc__gamma': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000],\n",
    "             'nmf__n_components':[2,4,6,8,10, 12, 14, 16, 18, 20]}\n",
    "\n",
    "pipe = make_pipeline(RobustScaler(), NMF(), SVC())\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random forest result for compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'randomforestclassifier__n_estimators': [5, 10, 20, 30, 50, 100, 300],\n",
    "              'randomforestclassifier__max_features': [1, 'auto', None],\n",
    "             'randomforestclassifier__max_depth':[1, 5, 10, 20, 30, None],\n",
    "             'randomforestclassifier__min_samples_leaf': [1,2,4]}\n",
    "\n",
    "pipe = make_pipeline(RandomForestClassifier())\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## min max scaler, random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'randomforestclassifier__n_estimators': [5, 10, 20, 30, 50, 100, 300],\n",
    "              'randomforestclassifier__max_features': [1, 'auto', None],\n",
    "             'randomforestclassifier__max_depth':[1, 5, 10, 20, 30, None],\n",
    "             'randomforestclassifier__min_samples_leaf': [1,2,4]}\n",
    "\n",
    "pipe = make_pipeline(MinMaxScaler(), RandomForestClassifier())\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))\n",
    "\n",
    "#scores = cross_val_score(grid_search, X_train_df, y_train_df, cv=5)\n",
    "#print(\"cross eval for all\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## min max scaler, pca, random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'randomforestclassifier__n_estimators': [5, 10, 20, 30, 50, 100, 300],\n",
    "              'randomforestclassifier__max_features': [1, 'auto', None],\n",
    "             'randomforestclassifier__max_depth':[1, 5, 10, 20, 30, None],\n",
    "             'randomforestclassifier__min_samples_leaf': [1,2,4]}\n",
    "\n",
    "pipe = make_pipeline(MinMaxScaler(), PCA(), RandomForestClassifier())\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))\n",
    "\n",
    "#scores = cross_val_score(grid_search, X_train_df, y_train_df, cv=5)\n",
    "#print(\"cross eval for all\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## robust scaler, random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'randomforestclassifier__n_estimators': [5, 10, 20, 30, 50, 100, 300],\n",
    "              'randomforestclassifier__max_features': [1, 'auto', None],\n",
    "             'randomforestclassifier__max_depth':[1, 5, 10, 20, 30, None],\n",
    "             'randomforestclassifier__min_samples_leaf': [1,2,4]}\n",
    "\n",
    "pipe = make_pipeline(RobustScaler(), RandomForestClassifier())\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))\n",
    "\n",
    "#scores = cross_val_score(grid_search, X_train_df, y_train_df, cv=5)\n",
    "#print(\"cross eval for all\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## robust scaler, pca, random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'randomforestclassifier__n_estimators': [5, 10, 20, 30, 50, 100, 300],\n",
    "              'randomforestclassifier__max_features': [1, 'auto', None],\n",
    "             'randomforestclassifier__max_depth':[1, 5, 10, 20, 30, None],\n",
    "             'randomforestclassifier__min_samples_leaf': [1,2,4]}\n",
    "\n",
    "pipe = make_pipeline(RobustScaler(), PCA(), RandomForestClassifier())\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))\n",
    "\n",
    "#scores = cross_val_score(grid_search, X_train_df, y_train_df, cv=5)\n",
    "#print(\"cross eval for all\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validated score of the best_estimator:  0.8305369127516778\n",
      "best parameters: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 10}\n",
      "test:  0.8305084745762712\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1QAAACJCAYAAAArKXkxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3X2UXXV97/H3J5OESABBQxGS1ESNIlhEG0Fbl0URCb1KLD4ltqvQcs3tvdBqrW3DrUWlugRr7bWSUlNJAW8VEB+IbUpKES+9LqEJimCCSC6PiUgagSSAeZiZz/1j7wmHMzPnYZ85OTOZz2utvebs39nf3+975szTd/Zv/7ZsExEREREREe2b0usEIiIiIiIiJqoUVBERERERERWloIqIiIiIiKgoBVVERERERERFKagiIiIiIiIqSkEVERERERFR0aQuqCTNkPQfkn4gaYOkj7UR+4CkuyTdIWl9G3EvK2OGth2SPtDg+FWStkr6YU3b8yTdKOne8uMR7eQ5Wnw7Y6nwN5I2SbpT0hmSbpa0sfxcvr+N+D3l863kWD/uq1v93EdEREREjLVJXVABu4E32X4lcCKwSNJr24h/o+0TbS9sNcD2PWXMicAvA08DX28QcgWwqK5tOXCT7QXATeV+O3mOFt/OWGcAC8ptGfAJ4I9sHwe8FjhP0nEtxv8M2NFijvXjXtbktUdEREREdM2kLqhceLLcnVZu+/NOx6cC/8/2g6MdYPsW4LG65sXAleXjK4G3tznuiPFtjrUYuKr8HN4KzAQeKfvZCdwNzG4lnqKwfa6koyuMe3hdXERERETEfjOpCyoASX2S7gC2Ajfavq3FUAP/Kul2ScsqDr8E+HKFuKNsP1I+/ilwVINjR8qznfjRjp0NPFxz3OayDUnzgFcBt7UYb+AXgG+1kOOo40ZERERE7G9Te51Ar9keAE6UdDjwdUmvsP3DZnHA621vkfQLwI2SflSe4WmJpOnAmcAF1TIv2LakRmfVhuXZZnxbx0o6BPgq8AHbOyS1Ev964CrgYuDTneQYEREREbE/TfqCaojtJyTdTHENUdOCyvaW8uNWSV8HTgJaLqgorgX6nu1HK6T7qKSjbT9STnfb2maeLcc3OHYLMLfmuDnAoxTF1D/a/lqr8WXBN4fi894sx5HG3dIg/4iIiIg4gJz+xpn+2WMDw9pvv3P3Wtv16wF03aSe8ifpyPLMFJKeA5wG/KhxFEiaKenQocfAW2ihCKuzlGrT/QBWA2eXj88Grm8zz5bim4y1GvjtctW91wLbKRamuNv2Z9qInynpTWX8jhZyHDZuzdTAiIiIiDjAbXtsgFvXzhm2AbOaxUpaJOmecsXoYQu7SfrFcuXq75crSv960z6LNQEmJ0knUCx40EdRXF5r+6IW4l7EMyvzTQW+ZPsTbYw7E3gIeJHt7U2O/TJwCsUXyKPAR4BvANcCvwg8CLzbdv1iEqPmKen5I8W3M5aKuXyXUpzRexr4X8AXgLuAwXLM/0lxHVWj+LdSXD/1MLC3hRzrx/0d2y0vWx8RERERE9urX3mQ//2GFwxrP+SYh25vtPq2pD7gxxQnUTYD64CltjfWHLMS+L7ty8oVq9fYntcon0ldUEVERERExMTyqldO983/MnxNtSNmb25WUL0O+Kjt08v9CwBsf7LmmM8D99m+pDz+r2z/SqN8cg1VRERERERMGAb27psQ9SyzJNXOXFppe2XN/kirRZ9c18dHKVbI/n2K2wK9uVk+KagiIiIiImLCGMTs8ogF1bZGZ6hatBS4wvZflWeovliuAj7igJCCKiIiIiIiJhAb9la7aqmV1aLPpbhWH9vflTSDYn2BUVfFntSr/EVERERExMRixF4P31qwDlggaX55T9glFCtI13oIOBVA0suBGcB/Nuo0BRUgadlkiZ1o+XYaGxEREREHFgN7mDJsaxpn9wPnA2uBuylW+N4g6SJJZ5aH/RHwPkk/oLjF0TlusopfVvkDJK2vOt9yosVOtHw7jY2IiIiIA8vLTzjIV/3T0cPaT3rhgw1X+euWXEMVEREREREThoG9Hj8T7SZFQTXj8Bk+5OhDRn1+5gtmMuvlsyqdqptoseMx3yOmPtUw9shjprHgl54zYuzj/TOrpBP7yexpDe9b3dCWvc8dw0yiG+ZO31Ep7uE9h41xJjHWqr63kPd3vJvTwXu7Oe/tuNbJ79w77+rfZvvIMUynq4prqMZPGTN+MumiQ44+hLdd+bZepxGjOGvW+uYHjeJr2zITcDz7+DE3VI798E8WjWEm0Q2fmXNjpbgPbj5tjDOJsVb1vYW8v+PdJbPXVo790y2nj2EmMdY6+Z07Z+5PHxzDVLrOFrtSUEVERERERLTPiD0pqCIiIiIiItpXXEPV1+s09hk/V3NFREREREQ0MXQNVf3WCkmLJN0jaZOk5SM8/9eS7ii3H0t6olmfXS+oWkj6IEnXlM/fJmlezXMXlO33SDq9pn2VpK2Sftjt/CMiIiIiYvwYROzytGFbM5L6gBXAGcBxwFJJx9UeY/sPbZ9o+0Tgc8DXmvXb1YKqlaSBc4HHbb8E+GvgkjL2OIq7Fx8PLAL+tuwP4IqyLSIiIiIiJhFb7HXfsK0FJwGbbN9new9wNbC4wfFLKW7u21C3z1C1kvRi4Mry8XXAqZJUtl9te7ft+4FNZX/YvgV4rMu5R0RERETEOGNgj6cO24BZktbXbMvqQmcDD9fsby7bhpH0QmA+8K1m+XR7UYqRkj55tGNs90vaDjy/bL+1LnbEFzyS8hO4DIp7IEVERERExMQ3iNg9OOIUv222x+qeOkuA62wPNDvwgF2UwvZK2wttL5xx+IxepxMREREREWOgWJSi0pS/LcDcmv05ZdtIltDCdD/ofkHVStL7jpE0FXgu8LMWYyMiIiIiYhLp4BqqdcACSfMlTacomlbXHyTpWOAI4LutdNrtgqqVpFcDZ5eP3wl8y7bL9iXlKoDzgQXAf3Q534iIiIiIGMeM2DU4bdjWNM7uB84H1gJ3A9fa3iDpIkln1hy6hGItB7eST1evoSqviRpKug9YNZQ0sN72auBy4IuSNlEsNLGkjN0g6VpgI9APnDc0h1HSl4FTKC482wx8xPbl3XwtERERERHRe53c2Nf2GmBNXduFdfsfbafPbi9K0TRp27uAd40S+wngEyO0Lx3jNCMiIiIiYgIwor9iQdUNXS+oIiIiIiIixooNewfHz9p6LRdUkl4KXAYcZfsVkk4AzrT98a5lF5WcNWt9pbhjp22rPOauDv5LcLCarkY5qqa3rj7AfPyYG3oy7q6WZhAPd+iU/M+mVZ+Zc2Pl2EN00Bhm0rqfWz0Zd6Lp5L09WNMrx+723sqxuzxYOXYy+fTsf60cO03V/xgcoOIPZeDpweqxk0knv29n9Oi93TmJvm2LZdPHz98Y7bzjfw9cAOwFsH0n5fVOERERERER+0cx5a9+65V2CqqDbdevstc/lslEREREREQ0Ukz56xu2tULSIkn3SNokafkox7xb0kZJGyR9qVmf7Zwr2ybpxRQLayDpncAjbcRHRERERER0ZBCxp8UCqpakPmAFcBqwGVgnabXtjTXHLKCYlferth+X9AvN+m2noDoPWAkcK2kLcD/wm23ER0REREREdMaiv0JBBZwEbLJ9H4Ckq4HFFLdpGvI+YIXtxwFsb23WaTtT/mz7zcCRwLG2X99m/LM0O91W3tD3mvL52yTNK9ufL+lmSU9KurTq+BERERERMfEY6PeUYRvFPWrX12zL6kJnAw/X7G8u22q9FHippO9IulXSomb5tHOG6qvAq20/VdN2HfDLbfQBtHa6DTgXeNz2SyQtAS4B3gPsAv4ceEW5RURERETEJGGgf+Rl07fZXthh91OBBcApwBzgFkm/ZPuJRgENSToWOB54rqSzap46DJhRMdFWTrctBj5aPr4OuFSSyoLu/0p6ScWxIyIiIiJigrKrXUMFbAHm1uzPKdtqbQZus70XuF/SjykKrHWjddrKGaqXAW8FDgfeVtO+k2KOYRUjnW47ebRjbPdL2g48H2jpZknlKb5lADNfMLNimhERERERMZ40OEPVzDpggaT5FIXUEuC9dcd8A1gK/IOkWRRTAO9r1GnTgsr29cD1kl5n+7tVMu8F2yspFtFg1stn5S52EREREREHACMGKhRU5Uma84G1QB+wyvYGSRcB622vLp97i6SNwADwx7Z/1qjfdq6h+r6k8yim/+2b6mf7d9t8LdDa6bahYzZLmgo8F2j4YiIiIiIi4sA2dB+qarFeA6ypa7uw5rGBD5ZbS9op7b4IvAA4Hfg/FEXQzjbia+073SZpOsXpttV1x6wGzi4fvxP4VvkCIyIiIiJi0irOUNVvvdLOGaqX2H6XpMW2ryzvGvzvVQZt8XTb5cAXJW0CHqMougCQ9ADFohjTJb0deEvdCoEREREREXEAsmFgUL1OY592Cqq95ccnJL0C+CnQ9M7Bo2nhdNsu4F2jxM6rOm5ERERERExcRpWn/HVDOwXVSklHAB+mmI53CMX9oCIiIiIiIvabwYl2hkrSFGCH7ceBW4AXdTWrceSsWesrxx47raUV3kf0lNupdZ/teVP6K8XNVPW5p1M6+pqu/h+Gjx1zQw9G7Z1Dp1T/uhig+iWIMypevtjJmJfMXls5dloHX8sHa3oH41b/qnqyg18MT3p35dhOPDowWCnukx28twd38Dme0tZlw8/W2Xtb/ftg2+DPK8fubX7IqJ7q4FqEj3fwc3lGxe/dKar+/dNH9djHBqt9DwDs6uDrohM7B6v/jOvkve3EtIrvb/V3B342UP17YLqqj7zHnVwHNH4KjG4rpvxV+1xJWgR8luJPwS/Yvrju+XOAv+SZBfMutf2FRn22lIntQeBP2k04IiIiIiJirA0OatjWjKQ+YAVwBnAcsFTScSMceo3tE8utYTEF7a3y92+SPiRprqTnDW1txEdERERERHTErrzK30nAJtv32d4DXA0s7jSfduYPvaf8eF5Nm5lE0/8iIiIiIqL3XG2q/Gzg4Zr9zcDJIxz3DklvAH4M/KHth0c4Zp+Wz1DZnj/Ctq+YknRaq301ImmRpHskbZK0fITn3yDpe5L6Jb1zLMaMiIiIiIiJwYw65W+WpPU127IK3X8TmGf7BOBG4MpmAdWvcB/uknLQymrmNZ5GUTGuk7S67h5TDwHnAB/qZKyIiIiIiJiADB4Y8QzVNtsLG0RuAebW7M/hmcUniq7tn9XsfgH4VLN0xvKWwmOxtEjTeY22H7B9J50t3hIREREREROS8ODwrQXrgAWS5kuaDiyhuB3UMz1LR9fsngnc3azTsTxDNRbrf7Y6rzEiIiIiIiYjV7uGyna/pPOBtRTLpq+yvUHSRcB626uBP5B0JtAPPEYxM66hsSyoxpVyzuQygJkvmNnjbCIiIiIiYsy42uQ422uANXVtF9Y8vgC4oJ0+x3LK3wNj0EfTeY2tsr3S9kLbC2ccPmMMUouIiIiIiJ4rr6Gq33ql5TNUks4aoXk7cJftrbZHer5d++Y1UhRSS4D3jkG/ERERERFxoKi2bHpXtDPl71zgdcDN5f4pwO3AfEkX2f5ip8m0Mq9R0muArwNHAG+T9DHbx3c6dkRERERETAAGjaPl6dopqKYCL7f9KICko4CrKBaNuAXouKCCluY1rqOYChgREREREZOOoIdT/Oq1U1DNHSqmSlvLtsck7R3jvCIiIiIiIoYz42rKXzuLUnxb0j9JOlvS2cD1ZdtM4InupBcREREREfFsGhy+tRQnLZJ0j6RNkpY3OO4dkiyp0Y2CgfbOUJ0HvAP41XL/KuCrtg28sY1+9rujpu3ggy+4sVLsoVMGKo87a8r0yrF7qT5uX8XV8He5+phjcheyCjqZPjtD1f+zcbCmVY4d7CDrjt6jDuxyxTe4g6+Lw6dUv6vDNPVVjn3aeyrHDg5Wf8E7Xf3rYudg9dc7Q9W/pp4YPKhS3FF9/ZXH7OR7YJqqvz/bB6p/XTzdwffBLld/bweo/jNuWkc/pyqHVn6PHu6vvmhxJ691kOrvz5QOfkDu7WCR5sOn9OZruRMDFcft5Punk6+LJwar//3Xyc/knR2MOxGpwhkqSX3ACuA0ivvdrpO02vbGuuMOBd4P3NZKvy3/xVIWTteVW0RERERExP5nqv5X/SRgk+37ACRdDSwGNtYd9xfAJcAft9Jpy//ikHSWpHslbZe0Q9JOSTtajY+IiIiIiBgLo0z5myVpfc22rC5sNvBwzf7msu2ZfqVXU6wT8c+t5tLOnJpPAW+zfXcbMREREREREWNGoy+bvs1202ueRu1XmgJ8Bjinnbh2JuE+Ol6KKUmrJG2V9MNe5xIREREREfuXBjRsa8EWYG7N/pyybcihwCsoFt57AHgtsLrZwhTtnKFaL+ka4BvA7qFG219ro4+xcgVwKcXCGBERERERMVlUv7HvOmCBpPkUhdQS4L37urW3A7OG9iV9G/iQ7fWNOm2noDoMeBp4S02bgf1eUNm+RdK8/T1uRERERESMAxUKKtv9ks4H1gJ9wCrbGyRdBKy3vbpKKu2s8vc7VQbolfIitGUAR8+uvmxmRERERESMLxXPUGF7DbCmru3CUY49pZU+mxZUkv7E9qckfY4R7ipj+w9aGWh/s70SWAlw/AnTe3TnhIiIiIiIGFPVp/x1RStnqIYWomg4dzAiIiIiIqLbxAQrqGx/s/x4ZffTiYiIiIiIaGACnqECQNJLgQ8B82rjbL9p7NNqmsuXgVMobt61GfiI7cv3dx4REREREbH/aaDXGTyjnVX+vgL8HfAFoKcvwfbSXo4fERERERE9Yiqt8gcgaRHwWYpV/r5g++K6538POI+i3nkSWGZ7Y6M+2ymo+m1f1l7KERERERERY6vKlD9JfcAK4DRgM7BO0uq6gulLtv+uPP5M4DPAokb9Tmkjh29K+h+Sjpb0vKGtvZcRERERERHRARdT/uq3FpwEbLJ9n+09wNXA4md1be+o2Z3JCKuc12vnDNXZ5cc/rh0TeFEbffTEg1uO4n3LP9DrNKILtr6m1xlEt/Q9rcqx03dWj43ue/LYPZVjZzw4fQwzaUMnX1IT8cYdHbzeXXOrv7/TH5lWLbCDz/HAc6oHa7D6J2rK7sqhTOmvPu7g1A5e78uerBzb31/9nqBTp1a70sTuze+CqvkC/PzJgyrH+uft/Flf7086iN3/BGjkL+VZkmpXJl9Z3kppyGzg4Zr9zcDJw/qXzgM+CEwHmq4X0dJnXtIU4Ldsf6eV4yMiIiIiIrpllCl/22wv7LRv2yuAFZLeC3yYZ04sjailKX+2B4FLO00uIiIiIiKiI9Wn/G0B5tbszynbRnM18PZmnbZzDdVNkt4hKXNpIiIiIiKiZzQ4fGvBOmCBpPmSpgNLgNXP6ldaULP7X4B7m3XaTkH13yiWTt8taYeknZJ2NAvqhKRVkrZK+mFN2/Mk3Sjp3vLjEd3MISIiIiIixhFXK6hs9wPnA2uBu4FrbW+QdFG5oh/A+ZI2SLqD4jqqhtP9oI1FKWwf2uqxY+gKiqmGV9W0LQdusn2xpOXl/p/2ILeIiIiIiNjPRLVl0wFsrwHW1LVdWPP4/e322dZyIOXZoAXAjJpBb2l30FbZvkXSvLrmxcAp5eMrgW+TgioiIiIiYnIwaGD8LKHackEl6b8C76e4eOsO4LXAd2lhKcExdpTtR8rHPwWOGukgScuAZQDTD86swIiIiIiIA0XVM1Td0M41VO8HXgM8aPuNwKuAJ7qSVYtsm1HuPmF7pe2FthdOmzFzP2cWERERERHdUnFRiq5op6DaZXsXgKSDbP8IeFl30mroUUlHl3kcDWztQQ4REREREdEDMkwZGL71SjsF1WZJhwPfAG6UdD3wYHfSamg1z6y2cTZwfQ9yiIiIiIiIHtGgh2290nJBZfs3bD9h+6PAnwOX08KNrjoh6csU12m9TNJmSecCFwOnSboXeHO5HxERERERk0H1G/siaZGkeyRtKlcMr3/+g5I2SrpT0k2SXtisz3ZX+Xs9sMD2P0g6EpgN3N9OH+2wvXSUp07t1pgRERERETG+VblmSlIfsAI4DdgMrJO02vbGmsO+Dyy0/bSk/w58CnhPo35bPkMl6SMUy5NfUDZNA/536y8hIiIiIiKiQ+Wy6fVbC04CNtm+z/Ye4GqKWzI907V9s+2ny91bKVY4b6ida6h+AzgTeKoc7CdAL272GxERERERk5Q8/Pqp8hqqWZLW12zL6kJnAw/X7G8u20ZzLvAvzfJpZ8rfHtuWZABJE2Yt8v4Z8Nhx6nUa0QWH3p/39UD15JzqF5fuPmL83OyvZZ2k3Ktvg4rjHnzv9MpDTtlbOZTB6sMyZU/12F69P+6rHqv+DmKfbOtqgmfZe1i1dY+n7Wzn/8PP1re7+hs0cFD1b9zBg6qPu/eI6suZTX2y+udqz/YZlWMZqP56ByvGam8HY86ovgb33t3VP8eeVn1c9U+uv4lGmfK3zfbCMelf+i1gIfBrzY5t56fetZI+Dxwu6X3A7wJ/Xy3FiIiIiIiICgzqr/QPjS3A3Jr9OWXbs0h6M/BnwK/Z3t2s05YLKtuflnQasIPi/lMX2r6x1fiIiIiIiIixUHGZ9HXAAknzKQqpJcB7n9Wv9Crg88Ai2y3d77at8/JlAZUiKiIiIiIiesPVVvmz3S/pfGAt0Aessr1B0kXAeturgb8EDgG+IgngIdtnNuq3aUElaScjz+5XkZcPa++ljDjGKuCtwFbbryjbngdcA8wDHgDebftxFa/ss8CvA08D59j+Xqc5RERERETE+CdodVW/YWyvAdbUtV1Y8/jN7fbZ9Ko524faPmyE7dCxKKZKVwCL6tqWAzfZXgDcVO4DnAEsKLdlwGVjlENERERERIx3NhoYHLb1SvVlSMaQ7VuAx+qaFwNXlo+vBN5e036VC7dSLJJx9P7JNCIiIiIiem2UZdN7YlwUVKM4yvYj5eOfAkeVj1taP17SsqE16Aeeeqq7mUZERERExP5R/ca+XTGeC6p9bJs279Jie6XthbYX9s2cMLfMioiIiIiIJjLlrzWPDk3lKz8OLVvY0vrxERERERFx4JGHn51q9QyVpEWS7pG0SdLyEZ5/g6TvSeqX9M5W+hzPBdVq4Ozy8dnA9TXtv63Ca4HtNVMDIyIiIiLiQDc4OHxrQlIfsIJikbvjgKWSjqs77CHgHOBLrabS1n2oukXSl4FTgFmSNgMfAS4GrpV0LvAg8O7y8DUUS6Zvolg2/Xf2e8IREREREdEbBvVXmuJ3ErDJ9n0Akq6mWPBu476u7QfK51oeYFwUVLaXjvLUqSMca+C87mYUERERERHjkj3aGalZktbX7K+0vbJmf6TF7U7uNJ1xUVBFRERERES0apRrprbZXri/c0lBFRERERERE4eBaqv6dWVxu0lRUO3+yeZt9/75Hz3Y4JBZwLaK3U+02ImWb6exEREREdHYC3udQHsMAwNVAtcBCyTNpyiklgDv7TSbSVFQ2T6y0fOS1lc9PTjRYidavp3GRkRERMQBxtUKKtv9ks4H1gJ9wCrbGyRdBKy3vVrSa4CvA0cAb5P0MdvHN+p3UhRUERERERFxgKg+5Q/bayhWDa9tu7Dm8TqKqYAtS0EVERERERETSOUpf12RgqqwsvkhB0zsRMu309iIiIiIOJCYcVVQqbitU0REROcknQgcU06pQNKZwHG2Lx6Dvj9AcU+RpzvtKyIiJq7nTjvSv3L4O4a137Dt87f34rr7Kft7wIiIOKCdCPz60I7t1WNRTJU+ABzcToCkvjEaOyIixguDBwaGbb2SgioiYhKSNE/S3ZL+XtIGSf8q6TmjHPtiSTdIul3Sv0s6tmx/l6QfSvqBpFskTQcuAt4j6Q5J75F0jqRLy+OvkHSZpFsl3SfpFEmryjyuqBnvMknry7w+Vrb9AXAMcLOkm8u2pZLuKnO4pCb+SUl/JekHwOskXSxpo6Q7JX26O5/RiIjYb2zo7x++9UgKqoiIyWsBsKJcDvYJYPj8icJK4Pdt/zLwIeBvy/YLgdNtvxI40/aesu0a2yfavmaEvo4AXgf8IbAa+GvgeOCXyumCAH9WTtk4Afg1SSfY/hvgJ8Abbb9R0jHAJcCbKM6KvUbS28v4mcBtZV53A78BHG/7BODj7X6SIiJivHHlM1SSFkm6R9ImSctHeP4gSdeUz98maV6zPlNQRURMXvfbvqN8fDswr/4ASYcAvwJ8RdIdwOeBo8unvwNcIel9FPfzaMU3XVy8exfwqO27bA8CG2rGf7ek7wHfpyi2jhuhn9cA37b9n7b7gX8E3lA+NwB8tXy8HdgFXC7pLCDXX0VETHRDi1LUb02U08BXAGdQ/G5ZKqn+d8y5wOO2X0LxT79LaCIFVUTE5LW75vEAI6/8OgV4ojzjNLS9HMD27wEfBuYCt0t6fhtjDtaNPwhMLe9e/yHg1PKM0j8DM9p5UcAu2wNljv3AScB1wFuBG9rsKyIixhnbDO7tH7a14CRgk+37ylkVVwOL645ZDFxZPr4OOFWSGnWaZdMjImJUtndIul/Su2x/pfylcoLtH0h6se3bgNsknUFRWO0EDu1gyMOAp4Dtko6i+C/it8vnhvreBvwH8DeSZgGPA0uBz9V3Vp5hO9j2GknfAe7rILeIiBgHdvL42n8bvHbWCE/NkLS+Zn+l7drb78wGHq7Z3wycXNfHvmNs90vaDjyf4nfPiFJQRUREM78JXCbpw8A0iv/o/QD4S0kLAAE3lW0PAcvL6YGfbHegslD7PvAjil9o36l5eiVwg6SflNdRLQduLsf/Z9vXj9DlocD1kmaUx32w3ZwiImJ8sb2o1znUyn2oIiIiIiLigCfpdcBHbZ9e7l8AYPuTNcesLY/5rqSpwE+BI92gaMo1VBERERERMRmsAxZIml/e6mMJxYqztVYDZ5eP3wl8q1ExBZnyFxERJUkrgF+ta/6s7X/oRT4RERFjqbwm6nxgLcXqtKtsb5B0EbDe9mrgcuCLkjYBj1EUXQ1lyl9ERERERERFmfIXERERERFRUQqqiIiIiIiIilJQRUREREREVJSCKiIiIiKqLKd0AAAAJUlEQVQioqIUVBERERERERWloIqIiIiIiKgoBVVERERERERF/x/k9Rda5zlkzgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efe3a8b77b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "param_grid = {'n_estimators': [3, 5, 7, 10, 50, 100, 200, 500],\n",
    "              'learning_rate': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "             'max_depth':[1,2,3,4,5,6]}\n",
    "\n",
    "grid_search = GridSearchCV(GradientBoostingClassifier(), param_grid, cv=5, n_jobs=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "plt.matshow(grid_search.cv_results_['mean_test_score'].reshape(6, -1),\n",
    "            vmin=0, cmap=\"viridis\")\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.ylabel(\"learning_rate\")\n",
    "plt.xticks(range(len(param_grid['n_estimators'])), param_grid['n_estimators'])\n",
    "plt.yticks(range(len(param_grid['learning_rate'])), param_grid['learning_rate'])\n",
    "plt.colorbar()\n",
    "\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validated score of the best_estimator:  0.8249158249158249\n",
      "best parameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "grid_search.fit(X_train_df, y_train_df)\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "\n",
    "\n",
    "test_df_noid = test_df.drop(\"PassengerId\", axis=1).copy()\n",
    "y_pred = grid_search.predict(test_df_noid).astype(int)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": test_df[\"PassengerId\"].astype(int),\n",
    "        \"Survived\": y_pred\n",
    "    })\n",
    "submission.to_csv('../output/submission_gradientboosting.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## todo: how to make a matshow correctly for 3 variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## robust scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validated score of the best_estimator:  0.8305369127516778\n",
      "best parameters: {'gradientboostingclassifier__learning_rate': 0.1, 'gradientboostingclassifier__max_depth': 3, 'gradientboostingclassifier__n_estimators': 10}\n",
      "test:  0.8305084745762712\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'gradientboostingclassifier__n_estimators': [3, 5, 7, 10, 50, 100, 200, 500],\n",
    "              'gradientboostingclassifier__learning_rate': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "             'gradientboostingclassifier__max_depth': [1,2,3,4,5,6]}\n",
    "\n",
    "pipe = make_pipeline(RobustScaler(), GradientBoostingClassifier(), )\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## robust, pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validated score of the best_estimator:  0.8120805369127517\n",
      "best parameters: {'gradientboostingclassifier__learning_rate': 0.01, 'gradientboostingclassifier__max_depth': 2, 'gradientboostingclassifier__n_estimators': 500}\n",
      "test:  0.8101694915254237\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'gradientboostingclassifier__n_estimators': [3, 5, 7, 10, 50, 100, 200, 500],\n",
    "              'gradientboostingclassifier__learning_rate': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "             'gradientboostingclassifier__max_depth': [1,2,3,4,5,6]}\n",
    "\n",
    "pipe = make_pipeline(RobustScaler(), PCA(), GradientBoostingClassifier(), )\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## minmaxscaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validated score of the best_estimator:  0.8305369127516778\n",
      "best parameters: {'gradientboostingclassifier__learning_rate': 0.1, 'gradientboostingclassifier__max_depth': 3, 'gradientboostingclassifier__n_estimators': 10}\n",
      "test:  0.8305084745762712\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'gradientboostingclassifier__n_estimators': [3, 5, 7, 10, 50, 100, 200, 500],\n",
    "              'gradientboostingclassifier__learning_rate': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "             'gradientboostingclassifier__max_depth': [1,2,3,4,5,6]}\n",
    "\n",
    "pipe = make_pipeline(MinMaxScaler(), GradientBoostingClassifier(), )\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## minmaxscaler, pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validated score of the best_estimator:  0.8305369127516778\n",
      "best parameters: {'gradientboostingclassifier__learning_rate': 0.1, 'gradientboostingclassifier__max_depth': 2, 'gradientboostingclassifier__n_estimators': 10}\n",
      "test:  0.8169491525423729\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'gradientboostingclassifier__n_estimators': [3, 5, 7, 10, 50, 100, 200, 500],\n",
    "              'gradientboostingclassifier__learning_rate': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "             'gradientboostingclassifier__max_depth': [1,2,3,4,5,6]}\n",
    "\n",
    "pipe = make_pipeline(MinMaxScaler(), PCA(), GradientBoostingClassifier(), )\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# for submit, copy the best model and export output csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search for pipeline\n",
    "param_grid = {'svc__C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "              'svc__gamma': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]}\n",
    "\n",
    "pipe = make_pipeline(RobustScaler(), SVC())\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "print(\"test: \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train_df, y_train_df)\n",
    "print(\"Mean cross-validated score of the best_estimator: \", grid_search.best_score_)\n",
    "print(\"best parameters:\", grid_search.best_params_)\n",
    "\n",
    "\n",
    "test_df_noid = test_df.drop(\"PassengerId\", axis=1).copy()\n",
    "y_pred = grid_search.predict(test_df_noid).astype(int)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": test_df[\"PassengerId\"].astype(int),\n",
    "        \"Survived\": y_pred\n",
    "    })\n",
    "submission.to_csv('../output/submission_robustscaler_svc.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_df_noid = test_df.drop(\"PassengerId\", axis=1).copy()\n",
    "y_pred = grid_search.predict(test_df_noid).astype(int)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": test_df[\"PassengerId\"],\n",
    "        \"Survived\": y_pred\n",
    "    })\n",
    "submission.to_csv('../output/submission_minmaxscaler_ranfore'+ time.strftime(\"%Y-%m-%d-%H-%M-%S\") + '.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
