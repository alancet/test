# current best result

## svc only. grid search

param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100],
              'gamma': [0.001, 0.01, 0.1, 1, 10, 100]}

#param_grid = [{'kernel': ['rbf'],
#               'C': [0.001, 0.01, 0.1, 1, 10, 100],
#               'gamma': [0.001, 0.01, 0.1, 1, 10, 100]},
#              {'kernel': ['linear'],
#               'C': [0.001, 0.01, 0.1, 1, 10, 100]}]

grid_search = GridSearchCV(SVC(), param_grid, cv=5)
#grid_search.fit(X_train, y_train)

scores = cross_val_score(grid_search, X_train, y_train, cv=5)
print("train", scores.mean())

# cannot show grid_search attribute because using cross_val_score
#print(grid_search.score(X_train, y_train))
#print(grid_search.best_params_)




# to get cv_results_, need to fit with data once

grid_search.fit(X_train, y_train)

plt.matshow(grid_search.cv_results_['mean_test_score'].reshape(6, -1),
            vmin=0, cmap="viridis")
plt.xlabel("C")
plt.ylabel("gamma")
plt.xticks(range(len(param_grid['C'])), param_grid['C'])
plt.yticks(range(len(param_grid['gamma'])), param_grid['gamma'])
plt.colorbar()


print("best scroe: ", grid_search.best_score_)
print("best estimator:", grid_search.best_estimator_)
print("test: ", grid_search.score(X_test, y_test))






train 0.8003734035987276
best scroe:  0.8204697986577181
best estimator: SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
test:  0.8067796610169492


------------------------------------------------------------------------------------------


# used one hot encoding for title
param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100],
              'gamma': [0.001, 0.01, 0.1, 1, 10, 100]}

#param_grid = [{'kernel': ['rbf'],
#               'C': [0.001, 0.01, 0.1, 1, 10, 100],
#               'gamma': [0.001, 0.01, 0.1, 1, 10, 100]},
#              {'kernel': ['linear'],
#               'C': [0.001, 0.01, 0.1, 1, 10, 100]}]

grid_search = GridSearchCV(SVC(), param_grid, cv=5)
#grid_search.fit(X_train, y_train)

scores = cross_val_score(grid_search, X_train, y_train, cv=5)
print("train", scores.mean())

# cannot show grid_search attribute because using cross_val_score
#print(grid_search.score(X_train, y_train))
#print(grid_search.best_params_)




# to get cv_results_, need to fit with data once

grid_search.fit(X_train, y_train)

plt.matshow(grid_search.cv_results_['mean_test_score'].reshape(6, -1),
            vmin=0, cmap="viridis")
plt.xlabel("C")
plt.ylabel("gamma")
plt.xticks(range(len(param_grid['C'])), param_grid['C'])
plt.yticks(range(len(param_grid['gamma'])), param_grid['gamma'])
plt.colorbar()


print("best scroe: ", grid_search.best_score_)
print("best estimator:", grid_search.best_estimator_)
print("test: ", grid_search.score(X_test, y_test))



train 0.8137765275601765
best scroe:  0.8221476510067114
best estimator: SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
test:  0.8101694915254237



-----

# used only Parch, SibSp. no 'FamilySize', 'IsAlone'

best scroe:  0.8322147651006712
best estimator: Pipeline(memory=None,
     steps=[('minmaxscaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('randomforestclassifier', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features=1, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=No...n_jobs=1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False))])
best param: {'randomforestclassifier__max_depth': None, 'randomforestclassifier__max_features': 1, 'randomforestclassifier__min_samples_leaf': 2, 'randomforestclassifier__n_estimators': 300}
test:  0.823728813559322


-----
# one hot encoding for Embarked
but this is starnge. test score is better than train.

train 0.8120960926743578
best scroe:  0.8154362416107382
best estimator: SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
test:  0.847457627118644



-----

# random forest with 6 fare band

best scroe:  0.825503355704698
best estimator: Pipeline(memory=None,
     steps=[('minmaxscaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('randomforestclassifier', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=5, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=...n_jobs=1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False))])
best param: {'randomforestclassifier__max_depth': 5, 'randomforestclassifier__max_features': 'auto', 'randomforestclassifier__min_samples_leaf': 2, 'randomforestclassifier__n_estimators': 50}
test:  0.8406779661016949





## if 4 fare band is used, the score of ranfore doesn't change

best scroe:  0.8288590604026845
best estimator: Pipeline(memory=None,
     steps=[('minmaxscaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('randomforestclassifier', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=5, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=...n_jobs=1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False))])
best param: {'randomforestclassifier__max_depth': 5, 'randomforestclassifier__max_features': 'auto', 'randomforestclassifier__min_samples_leaf': 2, 'randomforestclassifier__n_estimators': 100}
test:  0.8406779661016949



-----
# simple svc
Mean cross-validated score of the best_estimator:  0.8171140939597316
best parameters: {'C': 1000, 'gamma': 0.001}
test:  0.8440677966101695

# robust scaler, svc
これはコンスタントに性能良いな

but gradient boosting is better score in submission 0.79904

