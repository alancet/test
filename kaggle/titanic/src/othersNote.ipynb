{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# original\n",
    "\n",
    "https://www.kaggle.com/yuanxuan/titanic-random-forest-82-78/notebook\n",
    "\n",
    "# points\n",
    "\n",
    "- almost all are one hot encoding\n",
    "- columns: Index(['Survived', 'Age', 'Fare', 'Name_Len', 'Age_Null_Flag',\n",
    "       'Cabin_num_(1.999, 28.667]', 'Cabin_num_(28.667, 65.667]',\n",
    "       'Cabin_num_(65.667, 148.0]', 'Ticket_Len', 'Pclass_3', 'Pclass_1',\n",
    "       'Pclass_2', 'Sex_male', 'Sex_female', 'Embarked_S', 'Embarked_C',\n",
    "       'Embarked_Q', 'Ticket_Lett_A', 'Ticket_Lett_P', 'Ticket_Lett_S',\n",
    "       'Ticket_Lett_1', 'Ticket_Lett_3', 'Ticket_Lett_2', 'Ticket_Lett_C',\n",
    "       'Ticket_Lett_Low_ticket', 'Ticket_Lett_Other_ticket', 'Cabin_Letter_n',\n",
    "       'Cabin_Letter_C', 'Cabin_Letter_E', 'Cabin_Letter_G', 'Cabin_Letter_D',\n",
    "       'Cabin_Letter_A', 'Cabin_Letter_B', 'Cabin_Letter_F', 'Name_Title_Mr.',\n",
    "       'Name_Title_Mrs.', 'Name_Title_Miss.', 'Name_Title_Master.',\n",
    "       'Name_Title_Rev.', 'Name_Title_Dr.', 'Name_Title_Ms.',\n",
    "       'Name_Title_Col.', 'Fam_Size_Nuclear', 'Fam_Size_Solo', 'Fam_Size_Big'],\n",
    "      dtype='object')\n",
    "\n",
    "\tvariable\timportance\n",
    "12\tSex_female\t0.111215\n",
    "11\tSex_male\t0.109769\n",
    "33\tName_Title_Mr.\t0.109746\n",
    "1\tFare\t0.088209\n",
    "2\tName_Len\t0.087904\n",
    "0\tAge\t0.078651\n",
    "8\tPclass_3\t0.043268\n",
    "35\tName_Title_Miss.\t0.031292\n",
    "7\tTicket_Len\t0.031079\n",
    "34\tName_Title_Mrs.\t0.028852\n",
    "25\tCabin_Letter_n\t0.027893\n",
    "43\tFam_Size_Big\t0.025199\n",
    "41\tFam_Size_Nuclear\t0.022704\n",
    "9\tPclass_1\t0.021810\n",
    "19\tTicket_Lett_1\t0.017999\n",
    "20\tTicket_Lett_3\t0.012902\n",
    "10\tPclass_2\t0.012345\n",
    "36\tName_Title_Master.\t0.012098\n",
    "23\tTicket_Lett_Low_ticket\t0.011723\n",
    "13\tEmbarked_S\t0.011546\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# data analysis and wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# train, test, validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "\n",
    "# scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "# decomposition\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "# feature engineering\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# feature selection\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    \"\"\"Utility function to report best scores\n",
    "    \"\"\"\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Rank: {0}\".format(i))\n",
    "            print(\"Score: {0:f} (std: {1:f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Pars: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "            \n",
    "\n",
    "def report2(results, n_top=3):\n",
    "    \"\"\"Utility function to report best scores\n",
    "    \"\"\"\n",
    "    print(\"Rank|Score(std)|Params\", list(results['params'][0].keys()))\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"{0}|\".format(i), end=\"\")\n",
    "            print(\"{0:f}(std:{1:f})|\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]), end=\"\")\n",
    "            print(\"{0}\".format(list(results['params'][candidate].values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def names(train, test):\n",
    "    for i in [train, test]:\n",
    "        i['Name_Len'] = i['Name'].apply(lambda x: len(x))\n",
    "        i['Name_Title'] = i['Name'].apply(lambda x: x.split(',')[1]).apply(lambda x: x.split()[0])\n",
    "        del i['Name']\n",
    "    return train, test\n",
    "\n",
    "def age_impute(train, test):\n",
    "    for i in [train, test]:\n",
    "        i['Age_Null_Flag'] = i['Age'].apply(lambda x: 1 if pd.isnull(x) else 0)\n",
    "        data = train.groupby(['Name_Title', 'Pclass'])['Age']\n",
    "        i['Age'] = data.transform(lambda x: x.fillna(x.mean()))\n",
    "    return train, test\n",
    "\n",
    "\n",
    "def fam_size(train, test):\n",
    "    for i in [train, test]:\n",
    "        i['Fam_Size'] = np.where((i['SibSp']+i['Parch']) == 0 , 'Solo',\n",
    "                           np.where((i['SibSp']+i['Parch']) <= 3,'Nuclear', 'Big'))\n",
    "        del i['SibSp']\n",
    "        del i['Parch']\n",
    "    return train, test\n",
    "\n",
    "\n",
    "def ticket_grouped(train, test):\n",
    "    for i in [train, test]:\n",
    "        i['Ticket_Lett'] = i['Ticket'].apply(lambda x: str(x)[0])\n",
    "        i['Ticket_Lett'] = i['Ticket_Lett'].apply(lambda x: str(x))\n",
    "        i['Ticket_Lett'] = np.where((i['Ticket_Lett']).isin(['1', '2', '3', 'S', 'P', 'C', 'A']), i['Ticket_Lett'],\n",
    "                                   np.where((i['Ticket_Lett']).isin(['W', '4', '7', '6', 'L', '5', '8']),\n",
    "                                            'Low_ticket', 'Other_ticket'))\n",
    "        i['Ticket_Len'] = i['Ticket'].apply(lambda x: len(x))\n",
    "        del i['Ticket']\n",
    "    return train, test\n",
    "\n",
    "\n",
    "def cabin(train, test):\n",
    "    for i in [train, test]:\n",
    "        i['Cabin_Letter'] = i['Cabin'].apply(lambda x: str(x)[0])\n",
    "        del i['Cabin']\n",
    "    return train, test\n",
    "\n",
    "def cabin_num(train, test):\n",
    "    for i in [train, test]:\n",
    "        i['Cabin_num1'] = i['Cabin'].apply(lambda x: str(x).split(' ')[-1][1:])\n",
    "        i['Cabin_num1'].replace('an', np.NaN, inplace = True)\n",
    "        i['Cabin_num1'] = i['Cabin_num1'].apply(lambda x: int(x) if not pd.isnull(x) and x != '' else np.NaN)\n",
    "        i['Cabin_num'] = pd.qcut(train['Cabin_num1'],3)\n",
    "    train = pd.concat((train, pd.get_dummies(train['Cabin_num'], prefix = 'Cabin_num')), axis = 1)\n",
    "    test = pd.concat((test, pd.get_dummies(test['Cabin_num'], prefix = 'Cabin_num')), axis = 1)\n",
    "    del train['Cabin_num']\n",
    "    del test['Cabin_num']\n",
    "    del train['Cabin_num1']\n",
    "    del test['Cabin_num1']\n",
    "    return train, test\n",
    "\n",
    "\n",
    "def embarked_impute(train, test):\n",
    "    for i in [train, test]:\n",
    "        i['Embarked'] = i['Embarked'].fillna('S')\n",
    "    return train, test\n",
    "\n",
    "def dummies(train, test, columns = ['Pclass', 'Sex', 'Embarked', 'Ticket_Lett', 'Cabin_Letter', 'Name_Title', 'Fam_Size']):\n",
    "    for column in columns:\n",
    "        train[column] = train[column].apply(lambda x: str(x))\n",
    "        test[column] = test[column].apply(lambda x: str(x))\n",
    "        good_cols = [column+'_'+i for i in train[column].unique() if i in test[column].unique()]\n",
    "        train = pd.concat((train, pd.get_dummies(train[column], prefix = column)[good_cols]), axis = 1)\n",
    "        test = pd.concat((test, pd.get_dummies(test[column], prefix = column)[good_cols]), axis = 1)\n",
    "        del train[column]\n",
    "        del test[column]\n",
    "    return train, test\n",
    "\n",
    "def drop(train, test, bye = ['PassengerId']):\n",
    "    for i in [train, test]:\n",
    "        for z in bye:\n",
    "            del i[z]\n",
    "    return train, test\n",
    "\n",
    "\n",
    "train = pd.read_csv(os.path.join('../input', 'train.csv'))\n",
    "test = pd.read_csv(os.path.join('../input', 'test.csv'))\n",
    "train, test = names(train, test)\n",
    "train, test = age_impute(train, test)\n",
    "train, test = cabin_num(train, test)\n",
    "train, test = cabin(train, test)\n",
    "train, test = embarked_impute(train, test)\n",
    "train, test = fam_size(train, test)\n",
    "test['Fare'].fillna(train['Fare'].mean(), inplace = True)\n",
    "train, test = ticket_grouped(train, test)\n",
    "train, test = dummies(train, test, columns = ['Pclass', 'Sex', 'Embarked', 'Ticket_Lett',\n",
    "                                                                     'Cabin_Letter', 'Name_Title', 'Fam_Size'])\n",
    "train, test = drop(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 150 candidates, totalling 450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:   35.0s\n",
      "[Parallel(n_jobs=6)]: Done 438 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=6)]: Done 450 out of 450 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8383838383838383\n",
      "{'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 700}\n",
      "{'mean_fit_time': array([0.15842684, 0.20610189, 0.77891509, 1.3159349 , 1.81066648,\n",
      "       0.15871294, 0.21484613, 0.73826059, 1.30018926, 1.84731388,\n",
      "       0.16110396, 0.21298226, 0.74133595, 1.26565758, 1.74319816,\n",
      "       0.15601206, 0.20452531, 0.71357481, 1.2697436 , 1.79620226,\n",
      "       0.16151484, 0.20147006, 0.73195982, 1.28742313, 1.71358395,\n",
      "       0.15810053, 0.21529174, 0.70337979, 1.25526365, 1.74323511,\n",
      "       0.17875409, 0.20810652, 0.77733835, 1.246116  , 1.71341729,\n",
      "       0.16111787, 0.21901266, 0.74701532, 1.20088951, 1.68733319,\n",
      "       0.16582712, 0.21258068, 0.74446193, 1.3210837 , 1.65187192,\n",
      "       0.16184139, 0.21935638, 0.68294748, 1.18026821, 1.67313457,\n",
      "       0.16449817, 0.2005802 , 0.72505887, 1.20647383, 1.70750117,\n",
      "       0.16628273, 0.21318165, 0.78740104, 1.23061347, 1.77697086,\n",
      "       0.16222143, 0.2145226 , 0.75279522, 1.28087473, 1.66462541,\n",
      "       0.15975952, 0.20786293, 0.7450459 , 1.24511218, 1.71308104,\n",
      "       0.16273109, 0.21668061, 0.74466761, 1.31496946, 1.71599905,\n",
      "       0.1573081 , 0.21282371, 0.7774531 , 1.53156908, 2.14235202,\n",
      "       0.16803471, 0.21623842, 0.83755342, 1.43276445, 2.00449721,\n",
      "       0.15868298, 0.23461612, 0.85091925, 1.35571957, 1.82672397,\n",
      "       0.17162514, 0.2148126 , 0.77161058, 1.30692267, 1.81080858,\n",
      "       0.15645377, 0.20074511, 0.74289966, 1.42375414, 1.74854851,\n",
      "       0.16654634, 0.21431406, 0.72719328, 1.33922839, 1.88707272,\n",
      "       0.16665308, 0.20580967, 0.75142368, 1.33895175, 1.76392396,\n",
      "       0.15866772, 0.21509171, 0.77502624, 1.22754208, 1.81343587,\n",
      "       0.15612499, 0.21038016, 0.73967512, 1.27573935, 1.82796248,\n",
      "       0.16658401, 0.20950452, 0.75393677, 1.26171501, 1.76030087,\n",
      "       0.15346305, 0.21554399, 0.70827325, 1.22239375, 1.64393854,\n",
      "       0.16956989, 0.20020501, 0.65292279, 1.19061136, 1.65965398,\n",
      "       0.15406537, 0.20684393, 0.74965882, 1.20632052, 1.5916787 ,\n",
      "       0.16578341, 0.20938007, 0.7984457 , 1.23605863, 1.67508133,\n",
      "       0.15432866, 0.21217442, 0.73763967, 1.24139603, 1.68607593]), 'std_fit_time': array([0.01247273, 0.00710478, 0.12682929, 0.10393116, 0.07740821,\n",
      "       0.01386731, 0.00476293, 0.01350543, 0.11440316, 0.07323119,\n",
      "       0.00337225, 0.01924824, 0.06120653, 0.05212391, 0.0372338 ,\n",
      "       0.00057157, 0.01164736, 0.02430485, 0.06388365, 0.08157359,\n",
      "       0.00380567, 0.00426218, 0.01569656, 0.00893706, 0.03167985,\n",
      "       0.00347869, 0.00914792, 0.02092485, 0.13016829, 0.04720212,\n",
      "       0.0165306 , 0.02670112, 0.01752153, 0.02321051, 0.06478311,\n",
      "       0.01620391, 0.00639991, 0.04258145, 0.06605826, 0.03035931,\n",
      "       0.01595115, 0.01272701, 0.05876452, 0.08232074, 0.11015335,\n",
      "       0.00363424, 0.01021987, 0.01505602, 0.12536741, 0.05968449,\n",
      "       0.00237365, 0.01428734, 0.02042384, 0.04368053, 0.05760926,\n",
      "       0.01016786, 0.01108252, 0.02229596, 0.06605929, 0.10447909,\n",
      "       0.00531236, 0.00174077, 0.0198117 , 0.04024861, 0.04005655,\n",
      "       0.00309896, 0.01407694, 0.04213997, 0.02394279, 0.06361547,\n",
      "       0.00224293, 0.0059134 , 0.04967498, 0.00981019, 0.07202678,\n",
      "       0.00660175, 0.01577854, 0.03015354, 0.07497889, 0.04344057,\n",
      "       0.01266256, 0.00174142, 0.01517956, 0.07939293, 0.03043403,\n",
      "       0.00365604, 0.02708695, 0.02871318, 0.10422233, 0.09225936,\n",
      "       0.01223804, 0.00147583, 0.00734938, 0.12014318, 0.07029673,\n",
      "       0.00792969, 0.00258421, 0.06773786, 0.07687893, 0.09279126,\n",
      "       0.00740969, 0.00598727, 0.03906458, 0.01601948, 0.07802614,\n",
      "       0.00467417, 0.00460845, 0.02075543, 0.07119696, 0.02307167,\n",
      "       0.00966375, 0.0074599 , 0.00239219, 0.05311552, 0.13698138,\n",
      "       0.00821858, 0.02328844, 0.04944318, 0.01130923, 0.02326553,\n",
      "       0.01395891, 0.00826559, 0.0399785 , 0.0604889 , 0.09267216,\n",
      "       0.0110993 , 0.00544772, 0.04347078, 0.05250082, 0.05889327,\n",
      "       0.01207914, 0.00367719, 0.03537778, 0.03240694, 0.05308145,\n",
      "       0.00176118, 0.00740635, 0.02956326, 0.02768108, 0.07449768,\n",
      "       0.01147333, 0.00235897, 0.02102556, 0.0520764 , 0.07264118,\n",
      "       0.00920919, 0.00412767, 0.00703996, 0.02990283, 0.03345948]), 'mean_score_time': array([0.10162926, 0.10209878, 0.12328251, 0.20250328, 0.2226212 ,\n",
      "       0.10920636, 0.1083622 , 0.10152078, 0.20748146, 0.20171777,\n",
      "       0.10269054, 0.10579205, 0.11579831, 0.21648097, 0.20406787,\n",
      "       0.1030678 , 0.10228467, 0.10287015, 0.20925045, 0.20481078,\n",
      "       0.10157839, 0.11923639, 0.10155423, 0.20802728, 0.20232058,\n",
      "       0.1047612 , 0.10255965, 0.10214742, 0.21176219, 0.20481769,\n",
      "       0.10162226, 0.10159381, 0.10777235, 0.20589018, 0.20485489,\n",
      "       0.10860801, 0.10589242, 0.10195613, 0.20303869, 0.20466145,\n",
      "       0.11101937, 0.10262632, 0.11073319, 0.21269902, 0.20277238,\n",
      "       0.1014967 , 0.1134781 , 0.115309  , 0.20788296, 0.20301215,\n",
      "       0.10961946, 0.10150353, 0.10280689, 0.20646556, 0.20222759,\n",
      "       0.10297434, 0.10288692, 0.1215117 , 0.21218594, 0.20206745,\n",
      "       0.11264261, 0.10688686, 0.10417747, 0.22139239, 0.20416864,\n",
      "       0.1016051 , 0.10252062, 0.10619617, 0.21049205, 0.21327631,\n",
      "       0.11054913, 0.10746829, 0.11688264, 0.20803515, 0.20185677,\n",
      "       0.10164237, 0.10239498, 0.10850072, 0.21183896, 0.20752652,\n",
      "       0.10728526, 0.10721596, 0.10521483, 0.21049905, 0.20203463,\n",
      "       0.10381897, 0.10433904, 0.12698197, 0.21487538, 0.20658207,\n",
      "       0.10163649, 0.12005504, 0.1043543 , 0.21842567, 0.20790291,\n",
      "       0.1016655 , 0.10195978, 0.11999424, 0.2069815 , 0.20658517,\n",
      "       0.10265565, 0.10723265, 0.10363309, 0.21761552, 0.20157099,\n",
      "       0.10699892, 0.10768938, 0.10691818, 0.21803689, 0.20433728,\n",
      "       0.1036075 , 0.10176555, 0.11974883, 0.20349995, 0.20264268,\n",
      "       0.11192648, 0.10476661, 0.11715619, 0.22091158, 0.20286338,\n",
      "       0.10408632, 0.10519544, 0.115803  , 0.21693285, 0.21049198,\n",
      "       0.10313884, 0.10178693, 0.10800568, 0.20811049, 0.20631242,\n",
      "       0.10703421, 0.10158324, 0.10696864, 0.20990761, 0.20253555,\n",
      "       0.10154136, 0.10376604, 0.10579324, 0.21451592, 0.21151455,\n",
      "       0.10153262, 0.10719856, 0.10830323, 0.21573774, 0.20796998,\n",
      "       0.10766172, 0.10601719, 0.10628239, 0.20196827, 0.23525246]), 'std_score_time': array([2.06463423e-04, 2.70024757e-04, 1.62068797e-02, 1.10385830e-03,\n",
      "       2.08988750e-02, 1.11388160e-02, 9.57236741e-03, 1.23337321e-04,\n",
      "       7.93188526e-03, 4.47255010e-05, 1.54037096e-03, 5.80947568e-03,\n",
      "       1.01754584e-02, 1.51876866e-02, 3.16542431e-03, 8.36135789e-04,\n",
      "       9.93608048e-04, 1.80806477e-03, 7.12187260e-03, 4.21722902e-03,\n",
      "       3.20371254e-05, 1.30827784e-02, 9.05690088e-05, 3.93110716e-03,\n",
      "       5.96197618e-04, 4.71605527e-03, 1.50825101e-03, 9.41872978e-04,\n",
      "       1.16347837e-02, 4.66984853e-03, 7.33540092e-05, 1.59512582e-04,\n",
      "       6.72553668e-04, 4.63672437e-03, 4.53459780e-03, 1.01279315e-02,\n",
      "       6.16890236e-03, 3.62786441e-04, 1.73420795e-03, 3.39637395e-03,\n",
      "       1.26261958e-02, 1.05152537e-03, 7.48384004e-03, 1.26463882e-02,\n",
      "       1.34002994e-03, 9.94753248e-05, 5.81009851e-03, 1.26661000e-02,\n",
      "       8.28825593e-03, 1.90244036e-03, 1.03291721e-02, 1.86893437e-04,\n",
      "       1.14917508e-03, 1.43698679e-03, 4.09933044e-04, 1.82686997e-03,\n",
      "       8.58107451e-04, 1.87014184e-02, 1.13850619e-02, 4.38927086e-04,\n",
      "       8.01157553e-03, 4.84380835e-03, 2.02848127e-03, 9.93353908e-03,\n",
      "       2.76028126e-03, 2.11313148e-04, 6.12579947e-04, 5.86583357e-03,\n",
      "       1.03969940e-02, 8.88776055e-03, 4.69231403e-03, 8.36114401e-03,\n",
      "       7.70332988e-03, 8.49023480e-03, 3.72255439e-04, 1.15175177e-04,\n",
      "       1.14451206e-03, 5.93105151e-03, 4.26743885e-03, 4.42874939e-03,\n",
      "       4.25382479e-03, 4.83733433e-03, 3.81601973e-03, 1.18122551e-02,\n",
      "       2.03634436e-04, 3.16643373e-03, 2.99147903e-03, 1.81053842e-02,\n",
      "       8.95410247e-03, 6.45436939e-03, 1.19652929e-04, 1.82724855e-02,\n",
      "       3.21142784e-03, 9.63880081e-03, 4.25739159e-03, 3.08343778e-04,\n",
      "       5.70878782e-04, 2.29963860e-02, 7.47518782e-03, 5.96023180e-03,\n",
      "       1.60124478e-03, 7.85103621e-03, 3.15748123e-03, 1.38952413e-02,\n",
      "       9.31829362e-05, 5.46115871e-03, 2.18325745e-03, 7.49042804e-03,\n",
      "       1.32193880e-02, 1.96957007e-03, 2.77325459e-03, 5.60662984e-04,\n",
      "       9.40509217e-03, 1.54741478e-03, 1.56337999e-03, 9.95874171e-03,\n",
      "       2.60421201e-03, 1.05142194e-02, 2.59980810e-02, 1.59178376e-03,\n",
      "       3.40733107e-03, 5.10913884e-03, 6.33545278e-03, 1.98805537e-02,\n",
      "       1.23286791e-02, 2.19768582e-03, 5.52033025e-04, 5.31113616e-03,\n",
      "       5.48579996e-03, 4.24008943e-03, 4.02525189e-03, 3.17033962e-05,\n",
      "       6.88610968e-03, 9.67343119e-03, 1.01813479e-03, 6.50121996e-05,\n",
      "       1.88335946e-03, 6.16781511e-03, 8.52296136e-03, 8.67280330e-03,\n",
      "       4.51488387e-05, 6.21784000e-03, 6.04427239e-03, 1.00005539e-02,\n",
      "       4.41205953e-03, 8.55774090e-03, 4.95334922e-03, 5.76084284e-03,\n",
      "       1.92245850e-04, 4.73023650e-02]), 'param_criterion': masked_array(data=['gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_min_samples_leaf': masked_array(data=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                   1, 1, 1, 1, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "                   5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10,\n",
      "                   10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "                   10, 10, 10, 10, 10, 10, 10, 10, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                   1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5,\n",
      "                   5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "                   5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "                   10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "                   10, 10],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_min_samples_split': masked_array(data=[2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 10, 10, 10, 10, 10, 12,\n",
      "                   12, 12, 12, 12, 16, 16, 16, 16, 16, 2, 2, 2, 2, 2, 4,\n",
      "                   4, 4, 4, 4, 10, 10, 10, 10, 10, 12, 12, 12, 12, 12, 16,\n",
      "                   16, 16, 16, 16, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 10, 10,\n",
      "                   10, 10, 10, 12, 12, 12, 12, 12, 16, 16, 16, 16, 16, 2,\n",
      "                   2, 2, 2, 2, 4, 4, 4, 4, 4, 10, 10, 10, 10, 10, 12, 12,\n",
      "                   12, 12, 12, 16, 16, 16, 16, 16, 2, 2, 2, 2, 2, 4, 4, 4,\n",
      "                   4, 4, 10, 10, 10, 10, 10, 12, 12, 12, 12, 12, 16, 16,\n",
      "                   16, 16, 16, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 10, 10, 10,\n",
      "                   10, 10, 12, 12, 12, 12, 12, 16, 16, 16, 16, 16],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_n_estimators': masked_array(data=[50, 100, 400, 700, 1000, 50, 100, 400, 700, 1000, 50,\n",
      "                   100, 400, 700, 1000, 50, 100, 400, 700, 1000, 50, 100,\n",
      "                   400, 700, 1000, 50, 100, 400, 700, 1000, 50, 100, 400,\n",
      "                   700, 1000, 50, 100, 400, 700, 1000, 50, 100, 400, 700,\n",
      "                   1000, 50, 100, 400, 700, 1000, 50, 100, 400, 700, 1000,\n",
      "                   50, 100, 400, 700, 1000, 50, 100, 400, 700, 1000, 50,\n",
      "                   100, 400, 700, 1000, 50, 100, 400, 700, 1000, 50, 100,\n",
      "                   400, 700, 1000, 50, 100, 400, 700, 1000, 50, 100, 400,\n",
      "                   700, 1000, 50, 100, 400, 700, 1000, 50, 100, 400, 700,\n",
      "                   1000, 50, 100, 400, 700, 1000, 50, 100, 400, 700, 1000,\n",
      "                   50, 100, 400, 700, 1000, 50, 100, 400, 700, 1000, 50,\n",
      "                   100, 400, 700, 1000, 50, 100, 400, 700, 1000, 50, 100,\n",
      "                   400, 700, 1000, 50, 100, 400, 700, 1000, 50, 100, 400,\n",
      "                   700, 1000, 50, 100, 400, 700, 1000],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 12, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 12, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 12, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 12, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 12, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 16, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 16, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 16, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 16, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 16, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 12, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 12, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 12, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 12, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 12, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 16, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 16, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 16, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 16, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 16, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 12, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 12, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 12, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 12, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 12, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 16, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 16, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 16, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 16, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 16, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 12, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 12, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 12, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 12, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 12, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 16, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 16, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 16, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 16, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 16, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 12, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 12, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 12, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 12, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 12, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 16, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 16, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 16, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 16, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 16, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 12, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 12, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 12, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 12, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 12, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 16, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 16, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 16, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 16, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 16, 'n_estimators': 1000}], 'split0_test_score': array([0.80808081, 0.8013468 , 0.80808081, 0.81481481, 0.8047138 ,\n",
      "       0.81818182, 0.83164983, 0.82491582, 0.82491582, 0.82491582,\n",
      "       0.81144781, 0.81144781, 0.80808081, 0.81481481, 0.81818182,\n",
      "       0.80808081, 0.80808081, 0.81144781, 0.8047138 , 0.80808081,\n",
      "       0.81481481, 0.80808081, 0.80808081, 0.80808081, 0.80808081,\n",
      "       0.82154882, 0.81818182, 0.81818182, 0.81818182, 0.81818182,\n",
      "       0.82154882, 0.81818182, 0.81818182, 0.81818182, 0.81818182,\n",
      "       0.82154882, 0.81818182, 0.81818182, 0.81818182, 0.81818182,\n",
      "       0.83164983, 0.82491582, 0.81818182, 0.81818182, 0.81818182,\n",
      "       0.83164983, 0.82828283, 0.81481481, 0.81818182, 0.82154882,\n",
      "       0.81818182, 0.82154882, 0.81144781, 0.81481481, 0.81144781,\n",
      "       0.81818182, 0.82154882, 0.81144781, 0.81481481, 0.81144781,\n",
      "       0.81818182, 0.82154882, 0.81144781, 0.81481481, 0.81144781,\n",
      "       0.81818182, 0.82154882, 0.81144781, 0.81481481, 0.81144781,\n",
      "       0.81818182, 0.82154882, 0.81144781, 0.81481481, 0.81144781,\n",
      "       0.8013468 , 0.80808081, 0.81144781, 0.81144781, 0.80808081,\n",
      "       0.81144781, 0.80808081, 0.82491582, 0.82491582, 0.82491582,\n",
      "       0.80808081, 0.80808081, 0.81144781, 0.81144781, 0.81144781,\n",
      "       0.82828283, 0.81481481, 0.81144781, 0.81481481, 0.81481481,\n",
      "       0.80808081, 0.80808081, 0.81481481, 0.81481481, 0.81144781,\n",
      "       0.80808081, 0.81144781, 0.80808081, 0.81144781, 0.81481481,\n",
      "       0.80808081, 0.81144781, 0.80808081, 0.81144781, 0.81481481,\n",
      "       0.80808081, 0.81144781, 0.80808081, 0.81144781, 0.81481481,\n",
      "       0.81818182, 0.80808081, 0.81144781, 0.81144781, 0.81818182,\n",
      "       0.8047138 , 0.81144781, 0.81144781, 0.81144781, 0.81481481,\n",
      "       0.82828283, 0.82154882, 0.80808081, 0.80808081, 0.80808081,\n",
      "       0.82828283, 0.82154882, 0.80808081, 0.80808081, 0.80808081,\n",
      "       0.82828283, 0.82154882, 0.80808081, 0.80808081, 0.80808081,\n",
      "       0.82828283, 0.82154882, 0.80808081, 0.80808081, 0.80808081,\n",
      "       0.82828283, 0.82154882, 0.80808081, 0.80808081, 0.80808081]), 'split1_test_score': array([0.84511785, 0.85185185, 0.85858586, 0.85521886, 0.85521886,\n",
      "       0.84848485, 0.84175084, 0.85185185, 0.85185185, 0.84848485,\n",
      "       0.85185185, 0.84848485, 0.85521886, 0.85858586, 0.85858586,\n",
      "       0.83164983, 0.83838384, 0.84511785, 0.85185185, 0.85185185,\n",
      "       0.85858586, 0.84511785, 0.83838384, 0.84848485, 0.84511785,\n",
      "       0.82828283, 0.82828283, 0.83838384, 0.83838384, 0.83501684,\n",
      "       0.82828283, 0.82828283, 0.83838384, 0.83838384, 0.83501684,\n",
      "       0.82828283, 0.82828283, 0.83838384, 0.83838384, 0.83501684,\n",
      "       0.83164983, 0.83838384, 0.83164983, 0.84175084, 0.83501684,\n",
      "       0.82828283, 0.83164983, 0.83501684, 0.83501684, 0.83838384,\n",
      "       0.81818182, 0.83501684, 0.83164983, 0.83164983, 0.83164983,\n",
      "       0.81818182, 0.83501684, 0.83164983, 0.83164983, 0.83164983,\n",
      "       0.81818182, 0.83501684, 0.83164983, 0.83164983, 0.83164983,\n",
      "       0.81818182, 0.83501684, 0.83164983, 0.83164983, 0.83164983,\n",
      "       0.81818182, 0.83501684, 0.83164983, 0.83164983, 0.83164983,\n",
      "       0.83838384, 0.84511785, 0.85858586, 0.86195286, 0.86195286,\n",
      "       0.84511785, 0.86195286, 0.84848485, 0.84848485, 0.84848485,\n",
      "       0.84175084, 0.84175084, 0.84511785, 0.84848485, 0.84848485,\n",
      "       0.85185185, 0.85521886, 0.84848485, 0.84848485, 0.85521886,\n",
      "       0.84511785, 0.84848485, 0.84511785, 0.85185185, 0.84511785,\n",
      "       0.83501684, 0.84511785, 0.83501684, 0.83164983, 0.83501684,\n",
      "       0.83501684, 0.84511785, 0.83501684, 0.83164983, 0.83501684,\n",
      "       0.83501684, 0.84511785, 0.83501684, 0.83164983, 0.83501684,\n",
      "       0.82828283, 0.84848485, 0.83838384, 0.83501684, 0.83501684,\n",
      "       0.83501684, 0.84511785, 0.83164983, 0.83838384, 0.83838384,\n",
      "       0.83164983, 0.83164983, 0.83501684, 0.83164983, 0.82828283,\n",
      "       0.83164983, 0.83164983, 0.83501684, 0.83164983, 0.82828283,\n",
      "       0.83164983, 0.83164983, 0.83501684, 0.83164983, 0.82828283,\n",
      "       0.83164983, 0.83164983, 0.83501684, 0.83164983, 0.82828283,\n",
      "       0.83164983, 0.83164983, 0.83501684, 0.83164983, 0.82828283]), 'split2_test_score': array([0.82491582, 0.82828283, 0.83164983, 0.82828283, 0.82491582,\n",
      "       0.84511785, 0.83838384, 0.83164983, 0.83501684, 0.83501684,\n",
      "       0.84175084, 0.84511785, 0.83838384, 0.84175084, 0.83838384,\n",
      "       0.84175084, 0.84511785, 0.84175084, 0.84175084, 0.84175084,\n",
      "       0.82828283, 0.84511785, 0.83838384, 0.83501684, 0.83838384,\n",
      "       0.82154882, 0.82828283, 0.81481481, 0.81481481, 0.82154882,\n",
      "       0.82154882, 0.82828283, 0.81481481, 0.81481481, 0.82154882,\n",
      "       0.82154882, 0.82828283, 0.81481481, 0.81481481, 0.82154882,\n",
      "       0.81818182, 0.81818182, 0.81481481, 0.81481481, 0.81481481,\n",
      "       0.81144781, 0.80808081, 0.81818182, 0.81481481, 0.81818182,\n",
      "       0.82491582, 0.80808081, 0.7979798 , 0.7979798 , 0.7979798 ,\n",
      "       0.82491582, 0.80808081, 0.7979798 , 0.7979798 , 0.7979798 ,\n",
      "       0.82491582, 0.80808081, 0.7979798 , 0.7979798 , 0.7979798 ,\n",
      "       0.82491582, 0.80808081, 0.7979798 , 0.7979798 , 0.7979798 ,\n",
      "       0.82491582, 0.80808081, 0.7979798 , 0.7979798 , 0.7979798 ,\n",
      "       0.83838384, 0.82828283, 0.82828283, 0.82491582, 0.82154882,\n",
      "       0.82828283, 0.83838384, 0.84175084, 0.83501684, 0.83164983,\n",
      "       0.83838384, 0.84511785, 0.83501684, 0.84511785, 0.83838384,\n",
      "       0.83501684, 0.83501684, 0.84175084, 0.84175084, 0.84175084,\n",
      "       0.84175084, 0.85185185, 0.84175084, 0.83838384, 0.83838384,\n",
      "       0.81818182, 0.81818182, 0.81144781, 0.81481481, 0.81818182,\n",
      "       0.81818182, 0.81818182, 0.81144781, 0.81481481, 0.81818182,\n",
      "       0.81818182, 0.81818182, 0.81144781, 0.81481481, 0.81818182,\n",
      "       0.82154882, 0.82491582, 0.82154882, 0.82491582, 0.82491582,\n",
      "       0.83164983, 0.82154882, 0.82828283, 0.82154882, 0.82154882,\n",
      "       0.81818182, 0.8013468 , 0.7979798 , 0.7979798 , 0.7979798 ,\n",
      "       0.81818182, 0.8013468 , 0.7979798 , 0.7979798 , 0.7979798 ,\n",
      "       0.81818182, 0.8013468 , 0.7979798 , 0.7979798 , 0.7979798 ,\n",
      "       0.81818182, 0.8013468 , 0.7979798 , 0.7979798 , 0.7979798 ,\n",
      "       0.81818182, 0.8013468 , 0.7979798 , 0.7979798 , 0.7979798 ]), 'mean_test_score': array([0.82603816, 0.82716049, 0.83277217, 0.83277217, 0.82828283,\n",
      "       0.8372615 , 0.8372615 , 0.83613917, 0.8372615 , 0.83613917,\n",
      "       0.83501684, 0.83501684, 0.8338945 , 0.83838384, 0.83838384,\n",
      "       0.82716049, 0.8305275 , 0.83277217, 0.83277217, 0.8338945 ,\n",
      "       0.8338945 , 0.83277217, 0.82828283, 0.8305275 , 0.8305275 ,\n",
      "       0.82379349, 0.82491582, 0.82379349, 0.82379349, 0.82491582,\n",
      "       0.82379349, 0.82491582, 0.82379349, 0.82379349, 0.82491582,\n",
      "       0.82379349, 0.82491582, 0.82379349, 0.82379349, 0.82491582,\n",
      "       0.82716049, 0.82716049, 0.82154882, 0.82491582, 0.82267116,\n",
      "       0.82379349, 0.82267116, 0.82267116, 0.82267116, 0.82603816,\n",
      "       0.82042649, 0.82154882, 0.81369248, 0.81481481, 0.81369248,\n",
      "       0.82042649, 0.82154882, 0.81369248, 0.81481481, 0.81369248,\n",
      "       0.82042649, 0.82154882, 0.81369248, 0.81481481, 0.81369248,\n",
      "       0.82042649, 0.82154882, 0.81369248, 0.81481481, 0.81369248,\n",
      "       0.82042649, 0.82154882, 0.81369248, 0.81481481, 0.81369248,\n",
      "       0.82603816, 0.82716049, 0.83277217, 0.83277217, 0.8305275 ,\n",
      "       0.82828283, 0.83613917, 0.83838384, 0.83613917, 0.83501684,\n",
      "       0.82940516, 0.83164983, 0.8305275 , 0.83501684, 0.83277217,\n",
      "       0.83838384, 0.83501684, 0.8338945 , 0.83501684, 0.8372615 ,\n",
      "       0.83164983, 0.83613917, 0.8338945 , 0.83501684, 0.83164983,\n",
      "       0.82042649, 0.82491582, 0.81818182, 0.81930415, 0.82267116,\n",
      "       0.82042649, 0.82491582, 0.81818182, 0.81930415, 0.82267116,\n",
      "       0.82042649, 0.82491582, 0.81818182, 0.81930415, 0.82267116,\n",
      "       0.82267116, 0.82716049, 0.82379349, 0.82379349, 0.82603816,\n",
      "       0.82379349, 0.82603816, 0.82379349, 0.82379349, 0.82491582,\n",
      "       0.82603816, 0.81818182, 0.81369248, 0.81257015, 0.81144781,\n",
      "       0.82603816, 0.81818182, 0.81369248, 0.81257015, 0.81144781,\n",
      "       0.82603816, 0.81818182, 0.81369248, 0.81257015, 0.81144781,\n",
      "       0.82603816, 0.81818182, 0.81369248, 0.81257015, 0.81144781,\n",
      "       0.82603816, 0.81818182, 0.81369248, 0.81257015, 0.81144781]), 'std_test_score': array([0.01514112, 0.02063387, 0.02063387, 0.01679756, 0.0207556 ,\n",
      "       0.01356122, 0.00419939, 0.01144561, 0.01111054, 0.00965469,\n",
      "       0.01716842, 0.01672241, 0.01950409, 0.01802736, 0.01649488,\n",
      "       0.01410753, 0.01610853, 0.01514112, 0.02026428, 0.01871305,\n",
      "       0.01830472, 0.01745943, 0.01428499, 0.01679756, 0.01610853,\n",
      "       0.00317444, 0.00476166, 0.0104081 , 0.0104081 , 0.00727356,\n",
      "       0.00317444, 0.00476166, 0.0104081 , 0.0104081 , 0.00727356,\n",
      "       0.00317444, 0.00476166, 0.0104081 , 0.0104081 , 0.00727356,\n",
      "       0.00634888, 0.00839878, 0.00727356, 0.01198325, 0.00883727,\n",
      "       0.00883727, 0.0104081 , 0.00883727, 0.00883727, 0.00883727,\n",
      "       0.00317444, 0.01099659, 0.01383707, 0.01374573, 0.01383707,\n",
      "       0.00317444, 0.01099659, 0.01383707, 0.01374573, 0.01383707,\n",
      "       0.00317444, 0.01099659, 0.01383707, 0.01374573, 0.01383707,\n",
      "       0.00317444, 0.01099659, 0.01383707, 0.01374573, 0.01383707,\n",
      "       0.00317444, 0.01099659, 0.01383707, 0.01374573, 0.01383707,\n",
      "       0.01745943, 0.01514112, 0.01950409, 0.02135387, 0.02289122,\n",
      "       0.01374573, 0.02205037, 0.00991219, 0.00965469, 0.00991219,\n",
      "       0.01514112, 0.01672241, 0.01410753, 0.01672241, 0.01563231,\n",
      "       0.00991219, 0.01649488, 0.01610853, 0.01454712, 0.01679756,\n",
      "       0.01672241, 0.01988782, 0.01356122, 0.0153066 , 0.01454712,\n",
      "       0.01111054, 0.01454712, 0.01198325, 0.00883727, 0.00883727,\n",
      "       0.01111054, 0.01454712, 0.01198325, 0.00883727, 0.00883727,\n",
      "       0.01111054, 0.01454712, 0.01198325, 0.00883727, 0.00883727,\n",
      "       0.00419939, 0.01657107, 0.01111054, 0.00965469, 0.00691853,\n",
      "       0.01356122, 0.01410753, 0.00883727, 0.01111054, 0.00991219,\n",
      "       0.00572281, 0.01259817, 0.01563231, 0.01410753, 0.01259817,\n",
      "       0.00572281, 0.01259817, 0.01563231, 0.01410753, 0.01259817,\n",
      "       0.00572281, 0.01259817, 0.01563231, 0.01410753, 0.01259817,\n",
      "       0.00572281, 0.01259817, 0.01563231, 0.01410753, 0.01259817,\n",
      "       0.00572281, 0.01259817, 0.01563231, 0.01410753, 0.01259817]), 'rank_test_score': array([ 52,  46,  26,  26,  43,   5,   5,   9,   5,   9,  14,  14,  21,\n",
      "         1,   1,  46,  37,  26,  26,  21,  21,  26,  43,  37,  37,  73,\n",
      "        62,  73,  73,  62,  73,  62,  73,  73,  62,  73,  62,  73,  73,\n",
      "        62,  46,  46,  96,  62,  88,  73,  88,  88,  88,  52, 102,  96,\n",
      "       126, 121, 126, 102,  96, 126, 121, 126, 102,  96, 126, 121, 126,\n",
      "       102,  96, 126, 121, 126, 102,  96, 126, 121, 126,  52,  46,  26,\n",
      "        26,  37,  43,   9,   1,   9,  14,  42,  34,  37,  14,  26,   1,\n",
      "        14,  21,  14,   5,  34,   9,  21,  14,  34, 102,  62, 113, 110,\n",
      "        88, 102,  62, 113, 110,  88, 102,  62, 113, 110,  88,  88,  46,\n",
      "        73,  73,  52,  73,  52,  73,  73,  62,  52, 113, 126, 141, 146,\n",
      "        52, 113, 126, 141, 146,  52, 113, 126, 141, 146,  52, 113, 126,\n",
      "       141, 146,  52, 113, 126, 141, 146], dtype=int32), 'split0_train_score': array([0.9983165 , 0.9983165 , 0.9983165 , 0.9983165 , 0.9983165 ,\n",
      "       0.96969697, 0.97138047, 0.96969697, 0.96969697, 0.97138047,\n",
      "       0.91750842, 0.92424242, 0.92592593, 0.92424242, 0.92929293,\n",
      "       0.91077441, 0.91414141, 0.91582492, 0.91245791, 0.91245791,\n",
      "       0.90740741, 0.90909091, 0.90909091, 0.90740741, 0.90740741,\n",
      "       0.88383838, 0.88383838, 0.88383838, 0.88888889, 0.88720539,\n",
      "       0.88383838, 0.88383838, 0.88383838, 0.88888889, 0.88720539,\n",
      "       0.88383838, 0.88383838, 0.88383838, 0.88888889, 0.88720539,\n",
      "       0.88215488, 0.88047138, 0.88552189, 0.88552189, 0.88720539,\n",
      "       0.87373737, 0.88047138, 0.88047138, 0.88383838, 0.88215488,\n",
      "       0.85521886, 0.85858586, 0.87878788, 0.87710438, 0.87542088,\n",
      "       0.85521886, 0.85858586, 0.87878788, 0.87710438, 0.87542088,\n",
      "       0.85521886, 0.85858586, 0.87878788, 0.87710438, 0.87542088,\n",
      "       0.85521886, 0.85858586, 0.87878788, 0.87710438, 0.87542088,\n",
      "       0.85521886, 0.85858586, 0.87878788, 0.87710438, 0.87542088,\n",
      "       0.9983165 , 0.9983165 , 0.9983165 , 0.9983165 , 0.9983165 ,\n",
      "       0.96969697, 0.97138047, 0.97306397, 0.97306397, 0.97138047,\n",
      "       0.91750842, 0.92424242, 0.92760943, 0.93097643, 0.92929293,\n",
      "       0.90572391, 0.91245791, 0.91750842, 0.91919192, 0.92087542,\n",
      "       0.9040404 , 0.9040404 , 0.90740741, 0.90909091, 0.90740741,\n",
      "       0.88215488, 0.88888889, 0.88720539, 0.88552189, 0.88552189,\n",
      "       0.88215488, 0.88888889, 0.88720539, 0.88552189, 0.88552189,\n",
      "       0.88215488, 0.88888889, 0.88720539, 0.88552189, 0.88552189,\n",
      "       0.88215488, 0.88552189, 0.88383838, 0.88552189, 0.88383838,\n",
      "       0.88047138, 0.88383838, 0.88215488, 0.88552189, 0.88552189,\n",
      "       0.85521886, 0.85690236, 0.87037037, 0.86700337, 0.87037037,\n",
      "       0.85521886, 0.85690236, 0.87037037, 0.86700337, 0.87037037,\n",
      "       0.85521886, 0.85690236, 0.87037037, 0.86700337, 0.87037037,\n",
      "       0.85521886, 0.85690236, 0.87037037, 0.86700337, 0.87037037,\n",
      "       0.85521886, 0.85690236, 0.87037037, 0.86700337, 0.87037037]), 'split1_train_score': array([0.99326599, 0.996633  , 0.996633  , 0.996633  , 0.996633  ,\n",
      "       0.96464646, 0.96127946, 0.95959596, 0.96296296, 0.96127946,\n",
      "       0.91077441, 0.91245791, 0.91582492, 0.91582492, 0.91582492,\n",
      "       0.89057239, 0.8973064 , 0.9023569 , 0.9040404 , 0.90572391,\n",
      "       0.88047138, 0.88888889, 0.89225589, 0.89225589, 0.89393939,\n",
      "       0.87542088, 0.88047138, 0.87373737, 0.87373737, 0.87542088,\n",
      "       0.87542088, 0.88047138, 0.87373737, 0.87373737, 0.87542088,\n",
      "       0.87542088, 0.88047138, 0.87373737, 0.87373737, 0.87542088,\n",
      "       0.86868687, 0.86531987, 0.87037037, 0.86531987, 0.86868687,\n",
      "       0.85690236, 0.86026936, 0.86531987, 0.86363636, 0.86531987,\n",
      "       0.83333333, 0.83164983, 0.82996633, 0.82996633, 0.82996633,\n",
      "       0.83333333, 0.83164983, 0.82996633, 0.82996633, 0.82996633,\n",
      "       0.83333333, 0.83164983, 0.82996633, 0.82996633, 0.82996633,\n",
      "       0.83333333, 0.83164983, 0.82996633, 0.82996633, 0.82996633,\n",
      "       0.83333333, 0.83164983, 0.82996633, 0.82996633, 0.82996633,\n",
      "       0.99326599, 0.996633  , 0.996633  , 0.996633  , 0.996633  ,\n",
      "       0.96464646, 0.96464646, 0.96464646, 0.96464646, 0.96632997,\n",
      "       0.90740741, 0.90909091, 0.91582492, 0.91414141, 0.91414141,\n",
      "       0.90572391, 0.9040404 , 0.91245791, 0.91245791, 0.90909091,\n",
      "       0.88720539, 0.88888889, 0.8956229 , 0.89393939, 0.8956229 ,\n",
      "       0.86868687, 0.87037037, 0.87373737, 0.87037037, 0.87205387,\n",
      "       0.86868687, 0.87037037, 0.87373737, 0.87037037, 0.87205387,\n",
      "       0.86868687, 0.87037037, 0.87373737, 0.87037037, 0.87205387,\n",
      "       0.87037037, 0.87037037, 0.87205387, 0.86531987, 0.87037037,\n",
      "       0.86363636, 0.85690236, 0.86531987, 0.86363636, 0.86868687,\n",
      "       0.83333333, 0.83670034, 0.83164983, 0.82996633, 0.82996633,\n",
      "       0.83333333, 0.83670034, 0.83164983, 0.82996633, 0.82996633,\n",
      "       0.83333333, 0.83670034, 0.83164983, 0.82996633, 0.82996633,\n",
      "       0.83333333, 0.83670034, 0.83164983, 0.82996633, 0.82996633,\n",
      "       0.83333333, 0.83670034, 0.83164983, 0.82996633, 0.82996633]), 'split2_train_score': array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       0.95622896, 0.95622896, 0.95454545, 0.95454545, 0.95286195,\n",
      "       0.8989899 , 0.9023569 , 0.8989899 , 0.9006734 , 0.8989899 ,\n",
      "       0.88888889, 0.88215488, 0.88888889, 0.89225589, 0.89393939,\n",
      "       0.87878788, 0.87710438, 0.88047138, 0.87710438, 0.87542088,\n",
      "       0.86026936, 0.85690236, 0.85858586, 0.85858586, 0.85858586,\n",
      "       0.86026936, 0.85690236, 0.85858586, 0.85858586, 0.85858586,\n",
      "       0.86026936, 0.85690236, 0.85858586, 0.85858586, 0.85858586,\n",
      "       0.85858586, 0.85858586, 0.85858586, 0.85690236, 0.85858586,\n",
      "       0.85690236, 0.85690236, 0.85858586, 0.85858586, 0.85690236,\n",
      "       0.84680135, 0.84175084, 0.83670034, 0.83838384, 0.83838384,\n",
      "       0.84680135, 0.84175084, 0.83670034, 0.83838384, 0.83838384,\n",
      "       0.84680135, 0.84175084, 0.83670034, 0.83838384, 0.83838384,\n",
      "       0.84680135, 0.84175084, 0.83670034, 0.83838384, 0.83838384,\n",
      "       0.84680135, 0.84175084, 0.83670034, 0.83838384, 0.83838384,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       0.96296296, 0.96127946, 0.95454545, 0.96127946, 0.95622896,\n",
      "       0.8973064 , 0.90572391, 0.9006734 , 0.8989899 , 0.9006734 ,\n",
      "       0.88383838, 0.89057239, 0.8956229 , 0.8956229 , 0.8973064 ,\n",
      "       0.88552189, 0.88215488, 0.87542088, 0.88383838, 0.88047138,\n",
      "       0.86195286, 0.85690236, 0.86026936, 0.86026936, 0.86026936,\n",
      "       0.86195286, 0.85690236, 0.86026936, 0.86026936, 0.86026936,\n",
      "       0.86195286, 0.85690236, 0.86026936, 0.86026936, 0.86026936,\n",
      "       0.86026936, 0.85521886, 0.85858586, 0.85690236, 0.85690236,\n",
      "       0.85690236, 0.85185185, 0.85690236, 0.85690236, 0.85690236,\n",
      "       0.84175084, 0.84006734, 0.84006734, 0.83838384, 0.84006734,\n",
      "       0.84175084, 0.84006734, 0.84006734, 0.83838384, 0.84006734,\n",
      "       0.84175084, 0.84006734, 0.84006734, 0.83838384, 0.84006734,\n",
      "       0.84175084, 0.84006734, 0.84006734, 0.83838384, 0.84006734,\n",
      "       0.84175084, 0.84006734, 0.84006734, 0.83838384, 0.84006734]), 'mean_train_score': array([0.99719416, 0.9983165 , 0.9983165 , 0.9983165 , 0.9983165 ,\n",
      "       0.96352413, 0.96296296, 0.96127946, 0.9624018 , 0.96184063,\n",
      "       0.90909091, 0.91301908, 0.91358025, 0.91358025, 0.91470258,\n",
      "       0.89674523, 0.89786756, 0.9023569 , 0.90291807, 0.9040404 ,\n",
      "       0.88888889, 0.89169473, 0.89393939, 0.89225589, 0.89225589,\n",
      "       0.87317621, 0.87373737, 0.87205387, 0.87373737, 0.87373737,\n",
      "       0.87317621, 0.87373737, 0.87205387, 0.87373737, 0.87373737,\n",
      "       0.87317621, 0.87373737, 0.87205387, 0.87373737, 0.87373737,\n",
      "       0.8698092 , 0.8681257 , 0.8714927 , 0.86924804, 0.8714927 ,\n",
      "       0.86251403, 0.86588103, 0.8681257 , 0.86868687, 0.8681257 ,\n",
      "       0.84511785, 0.84399551, 0.84848485, 0.84848485, 0.84792368,\n",
      "       0.84511785, 0.84399551, 0.84848485, 0.84848485, 0.84792368,\n",
      "       0.84511785, 0.84399551, 0.84848485, 0.84848485, 0.84792368,\n",
      "       0.84511785, 0.84399551, 0.84848485, 0.84848485, 0.84792368,\n",
      "       0.84511785, 0.84399551, 0.84848485, 0.84848485, 0.84792368,\n",
      "       0.99719416, 0.9983165 , 0.9983165 , 0.9983165 , 0.9983165 ,\n",
      "       0.9657688 , 0.9657688 , 0.9640853 , 0.96632997, 0.96464646,\n",
      "       0.90740741, 0.91301908, 0.91470258, 0.91470258, 0.91470258,\n",
      "       0.89842873, 0.9023569 , 0.90852974, 0.90909091, 0.90909091,\n",
      "       0.89225589, 0.89169473, 0.89281706, 0.8956229 , 0.89450056,\n",
      "       0.87093154, 0.87205387, 0.87373737, 0.87205387, 0.87261504,\n",
      "       0.87093154, 0.87205387, 0.87373737, 0.87205387, 0.87261504,\n",
      "       0.87093154, 0.87205387, 0.87373737, 0.87205387, 0.87261504,\n",
      "       0.87093154, 0.87037037, 0.8714927 , 0.86924804, 0.87037037,\n",
      "       0.86700337, 0.86419753, 0.8681257 , 0.86868687, 0.87037037,\n",
      "       0.84343434, 0.84455668, 0.84736251, 0.84511785, 0.84680135,\n",
      "       0.84343434, 0.84455668, 0.84736251, 0.84511785, 0.84680135,\n",
      "       0.84343434, 0.84455668, 0.84736251, 0.84511785, 0.84680135,\n",
      "       0.84343434, 0.84455668, 0.84736251, 0.84511785, 0.84680135,\n",
      "       0.84343434, 0.84455668, 0.84736251, 0.84511785, 0.84680135]), 'std_train_score': array([0.0028614 , 0.00137457, 0.00137457, 0.00137457, 0.00137457,\n",
      "       0.00555527, 0.00629909, 0.00629909, 0.00619829, 0.00757056,\n",
      "       0.0076533 , 0.00894353, 0.01111054, 0.00975205, 0.01239659,\n",
      "       0.00994391, 0.01306447, 0.01099659, 0.00828553, 0.0076533 ,\n",
      "       0.01311259, 0.01320831, 0.01174436, 0.01237116, 0.01311259,\n",
      "       0.00975205, 0.01198325, 0.0103778 , 0.01237116, 0.01174436,\n",
      "       0.00975205, 0.01198325, 0.0103778 , 0.01237116, 0.01174436,\n",
      "       0.00975205, 0.01198325, 0.0103778 , 0.01237116, 0.01174436,\n",
      "       0.00965469, 0.00915236, 0.01102519, 0.0120095 , 0.01185113,\n",
      "       0.0079361 , 0.0104081 , 0.00915236, 0.01091034, 0.01049848,\n",
      "       0.00901368, 0.01111054, 0.02160312, 0.02052676, 0.01974479,\n",
      "       0.00901368, 0.01111054, 0.02160312, 0.02052676, 0.01974479,\n",
      "       0.00901368, 0.01111054, 0.02160312, 0.02052676, 0.01974479,\n",
      "       0.00901368, 0.01111054, 0.02160312, 0.02052676, 0.01974479,\n",
      "       0.00901368, 0.01111054, 0.02160312, 0.02052676, 0.01974479,\n",
      "       0.0028614 , 0.00137457, 0.00137457, 0.00137457, 0.00137457,\n",
      "       0.0028614 , 0.00419939, 0.00757056, 0.00495609, 0.00629909,\n",
      "       0.00824744, 0.00805426, 0.01102519, 0.01306447, 0.01169061,\n",
      "       0.01031693, 0.00901368, 0.00935653, 0.00991219, 0.00962201,\n",
      "       0.0083612 , 0.00915236, 0.01320831, 0.0103778 , 0.01102519,\n",
      "       0.00839878, 0.01311259, 0.01099659, 0.0103778 , 0.01031693,\n",
      "       0.00839878, 0.01311259, 0.01099659, 0.0103778 , 0.01031693,\n",
      "       0.00839878, 0.01311259, 0.01099659, 0.0103778 , 0.01031693,\n",
      "       0.00894353, 0.01237116, 0.01031693, 0.0120095 , 0.01099659,\n",
      "       0.00991219, 0.0140404 , 0.01049848, 0.01221748, 0.01174436,\n",
      "       0.00901368, 0.00883727, 0.01662798, 0.01585235, 0.01716842,\n",
      "       0.00901368, 0.00883727, 0.01662798, 0.01585235, 0.01716842,\n",
      "       0.00901368, 0.00883727, 0.01662798, 0.01585235, 0.01716842,\n",
      "       0.00901368, 0.00883727, 0.01662798, 0.01585235, 0.01716842,\n",
      "       0.00901368, 0.00883727, 0.01662798, 0.01585235, 0.01716842])}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(max_features='auto', oob_score=True, random_state=1, n_jobs=3)\n",
    "\n",
    "param_grid = { \"criterion\" : [\"gini\", \"entropy\"], \n",
    "              \"min_samples_leaf\" : [1, 5, 10], \n",
    "              \"min_samples_split\" : [2, 4, 10, 12, 16],\n",
    "              \"n_estimators\": [50, 100, 400, 700, 1000]}\n",
    "\n",
    "gs = GridSearchCV(estimator=rf, param_grid=param_grid, scoring='accuracy', \n",
    "                  cv=3, n_jobs=6, verbose=1)\n",
    "\n",
    "gs = gs.fit(train.iloc[:, 1:], train.iloc[:, 0])\n",
    "\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)\n",
    "print(gs.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8294\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(criterion='gini', \n",
    "                             n_estimators=700,\n",
    "                             min_samples_split=10,\n",
    "                             min_samples_leaf=1,\n",
    "                             max_features='auto',\n",
    "                             oob_score=True,\n",
    "                             random_state=1,\n",
    "                             n_jobs=-1)\n",
    "rf.fit(train.iloc[:, 1:], train.iloc[:, 0])\n",
    "print(\"%.4f\" % rf.oob_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 700}\n",
      "Mean cross-validated score of the best_estimator:  0.8383838383838383\n",
      "\n",
      "Rank|Score(std)|Params ['criterion', 'min_samples_leaf', 'min_samples_split', 'n_estimators']\n",
      "1|0.838384(std:0.018027)|['gini', 1, 10, 700]\n",
      "1|0.838384(std:0.016495)|['gini', 1, 10, 1000]\n",
      "1|0.838384(std:0.009912)|['entropy', 1, 4, 400]\n",
      "1|0.838384(std:0.009912)|['entropy', 1, 12, 50]\n",
      "5|0.837262(std:0.013561)|['gini', 1, 4, 50]\n",
      "5|0.837262(std:0.004199)|['gini', 1, 4, 100]\n",
      "5|0.837262(std:0.011111)|['gini', 1, 4, 700]\n",
      "5|0.837262(std:0.016798)|['entropy', 1, 12, 1000]\n",
      "9|0.836139(std:0.011446)|['gini', 1, 4, 400]\n",
      "9|0.836139(std:0.009655)|['gini', 1, 4, 1000]\n",
      "9|0.836139(std:0.022050)|['entropy', 1, 4, 100]\n",
      "9|0.836139(std:0.009655)|['entropy', 1, 4, 700]\n",
      "9|0.836139(std:0.019888)|['entropy', 1, 16, 100]\n"
     ]
    }
   ],
   "source": [
    "print(\"best parameters:\", gs.best_params_)\n",
    "print(\"Mean cross-validated score of the best_estimator: \", gs.best_score_)\n",
    "print(\"\")\n",
    "report2(gs.cv_results_, n_top=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Survived', 'Age', 'Fare', 'Name_Len', 'Age_Null_Flag',\n",
       "       'Cabin_num_(1.999, 28.667]', 'Cabin_num_(28.667, 65.667]',\n",
       "       'Cabin_num_(65.667, 148.0]', 'Ticket_Len', 'Pclass_3', 'Pclass_1',\n",
       "       'Pclass_2', 'Sex_male', 'Sex_female', 'Embarked_S', 'Embarked_C',\n",
       "       'Embarked_Q', 'Ticket_Lett_A', 'Ticket_Lett_P', 'Ticket_Lett_S',\n",
       "       'Ticket_Lett_1', 'Ticket_Lett_3', 'Ticket_Lett_2', 'Ticket_Lett_C',\n",
       "       'Ticket_Lett_Low_ticket', 'Ticket_Lett_Other_ticket', 'Cabin_Letter_n',\n",
       "       'Cabin_Letter_C', 'Cabin_Letter_E', 'Cabin_Letter_G', 'Cabin_Letter_D',\n",
       "       'Cabin_Letter_A', 'Cabin_Letter_B', 'Cabin_Letter_F', 'Name_Title_Mr.',\n",
       "       'Name_Title_Mrs.', 'Name_Title_Miss.', 'Name_Title_Master.',\n",
       "       'Name_Title_Rev.', 'Name_Title_Dr.', 'Name_Title_Ms.',\n",
       "       'Name_Title_Col.', 'Fam_Size_Nuclear', 'Fam_Size_Solo', 'Fam_Size_Big'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Sex_male</td>\n",
       "      <td>0.111215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Pclass_2</td>\n",
       "      <td>0.109769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Cabin_Letter_F</td>\n",
       "      <td>0.109746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.088209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fare</td>\n",
       "      <td>0.087904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Survived</td>\n",
       "      <td>0.078651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ticket_Len</td>\n",
       "      <td>0.043268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Name_Title_Mrs.</td>\n",
       "      <td>0.031292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cabin_num_(65.667, 148.0]</td>\n",
       "      <td>0.031079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Name_Title_Mr.</td>\n",
       "      <td>0.028852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Ticket_Lett_Other_ticket</td>\n",
       "      <td>0.027893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Fam_Size_Solo</td>\n",
       "      <td>0.025199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Name_Title_Col.</td>\n",
       "      <td>0.022704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pclass_3</td>\n",
       "      <td>0.021810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Ticket_Lett_S</td>\n",
       "      <td>0.017999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Ticket_Lett_1</td>\n",
       "      <td>0.012902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Pclass_1</td>\n",
       "      <td>0.012345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Name_Title_Miss.</td>\n",
       "      <td>0.012098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Ticket_Lett_C</td>\n",
       "      <td>0.011723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sex_female</td>\n",
       "      <td>0.011546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Fam_Size_Nuclear</td>\n",
       "      <td>0.010619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Age_Null_Flag</td>\n",
       "      <td>0.009380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Embarked_S</td>\n",
       "      <td>0.008760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Name_Len</td>\n",
       "      <td>0.008420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Cabin_Letter_C</td>\n",
       "      <td>0.007851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Ticket_Lett_3</td>\n",
       "      <td>0.007336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Embarked_C</td>\n",
       "      <td>0.005978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Ticket_Lett_P</td>\n",
       "      <td>0.005167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cabin_num_(1.999, 28.667]</td>\n",
       "      <td>0.005064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Cabin_Letter_G</td>\n",
       "      <td>0.004613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Cabin_Letter_n</td>\n",
       "      <td>0.003985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cabin_num_(28.667, 65.667]</td>\n",
       "      <td>0.003982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Ticket_Lett_A</td>\n",
       "      <td>0.003618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Ticket_Lett_2</td>\n",
       "      <td>0.003242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Embarked_Q</td>\n",
       "      <td>0.003158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Cabin_Letter_A</td>\n",
       "      <td>0.003157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Name_Title_Master.</td>\n",
       "      <td>0.002610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Cabin_Letter_D</td>\n",
       "      <td>0.001813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Name_Title_Rev.</td>\n",
       "      <td>0.001495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Cabin_Letter_B</td>\n",
       "      <td>0.001348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Cabin_Letter_E</td>\n",
       "      <td>0.001016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Ticket_Lett_Low_ticket</td>\n",
       "      <td>0.000569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Name_Title_Ms.</td>\n",
       "      <td>0.000430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Name_Title_Dr.</td>\n",
       "      <td>0.000184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Fam_Size_Big</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      variable  importance\n",
       "12                    Sex_male    0.111215\n",
       "11                    Pclass_2    0.109769\n",
       "33              Cabin_Letter_F    0.109746\n",
       "1                          Age    0.088209\n",
       "2                         Fare    0.087904\n",
       "0                     Survived    0.078651\n",
       "8                   Ticket_Len    0.043268\n",
       "35             Name_Title_Mrs.    0.031292\n",
       "7    Cabin_num_(65.667, 148.0]    0.031079\n",
       "34              Name_Title_Mr.    0.028852\n",
       "25    Ticket_Lett_Other_ticket    0.027893\n",
       "43               Fam_Size_Solo    0.025199\n",
       "41             Name_Title_Col.    0.022704\n",
       "9                     Pclass_3    0.021810\n",
       "19               Ticket_Lett_S    0.017999\n",
       "20               Ticket_Lett_1    0.012902\n",
       "10                    Pclass_1    0.012345\n",
       "36            Name_Title_Miss.    0.012098\n",
       "23               Ticket_Lett_C    0.011723\n",
       "13                  Sex_female    0.011546\n",
       "42            Fam_Size_Nuclear    0.010619\n",
       "4                Age_Null_Flag    0.009380\n",
       "14                  Embarked_S    0.008760\n",
       "3                     Name_Len    0.008420\n",
       "27              Cabin_Letter_C    0.007851\n",
       "21               Ticket_Lett_3    0.007336\n",
       "15                  Embarked_C    0.005978\n",
       "18               Ticket_Lett_P    0.005167\n",
       "5    Cabin_num_(1.999, 28.667]    0.005064\n",
       "29              Cabin_Letter_G    0.004613\n",
       "26              Cabin_Letter_n    0.003985\n",
       "6   Cabin_num_(28.667, 65.667]    0.003982\n",
       "17               Ticket_Lett_A    0.003618\n",
       "22               Ticket_Lett_2    0.003242\n",
       "16                  Embarked_Q    0.003158\n",
       "31              Cabin_Letter_A    0.003157\n",
       "37          Name_Title_Master.    0.002610\n",
       "30              Cabin_Letter_D    0.001813\n",
       "38             Name_Title_Rev.    0.001495\n",
       "32              Cabin_Letter_B    0.001348\n",
       "28              Cabin_Letter_E    0.001016\n",
       "24      Ticket_Lett_Low_ticket    0.000569\n",
       "40              Name_Title_Ms.    0.000430\n",
       "39              Name_Title_Dr.    0.000184\n",
       "44                Fam_Size_Big         NaN"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat((pd.DataFrame(train.columns, columns = ['variable']), \n",
    "           pd.DataFrame(gs.best_estimator_.feature_importances_, columns = ['importance'])), \n",
    "          axis = 1).sort_values(by='importance', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get passenger id\n",
    "_test = pd.read_csv(os.path.join('../input', 'test.csv'))\n",
    "\n",
    "y_pred = gs.best_estimator_.predict(test).astype(int)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": _test[\"PassengerId\"].astype(int),\n",
    "        \"Survived\": y_pred\n",
    "    })\n",
    "submission.to_csv('../output/_titanic-random-forest-82-78.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# original\n",
    "\n",
    "https://www.kaggle.com/konstantinmasich/titanic-0-82-0-83/\n",
    "\n",
    "# points\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# original\n",
    "\n",
    "https://www.kaggle.com/francksylla/titanic-machine-learning-from-disaster\n",
    "\n",
    "# points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
