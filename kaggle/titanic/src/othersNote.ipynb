{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# original\n",
    "\n",
    "https://www.kaggle.com/yuanxuan/titanic-random-forest-82-78/notebook\n",
    "\n",
    "# special\n",
    "\n",
    "- almost all are one hot encoding\n",
    "- many features\n",
    "\n",
    "# score\n",
    "\n",
    "cv score for all training set is not so high. 0.8383838383838383\n",
    "it is below my current best score 2018/04/01.\n",
    "\n",
    "\n",
    "# columns\n",
    "\n",
    "Index(['Survived', 'Age', 'Fare', 'Name_Len', 'Age_Null_Flag',\n",
    "       'Cabin_num_(1.999, 28.667]', 'Cabin_num_(28.667, 65.667]',\n",
    "       'Cabin_num_(65.667, 148.0]', 'Ticket_Len', 'Pclass_3', 'Pclass_1',\n",
    "       'Pclass_2', 'Sex_male', 'Sex_female', 'Embarked_S', 'Embarked_C',\n",
    "       'Embarked_Q', 'Ticket_Lett_A', 'Ticket_Lett_P', 'Ticket_Lett_S',\n",
    "       'Ticket_Lett_1', 'Ticket_Lett_3', 'Ticket_Lett_2', 'Ticket_Lett_C',\n",
    "       'Ticket_Lett_Low_ticket', 'Ticket_Lett_Other_ticket', 'Cabin_Letter_n',\n",
    "       'Cabin_Letter_C', 'Cabin_Letter_E', 'Cabin_Letter_G', 'Cabin_Letter_D',\n",
    "       'Cabin_Letter_A', 'Cabin_Letter_B', 'Cabin_Letter_F', 'Name_Title_Mr.',\n",
    "       'Name_Title_Mrs.', 'Name_Title_Miss.', 'Name_Title_Master.',\n",
    "       'Name_Title_Rev.', 'Name_Title_Dr.', 'Name_Title_Ms.',\n",
    "       'Name_Title_Col.', 'Fam_Size_Nuclear', 'Fam_Size_Solo', 'Fam_Size_Big'],\n",
    "      dtype='object')\n",
    "\n",
    "# else\n",
    "\n",
    "\tvariable\timportance\n",
    "12\tSex_female\t0.111215\n",
    "11\tSex_male\t0.109769\n",
    "33\tName_Title_Mr.\t0.109746\n",
    "1\tFare\t0.088209\n",
    "2\tName_Len\t0.087904\n",
    "0\tAge\t0.078651\n",
    "8\tPclass_3\t0.043268\n",
    "35\tName_Title_Miss.\t0.031292\n",
    "7\tTicket_Len\t0.031079\n",
    "34\tName_Title_Mrs.\t0.028852\n",
    "25\tCabin_Letter_n\t0.027893\n",
    "43\tFam_Size_Big\t0.025199\n",
    "41\tFam_Size_Nuclear\t0.022704\n",
    "9\tPclass_1\t0.021810\n",
    "19\tTicket_Lett_1\t0.017999\n",
    "20\tTicket_Lett_3\t0.012902\n",
    "10\tPclass_2\t0.012345\n",
    "36\tName_Title_Master.\t0.012098\n",
    "23\tTicket_Lett_Low_ticket\t0.011723\n",
    "13\tEmbarked_S\t0.011546\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# data analysis and wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# train, test, validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "\n",
    "# scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "# decomposition\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "# feature engineering\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# feature selection\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    \"\"\"Utility function to report best scores\n",
    "    \"\"\"\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Rank: {0}\".format(i))\n",
    "            print(\"Score: {0:f} (std: {1:f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Pars: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "            \n",
    "\n",
    "def report2(results, n_top=3):\n",
    "    \"\"\"Utility function to report best scores\n",
    "    \"\"\"\n",
    "    print(\"Rank|Score(std)|Params\", list(results['params'][0].keys()))\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"{0}|\".format(i), end=\"\")\n",
    "            print(\"{0:f}(std:{1:f})|\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]), end=\"\")\n",
    "            print(\"{0}\".format(list(results['params'][candidate].values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def names(train, test):\n",
    "    for i in [train, test]:\n",
    "        i['Name_Len'] = i['Name'].apply(lambda x: len(x))\n",
    "        i['Name_Title'] = i['Name'].apply(lambda x: x.split(',')[1]).apply(lambda x: x.split()[0])\n",
    "        del i['Name']\n",
    "    return train, test\n",
    "\n",
    "def age_impute(train, test):\n",
    "    for i in [train, test]:\n",
    "        i['Age_Null_Flag'] = i['Age'].apply(lambda x: 1 if pd.isnull(x) else 0)\n",
    "        data = train.groupby(['Name_Title', 'Pclass'])['Age']\n",
    "        i['Age'] = data.transform(lambda x: x.fillna(x.mean()))\n",
    "    return train, test\n",
    "\n",
    "\n",
    "def fam_size(train, test):\n",
    "    for i in [train, test]:\n",
    "        i['Fam_Size'] = np.where((i['SibSp']+i['Parch']) == 0 , 'Solo',\n",
    "                           np.where((i['SibSp']+i['Parch']) <= 3,'Nuclear', 'Big'))\n",
    "        del i['SibSp']\n",
    "        del i['Parch']\n",
    "    return train, test\n",
    "\n",
    "\n",
    "def ticket_grouped(train, test):\n",
    "    for i in [train, test]:\n",
    "        i['Ticket_Lett'] = i['Ticket'].apply(lambda x: str(x)[0])\n",
    "        i['Ticket_Lett'] = i['Ticket_Lett'].apply(lambda x: str(x))\n",
    "        i['Ticket_Lett'] = np.where((i['Ticket_Lett']).isin(['1', '2', '3', 'S', 'P', 'C', 'A']), i['Ticket_Lett'],\n",
    "                                   np.where((i['Ticket_Lett']).isin(['W', '4', '7', '6', 'L', '5', '8']),\n",
    "                                            'Low_ticket', 'Other_ticket'))\n",
    "        i['Ticket_Len'] = i['Ticket'].apply(lambda x: len(x))\n",
    "        del i['Ticket']\n",
    "    return train, test\n",
    "\n",
    "\n",
    "def cabin(train, test):\n",
    "    for i in [train, test]:\n",
    "        i['Cabin_Letter'] = i['Cabin'].apply(lambda x: str(x)[0])\n",
    "        del i['Cabin']\n",
    "    return train, test\n",
    "\n",
    "def cabin_num(train, test):\n",
    "    for i in [train, test]:\n",
    "        i['Cabin_num1'] = i['Cabin'].apply(lambda x: str(x).split(' ')[-1][1:])\n",
    "        i['Cabin_num1'].replace('an', np.NaN, inplace = True)\n",
    "        i['Cabin_num1'] = i['Cabin_num1'].apply(lambda x: int(x) if not pd.isnull(x) and x != '' else np.NaN)\n",
    "        i['Cabin_num'] = pd.qcut(train['Cabin_num1'],3)\n",
    "    train = pd.concat((train, pd.get_dummies(train['Cabin_num'], prefix = 'Cabin_num')), axis = 1)\n",
    "    test = pd.concat((test, pd.get_dummies(test['Cabin_num'], prefix = 'Cabin_num')), axis = 1)\n",
    "    del train['Cabin_num']\n",
    "    del test['Cabin_num']\n",
    "    del train['Cabin_num1']\n",
    "    del test['Cabin_num1']\n",
    "    return train, test\n",
    "\n",
    "\n",
    "def embarked_impute(train, test):\n",
    "    for i in [train, test]:\n",
    "        i['Embarked'] = i['Embarked'].fillna('S')\n",
    "    return train, test\n",
    "\n",
    "def dummies(train, test, columns = ['Pclass', 'Sex', 'Embarked', 'Ticket_Lett', 'Cabin_Letter', 'Name_Title', 'Fam_Size']):\n",
    "    for column in columns:\n",
    "        train[column] = train[column].apply(lambda x: str(x))\n",
    "        test[column] = test[column].apply(lambda x: str(x))\n",
    "        good_cols = [column+'_'+i for i in train[column].unique() if i in test[column].unique()]\n",
    "        train = pd.concat((train, pd.get_dummies(train[column], prefix = column)[good_cols]), axis = 1)\n",
    "        test = pd.concat((test, pd.get_dummies(test[column], prefix = column)[good_cols]), axis = 1)\n",
    "        del train[column]\n",
    "        del test[column]\n",
    "    return train, test\n",
    "\n",
    "def drop(train, test, bye = ['PassengerId']):\n",
    "    for i in [train, test]:\n",
    "        for z in bye:\n",
    "            del i[z]\n",
    "    return train, test\n",
    "\n",
    "\n",
    "train = pd.read_csv(os.path.join('../input', 'train.csv'))\n",
    "test = pd.read_csv(os.path.join('../input', 'test.csv'))\n",
    "train, test = names(train, test)\n",
    "train, test = age_impute(train, test)\n",
    "train, test = cabin_num(train, test)\n",
    "train, test = cabin(train, test)\n",
    "train, test = embarked_impute(train, test)\n",
    "train, test = fam_size(train, test)\n",
    "test['Fare'].fillna(train['Fare'].mean(), inplace = True)\n",
    "train, test = ticket_grouped(train, test)\n",
    "train, test = dummies(train, test, columns = ['Pclass', 'Sex', 'Embarked', 'Ticket_Lett',\n",
    "                                                                     'Cabin_Letter', 'Name_Title', 'Fam_Size'])\n",
    "train, test = drop(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 150 candidates, totalling 450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:   36.3s\n",
      "[Parallel(n_jobs=6)]: Done 438 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=6)]: Done 450 out of 450 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8383838383838383\n",
      "{'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 700}\n",
      "{'mean_fit_time': array([0.23539925, 0.33712943, 0.80466318, 1.52326751, 2.00184425,\n",
      "       0.17175182, 0.22084697, 0.78224889, 1.39152304, 1.83824134,\n",
      "       0.16723434, 0.20508679, 0.84553933, 1.32509335, 1.77881598,\n",
      "       0.17081602, 0.20941639, 0.79459302, 1.30329251, 1.80821745,\n",
      "       0.16890256, 0.20205522, 0.72184642, 1.33989016, 1.7373414 ,\n",
      "       0.16834307, 0.2179021 , 0.77509522, 1.35552971, 1.68355417,\n",
      "       0.15951784, 0.20614894, 0.78354462, 1.25358796, 1.88760201,\n",
      "       0.18347692, 0.20698452, 0.74847523, 1.32237927, 1.81297882,\n",
      "       0.17015107, 0.21768355, 0.76765545, 1.17944884, 1.83665284,\n",
      "       0.16612903, 0.21771232, 0.71689423, 1.36948991, 1.78488994,\n",
      "       0.17578101, 0.19873563, 0.7647051 , 1.32978241, 1.73306211,\n",
      "       0.16512211, 0.22019458, 0.74051412, 1.25883142, 1.77190924,\n",
      "       0.15898236, 0.18706004, 0.80248117, 1.32517234, 1.77281531,\n",
      "       0.14918113, 0.21606088, 0.72094671, 1.19540652, 1.62740707,\n",
      "       0.15886847, 0.20652048, 0.74597534, 1.32155228, 1.59782203,\n",
      "       0.16217152, 0.28236286, 0.88919743, 1.53690418, 1.91378824,\n",
      "       0.16668781, 0.25739821, 0.86646557, 1.37219421, 2.01672578,\n",
      "       0.17628463, 0.23562392, 0.85421006, 1.4060812 , 1.92443061,\n",
      "       0.16232896, 0.21424373, 0.79296859, 1.45499484, 1.93929529,\n",
      "       0.16198516, 0.20014389, 0.76023404, 1.39574655, 1.79897785,\n",
      "       0.16060813, 0.21396891, 0.7318217 , 1.37869549, 1.84873215,\n",
      "       0.16134858, 0.21452292, 0.74028413, 1.45296462, 1.78416236,\n",
      "       0.17247629, 0.19390941, 0.7821238 , 1.23745275, 1.83110762,\n",
      "       0.1601812 , 0.22625868, 0.75695101, 1.32709519, 1.78819609,\n",
      "       0.1656719 , 0.21362305, 0.75046086, 1.34195431, 1.82161721,\n",
      "       0.15797893, 0.21779696, 0.75906483, 1.3831594 , 1.72778988,\n",
      "       0.15893324, 0.20645897, 0.79070608, 1.29803443, 1.72365713,\n",
      "       0.16098078, 0.22778765, 0.77824235, 1.35128029, 1.7069025 ,\n",
      "       0.1576395 , 0.21614973, 0.72654581, 1.31944013, 1.76313551,\n",
      "       0.16379547, 0.22062095, 0.76073583, 1.30580298, 1.68834654]), 'std_fit_time': array([0.00147061, 0.00493527, 0.02092673, 0.05950536, 0.07126169,\n",
      "       0.00996191, 0.00846711, 0.0359537 , 0.02597972, 0.0621426 ,\n",
      "       0.0101973 , 0.00809136, 0.05838003, 0.11329775, 0.08599537,\n",
      "       0.0068119 , 0.00623236, 0.01105572, 0.10293789, 0.11814578,\n",
      "       0.00735189, 0.01027584, 0.05994059, 0.11281271, 0.07701213,\n",
      "       0.01061663, 0.01647491, 0.05201268, 0.02925239, 0.04322925,\n",
      "       0.00710131, 0.00858887, 0.01659893, 0.03952324, 0.09227466,\n",
      "       0.01832936, 0.0022065 , 0.05603137, 0.0985363 , 0.01257294,\n",
      "       0.01092127, 0.00730312, 0.02354504, 0.15343304, 0.12410368,\n",
      "       0.01265405, 0.0047969 , 0.0601695 , 0.07861751, 0.03865157,\n",
      "       0.01144455, 0.0065763 , 0.01503716, 0.07396088, 0.18539702,\n",
      "       0.00210103, 0.00201334, 0.03703065, 0.11585366, 0.04233184,\n",
      "       0.00332111, 0.01243327, 0.04106363, 0.06426963, 0.09598835,\n",
      "       0.00746812, 0.00687597, 0.07274221, 0.08873659, 0.05869874,\n",
      "       0.00359538, 0.00874202, 0.04258175, 0.00521859, 0.0581845 ,\n",
      "       0.00715054, 0.04238632, 0.07344777, 0.05421441, 0.058107  ,\n",
      "       0.01292785, 0.05399904, 0.01480801, 0.07974982, 0.04004174,\n",
      "       0.00669499, 0.01846799, 0.02878039, 0.08877119, 0.03482082,\n",
      "       0.0079309 , 0.01160558, 0.07944209, 0.03373104, 0.04199919,\n",
      "       0.00321177, 0.00970839, 0.06744494, 0.06953242, 0.05667198,\n",
      "       0.00241263, 0.01221472, 0.07065765, 0.02906742, 0.08236384,\n",
      "       0.00552382, 0.00571459, 0.04666861, 0.0461871 , 0.08579974,\n",
      "       0.00741401, 0.01056078, 0.04247524, 0.02994371, 0.09347295,\n",
      "       0.01468872, 0.0034849 , 0.00813275, 0.02110132, 0.17899757,\n",
      "       0.00405142, 0.00423677, 0.07449351, 0.02353339, 0.02847948,\n",
      "       0.00683114, 0.00947063, 0.01617232, 0.100697  , 0.04627388,\n",
      "       0.00185989, 0.00701778, 0.03010941, 0.09232695, 0.11287385,\n",
      "       0.01572668, 0.00835272, 0.03925062, 0.02673329, 0.0687079 ,\n",
      "       0.00114838, 0.00437964, 0.0668308 , 0.05560685, 0.0902012 ,\n",
      "       0.00863041, 0.00304236, 0.04518345, 0.06449306, 0.05870735]), 'mean_score_time': array([0.10264802, 0.10623725, 0.10888735, 0.21531288, 0.20836306,\n",
      "       0.10145132, 0.10290837, 0.10759211, 0.20986708, 0.2064995 ,\n",
      "       0.11107405, 0.10820278, 0.11305149, 0.20910684, 0.20183778,\n",
      "       0.11056081, 0.10313241, 0.10761078, 0.21228425, 0.20413621,\n",
      "       0.10210021, 0.11095293, 0.10705185, 0.21065688, 0.2100482 ,\n",
      "       0.11213708, 0.1195569 , 0.10649427, 0.21410457, 0.20271428,\n",
      "       0.1044488 , 0.10357173, 0.1085194 , 0.21356678, 0.20807838,\n",
      "       0.11056582, 0.10416436, 0.11968462, 0.21343056, 0.20339163,\n",
      "       0.1055061 , 0.11763891, 0.10152268, 0.21476563, 0.20977879,\n",
      "       0.10182953, 0.10151092, 0.12631567, 0.20429635, 0.2140739 ,\n",
      "       0.10335183, 0.1014111 , 0.12102397, 0.20198989, 0.2709341 ,\n",
      "       0.11587858, 0.10332274, 0.10174576, 0.21463784, 0.20189357,\n",
      "       0.10188858, 0.10406534, 0.11304275, 0.21707479, 0.20929686,\n",
      "       0.10152411, 0.10664296, 0.10189295, 0.20220828, 0.20153936,\n",
      "       0.10420521, 0.10243527, 0.10744754, 0.20323459, 0.20890729,\n",
      "       0.10175355, 0.10283264, 0.12444011, 0.21021024, 0.20192989,\n",
      "       0.10532816, 0.11269609, 0.10179949, 0.21449844, 0.20597386,\n",
      "       0.10442313, 0.11897612, 0.10997661, 0.22197922, 0.20436605,\n",
      "       0.10387945, 0.10153023, 0.11185153, 0.20898636, 0.20366327,\n",
      "       0.11544927, 0.10153262, 0.11030547, 0.21437279, 0.20613893,\n",
      "       0.1016225 , 0.1016686 , 0.11321473, 0.22145001, 0.20221416,\n",
      "       0.10541574, 0.10156409, 0.11737792, 0.20811415, 0.21187377,\n",
      "       0.10193133, 0.10919873, 0.10830998, 0.21220978, 0.21097652,\n",
      "       0.11079272, 0.10140785, 0.11507591, 0.21947193, 0.20445053,\n",
      "       0.1117382 , 0.10153119, 0.11781247, 0.2096285 , 0.20771599,\n",
      "       0.1014568 , 0.10572457, 0.10141214, 0.20841169, 0.2055033 ,\n",
      "       0.10160375, 0.10146538, 0.12329062, 0.21693738, 0.20594811,\n",
      "       0.11238337, 0.11578647, 0.10199126, 0.20546007, 0.20299164,\n",
      "       0.10581295, 0.10244219, 0.11709976, 0.20990213, 0.20410538,\n",
      "       0.10426052, 0.11143343, 0.10414314, 0.20531114, 0.20193283]), 'std_score_time': array([3.75876903e-04, 6.01108581e-03, 1.04002076e-02, 9.96152893e-03,\n",
      "       9.11979204e-03, 7.87610122e-05, 1.83144602e-03, 6.53559129e-03,\n",
      "       3.32734428e-03, 3.47112126e-03, 6.65929044e-03, 6.14789753e-03,\n",
      "       4.33937167e-03, 1.01065471e-02, 2.23619936e-04, 6.98539829e-03,\n",
      "       1.46592661e-03, 6.58490142e-03, 1.46995588e-02, 3.63568158e-03,\n",
      "       5.33364630e-04, 7.13367219e-03, 5.52334065e-03, 3.14706056e-03,\n",
      "       1.18665569e-02, 7.31606716e-03, 2.55589057e-02, 5.51566641e-03,\n",
      "       9.10664259e-03, 5.70939717e-04, 4.12033836e-03, 3.06305157e-03,\n",
      "       5.22590817e-03, 5.29198582e-03, 4.81173421e-03, 1.25979280e-02,\n",
      "       2.45842564e-03, 1.74004160e-02, 1.44718372e-02, 1.23553161e-03,\n",
      "       5.67744242e-03, 1.18511828e-02, 7.74335684e-05, 9.06754223e-03,\n",
      "       8.02647994e-03, 3.59955051e-04, 4.49857103e-05, 1.80950521e-03,\n",
      "       3.73675406e-03, 4.68463732e-03, 2.46227916e-03, 3.74051322e-05,\n",
      "       1.39332758e-02, 2.15840416e-04, 4.84552930e-02, 1.78233594e-02,\n",
      "       2.15300946e-03, 3.09264363e-04, 8.29968071e-03, 5.29493258e-05,\n",
      "       3.15455942e-04, 2.30003081e-03, 8.41852785e-03, 1.67171190e-02,\n",
      "       7.60964408e-03, 1.45660679e-04, 5.71083688e-03, 3.70217661e-04,\n",
      "       4.25212345e-04, 1.22595741e-04, 3.77035279e-03, 1.42238127e-03,\n",
      "       5.56380906e-03, 1.66283414e-03, 9.96066621e-03, 2.52787139e-04,\n",
      "       1.88384794e-03, 1.74030433e-02, 8.25975972e-03, 2.74112273e-04,\n",
      "       3.21637038e-03, 1.93840126e-03, 4.02878630e-04, 1.67365562e-02,\n",
      "       3.73478397e-03, 3.80630181e-03, 1.44560284e-02, 1.20986178e-02,\n",
      "       1.39056033e-02, 3.21739516e-03, 3.05964729e-03, 1.74320380e-04,\n",
      "       7.44054981e-03, 2.30579753e-03, 2.48018592e-03, 1.14143953e-02,\n",
      "       1.21853795e-04, 6.22810496e-03, 2.85466172e-03, 5.70177649e-03,\n",
      "       1.37243577e-04, 1.22052771e-04, 1.00976590e-02, 1.44823558e-02,\n",
      "       7.38796058e-04, 5.24882210e-03, 8.87293747e-05, 4.80739639e-03,\n",
      "       2.26679471e-03, 9.98302367e-03, 3.30653535e-04, 1.07903570e-02,\n",
      "       5.52889453e-03, 7.81364706e-03, 3.70024348e-03, 1.32020543e-02,\n",
      "       6.29124947e-05, 7.87354357e-03, 1.27025473e-02, 3.68525254e-03,\n",
      "       7.18336484e-03, 1.58265207e-04, 1.15907772e-02, 8.40819828e-03,\n",
      "       8.82509962e-03, 7.79173738e-05, 6.04094400e-03, 7.71487877e-05,\n",
      "       9.42076270e-03, 4.36555319e-03, 7.93288038e-05, 7.37805245e-05,\n",
      "       1.55748632e-02, 6.02874832e-03, 5.84223383e-03, 1.42492471e-02,\n",
      "       1.13332712e-02, 3.73181075e-04, 3.62140290e-03, 1.54725245e-03,\n",
      "       1.43634425e-03, 1.25163678e-03, 1.38364042e-02, 6.55337197e-03,\n",
      "       8.41493435e-04, 3.90313421e-03, 4.69785109e-03, 2.27505482e-03,\n",
      "       3.54599377e-03, 2.92666443e-04]), 'param_criterion': masked_array(data=['gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
      "                   'gini', 'gini', 'gini', 'gini', 'gini', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
      "                   'entropy', 'entropy', 'entropy', 'entropy'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_min_samples_leaf': masked_array(data=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                   1, 1, 1, 1, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "                   5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10,\n",
      "                   10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "                   10, 10, 10, 10, 10, 10, 10, 10, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                   1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5,\n",
      "                   5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "                   5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "                   10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "                   10, 10],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_min_samples_split': masked_array(data=[2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 10, 10, 10, 10, 10, 12,\n",
      "                   12, 12, 12, 12, 16, 16, 16, 16, 16, 2, 2, 2, 2, 2, 4,\n",
      "                   4, 4, 4, 4, 10, 10, 10, 10, 10, 12, 12, 12, 12, 12, 16,\n",
      "                   16, 16, 16, 16, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 10, 10,\n",
      "                   10, 10, 10, 12, 12, 12, 12, 12, 16, 16, 16, 16, 16, 2,\n",
      "                   2, 2, 2, 2, 4, 4, 4, 4, 4, 10, 10, 10, 10, 10, 12, 12,\n",
      "                   12, 12, 12, 16, 16, 16, 16, 16, 2, 2, 2, 2, 2, 4, 4, 4,\n",
      "                   4, 4, 10, 10, 10, 10, 10, 12, 12, 12, 12, 12, 16, 16,\n",
      "                   16, 16, 16, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 10, 10, 10,\n",
      "                   10, 10, 12, 12, 12, 12, 12, 16, 16, 16, 16, 16],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_n_estimators': masked_array(data=[50, 100, 400, 700, 1000, 50, 100, 400, 700, 1000, 50,\n",
      "                   100, 400, 700, 1000, 50, 100, 400, 700, 1000, 50, 100,\n",
      "                   400, 700, 1000, 50, 100, 400, 700, 1000, 50, 100, 400,\n",
      "                   700, 1000, 50, 100, 400, 700, 1000, 50, 100, 400, 700,\n",
      "                   1000, 50, 100, 400, 700, 1000, 50, 100, 400, 700, 1000,\n",
      "                   50, 100, 400, 700, 1000, 50, 100, 400, 700, 1000, 50,\n",
      "                   100, 400, 700, 1000, 50, 100, 400, 700, 1000, 50, 100,\n",
      "                   400, 700, 1000, 50, 100, 400, 700, 1000, 50, 100, 400,\n",
      "                   700, 1000, 50, 100, 400, 700, 1000, 50, 100, 400, 700,\n",
      "                   1000, 50, 100, 400, 700, 1000, 50, 100, 400, 700, 1000,\n",
      "                   50, 100, 400, 700, 1000, 50, 100, 400, 700, 1000, 50,\n",
      "                   100, 400, 700, 1000, 50, 100, 400, 700, 1000, 50, 100,\n",
      "                   400, 700, 1000, 50, 100, 400, 700, 1000, 50, 100, 400,\n",
      "                   700, 1000, 50, 100, 400, 700, 1000],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 12, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 12, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 12, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 12, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 12, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 16, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 16, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 16, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 16, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 16, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 12, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 12, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 12, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 12, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 12, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 16, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 16, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 16, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 16, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 16, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 12, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 12, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 12, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 12, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 12, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 16, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 16, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 16, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 16, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 16, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 12, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 12, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 12, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 12, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 12, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 16, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 16, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 16, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 16, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 16, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 12, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 12, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 12, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 12, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 12, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 16, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 16, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 16, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 16, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 16, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 12, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 12, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 12, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 12, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 12, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 16, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 16, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 16, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 16, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 16, 'n_estimators': 1000}], 'split0_test_score': array([0.80808081, 0.8013468 , 0.80808081, 0.81481481, 0.8047138 ,\n",
      "       0.81818182, 0.83164983, 0.82491582, 0.82491582, 0.82491582,\n",
      "       0.81144781, 0.81144781, 0.80808081, 0.81481481, 0.81818182,\n",
      "       0.80808081, 0.80808081, 0.81144781, 0.8047138 , 0.80808081,\n",
      "       0.81481481, 0.80808081, 0.80808081, 0.80808081, 0.80808081,\n",
      "       0.82154882, 0.81818182, 0.81818182, 0.81818182, 0.81818182,\n",
      "       0.82154882, 0.81818182, 0.81818182, 0.81818182, 0.81818182,\n",
      "       0.82154882, 0.81818182, 0.81818182, 0.81818182, 0.81818182,\n",
      "       0.83164983, 0.82491582, 0.81818182, 0.81818182, 0.81818182,\n",
      "       0.83164983, 0.82828283, 0.81481481, 0.81818182, 0.82154882,\n",
      "       0.81818182, 0.82154882, 0.81144781, 0.81481481, 0.81144781,\n",
      "       0.81818182, 0.82154882, 0.81144781, 0.81481481, 0.81144781,\n",
      "       0.81818182, 0.82154882, 0.81144781, 0.81481481, 0.81144781,\n",
      "       0.81818182, 0.82154882, 0.81144781, 0.81481481, 0.81144781,\n",
      "       0.81818182, 0.82154882, 0.81144781, 0.81481481, 0.81144781,\n",
      "       0.8013468 , 0.80808081, 0.81144781, 0.81144781, 0.80808081,\n",
      "       0.81144781, 0.80808081, 0.82491582, 0.82491582, 0.82491582,\n",
      "       0.80808081, 0.80808081, 0.81144781, 0.81144781, 0.81144781,\n",
      "       0.82828283, 0.81481481, 0.81144781, 0.81481481, 0.81481481,\n",
      "       0.80808081, 0.80808081, 0.81481481, 0.81481481, 0.81144781,\n",
      "       0.80808081, 0.81144781, 0.80808081, 0.81144781, 0.81481481,\n",
      "       0.80808081, 0.81144781, 0.80808081, 0.81144781, 0.81481481,\n",
      "       0.80808081, 0.81144781, 0.80808081, 0.81144781, 0.81481481,\n",
      "       0.81818182, 0.80808081, 0.81144781, 0.81144781, 0.81818182,\n",
      "       0.8047138 , 0.81144781, 0.81144781, 0.81144781, 0.81481481,\n",
      "       0.82828283, 0.82154882, 0.80808081, 0.80808081, 0.80808081,\n",
      "       0.82828283, 0.82154882, 0.80808081, 0.80808081, 0.80808081,\n",
      "       0.82828283, 0.82154882, 0.80808081, 0.80808081, 0.80808081,\n",
      "       0.82828283, 0.82154882, 0.80808081, 0.80808081, 0.80808081,\n",
      "       0.82828283, 0.82154882, 0.80808081, 0.80808081, 0.80808081]), 'split1_test_score': array([0.84511785, 0.85185185, 0.85858586, 0.85521886, 0.85521886,\n",
      "       0.84848485, 0.84175084, 0.85185185, 0.85185185, 0.84848485,\n",
      "       0.85185185, 0.84848485, 0.85521886, 0.85858586, 0.85858586,\n",
      "       0.83164983, 0.83838384, 0.84511785, 0.85185185, 0.85185185,\n",
      "       0.85858586, 0.84511785, 0.83838384, 0.84848485, 0.84511785,\n",
      "       0.82828283, 0.82828283, 0.83838384, 0.83838384, 0.83501684,\n",
      "       0.82828283, 0.82828283, 0.83838384, 0.83838384, 0.83501684,\n",
      "       0.82828283, 0.82828283, 0.83838384, 0.83838384, 0.83501684,\n",
      "       0.83164983, 0.83838384, 0.83164983, 0.84175084, 0.83501684,\n",
      "       0.82828283, 0.83164983, 0.83501684, 0.83501684, 0.83838384,\n",
      "       0.81818182, 0.83501684, 0.83164983, 0.83164983, 0.83164983,\n",
      "       0.81818182, 0.83501684, 0.83164983, 0.83164983, 0.83164983,\n",
      "       0.81818182, 0.83501684, 0.83164983, 0.83164983, 0.83164983,\n",
      "       0.81818182, 0.83501684, 0.83164983, 0.83164983, 0.83164983,\n",
      "       0.81818182, 0.83501684, 0.83164983, 0.83164983, 0.83164983,\n",
      "       0.83838384, 0.84511785, 0.85858586, 0.86195286, 0.86195286,\n",
      "       0.84511785, 0.86195286, 0.84848485, 0.84848485, 0.84848485,\n",
      "       0.84175084, 0.84175084, 0.84511785, 0.84848485, 0.84848485,\n",
      "       0.85185185, 0.85521886, 0.84848485, 0.84848485, 0.85521886,\n",
      "       0.84511785, 0.84848485, 0.84511785, 0.85185185, 0.84511785,\n",
      "       0.83501684, 0.84511785, 0.83501684, 0.83164983, 0.83501684,\n",
      "       0.83501684, 0.84511785, 0.83501684, 0.83164983, 0.83501684,\n",
      "       0.83501684, 0.84511785, 0.83501684, 0.83164983, 0.83501684,\n",
      "       0.82828283, 0.84848485, 0.83838384, 0.83501684, 0.83501684,\n",
      "       0.83501684, 0.84511785, 0.83164983, 0.83838384, 0.83838384,\n",
      "       0.83164983, 0.83164983, 0.83501684, 0.83164983, 0.82828283,\n",
      "       0.83164983, 0.83164983, 0.83501684, 0.83164983, 0.82828283,\n",
      "       0.83164983, 0.83164983, 0.83501684, 0.83164983, 0.82828283,\n",
      "       0.83164983, 0.83164983, 0.83501684, 0.83164983, 0.82828283,\n",
      "       0.83164983, 0.83164983, 0.83501684, 0.83164983, 0.82828283]), 'split2_test_score': array([0.82491582, 0.82828283, 0.83164983, 0.82828283, 0.82491582,\n",
      "       0.84511785, 0.83838384, 0.83164983, 0.83501684, 0.83501684,\n",
      "       0.84175084, 0.84511785, 0.83838384, 0.84175084, 0.83838384,\n",
      "       0.84175084, 0.84511785, 0.84175084, 0.84175084, 0.84175084,\n",
      "       0.82828283, 0.84511785, 0.83838384, 0.83501684, 0.83838384,\n",
      "       0.82154882, 0.82828283, 0.81481481, 0.81481481, 0.82154882,\n",
      "       0.82154882, 0.82828283, 0.81481481, 0.81481481, 0.82154882,\n",
      "       0.82154882, 0.82828283, 0.81481481, 0.81481481, 0.82154882,\n",
      "       0.81818182, 0.81818182, 0.81481481, 0.81481481, 0.81481481,\n",
      "       0.81144781, 0.80808081, 0.81818182, 0.81481481, 0.81818182,\n",
      "       0.82491582, 0.80808081, 0.7979798 , 0.7979798 , 0.7979798 ,\n",
      "       0.82491582, 0.80808081, 0.7979798 , 0.7979798 , 0.7979798 ,\n",
      "       0.82491582, 0.80808081, 0.7979798 , 0.7979798 , 0.7979798 ,\n",
      "       0.82491582, 0.80808081, 0.7979798 , 0.7979798 , 0.7979798 ,\n",
      "       0.82491582, 0.80808081, 0.7979798 , 0.7979798 , 0.7979798 ,\n",
      "       0.83838384, 0.82828283, 0.82828283, 0.82491582, 0.82154882,\n",
      "       0.82828283, 0.83838384, 0.84175084, 0.83501684, 0.83164983,\n",
      "       0.83838384, 0.84511785, 0.83501684, 0.84511785, 0.83838384,\n",
      "       0.83501684, 0.83501684, 0.84175084, 0.84175084, 0.84175084,\n",
      "       0.84175084, 0.85185185, 0.84175084, 0.83838384, 0.83838384,\n",
      "       0.81818182, 0.81818182, 0.81144781, 0.81481481, 0.81818182,\n",
      "       0.81818182, 0.81818182, 0.81144781, 0.81481481, 0.81818182,\n",
      "       0.81818182, 0.81818182, 0.81144781, 0.81481481, 0.81818182,\n",
      "       0.82154882, 0.82491582, 0.82154882, 0.82491582, 0.82491582,\n",
      "       0.83164983, 0.82154882, 0.82828283, 0.82154882, 0.82154882,\n",
      "       0.81818182, 0.8013468 , 0.7979798 , 0.7979798 , 0.7979798 ,\n",
      "       0.81818182, 0.8013468 , 0.7979798 , 0.7979798 , 0.7979798 ,\n",
      "       0.81818182, 0.8013468 , 0.7979798 , 0.7979798 , 0.7979798 ,\n",
      "       0.81818182, 0.8013468 , 0.7979798 , 0.7979798 , 0.7979798 ,\n",
      "       0.81818182, 0.8013468 , 0.7979798 , 0.7979798 , 0.7979798 ]), 'mean_test_score': array([0.82603816, 0.82716049, 0.83277217, 0.83277217, 0.82828283,\n",
      "       0.8372615 , 0.8372615 , 0.83613917, 0.8372615 , 0.83613917,\n",
      "       0.83501684, 0.83501684, 0.8338945 , 0.83838384, 0.83838384,\n",
      "       0.82716049, 0.8305275 , 0.83277217, 0.83277217, 0.8338945 ,\n",
      "       0.8338945 , 0.83277217, 0.82828283, 0.8305275 , 0.8305275 ,\n",
      "       0.82379349, 0.82491582, 0.82379349, 0.82379349, 0.82491582,\n",
      "       0.82379349, 0.82491582, 0.82379349, 0.82379349, 0.82491582,\n",
      "       0.82379349, 0.82491582, 0.82379349, 0.82379349, 0.82491582,\n",
      "       0.82716049, 0.82716049, 0.82154882, 0.82491582, 0.82267116,\n",
      "       0.82379349, 0.82267116, 0.82267116, 0.82267116, 0.82603816,\n",
      "       0.82042649, 0.82154882, 0.81369248, 0.81481481, 0.81369248,\n",
      "       0.82042649, 0.82154882, 0.81369248, 0.81481481, 0.81369248,\n",
      "       0.82042649, 0.82154882, 0.81369248, 0.81481481, 0.81369248,\n",
      "       0.82042649, 0.82154882, 0.81369248, 0.81481481, 0.81369248,\n",
      "       0.82042649, 0.82154882, 0.81369248, 0.81481481, 0.81369248,\n",
      "       0.82603816, 0.82716049, 0.83277217, 0.83277217, 0.8305275 ,\n",
      "       0.82828283, 0.83613917, 0.83838384, 0.83613917, 0.83501684,\n",
      "       0.82940516, 0.83164983, 0.8305275 , 0.83501684, 0.83277217,\n",
      "       0.83838384, 0.83501684, 0.8338945 , 0.83501684, 0.8372615 ,\n",
      "       0.83164983, 0.83613917, 0.8338945 , 0.83501684, 0.83164983,\n",
      "       0.82042649, 0.82491582, 0.81818182, 0.81930415, 0.82267116,\n",
      "       0.82042649, 0.82491582, 0.81818182, 0.81930415, 0.82267116,\n",
      "       0.82042649, 0.82491582, 0.81818182, 0.81930415, 0.82267116,\n",
      "       0.82267116, 0.82716049, 0.82379349, 0.82379349, 0.82603816,\n",
      "       0.82379349, 0.82603816, 0.82379349, 0.82379349, 0.82491582,\n",
      "       0.82603816, 0.81818182, 0.81369248, 0.81257015, 0.81144781,\n",
      "       0.82603816, 0.81818182, 0.81369248, 0.81257015, 0.81144781,\n",
      "       0.82603816, 0.81818182, 0.81369248, 0.81257015, 0.81144781,\n",
      "       0.82603816, 0.81818182, 0.81369248, 0.81257015, 0.81144781,\n",
      "       0.82603816, 0.81818182, 0.81369248, 0.81257015, 0.81144781]), 'std_test_score': array([0.01514112, 0.02063387, 0.02063387, 0.01679756, 0.0207556 ,\n",
      "       0.01356122, 0.00419939, 0.01144561, 0.01111054, 0.00965469,\n",
      "       0.01716842, 0.01672241, 0.01950409, 0.01802736, 0.01649488,\n",
      "       0.01410753, 0.01610853, 0.01514112, 0.02026428, 0.01871305,\n",
      "       0.01830472, 0.01745943, 0.01428499, 0.01679756, 0.01610853,\n",
      "       0.00317444, 0.00476166, 0.0104081 , 0.0104081 , 0.00727356,\n",
      "       0.00317444, 0.00476166, 0.0104081 , 0.0104081 , 0.00727356,\n",
      "       0.00317444, 0.00476166, 0.0104081 , 0.0104081 , 0.00727356,\n",
      "       0.00634888, 0.00839878, 0.00727356, 0.01198325, 0.00883727,\n",
      "       0.00883727, 0.0104081 , 0.00883727, 0.00883727, 0.00883727,\n",
      "       0.00317444, 0.01099659, 0.01383707, 0.01374573, 0.01383707,\n",
      "       0.00317444, 0.01099659, 0.01383707, 0.01374573, 0.01383707,\n",
      "       0.00317444, 0.01099659, 0.01383707, 0.01374573, 0.01383707,\n",
      "       0.00317444, 0.01099659, 0.01383707, 0.01374573, 0.01383707,\n",
      "       0.00317444, 0.01099659, 0.01383707, 0.01374573, 0.01383707,\n",
      "       0.01745943, 0.01514112, 0.01950409, 0.02135387, 0.02289122,\n",
      "       0.01374573, 0.02205037, 0.00991219, 0.00965469, 0.00991219,\n",
      "       0.01514112, 0.01672241, 0.01410753, 0.01672241, 0.01563231,\n",
      "       0.00991219, 0.01649488, 0.01610853, 0.01454712, 0.01679756,\n",
      "       0.01672241, 0.01988782, 0.01356122, 0.0153066 , 0.01454712,\n",
      "       0.01111054, 0.01454712, 0.01198325, 0.00883727, 0.00883727,\n",
      "       0.01111054, 0.01454712, 0.01198325, 0.00883727, 0.00883727,\n",
      "       0.01111054, 0.01454712, 0.01198325, 0.00883727, 0.00883727,\n",
      "       0.00419939, 0.01657107, 0.01111054, 0.00965469, 0.00691853,\n",
      "       0.01356122, 0.01410753, 0.00883727, 0.01111054, 0.00991219,\n",
      "       0.00572281, 0.01259817, 0.01563231, 0.01410753, 0.01259817,\n",
      "       0.00572281, 0.01259817, 0.01563231, 0.01410753, 0.01259817,\n",
      "       0.00572281, 0.01259817, 0.01563231, 0.01410753, 0.01259817,\n",
      "       0.00572281, 0.01259817, 0.01563231, 0.01410753, 0.01259817,\n",
      "       0.00572281, 0.01259817, 0.01563231, 0.01410753, 0.01259817]), 'rank_test_score': array([ 52,  46,  26,  26,  43,   5,   5,   9,   5,   9,  14,  14,  21,\n",
      "         1,   1,  46,  37,  26,  26,  21,  21,  26,  43,  37,  37,  73,\n",
      "        62,  73,  73,  62,  73,  62,  73,  73,  62,  73,  62,  73,  73,\n",
      "        62,  46,  46,  96,  62,  88,  73,  88,  88,  88,  52, 102,  96,\n",
      "       126, 121, 126, 102,  96, 126, 121, 126, 102,  96, 126, 121, 126,\n",
      "       102,  96, 126, 121, 126, 102,  96, 126, 121, 126,  52,  46,  26,\n",
      "        26,  37,  43,   9,   1,   9,  14,  42,  34,  37,  14,  26,   1,\n",
      "        14,  21,  14,   5,  34,   9,  21,  14,  34, 102,  62, 113, 110,\n",
      "        88, 102,  62, 113, 110,  88, 102,  62, 113, 110,  88,  88,  46,\n",
      "        73,  73,  52,  73,  52,  73,  73,  62,  52, 113, 126, 141, 146,\n",
      "        52, 113, 126, 141, 146,  52, 113, 126, 141, 146,  52, 113, 126,\n",
      "       141, 146,  52, 113, 126, 141, 146], dtype=int32), 'split0_train_score': array([0.9983165 , 0.9983165 , 0.9983165 , 0.9983165 , 0.9983165 ,\n",
      "       0.96969697, 0.97138047, 0.96969697, 0.96969697, 0.97138047,\n",
      "       0.91750842, 0.92424242, 0.92592593, 0.92424242, 0.92929293,\n",
      "       0.91077441, 0.91414141, 0.91582492, 0.91245791, 0.91245791,\n",
      "       0.90740741, 0.90909091, 0.90909091, 0.90740741, 0.90740741,\n",
      "       0.88383838, 0.88383838, 0.88383838, 0.88888889, 0.88720539,\n",
      "       0.88383838, 0.88383838, 0.88383838, 0.88888889, 0.88720539,\n",
      "       0.88383838, 0.88383838, 0.88383838, 0.88888889, 0.88720539,\n",
      "       0.88215488, 0.88047138, 0.88552189, 0.88552189, 0.88720539,\n",
      "       0.87373737, 0.88047138, 0.88047138, 0.88383838, 0.88215488,\n",
      "       0.85521886, 0.85858586, 0.87878788, 0.87710438, 0.87542088,\n",
      "       0.85521886, 0.85858586, 0.87878788, 0.87710438, 0.87542088,\n",
      "       0.85521886, 0.85858586, 0.87878788, 0.87710438, 0.87542088,\n",
      "       0.85521886, 0.85858586, 0.87878788, 0.87710438, 0.87542088,\n",
      "       0.85521886, 0.85858586, 0.87878788, 0.87710438, 0.87542088,\n",
      "       0.9983165 , 0.9983165 , 0.9983165 , 0.9983165 , 0.9983165 ,\n",
      "       0.96969697, 0.97138047, 0.97306397, 0.97306397, 0.97138047,\n",
      "       0.91750842, 0.92424242, 0.92760943, 0.93097643, 0.92929293,\n",
      "       0.90572391, 0.91245791, 0.91750842, 0.91919192, 0.92087542,\n",
      "       0.9040404 , 0.9040404 , 0.90740741, 0.90909091, 0.90740741,\n",
      "       0.88215488, 0.88888889, 0.88720539, 0.88552189, 0.88552189,\n",
      "       0.88215488, 0.88888889, 0.88720539, 0.88552189, 0.88552189,\n",
      "       0.88215488, 0.88888889, 0.88720539, 0.88552189, 0.88552189,\n",
      "       0.88215488, 0.88552189, 0.88383838, 0.88552189, 0.88383838,\n",
      "       0.88047138, 0.88383838, 0.88215488, 0.88552189, 0.88552189,\n",
      "       0.85521886, 0.85690236, 0.87037037, 0.86700337, 0.87037037,\n",
      "       0.85521886, 0.85690236, 0.87037037, 0.86700337, 0.87037037,\n",
      "       0.85521886, 0.85690236, 0.87037037, 0.86700337, 0.87037037,\n",
      "       0.85521886, 0.85690236, 0.87037037, 0.86700337, 0.87037037,\n",
      "       0.85521886, 0.85690236, 0.87037037, 0.86700337, 0.87037037]), 'split1_train_score': array([0.99326599, 0.996633  , 0.996633  , 0.996633  , 0.996633  ,\n",
      "       0.96464646, 0.96127946, 0.95959596, 0.96296296, 0.96127946,\n",
      "       0.91077441, 0.91245791, 0.91582492, 0.91582492, 0.91582492,\n",
      "       0.89057239, 0.8973064 , 0.9023569 , 0.9040404 , 0.90572391,\n",
      "       0.88047138, 0.88888889, 0.89225589, 0.89225589, 0.89393939,\n",
      "       0.87542088, 0.88047138, 0.87373737, 0.87373737, 0.87542088,\n",
      "       0.87542088, 0.88047138, 0.87373737, 0.87373737, 0.87542088,\n",
      "       0.87542088, 0.88047138, 0.87373737, 0.87373737, 0.87542088,\n",
      "       0.86868687, 0.86531987, 0.87037037, 0.86531987, 0.86868687,\n",
      "       0.85690236, 0.86026936, 0.86531987, 0.86363636, 0.86531987,\n",
      "       0.83333333, 0.83164983, 0.82996633, 0.82996633, 0.82996633,\n",
      "       0.83333333, 0.83164983, 0.82996633, 0.82996633, 0.82996633,\n",
      "       0.83333333, 0.83164983, 0.82996633, 0.82996633, 0.82996633,\n",
      "       0.83333333, 0.83164983, 0.82996633, 0.82996633, 0.82996633,\n",
      "       0.83333333, 0.83164983, 0.82996633, 0.82996633, 0.82996633,\n",
      "       0.99326599, 0.996633  , 0.996633  , 0.996633  , 0.996633  ,\n",
      "       0.96464646, 0.96464646, 0.96464646, 0.96464646, 0.96632997,\n",
      "       0.90740741, 0.90909091, 0.91582492, 0.91414141, 0.91414141,\n",
      "       0.90572391, 0.9040404 , 0.91245791, 0.91245791, 0.90909091,\n",
      "       0.88720539, 0.88888889, 0.8956229 , 0.89393939, 0.8956229 ,\n",
      "       0.86868687, 0.87037037, 0.87373737, 0.87037037, 0.87205387,\n",
      "       0.86868687, 0.87037037, 0.87373737, 0.87037037, 0.87205387,\n",
      "       0.86868687, 0.87037037, 0.87373737, 0.87037037, 0.87205387,\n",
      "       0.87037037, 0.87037037, 0.87205387, 0.86531987, 0.87037037,\n",
      "       0.86363636, 0.85690236, 0.86531987, 0.86363636, 0.86868687,\n",
      "       0.83333333, 0.83670034, 0.83164983, 0.82996633, 0.82996633,\n",
      "       0.83333333, 0.83670034, 0.83164983, 0.82996633, 0.82996633,\n",
      "       0.83333333, 0.83670034, 0.83164983, 0.82996633, 0.82996633,\n",
      "       0.83333333, 0.83670034, 0.83164983, 0.82996633, 0.82996633,\n",
      "       0.83333333, 0.83670034, 0.83164983, 0.82996633, 0.82996633]), 'split2_train_score': array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       0.95622896, 0.95622896, 0.95454545, 0.95454545, 0.95286195,\n",
      "       0.8989899 , 0.9023569 , 0.8989899 , 0.9006734 , 0.8989899 ,\n",
      "       0.88888889, 0.88215488, 0.88888889, 0.89225589, 0.89393939,\n",
      "       0.87878788, 0.87710438, 0.88047138, 0.87710438, 0.87542088,\n",
      "       0.86026936, 0.85690236, 0.85858586, 0.85858586, 0.85858586,\n",
      "       0.86026936, 0.85690236, 0.85858586, 0.85858586, 0.85858586,\n",
      "       0.86026936, 0.85690236, 0.85858586, 0.85858586, 0.85858586,\n",
      "       0.85858586, 0.85858586, 0.85858586, 0.85690236, 0.85858586,\n",
      "       0.85690236, 0.85690236, 0.85858586, 0.85858586, 0.85690236,\n",
      "       0.84680135, 0.84175084, 0.83670034, 0.83838384, 0.83838384,\n",
      "       0.84680135, 0.84175084, 0.83670034, 0.83838384, 0.83838384,\n",
      "       0.84680135, 0.84175084, 0.83670034, 0.83838384, 0.83838384,\n",
      "       0.84680135, 0.84175084, 0.83670034, 0.83838384, 0.83838384,\n",
      "       0.84680135, 0.84175084, 0.83670034, 0.83838384, 0.83838384,\n",
      "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
      "       0.96296296, 0.96127946, 0.95454545, 0.96127946, 0.95622896,\n",
      "       0.8973064 , 0.90572391, 0.9006734 , 0.8989899 , 0.9006734 ,\n",
      "       0.88383838, 0.89057239, 0.8956229 , 0.8956229 , 0.8973064 ,\n",
      "       0.88552189, 0.88215488, 0.87542088, 0.88383838, 0.88047138,\n",
      "       0.86195286, 0.85690236, 0.86026936, 0.86026936, 0.86026936,\n",
      "       0.86195286, 0.85690236, 0.86026936, 0.86026936, 0.86026936,\n",
      "       0.86195286, 0.85690236, 0.86026936, 0.86026936, 0.86026936,\n",
      "       0.86026936, 0.85521886, 0.85858586, 0.85690236, 0.85690236,\n",
      "       0.85690236, 0.85185185, 0.85690236, 0.85690236, 0.85690236,\n",
      "       0.84175084, 0.84006734, 0.84006734, 0.83838384, 0.84006734,\n",
      "       0.84175084, 0.84006734, 0.84006734, 0.83838384, 0.84006734,\n",
      "       0.84175084, 0.84006734, 0.84006734, 0.83838384, 0.84006734,\n",
      "       0.84175084, 0.84006734, 0.84006734, 0.83838384, 0.84006734,\n",
      "       0.84175084, 0.84006734, 0.84006734, 0.83838384, 0.84006734]), 'mean_train_score': array([0.99719416, 0.9983165 , 0.9983165 , 0.9983165 , 0.9983165 ,\n",
      "       0.96352413, 0.96296296, 0.96127946, 0.9624018 , 0.96184063,\n",
      "       0.90909091, 0.91301908, 0.91358025, 0.91358025, 0.91470258,\n",
      "       0.89674523, 0.89786756, 0.9023569 , 0.90291807, 0.9040404 ,\n",
      "       0.88888889, 0.89169473, 0.89393939, 0.89225589, 0.89225589,\n",
      "       0.87317621, 0.87373737, 0.87205387, 0.87373737, 0.87373737,\n",
      "       0.87317621, 0.87373737, 0.87205387, 0.87373737, 0.87373737,\n",
      "       0.87317621, 0.87373737, 0.87205387, 0.87373737, 0.87373737,\n",
      "       0.8698092 , 0.8681257 , 0.8714927 , 0.86924804, 0.8714927 ,\n",
      "       0.86251403, 0.86588103, 0.8681257 , 0.86868687, 0.8681257 ,\n",
      "       0.84511785, 0.84399551, 0.84848485, 0.84848485, 0.84792368,\n",
      "       0.84511785, 0.84399551, 0.84848485, 0.84848485, 0.84792368,\n",
      "       0.84511785, 0.84399551, 0.84848485, 0.84848485, 0.84792368,\n",
      "       0.84511785, 0.84399551, 0.84848485, 0.84848485, 0.84792368,\n",
      "       0.84511785, 0.84399551, 0.84848485, 0.84848485, 0.84792368,\n",
      "       0.99719416, 0.9983165 , 0.9983165 , 0.9983165 , 0.9983165 ,\n",
      "       0.9657688 , 0.9657688 , 0.9640853 , 0.96632997, 0.96464646,\n",
      "       0.90740741, 0.91301908, 0.91470258, 0.91470258, 0.91470258,\n",
      "       0.89842873, 0.9023569 , 0.90852974, 0.90909091, 0.90909091,\n",
      "       0.89225589, 0.89169473, 0.89281706, 0.8956229 , 0.89450056,\n",
      "       0.87093154, 0.87205387, 0.87373737, 0.87205387, 0.87261504,\n",
      "       0.87093154, 0.87205387, 0.87373737, 0.87205387, 0.87261504,\n",
      "       0.87093154, 0.87205387, 0.87373737, 0.87205387, 0.87261504,\n",
      "       0.87093154, 0.87037037, 0.8714927 , 0.86924804, 0.87037037,\n",
      "       0.86700337, 0.86419753, 0.8681257 , 0.86868687, 0.87037037,\n",
      "       0.84343434, 0.84455668, 0.84736251, 0.84511785, 0.84680135,\n",
      "       0.84343434, 0.84455668, 0.84736251, 0.84511785, 0.84680135,\n",
      "       0.84343434, 0.84455668, 0.84736251, 0.84511785, 0.84680135,\n",
      "       0.84343434, 0.84455668, 0.84736251, 0.84511785, 0.84680135,\n",
      "       0.84343434, 0.84455668, 0.84736251, 0.84511785, 0.84680135]), 'std_train_score': array([0.0028614 , 0.00137457, 0.00137457, 0.00137457, 0.00137457,\n",
      "       0.00555527, 0.00629909, 0.00629909, 0.00619829, 0.00757056,\n",
      "       0.0076533 , 0.00894353, 0.01111054, 0.00975205, 0.01239659,\n",
      "       0.00994391, 0.01306447, 0.01099659, 0.00828553, 0.0076533 ,\n",
      "       0.01311259, 0.01320831, 0.01174436, 0.01237116, 0.01311259,\n",
      "       0.00975205, 0.01198325, 0.0103778 , 0.01237116, 0.01174436,\n",
      "       0.00975205, 0.01198325, 0.0103778 , 0.01237116, 0.01174436,\n",
      "       0.00975205, 0.01198325, 0.0103778 , 0.01237116, 0.01174436,\n",
      "       0.00965469, 0.00915236, 0.01102519, 0.0120095 , 0.01185113,\n",
      "       0.0079361 , 0.0104081 , 0.00915236, 0.01091034, 0.01049848,\n",
      "       0.00901368, 0.01111054, 0.02160312, 0.02052676, 0.01974479,\n",
      "       0.00901368, 0.01111054, 0.02160312, 0.02052676, 0.01974479,\n",
      "       0.00901368, 0.01111054, 0.02160312, 0.02052676, 0.01974479,\n",
      "       0.00901368, 0.01111054, 0.02160312, 0.02052676, 0.01974479,\n",
      "       0.00901368, 0.01111054, 0.02160312, 0.02052676, 0.01974479,\n",
      "       0.0028614 , 0.00137457, 0.00137457, 0.00137457, 0.00137457,\n",
      "       0.0028614 , 0.00419939, 0.00757056, 0.00495609, 0.00629909,\n",
      "       0.00824744, 0.00805426, 0.01102519, 0.01306447, 0.01169061,\n",
      "       0.01031693, 0.00901368, 0.00935653, 0.00991219, 0.00962201,\n",
      "       0.0083612 , 0.00915236, 0.01320831, 0.0103778 , 0.01102519,\n",
      "       0.00839878, 0.01311259, 0.01099659, 0.0103778 , 0.01031693,\n",
      "       0.00839878, 0.01311259, 0.01099659, 0.0103778 , 0.01031693,\n",
      "       0.00839878, 0.01311259, 0.01099659, 0.0103778 , 0.01031693,\n",
      "       0.00894353, 0.01237116, 0.01031693, 0.0120095 , 0.01099659,\n",
      "       0.00991219, 0.0140404 , 0.01049848, 0.01221748, 0.01174436,\n",
      "       0.00901368, 0.00883727, 0.01662798, 0.01585235, 0.01716842,\n",
      "       0.00901368, 0.00883727, 0.01662798, 0.01585235, 0.01716842,\n",
      "       0.00901368, 0.00883727, 0.01662798, 0.01585235, 0.01716842,\n",
      "       0.00901368, 0.00883727, 0.01662798, 0.01585235, 0.01716842,\n",
      "       0.00901368, 0.00883727, 0.01662798, 0.01585235, 0.01716842])}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(max_features='auto', oob_score=True, random_state=1, n_jobs=3)\n",
    "\n",
    "param_grid = { \"criterion\" : [\"gini\", \"entropy\"], \n",
    "              \"min_samples_leaf\" : [1, 5, 10], \n",
    "              \"min_samples_split\" : [2, 4, 10, 12, 16],\n",
    "              \"n_estimators\": [50, 100, 400, 700, 1000]}\n",
    "\n",
    "gs = GridSearchCV(estimator=rf, param_grid=param_grid, scoring='accuracy', \n",
    "                  cv=3, n_jobs=6, verbose=1)\n",
    "\n",
    "gs = gs.fit(train.iloc[:, 1:], train.iloc[:, 0])\n",
    "\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)\n",
    "print(gs.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8294\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(criterion='gini', \n",
    "                             n_estimators=700,\n",
    "                             min_samples_split=10,\n",
    "                             min_samples_leaf=1,\n",
    "                             max_features='auto',\n",
    "                             oob_score=True,\n",
    "                             random_state=1,\n",
    "                             n_jobs=-1)\n",
    "rf.fit(train.iloc[:, 1:], train.iloc[:, 0])\n",
    "print(\"%.4f\" % rf.oob_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 700}\n",
      "Mean cross-validated score of the best_estimator:  0.8383838383838383\n",
      "\n",
      "Rank|Score(std)|Params ['criterion', 'min_samples_leaf', 'min_samples_split', 'n_estimators']\n",
      "1|0.838384(std:0.018027)|['gini', 1, 10, 700]\n",
      "1|0.838384(std:0.016495)|['gini', 1, 10, 1000]\n",
      "1|0.838384(std:0.009912)|['entropy', 1, 4, 400]\n",
      "1|0.838384(std:0.009912)|['entropy', 1, 12, 50]\n",
      "5|0.837262(std:0.013561)|['gini', 1, 4, 50]\n",
      "5|0.837262(std:0.004199)|['gini', 1, 4, 100]\n",
      "5|0.837262(std:0.011111)|['gini', 1, 4, 700]\n",
      "5|0.837262(std:0.016798)|['entropy', 1, 12, 1000]\n",
      "9|0.836139(std:0.011446)|['gini', 1, 4, 400]\n",
      "9|0.836139(std:0.009655)|['gini', 1, 4, 1000]\n",
      "9|0.836139(std:0.022050)|['entropy', 1, 4, 100]\n",
      "9|0.836139(std:0.009655)|['entropy', 1, 4, 700]\n",
      "9|0.836139(std:0.019888)|['entropy', 1, 16, 100]\n"
     ]
    }
   ],
   "source": [
    "print(\"best parameters:\", gs.best_params_)\n",
    "print(\"Mean cross-validated score of the best_estimator: \", gs.best_score_)\n",
    "print(\"\")\n",
    "report2(gs.cv_results_, n_top=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Survived', 'Age', 'Fare', 'Name_Len', 'Age_Null_Flag',\n",
       "       'Cabin_num_(1.999, 28.667]', 'Cabin_num_(28.667, 65.667]',\n",
       "       'Cabin_num_(65.667, 148.0]', 'Ticket_Len', 'Pclass_3', 'Pclass_1',\n",
       "       'Pclass_2', 'Sex_male', 'Sex_female', 'Embarked_S', 'Embarked_C',\n",
       "       'Embarked_Q', 'Ticket_Lett_A', 'Ticket_Lett_P', 'Ticket_Lett_S',\n",
       "       'Ticket_Lett_1', 'Ticket_Lett_3', 'Ticket_Lett_2', 'Ticket_Lett_C',\n",
       "       'Ticket_Lett_Low_ticket', 'Ticket_Lett_Other_ticket', 'Cabin_Letter_n',\n",
       "       'Cabin_Letter_C', 'Cabin_Letter_E', 'Cabin_Letter_G', 'Cabin_Letter_D',\n",
       "       'Cabin_Letter_A', 'Cabin_Letter_B', 'Cabin_Letter_F', 'Name_Title_Mr.',\n",
       "       'Name_Title_Mrs.', 'Name_Title_Miss.', 'Name_Title_Master.',\n",
       "       'Name_Title_Rev.', 'Name_Title_Dr.', 'Name_Title_Ms.',\n",
       "       'Name_Title_Col.', 'Fam_Size_Nuclear', 'Fam_Size_Solo', 'Fam_Size_Big'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Sex_male</td>\n",
       "      <td>0.111215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Pclass_2</td>\n",
       "      <td>0.109769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Cabin_Letter_F</td>\n",
       "      <td>0.109746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.088209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fare</td>\n",
       "      <td>0.087904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Survived</td>\n",
       "      <td>0.078651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ticket_Len</td>\n",
       "      <td>0.043268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Name_Title_Mrs.</td>\n",
       "      <td>0.031292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cabin_num_(65.667, 148.0]</td>\n",
       "      <td>0.031079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Name_Title_Mr.</td>\n",
       "      <td>0.028852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Ticket_Lett_Other_ticket</td>\n",
       "      <td>0.027893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Fam_Size_Solo</td>\n",
       "      <td>0.025199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Name_Title_Col.</td>\n",
       "      <td>0.022704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pclass_3</td>\n",
       "      <td>0.021810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Ticket_Lett_S</td>\n",
       "      <td>0.017999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Ticket_Lett_1</td>\n",
       "      <td>0.012902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Pclass_1</td>\n",
       "      <td>0.012345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Name_Title_Miss.</td>\n",
       "      <td>0.012098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Ticket_Lett_C</td>\n",
       "      <td>0.011723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sex_female</td>\n",
       "      <td>0.011546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Fam_Size_Nuclear</td>\n",
       "      <td>0.010619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Age_Null_Flag</td>\n",
       "      <td>0.009380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Embarked_S</td>\n",
       "      <td>0.008760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Name_Len</td>\n",
       "      <td>0.008420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Cabin_Letter_C</td>\n",
       "      <td>0.007851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Ticket_Lett_3</td>\n",
       "      <td>0.007336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Embarked_C</td>\n",
       "      <td>0.005978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Ticket_Lett_P</td>\n",
       "      <td>0.005167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cabin_num_(1.999, 28.667]</td>\n",
       "      <td>0.005064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Cabin_Letter_G</td>\n",
       "      <td>0.004613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Cabin_Letter_n</td>\n",
       "      <td>0.003985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cabin_num_(28.667, 65.667]</td>\n",
       "      <td>0.003982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Ticket_Lett_A</td>\n",
       "      <td>0.003618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Ticket_Lett_2</td>\n",
       "      <td>0.003242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Embarked_Q</td>\n",
       "      <td>0.003158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Cabin_Letter_A</td>\n",
       "      <td>0.003157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Name_Title_Master.</td>\n",
       "      <td>0.002610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Cabin_Letter_D</td>\n",
       "      <td>0.001813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Name_Title_Rev.</td>\n",
       "      <td>0.001495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Cabin_Letter_B</td>\n",
       "      <td>0.001348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Cabin_Letter_E</td>\n",
       "      <td>0.001016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Ticket_Lett_Low_ticket</td>\n",
       "      <td>0.000569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Name_Title_Ms.</td>\n",
       "      <td>0.000430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Name_Title_Dr.</td>\n",
       "      <td>0.000184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Fam_Size_Big</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      variable  importance\n",
       "12                    Sex_male    0.111215\n",
       "11                    Pclass_2    0.109769\n",
       "33              Cabin_Letter_F    0.109746\n",
       "1                          Age    0.088209\n",
       "2                         Fare    0.087904\n",
       "0                     Survived    0.078651\n",
       "8                   Ticket_Len    0.043268\n",
       "35             Name_Title_Mrs.    0.031292\n",
       "7    Cabin_num_(65.667, 148.0]    0.031079\n",
       "34              Name_Title_Mr.    0.028852\n",
       "25    Ticket_Lett_Other_ticket    0.027893\n",
       "43               Fam_Size_Solo    0.025199\n",
       "41             Name_Title_Col.    0.022704\n",
       "9                     Pclass_3    0.021810\n",
       "19               Ticket_Lett_S    0.017999\n",
       "20               Ticket_Lett_1    0.012902\n",
       "10                    Pclass_1    0.012345\n",
       "36            Name_Title_Miss.    0.012098\n",
       "23               Ticket_Lett_C    0.011723\n",
       "13                  Sex_female    0.011546\n",
       "42            Fam_Size_Nuclear    0.010619\n",
       "4                Age_Null_Flag    0.009380\n",
       "14                  Embarked_S    0.008760\n",
       "3                     Name_Len    0.008420\n",
       "27              Cabin_Letter_C    0.007851\n",
       "21               Ticket_Lett_3    0.007336\n",
       "15                  Embarked_C    0.005978\n",
       "18               Ticket_Lett_P    0.005167\n",
       "5    Cabin_num_(1.999, 28.667]    0.005064\n",
       "29              Cabin_Letter_G    0.004613\n",
       "26              Cabin_Letter_n    0.003985\n",
       "6   Cabin_num_(28.667, 65.667]    0.003982\n",
       "17               Ticket_Lett_A    0.003618\n",
       "22               Ticket_Lett_2    0.003242\n",
       "16                  Embarked_Q    0.003158\n",
       "31              Cabin_Letter_A    0.003157\n",
       "37          Name_Title_Master.    0.002610\n",
       "30              Cabin_Letter_D    0.001813\n",
       "38             Name_Title_Rev.    0.001495\n",
       "32              Cabin_Letter_B    0.001348\n",
       "28              Cabin_Letter_E    0.001016\n",
       "24      Ticket_Lett_Low_ticket    0.000569\n",
       "40              Name_Title_Ms.    0.000430\n",
       "39              Name_Title_Dr.    0.000184\n",
       "44                Fam_Size_Big         NaN"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat((pd.DataFrame(train.columns, columns = ['variable']), \n",
    "           pd.DataFrame(gs.best_estimator_.feature_importances_, columns = ['importance'])), \n",
    "          axis = 1).sort_values(by='importance', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get passenger id\n",
    "_test = pd.read_csv(os.path.join('../input', 'test.csv'))\n",
    "\n",
    "y_pred = gs.best_estimator_.predict(test).astype(int)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": _test[\"PassengerId\"].astype(int),\n",
    "        \"Survived\": y_pred\n",
    "    })\n",
    "submission.to_csv('../output/_titanic-random-forest-82-78.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "----\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# original\n",
    "\n",
    "https://www.kaggle.com/shunjiangxu/blood-is-thicker-than-water-friendship-forever\n",
    "\n",
    "\n",
    "# special\n",
    "\n",
    "- family/group survival feature\n",
    "  - The family/group information is extracted from name, fare and ticket number\n",
    "  - This new feature improved the score by ~1.5% and put the score to be 0.81818.\n",
    "  - **this feature express that other member of passenger's family are survived or not.**\n",
    "    - **this feature doesn't include my survival count.**\n",
    "- fill age by randint from Age statics\n",
    "\n",
    "age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\n",
    "dataset['Age'][np.isnan(dataset['Age'])] = age_null_random_list\n",
    "dataset['Age'] = dataset['Age'].astype(int)\n",
    "\n",
    "- using Rare title for many titles\n",
    "- **The Fare is actually for the whole family**\n",
    "\n",
    "  \n",
    "\n",
    "# score\n",
    "\n",
    "- 0.81818\n",
    "\n",
    "\n",
    "# columns\n",
    "\n",
    "    \n",
    "# else\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n",
      "None\n",
      "   FamilySize  Survived\n",
      "0           1  0.303538\n",
      "1           2  0.552795\n",
      "2           3  0.578431\n",
      "3           4  0.724138\n",
      "4           5  0.200000\n",
      "5           6  0.136364\n",
      "6           7  0.333333\n",
      "7           8  0.000000\n",
      "8          11  0.000000\n",
      "   IsAlone  Survived\n",
      "0        0  0.505650\n",
      "1        1  0.303538\n",
      "  Embarked  Survived\n",
      "0        C  0.553571\n",
      "1        Q  0.389610\n",
      "2        S  0.339009\n",
      "   CategoricalFare  Survived\n",
      "0   (-0.001, 7.91]  0.197309\n",
      "1   (7.91, 14.454]  0.303571\n",
      "2   (14.454, 31.0]  0.454955\n",
      "3  (31.0, 512.329]  0.581081\n",
      "  CategoricalAge  Survived\n",
      "0  (-0.08, 16.0]  0.522523\n",
      "1   (16.0, 32.0]  0.344595\n",
      "2   (32.0, 48.0]  0.390625\n",
      "3   (48.0, 64.0]  0.434783\n",
      "4   (64.0, 80.0]  0.090909\n",
      "Sex           female  male\n",
      "Title                     \n",
      "Capt               0     1\n",
      "Col                0     2\n",
      "Don                0     1\n",
      "Dr                 1     6\n",
      "Jonkheer           0     1\n",
      "Lady               1     0\n",
      "Major              0     2\n",
      "Master             0    40\n",
      "Miss             182     0\n",
      "Mlle               2     0\n",
      "Mme                1     0\n",
      "Mr                 0   517\n",
      "Mrs              125     0\n",
      "Ms                 1     0\n",
      "Rev                0     6\n",
      "Sir                0     1\n",
      "the Countess       1     0\n",
      "          Title  Survived\n",
      "0        Master  0.575000\n",
      "1          Miss  0.702703\n",
      "2            Mr  0.156673\n",
      "3           Mrs  0.793651\n",
      "4          Rare  0.318182\n",
      "5  the Countess  1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re as re\n",
    "\n",
    "train = pd.read_csv('../input/train.csv', header = 0, dtype={'Age': np.float64})\n",
    "test  = pd.read_csv('../input/test.csv' , header = 0, dtype={'Age': np.float64})\n",
    "full_data = [train, test]\n",
    "\n",
    "print (train.info())\n",
    "\n",
    "for dataset in full_data:\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "print (train[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean())\n",
    "\n",
    "\n",
    "for dataset in full_data:\n",
    "    dataset['IsAlone'] = 0\n",
    "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "print (train[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean())\n",
    "\n",
    "for dataset in full_data:\n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna('S')\n",
    "print (train[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean())\n",
    "\n",
    "\n",
    "\n",
    "for dataset in full_data:\n",
    "    dataset['Fare'] = dataset['Fare'].fillna(train['Fare'].median())\n",
    "train['CategoricalFare'] = pd.qcut(train['Fare'], 4)\n",
    "print (train[['CategoricalFare', 'Survived']].groupby(['CategoricalFare'], as_index=False).mean())\n",
    "\n",
    "\n",
    "for dataset in full_data:\n",
    "    age_avg = dataset['Age'].mean()\n",
    "    age_std = dataset['Age'].std()\n",
    "    age_null_count = dataset['Age'].isnull().sum()\n",
    "    \n",
    "    age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\n",
    "    dataset['Age'][np.isnan(dataset['Age'])] = age_null_random_list\n",
    "    dataset['Age'] = dataset['Age'].astype(int)\n",
    "    \n",
    "train['CategoricalAge'] = pd.cut(train['Age'], 5)\n",
    "\n",
    "print (train[['CategoricalAge', 'Survived']].groupby(['CategoricalAge'], as_index=False).mean())\n",
    "\n",
    "\n",
    "for dataset in full_data:\n",
    "    dataset['Title'] = [x[1].split(\".\")[0].strip(\" \") for x in dataset['Name'].str.split(\",\")]\n",
    "\n",
    "print(pd.crosstab(train['Title'], train['Sex']))\n",
    "\n",
    "for dataset in full_data:\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n",
    " \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "print (train[['Title', 'Survived']].groupby(['Title'], as_index=False).mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting family information\n",
    "\n",
    "- First we can use **last name** to divide the passengers into families. \n",
    "- And if you closely examin the data, **same family are paying the same fare** for the tickets. This suggests the fare is for the family. \n",
    "- We can use **both last name and fare to grout passengers into families** in case different families with the same last name.\n",
    "- **The Fare is actually for the whole family**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of families with different fares is: 1.7%\n",
      "Whole family survived: 44.7%\n",
      "Whole family perished: 35.7%\n",
      "Number of passenger with family survival information: 420\n",
      "partial age group: 0\n",
      "partial cabin group: 4\n",
      "              Age\n",
      "count  165.000000\n",
      "mean     9.569697\n",
      "std     10.906601\n",
      "min      0.000000\n",
      "25%      2.000000\n",
      "50%      6.000000\n",
      "75%     13.000000\n",
      "max     48.000000\n"
     ]
    }
   ],
   "source": [
    "train_size = len(train)\n",
    "test_size = len(test)\n",
    "\n",
    "all_df = train.append(test)\n",
    "all_df = all_df[list(train.columns)]\n",
    "\n",
    "all_df.set_index(['PassengerId'], inplace=True) ## This is to make sure of a unique index for both train & test\n",
    "\n",
    "## Processing family information\n",
    "all_df['Last name'] = all_df['Name'].apply(lambda x: str.split(x, \",\")[0])\n",
    "all_df['Fare'].fillna(all_df['Fare'].mean(), inplace=True)\n",
    "\n",
    "# The Fare is actually for the whole family\n",
    "fare_df = all_df.loc[all_df['FamilySize']>1, [\"Last name\", \"Fare\", \"FamilySize\"]].iloc[:train_size]\n",
    "fare_diff = (((fare_df.groupby(['Last name', 'FamilySize']).max() \n",
    " - fare_df.groupby(['Last name', 'FamilySize']).min())!=0).sum()/train_size * 100)\n",
    "print((\"Percentage of families with different fares is: %.1f\" %(fare_diff.values[0])) + '%')\n",
    "# The data shows only 1.7% has a different fare value between family memebers. It's some type of anomaly\n",
    "# Will use last name and fare to group passengers into families\n",
    "# First would like to show there is value in doing this\n",
    "train_temp_df = all_df.iloc[:train_size]\n",
    "family_df_grpby = train_temp_df[train_temp_df['FamilySize']>1][\n",
    "    ['Last name', 'Fare', 'FamilySize', 'Survived']].groupby(['Last name', 'Fare'])\n",
    "family_df = pd.DataFrame(data=family_df_grpby.size(), columns=['Size in train'])\n",
    "family_df['Survived total'] = family_df_grpby['Survived'].sum().astype(int)\n",
    "family_df['FamilySize'] = family_df_grpby['FamilySize'].mean().astype(int)\n",
    "#family_df = family_df[family_df['FamilySize']==8]\n",
    "print(\"Whole family survived: %.1f\" \n",
    "      %(100*len(family_df[family_df['Size in train']==family_df['Survived total'] ])/len(family_df))+'%') \n",
    "print(\"Whole family perished: %.1f\" \n",
    "      %(100*len(family_df[family_df['Survived total'] == 0])/len(family_df))+'%') \n",
    "## Majority family either all perished or all survived, this means we can use this as one feature to \n",
    "## predict survival\n",
    "\n",
    "# Now let's do the feature extraction\n",
    "# Intialize all 'Family survival', meaning there is no information on if any family members survived. \n",
    "# This number can be tuned I guess but I will use it to start with.\n",
    "grp_partial_age = 0\n",
    "grp_partial_cabin = 0\n",
    "grp_age_diff_df = pd.DataFrame()\n",
    "all_df['Family survival'] = 0.5\n",
    "for grp, grp_df in all_df[['Survived','Name', 'Last name', 'Fare', \n",
    "                           'SibSp', 'Parch', 'Age', 'Cabin']].groupby(['Last name', 'Fare']):\n",
    "    if (len(grp_df) != 1):\n",
    "        grp_missing_age = len(grp_df[grp_df['Age'].isnull()])\n",
    "        is_partial_age = (grp_missing_age != 0) & (grp_missing_age != len(grp_df))\n",
    "        grp_partial_age += is_partial_age\n",
    "        \n",
    "        sibsp_df = grp_df.loc[grp_df['SibSp']!=0, ['Age']]\n",
    "        #print(sibsp_df.info())\n",
    "        sibsp_age_diff = sibsp_df.max() - sibsp_df.min()\n",
    "        grp_age_diff_df = grp_age_diff_df.append(sibsp_age_diff, ignore_index=True)\n",
    "\n",
    "        grp_missing_cabin = len(grp_df[grp_df['Cabin'].isnull()])\n",
    "        grp_partial_cabin += (grp_missing_cabin != 0) & (grp_missing_cabin != len(grp_df))\n",
    "\n",
    "\n",
    "        for PassID, row in grp_df.iterrows():\n",
    "            ## Find out if any family memebers survived or not\n",
    "            smax = grp_df.drop(PassID)['Survived'].max()\n",
    "            smin = grp_df.drop(PassID)['Survived'].min()\n",
    "\n",
    "            ## If any family memebers survived, put this feature as 1\n",
    "            if (smax==1.0): all_df.loc[PassID, 'Family survival'] = 1\n",
    "            ## Otherwise if any family memebers perished, put this feature as 0\n",
    "            elif (smin==0.0): all_df.loc[PassID, 'Family survival'] = 0\n",
    "\n",
    "print(\"Number of passenger with family survival information: \" \n",
    "      +str(all_df[all_df['Family survival']!=0.5].shape[0]))\n",
    "\n",
    "print('partial age group: ' + str(grp_partial_age))\n",
    "print('partial cabin group: ' + str(grp_partial_cabin))\n",
    "print(grp_age_diff_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting group information\n",
    "\n",
    "- In addtional to family, if you examin the data closely, you will see **there are groups of people with same ticket number, and they pay the same fare. **\n",
    "  - This suggests **group of friends** are travelling together. \n",
    "  - One will think **these friends will help each other and will survive or perish at the same time.**\n",
    "  - We will explore this informtion here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of groups in training set that is not family: 44\n",
      "Whole group perished: 29.5%\n",
      "Whole group survived: 36.4%\n",
      "partial age group: 0\n",
      "partial cabin group: 12\n",
      "Number of passenger with family/group survival information: 546\n",
      "        Age diff\n",
      "count        216\n",
      "unique        47\n",
      "top            4\n",
      "freq          14\n"
     ]
    }
   ],
   "source": [
    "# First find out how many such groups exists that are not families and what is the chance of \n",
    "# passengers within the same group survive or perish together\n",
    "train_temp_df = all_df.iloc[:train_size]\n",
    "ticket_grpby = train_temp_df.groupby('Ticket')\n",
    "ticket_df = pd.DataFrame(data=ticket_grpby.size(), columns=['Size in train'])\n",
    "ticket_df['Survived total'] = ticket_grpby['Survived'].sum().astype(int)\n",
    "ticket_df['Not family'] = ticket_grpby['Last name'].unique().apply(len)\n",
    "#ticket_df['Pclass'] = ticket_grpby['Pclass'].median()\n",
    "ticket_df = ticket_df[(ticket_df['Size in train'] > 1) & (ticket_df['Not family']>1)]\n",
    "print('Number of groups in training set that is not family: '+ str(len(ticket_df)))\n",
    "#print(\"Groups in Pclass 2/3: \" + str(len(ticket_df[ticket_df['Pclass']!=1])))\n",
    "print((\"Whole group perished: %.1f\" %(100/len(ticket_df)*len(ticket_df[ticket_df['Survived total']==0]))) + '%')\n",
    "print((\"Whole group survived: %.1f\" \n",
    "       %(100/len(ticket_df)*len(ticket_df[ticket_df['Survived total']==ticket_df['Size in train']]))) + '%')\n",
    "\n",
    "## Looking at the output, one can see ~76% of group members stay together. So let's extract this feature.\n",
    "## We will overload the 'Family survival' column instead of creating a seperate feature.\n",
    "grp_partial_age = 0\n",
    "grp_partial_cabin = 0\n",
    "grp_age_diff_df = pd.DataFrame(columns=['Age diff'])\n",
    "ticket_grpby = all_df.groupby('Ticket')\n",
    "for _, grp_df in ticket_grpby:\n",
    "    if (len(grp_df) > 1):\n",
    "        grp_missing_age = len(grp_df[grp_df['Age'].isnull()])\n",
    "        grp_partial_age += (grp_missing_age != 0) & (grp_missing_age != len(grp_df))\n",
    "\n",
    "        grp_age_diff_df = grp_age_diff_df.append(pd.DataFrame(data=[grp_df['Age'].max() \n",
    "                                                                    - grp_df['Age'].min()]\n",
    "                                                              , columns=['Age diff']))\n",
    "\n",
    "\n",
    "        grp_missing_cabin = len(grp_df[grp_df['Cabin'].isnull()])\n",
    "        grp_partial_cabin += (grp_missing_cabin != 0) & (grp_missing_cabin != len(grp_df))\n",
    "        for PassID, row in grp_df.iterrows():\n",
    "            if (row['Family survival']==0)|(row['Family survival']==0.5):\n",
    "                smax = grp_df.drop(PassID)['Survived'].max()\n",
    "                smin = grp_df.drop(PassID)['Survived'].min()\n",
    "                if (smax==1.0): all_df.loc[PassID, 'Family survival'] = 1\n",
    "                elif (smin==0.0): all_df.loc[PassID, 'Family survival'] = 0\n",
    "print('partial age group: ' + str(grp_partial_age))\n",
    "print('partial cabin group: ' + str(grp_partial_cabin))\n",
    "print(\"Number of passenger with family/group survival information: \" \n",
    "      +str(all_df[all_df['Family survival']!=0.5].shape[0]))\n",
    "train['Family survival'] = (all_df.iloc[:train_size]['Family survival'].values).astype(float)\n",
    "test['Family survival'] = (all_df.iloc[train_size:]['Family survival'].values).astype(float)\n",
    "print(grp_age_diff_df.describe())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_temp_df.groupby('Ticket').Survived.value_counts().unique()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_temp_df = all_df.iloc[:train_size]\n",
    "ticket_grpby = train_temp_df.groupby('Ticket')\n",
    "ticket_grpby.size().value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ticket_grpby['Survived'].sum().head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ticket_grpby['Last name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Survived  Pclass  Sex  Age  Fare  Embarked  IsAlone  Title  Family survival\n",
      "0         0       3    1    1     0         0        0    1.0              0.5\n",
      "1         1       1    0    2     3         1        0    3.0              0.5\n",
      "2         1       3    0    1     1         0        1    2.0              0.5\n",
      "3         1       1    0    2     3         0        0    3.0              0.0\n",
      "4         0       3    1    2     1         0        1    1.0              0.5\n",
      "5         0       3    1    1     1         2        1    1.0              0.5\n",
      "6         0       1    1    3     3         0        1    1.0              0.5\n",
      "7         0       3    1    0     2         0        0    4.0              0.0\n",
      "8         1       3    0    1     1         0        0    3.0              1.0\n",
      "9         1       2    0    0     2         1        0    3.0              0.0\n"
     ]
    }
   ],
   "source": [
    "for dataset in full_data:\n",
    "    # Mapping Sex\n",
    "    dataset['Sex'] = dataset['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n",
    "    \n",
    "    # Mapping titles\n",
    "    title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "    dataset['Title'] = dataset['Title'].map(title_mapping)\n",
    "    dataset['Title'] = dataset['Title'].fillna(0)\n",
    "    \n",
    "    # Mapping Embarked\n",
    "    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
    "    \n",
    "    # Mapping Fare\n",
    "    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] \t\t\t\t\t\t        = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
    "    dataset.loc[ dataset['Fare'] > 31, 'Fare'] \t\t\t\t\t\t\t        = 3\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "    \n",
    "    # Mapping Age\n",
    "    dataset.loc[ dataset['Age'] <= 16, 'Age'] \t\t\t\t\t       = 0\n",
    "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
    "    dataset.loc[ dataset['Age'] > 64, 'Age']                           = 4\n",
    "\n",
    "# Feature Selection\n",
    "drop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp',\\\n",
    "                 'Parch', 'FamilySize']\n",
    "train = train.drop(drop_elements, axis = 1)\n",
    "train = train.drop(['CategoricalAge', 'CategoricalFare'], axis = 1)\n",
    "\n",
    "test  = test.drop(drop_elements, axis = 1)\n",
    "\n",
    "print (train.head(10))\n",
    "\n",
    "train = train.values\n",
    "test  = test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fb3cd0302e8>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb3cdce50f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(probability=True),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    GaussianNB(),\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "    LogisticRegression()]\n",
    "\n",
    "log_cols = [\"Classifier\", \"Accuracy\"]\n",
    "log = pd.DataFrame(columns=log_cols)\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=10, test_size=0.1, random_state=0)\n",
    "\n",
    "X = train[0::, 1::]\n",
    "y = train[0::, 0]\n",
    "\n",
    "acc_dict = {}\n",
    "\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    for clf in classifiers:\n",
    "        name = clf.__class__.__name__\n",
    "        clf.fit(X_train, y_train)\n",
    "        train_predictions = clf.predict(X_test)\n",
    "        acc = accuracy_score(y_test, train_predictions)\n",
    "        if name in acc_dict:\n",
    "            acc_dict[name] += acc\n",
    "        else:\n",
    "            acc_dict[name] = acc\n",
    "\n",
    "for clf in acc_dict:\n",
    "    acc_dict[clf] = acc_dict[clf] / 10.0\n",
    "    log_entry = pd.DataFrame([[clf, acc_dict[clf]]], columns=log_cols)\n",
    "    log = log.append(log_entry)\n",
    "\n",
    "plt.xlabel('Accuracy')\n",
    "plt.title('Classifier Accuracy')\n",
    "\n",
    "sns.set_color_codes(\"muted\")\n",
    "sns.barplot(x='Accuracy', y='Classifier', data=log, color=\"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AdaBoostClassifier': 0.8377777777777776,\n",
       " 'DecisionTreeClassifier': 0.8255555555555555,\n",
       " 'GaussianNB': 0.7799999999999999,\n",
       " 'GradientBoostingClassifier': 0.8388888888888889,\n",
       " 'KNeighborsClassifier': 0.8166666666666667,\n",
       " 'LinearDiscriminantAnalysis': 0.8422222222222222,\n",
       " 'LogisticRegression': 0.8444444444444444,\n",
       " 'QuadraticDiscriminantAnalysis': 0.82,\n",
       " 'RandomForestClassifier': 0.8233333333333333,\n",
       " 'SVC': 0.8477777777777777}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "----\n",
    "----\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# original\n",
    "\n",
    "https://www.kaggle.com/konstantinmasich/titanic-0-82-0-83/\n",
    "\n",
    "# special\n",
    "\n",
    "- cv 10\n",
    "- less features\n",
    "- not using columns = [train_df, test_df]\n",
    "  - data_df = train_df.append(test_df)\n",
    "  - train_df['Age'] = data_df['Age'][:891]\n",
    "- **make a Title feature for imputing ages**\n",
    "  - titles = ['Dr', 'Master', 'Miss', 'Mr', 'Mrs', 'Rev']\n",
    "    - Replacing rare titles with more common ones\n",
    "      - mapping = {'Mlle': 'Miss', 'Major': 'Mr', 'Col': 'Mr', 'Sir': 'Mr', 'Don': 'Mr', 'Mme': 'Miss','Jonkheer': 'Mr', 'Lady': 'Mrs', 'Capt': 'Mr', 'Countess': 'Mrs', 'Ms': 'Miss', 'Dona': 'Mrs'}\n",
    "- **Adding Family_Survival**\n",
    "  - **this feature express that other member of passenger's family are survived or not.**\n",
    "    - **this feature doesn't include my survival count.**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# score\n",
    "\n",
    "- best score of 10 cv score: **0.879492358564**\n",
    "- submit score: 0.83253\n",
    "\n",
    "# columns\n",
    "\n",
    "\tSurvived\tPclass\tSex\tFamily_Size\tFamily_Survival\n",
    "    \n",
    "# else\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy\n",
    "import numpy as np\n",
    "\n",
    "# Dataframe operations\n",
    "import pandas as pd\n",
    "\n",
    "# Data visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scalers\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression #logistic regression\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn import svm #support vector Machine\n",
    "from sklearn.ensemble import RandomForestClassifier #Random Forest\n",
    "from sklearn.neighbors import KNeighborsClassifier #KNN\n",
    "from sklearn.naive_bayes import GaussianNB #Naive bayes\n",
    "from sklearn.tree import DecisionTreeClassifier #Decision Tree\n",
    "from sklearn.model_selection import train_test_split #training and testing data split\n",
    "from sklearn import metrics #accuracy measure\n",
    "from sklearn.metrics import confusion_matrix #for confusion matrix\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Cross-validation\n",
    "from sklearn.model_selection import KFold #for K-fold cross validation\n",
    "from sklearn.model_selection import cross_val_score #score evaluation\n",
    "from sklearn.model_selection import cross_val_predict #prediction\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Common Model Algorithms\n",
    "from sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
    "\n",
    "#Common Model Helpers\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn import feature_selection\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "\n",
    "#Visualization\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import seaborn as sns\n",
    "from pandas.tools.plotting import scatter_matrix"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## understanding Family_Survival feature"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_df = pd.read_csv(\"../input/train.csv\")\n",
    "test_df = pd.read_csv(\"../input/test.csv\")\n",
    "data_df = train_df.append(test_df) # The entire data: train + test.\n",
    "\n",
    "data_df['Last_Name'] = data_df['Name'].apply(lambda x: str.split(x, \",\")[0])\n",
    "data_df['Fare'].fillna(data_df['Fare'].mean(), inplace=True)\n",
    "\n",
    "DEFAULT_SURVIVAL_VALUE = 0.5\n",
    "data_df['Family_Survival'] = DEFAULT_SURVIVAL_VALUE\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data_df[[\"Name\", \"Last_Name\"]].head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "groupbyData = data_df[['Survived','Name', 'Last_Name', 'Fare', 'Ticket', 'PassengerId',\n",
    "         'SibSp', 'Parch', 'Age', 'Cabin']].groupby(['Last_Name', 'Fare'])\n",
    "for i in groupbyData:\n",
    "    print(type(i))\n",
    "    print(len(i))\n",
    "    print(i[0])\n",
    "    print(type(i[1]))\n",
    "    print(i[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "for grp, grp_df in data_df[['Survived','Name', 'Last_Name', 'Fare', 'Ticket', 'PassengerId',\n",
    "                           'SibSp', 'Parch', 'Age', 'Cabin']].groupby(['Last_Name', 'Fare']):\n",
    "    \n",
    "    if (len(grp_df) != 1):\n",
    "        # A Family group is found.\n",
    "        for ind, row in grp_df.iterrows():\n",
    "            print(ind)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "for grp, grp_df in data_df[['Survived','Name', 'Last_Name', 'Fare', 'Ticket', 'PassengerId',\n",
    "                           'SibSp', 'Parch', 'Age', 'Cabin']].groupby(['Last_Name', 'Fare']):\n",
    "    \n",
    "    if (len(grp_df) != 1):\n",
    "        # A Family group is found.\n",
    "        #print(grp_df[\"Survived\"])\n",
    "        \n",
    "        for ind, row in grp_df.iterrows():\n",
    "            smax = grp_df.drop(ind)['Survived'].max()\n",
    "            smin = grp_df.drop(ind)['Survived'].min()\n",
    "            print(ind)\n",
    "            print(grp_df.drop(ind)['Survived'])\n",
    "            print(smax, smin)\n",
    "            \n",
    "            \n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of passengers with family survival information: 420\n",
      "Number of passenger with family/group survival information: 546\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"../input/train.csv\")\n",
    "test_df = pd.read_csv(\"../input/test.csv\")\n",
    "data_df = train_df.append(test_df) # The entire data: train + test.\n",
    "\n",
    "data_df['Title'] = data_df['Name']\n",
    "# Cleaning name and extracting Title\n",
    "for name_string in data_df['Name']:\n",
    "    data_df['Title'] = data_df['Name'].str.extract('([A-Za-z]+)\\.', expand=True)\n",
    "\n",
    "# Replacing rare titles with more common ones\n",
    "mapping = {'Mlle': 'Miss', 'Major': 'Mr', 'Col': 'Mr', 'Sir': 'Mr', 'Don': 'Mr', 'Mme': 'Miss',\n",
    "          'Jonkheer': 'Mr', 'Lady': 'Mrs', 'Capt': 'Mr', 'Countess': 'Mrs', 'Ms': 'Miss', 'Dona': 'Mrs'}\n",
    "data_df.replace({'Title': mapping}, inplace=True)\n",
    "titles = ['Dr', 'Master', 'Miss', 'Mr', 'Mrs', 'Rev']\n",
    "for title in titles:\n",
    "    age_to_impute = data_df.groupby('Title')['Age'].median()[titles.index(title)]\n",
    "    data_df.loc[(data_df['Age'].isnull()) & (data_df['Title'] == title), 'Age'] = age_to_impute\n",
    "    \n",
    "# Substituting Age values in TRAIN_DF and TEST_DF:\n",
    "train_df['Age'] = data_df['Age'][:891]\n",
    "test_df['Age'] = data_df['Age'][891:]\n",
    "\n",
    "# Dropping Title feature\n",
    "data_df.drop('Title', axis = 1, inplace = True)\n",
    "\n",
    "\n",
    "data_df['Family_Size'] = data_df['Parch'] + data_df['SibSp']\n",
    "\n",
    "# Substituting Age values in TRAIN_DF and TEST_DF:\n",
    "train_df['Family_Size'] = data_df['Family_Size'][:891]\n",
    "test_df['Family_Size'] = data_df['Family_Size'][891:]\n",
    "\n",
    "\n",
    "\n",
    "data_df['Last_Name'] = data_df['Name'].apply(lambda x: str.split(x, \",\")[0])\n",
    "data_df['Fare'].fillna(data_df['Fare'].mean(), inplace=True)\n",
    "\n",
    "DEFAULT_SURVIVAL_VALUE = 0.5\n",
    "data_df['Family_Survival'] = DEFAULT_SURVIVAL_VALUE\n",
    "\n",
    "# group of same family\n",
    "for grp, grp_df in data_df[['Survived','Name', 'Last_Name', 'Fare', 'Ticket', 'PassengerId',\n",
    "                           'SibSp', 'Parch', 'Age', 'Cabin']].groupby(['Last_Name', 'Fare']):\n",
    "    \n",
    "    if (len(grp_df) != 1):\n",
    "        # A Family group is found.\n",
    "        for ind, row in grp_df.iterrows():\n",
    "            smax = grp_df.drop(ind)['Survived'].max()\n",
    "            smin = grp_df.drop(ind)['Survived'].min()\n",
    "            passID = row['PassengerId']\n",
    "            \n",
    "            # If any family memebers survived, put this feature as 1\n",
    "            # Otherwise if any family memebers perished, put this feature as 0\n",
    "            if (smax == 1.0):\n",
    "                data_df.loc[data_df['PassengerId'] == passID, 'Family_Survival'] = 1\n",
    "            elif (smin==0.0):\n",
    "                data_df.loc[data_df['PassengerId'] == passID, 'Family_Survival'] = 0\n",
    "\n",
    "print(\"Number of passengers with family survival information:\", \n",
    "      data_df.loc[data_df['Family_Survival']!=0.5].shape[0])\n",
    "\n",
    "\n",
    "# also, group of same friends. they have same Ticket feature.\n",
    "for _, grp_df in data_df.groupby('Ticket'):\n",
    "    if (len(grp_df) != 1):\n",
    "        for ind, row in grp_df.iterrows():\n",
    "            if (row['Family_Survival'] == 0) | (row['Family_Survival']== 0.5):\n",
    "                smax = grp_df.drop(ind)['Survived'].max()\n",
    "                smin = grp_df.drop(ind)['Survived'].min()\n",
    "                passID = row['PassengerId']\n",
    "                if (smax == 1.0):\n",
    "                    data_df.loc[data_df['PassengerId'] == passID, 'Family_Survival'] = 1\n",
    "                elif (smin==0.0):\n",
    "                    data_df.loc[data_df['PassengerId'] == passID, 'Family_Survival'] = 0\n",
    "                        \n",
    "print(\"Number of passenger with family/group survival information: \" \n",
    "      +str(data_df[data_df['Family_Survival']!=0.5].shape[0]))\n",
    "\n",
    "# # Family_Survival in TRAIN_DF and TEST_DF:\n",
    "train_df['Family_Survival'] = data_df['Family_Survival'][:891]\n",
    "test_df['Family_Survival'] = data_df['Family_Survival'][891:]\n",
    "\n",
    "\n",
    "data_df['Fare'].fillna(data_df['Fare'].median(), inplace = True)\n",
    "\n",
    "# Making Bins\n",
    "data_df['FareBin'] = pd.qcut(data_df['Fare'], 5)\n",
    "\n",
    "label = LabelEncoder()\n",
    "data_df['FareBin_Code'] = label.fit_transform(data_df['FareBin'])\n",
    "\n",
    "train_df['FareBin_Code'] = data_df['FareBin_Code'][:891]\n",
    "test_df['FareBin_Code'] = data_df['FareBin_Code'][891:]\n",
    "\n",
    "train_df.drop(['Fare'], 1, inplace=True)\n",
    "test_df.drop(['Fare'], 1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data_df['AgeBin'] = pd.qcut(data_df['Age'], 4)\n",
    "\n",
    "label = LabelEncoder()\n",
    "data_df['AgeBin_Code'] = label.fit_transform(data_df['AgeBin'])\n",
    "\n",
    "train_df['AgeBin_Code'] = data_df['AgeBin_Code'][:891]\n",
    "test_df['AgeBin_Code'] = data_df['AgeBin_Code'][891:]\n",
    "\n",
    "train_df.drop(['Age'], 1, inplace=True)\n",
    "test_df.drop(['Age'], 1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "train_df['Sex'].replace(['male','female'],[0,1],inplace=True)\n",
    "test_df['Sex'].replace(['male','female'],[0,1],inplace=True)\n",
    "\n",
    "train_df.drop(['Name', 'PassengerId', 'SibSp', 'Parch', 'Ticket', 'Cabin',\n",
    "               'Embarked'], axis = 1, inplace = True)\n",
    "test_df.drop(['Name','PassengerId', 'SibSp', 'Parch', 'Ticket', 'Cabin',\n",
    "              'Embarked'], axis = 1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Family_Survival</th>\n",
       "      <th>FareBin_Code</th>\n",
       "      <th>AgeBin_Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex  Family_Size  Family_Survival  FareBin_Code  \\\n",
       "0         0       3    0            1              0.5             0   \n",
       "1         1       1    1            1              0.5             4   \n",
       "2         1       3    1            0              0.5             1   \n",
       "\n",
       "   AgeBin_Code  \n",
       "0            0  \n",
       "1            3  \n",
       "2            1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 240 candidates, totalling 2400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done 766 tasks      | elapsed:    3.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.879492358564122\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=26, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=18, p=2,\n",
      "           weights='uniform')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done 2400 out of 2400 | elapsed:    7.6s finished\n"
     ]
    }
   ],
   "source": [
    "X = train_df.drop('Survived', 1)\n",
    "y = train_df['Survived']\n",
    "X_test = test_df.copy()\n",
    "\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "X = std_scaler.fit_transform(X)\n",
    "X_test = std_scaler.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "n_neighbors = [6,7,8,9,10,11,12,14,16,18,20,22]\n",
    "algorithm = ['auto']\n",
    "weights = ['uniform', 'distance']\n",
    "leaf_size = list(range(1,50,5))\n",
    "hyperparams = {'algorithm': algorithm, 'weights': weights, 'leaf_size': leaf_size, \n",
    "               'n_neighbors': n_neighbors}\n",
    "gd=GridSearchCV(estimator = KNeighborsClassifier(), param_grid = hyperparams, verbose=True, \n",
    "                cv=10, scoring = \"roc_auc\", n_jobs=3)\n",
    "gd.fit(X, y)\n",
    "print(gd.best_score_)\n",
    "print(gd.best_estimator_)\n",
    "\n",
    "gd.best_estimator_.fit(X, y)\n",
    "y_pred = gd.best_estimator_.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "----\n",
    "----\n",
    "----\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# original\n",
    "\n",
    "https://www.kaggle.com/francksylla/titanic-machine-learning-from-disaster\n",
    "\n",
    "# points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuki/.local/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:30: FutureWarning: Categorical.from_array is deprecated, use Categorical instead\n",
      "/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: FutureWarning: Categorical.from_array is deprecated, use Categorical instead\n",
      "/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:84: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:86: FutureWarning: Categorical.from_array is deprecated, use Categorical instead\n",
      "/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:88: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Buffer dtype mismatch, expected 'Python object' but got 'long'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;31mValueError\u001b[0m: Buffer dtype mismatch, expected 'Python object' but got 'long'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'pandas._libs.lib.is_bool_array'\n",
      "ValueError: Buffer dtype mismatch, expected 'Python object' but got 'long'\n",
      "/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:101: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:107: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:109: FutureWarning: Categorical.from_array is deprecated, use Categorical instead\n",
      "/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:111: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Buffer dtype mismatch, expected 'Python object' but got 'long'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;31mValueError\u001b[0m: Buffer dtype mismatch, expected 'Python object' but got 'long'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'pandas._libs.lib.is_bool_array'\n",
      "ValueError: Buffer dtype mismatch, expected 'Python object' but got 'long'\n",
      "/home/yuki/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:126: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features importance :\n",
      "68.85 female\n",
      "68.85 male\n",
      "64.90 male_adult\n",
      "53.23 female_adult\n",
      "26.22 TitleCat\n",
      "24.60 Pclass\n",
      "24.60 Pclass\n",
      "23.69 NameLength\n",
      "17.75 CabinCat\n",
      "17.00 Ticket_surviving_men\n",
      "16.28 CabinType\n",
      "14.21 Fare\n",
      "13.54 Ticket_perishing_women\n",
      "13.04 Surname_surviving_men\n",
      "10.36 Surname_perishing_women\n",
      "6.94 Embarked\n",
      "5.27 Ticket_Members\n",
      "3.59 child\n",
      "2.93 FamilySize\n",
      "1.83 Parch\n",
      "1.79 Age\n",
      "1.07 Ticket_Id\n",
      "0.73 Surname_Members\n",
      "0.53 SibSp\n",
      "Accuracy: 89.675 (+/- 0.88) [RFC Cross Validation]\n",
      "Accuracy: 96.296            [RFC full test]\n",
      "1. feature 3 (9.065882) Age\n",
      "2. feature 16 (8.847920) Fare\n",
      "3. feature 11 (8.524511) NameLength\n",
      "4. feature 21 (7.702126) Ticket_perishing_women\n",
      "5. feature 7 (6.984746) TitleCat\n",
      "6. feature 2 (6.805425) male\n",
      "7. feature 23 (6.511190) Surname_perishing_women\n",
      "8. feature 1 (5.858741) female\n",
      "9. feature 4 (4.639197) male_adult\n",
      "10. feature 22 (4.528991) Ticket_surviving_men\n",
      "11. feature 9 (3.971880) Pclass\n",
      "12. feature 8 (3.825686) Pclass\n",
      "13. feature 5 (3.749371) female_adult\n",
      "14. feature 19 (2.678212) Ticket_Members\n",
      "15. feature 24 (2.526357) Surname_surviving_men\n",
      "16. feature 13 (2.408370) CabinCat\n",
      "17. feature 20 (2.203285) FamilySize\n",
      "18. feature 18 (1.857232) Surname_Members\n",
      "19. feature 12 (1.774543) CabinType\n",
      "20. feature 17 (1.690243) Embarked\n",
      "21. feature 10 (1.246668) Ticket_Id\n",
      "22. feature 14 (1.169161) SibSp\n",
      "23. feature 15 (0.729642) Parch\n",
      "24. feature 6 (0.700622) child\n",
      "The end ...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesRegressor\n",
    "from sklearn import cross_validation\n",
    "import re\n",
    "import operator\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "#Print you can execute arbitrary python code\n",
    "train = pd.read_csv(\"../input/train.csv\", dtype={\"Age\": np.float64}, )\n",
    "test = pd.read_csv(\"../input/test.csv\", dtype={\"Age\": np.float64}, )\n",
    "\n",
    "target = train[\"Survived\"].values\n",
    "full = pd.concat([train, test])\n",
    "#print(full.head())\n",
    "#print(full.describe())\n",
    "#print(full.info())\n",
    "\n",
    "full['surname'] = full[\"Name\"].apply(lambda x: x.split(',')[0].lower())\n",
    "\n",
    "full[\"Title\"] = full[\"Name\"].apply(lambda x: re.search(' ([A-Za-z]+)\\.',x).group(1))\n",
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Dr\": 5, \"Rev\": 6, \"Major\": 7, \"Col\": 7, \"Mlle\": 2, \"Mme\": 3,\"Don\": 9,\"Dona\": 9, \"Lady\": 10, \"Countess\": 10, \"Jonkheer\": 10, \"Sir\": 9, \"Capt\": 7, \"Ms\": 2}\n",
    "full[\"TitleCat\"] = full.loc[:,'Title'].map(title_mapping)\n",
    "\n",
    "full[\"FamilySize\"] = full[\"SibSp\"] + full[\"Parch\"] + 1\n",
    "full[\"FamilySize\"] = pd.cut(full[\"FamilySize\"], bins=[0,1,4,20], labels=[0,1,2])\n",
    "\n",
    "full[\"NameLength\"] = full[\"Name\"].apply(lambda x: len(x))\n",
    "\n",
    "full[\"Embarked\"] = pd.Categorical.from_array(full.Embarked).codes\n",
    "\n",
    "full[\"Fare\"] = full[\"Fare\"].fillna(8.05)\n",
    "\n",
    "full = pd.concat([full,pd.get_dummies(full['Sex'])],axis=1)\n",
    "\n",
    "full['CabinCat'] = pd.Categorical.from_array(full.Cabin.fillna('0').apply(lambda x: x[0])).codes\n",
    "\n",
    "# function to get oven/odd/null from cabine \n",
    "def get_type_cabine(cabine):\n",
    "    # Use a regular expression to search for a title. \n",
    "    cabine_search = re.search('\\d+', cabine)\n",
    "    # If the title exists, extract and return it.\n",
    "    if cabine_search:\n",
    "        num = cabine_search.group(0)\n",
    "        if np.float64(num) % 2 == 0:\n",
    "            return '2'\n",
    "        else:\n",
    "            return '1'\n",
    "    return '0'\n",
    "full[\"Cabin\"] = full[\"Cabin\"].fillna(\" \")\n",
    "\n",
    "full[\"CabinType\"] = full[\"Cabin\"].apply(get_type_cabine)\n",
    "#print(pd.value_counts(full[\"CabinType\"]))\n",
    "\n",
    "\n",
    "\n",
    "#### CHILD/FEMALE ADULT/MALE ADULT------------------------------------------------------------\n",
    "child_age = 18\n",
    "def get_person(passenger):\n",
    "    age, sex = passenger\n",
    "    if (age < child_age):\n",
    "        return 'child'\n",
    "    elif (sex == 'female'):\n",
    "        return 'female_adult'\n",
    "    else:\n",
    "        return 'male_adult'\n",
    "full = pd.concat([full, pd.DataFrame(full[['Age', 'Sex']].apply(get_person, axis=1), columns=['person'])],axis=1)\n",
    "full = pd.concat([full,pd.get_dummies(full['person'])],axis=1)\n",
    "\n",
    "### FEATURES BASED ON TICKET   --------------------------------------------------------\n",
    "table_ticket = pd.DataFrame(full[\"Ticket\"].value_counts())\n",
    "table_ticket.rename(columns={'Ticket':'Ticket_Members'}, inplace=True)\n",
    "\n",
    "table_ticket['Ticket_perishing_women'] = full.Ticket[(full.female_adult == 1.0) \n",
    "                                    & (full.Survived == 0.0) \n",
    "                                    & ((full.Parch > 0) | (full.SibSp > 0))].value_counts()\n",
    "table_ticket['Ticket_perishing_women'] = table_ticket['Ticket_perishing_women'].fillna(0)\n",
    "table_ticket['Ticket_perishing_women'][table_ticket['Ticket_perishing_women'] > 0] = 1.0 \n",
    "\n",
    "table_ticket['Ticket_surviving_men'] = full.Ticket[(full.male_adult == 1.0) \n",
    "                                    & (full.Survived == 1.0) \n",
    "                                    & ((full.Parch > 0) | (full.SibSp > 0))].value_counts()\n",
    "table_ticket['Ticket_surviving_men'] = table_ticket['Ticket_surviving_men'].fillna(0)\n",
    "table_ticket['Ticket_surviving_men'][table_ticket['Ticket_surviving_men'] > 0] = 1.0 \n",
    "\n",
    "table_ticket[\"Ticket_Id\"]= pd.Categorical.from_array(table_ticket.index).codes\n",
    "# compress under 3 members into one code.\n",
    "table_ticket[\"Ticket_Id\"][table_ticket[\"Ticket_Members\"] < 3 ] = -1\n",
    "table_ticket[\"Ticket_Members\"] = pd.cut(table_ticket[\"Ticket_Members\"], bins=[0,1,4,20], labels=[0,1,2])\n",
    "\n",
    "full = pd.merge(full, table_ticket, left_on=\"Ticket\",right_index=True,how='left', sort=False)\n",
    "\n",
    "### FEATURES BASED ON SURNAME    --------------------------------------------------------\n",
    "table_surname = pd.DataFrame(full[\"surname\"].value_counts())\n",
    "table_surname.rename(columns={'surname':'Surname_Members'}, inplace=True)\n",
    "\n",
    "table_surname['Surname_perishing_women'] = full.surname[(full.female_adult == 1.0) \n",
    "                                    & (full.Survived == 0.0) \n",
    "                                    & ((full.Parch > 0) | (full.SibSp > 0))].value_counts()\n",
    "table_surname['Surname_perishing_women'] = table_surname['Surname_perishing_women'].fillna(0)\n",
    "table_surname['Surname_perishing_women'][table_surname['Surname_perishing_women'] > 0] = 1.0 \n",
    "\n",
    "table_surname['Surname_surviving_men'] = full.surname[(full.male_adult == 1.0) \n",
    "                                    & (full.Survived == 1.0) \n",
    "                                    & ((full.Parch > 0) | (full.SibSp > 0))].value_counts()\n",
    "table_surname['Surname_surviving_men'] = table_surname['Surname_surviving_men'].fillna(0)\n",
    "table_surname['Surname_surviving_men'][table_surname['Surname_surviving_men'] > 0] = 1.0 \n",
    "\n",
    "table_surname[\"Surname_Id\"]= pd.Categorical.from_array(table_surname.index).codes\n",
    "# compress under 3 members into one code.\n",
    "table_surname[\"Surname_Id\"][table_surname[\"Surname_Members\"] < 3 ] = -1\n",
    "\n",
    "table_surname[\"Surname_Members\"] = pd.cut(table_surname[\"Surname_Members\"], bins=[0,1,4,20], labels=[0,1,2])\n",
    "\n",
    "full = pd.merge(full, table_surname, left_on=\"surname\",right_index=True,how='left', sort=False)\n",
    "\n",
    "### AGE PROCESSING --------------------------------------------------------------------------\n",
    "classers = ['Fare','Parch','Pclass','SibSp','TitleCat', \n",
    "'CabinCat','female','male', 'Embarked', 'FamilySize', 'NameLength','Ticket_Members','Ticket_Id']\n",
    "etr = ExtraTreesRegressor(n_estimators=200)\n",
    "X_train = full[classers][full['Age'].notnull()]\n",
    "Y_train = full['Age'][full['Age'].notnull()]\n",
    "X_test = full[classers][full['Age'].isnull()]\n",
    "etr.fit(X_train,np.ravel(Y_train))\n",
    "age_preds = etr.predict(X_test)\n",
    "full['Age'][full['Age'].isnull()] = age_preds\n",
    "\n",
    "# FEATURES -----------------------------------------------------------------------------------\n",
    "features = ['female','male','Age','male_adult','female_adult', 'child','TitleCat', 'Pclass',\n",
    "'Pclass','Ticket_Id','NameLength','CabinType','CabinCat', 'SibSp', 'Parch',\n",
    "'Fare','Embarked','Surname_Members','Ticket_Members','FamilySize',\n",
    "'Ticket_perishing_women','Ticket_surviving_men',\n",
    "'Surname_perishing_women','Surname_surviving_men']\n",
    "\n",
    "train = full[0:891].copy()\n",
    "test = full[891:].copy()\n",
    "\n",
    "selector = SelectKBest(f_classif, k=len(features))\n",
    "selector.fit(train[features], target)\n",
    "scores = -np.log10(selector.pvalues_)\n",
    "indices = np.argsort(scores)[::-1]\n",
    "print(\"Features importance :\")\n",
    "for f in range(len(scores)):\n",
    "    print(\"%0.2f %s\" % (scores[indices[f]],features[indices[f]]))\n",
    "\n",
    "# BEST CLASSIFIER METHOD ==> RANDOM FOREST -----------------------------------------------------\n",
    "rfc = RandomForestClassifier(n_estimators=3000, min_samples_split=4, class_weight={0:0.745,1:0.255})\n",
    "\n",
    "\n",
    "# CROSS VALIDATION WITH RANDOM FOREST CLASSIFIER METHOD-----------------------------------------\n",
    "kf = cross_validation.KFold(train.shape[0], n_folds=3, random_state=1)\n",
    "\n",
    "scores = cross_validation.cross_val_score(rfc, train[features], target, cv=kf)\n",
    "print(\"Accuracy: %0.3f (+/- %0.2f) [%s]\" % (scores.mean()*100, scores.std()*100, 'RFC Cross Validation'))\n",
    "rfc.fit(train[features], target)\n",
    "score = rfc.score(train[features], target)\n",
    "print(\"Accuracy: %0.3f            [%s]\" % (score*100, 'RFC full test'))\n",
    "importances = rfc.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "for f in range(len(features)):\n",
    "    print(\"%d. feature %d (%f) %s\" % (f + 1, indices[f]+1, importances[indices[f]]*100, features[indices[f]]))\n",
    "\n",
    "\n",
    "# PREDICTION  -----------------------------------------------------------------------------------\n",
    "rfc.fit(train[features], target)\n",
    "predictions = rfc.predict(test[features])\n",
    "\n",
    "# OUTPUT FILE -----------------------------------------------------------------------------------\n",
    "PassengerId =np.array(test[\"PassengerId\"]).astype(int)\n",
    "my_prediction = pd.DataFrame(predictions, PassengerId, columns = [\"Survived\"])\n",
    "\n",
    "#my_prediction.to_csv(\"my_prediction.csv\", index_label = [\"PassengerId\"])\n",
    "\n",
    "print(\"The end ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
