{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ハイパーパラメータ自動調整いろいろ\n",
    "## Kerasと遺伝アルゴリズム\n",
    "\n",
    "https://qiita.com/cvusk/items/1f3b178f34c39beb29ff#_reference-3c5df6e5237c0c705690\n",
    "\n",
    "https://github.com/shibuiwilliam/keras_opt/blob/master/ga_nn.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from keras.layers import Activation, Dropout, BatchNormalization, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.datasets import mnist\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST class\n",
    "class MNIST():\n",
    "    def __init__(self,\n",
    "                 l1_out=512, \n",
    "                 l2_out=512, \n",
    "                 l1_drop=0.2, \n",
    "                 l2_drop=0.2, \n",
    "                 bn1=0,\n",
    "                 bn2=0,\n",
    "                 batch_size=100, \n",
    "                 epochs=10, \n",
    "                 validation_split=0.1):\n",
    "        self.l1_out = l1_out\n",
    "        self.l2_out = l2_out\n",
    "        self.l1_drop = l1_drop\n",
    "        self.l2_drop = l2_drop\n",
    "        self.bn1 = bn1\n",
    "        self.bn2 = bn2\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.validation_split = validation_split\n",
    "        self.__x_train, self.__x_test, self.__y_train, self.__y_test = self.mnist_data()\n",
    "        self.__model = self.mnist_model()\n",
    "        params = \"\"\"\n",
    "        l1_out:\\t{0}\n",
    "        l2_out:\\t{1}\n",
    "        l1_drop:\\t{2}\n",
    "        l2_drop:\\t{3}\n",
    "        bn1:\\t{4}\n",
    "        bn2:\\t{5}\n",
    "        batch_size:\\t{6}\n",
    "        epochs:\\t{7}\n",
    "        validation_split:\\t{8}\n",
    "        \"\"\".format(self.l1_out, self.l2_out,\n",
    "                   self.l1_drop, self.l2_drop,\n",
    "                   self.bn1, self.bn2,\n",
    "                   self.batch_size, self.epochs,\n",
    "                   self.validation_split)\n",
    "        print(params)\n",
    "        \n",
    "    # load mnist data from keras dataset\n",
    "    def mnist_data(self):\n",
    "        (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "        X_train = X_train.reshape(60000, 784)\n",
    "        X_test = X_test.reshape(10000, 784)\n",
    "\n",
    "        X_train = X_train.astype('float32')\n",
    "        X_test = X_test.astype('float32')\n",
    "        X_train /= 255\n",
    "        X_test /= 255\n",
    "\n",
    "        Y_train = np_utils.to_categorical(y_train, 10)\n",
    "        Y_test = np_utils.to_categorical(y_test, 10)\n",
    "        return X_train, X_test, Y_train, Y_test\n",
    "    \n",
    "    # mnist model\n",
    "    def mnist_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(self.l1_out, input_shape=(784,)))\n",
    "        if self.bn1 == 0:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(self.l1_drop))\n",
    "        model.add(Dense(self.l2_out))\n",
    "        if self.bn2 == 0:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(self.l2_drop))\n",
    "        model.add(Dense(10))\n",
    "        model.add(Activation('softmax'))\n",
    "        model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer=Adam(),\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        return model\n",
    "    \n",
    "    # fit mnist model\n",
    "    def mnist_fit(self):\n",
    "        early_stopping = EarlyStopping(patience=0, verbose=1)\n",
    "        \n",
    "        self.__model.fit(self.__x_train, self.__y_train,\n",
    "                       batch_size=self.batch_size,\n",
    "                       epochs=self.epochs,\n",
    "                       verbose=0,\n",
    "                       validation_split=self.validation_split,\n",
    "                       callbacks=[early_stopping])\n",
    "    \n",
    "    # evaluate mnist model\n",
    "    def mnist_evaluate(self):\n",
    "        self.mnist_fit()\n",
    "        \n",
    "        evaluation = self.__model.evaluate(self.__x_test, self.__y_test, batch_size=self.batch_size, verbose=0)\n",
    "        return evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (60000, 28, 28) [[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "y_train (60000,) [5 0 4 1 9 2]\n",
      "(60000, 784)\n",
      "[0 0 0 0 0 0]\n",
      "(60000, 784)\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "(60000, 784)\n",
      "[0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "print(\"X_train\", X_train.shape, X_train[0, :6, :6])\n",
    "print(\"y_train\", y_train.shape, y_train[:6])\n",
    "\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "print(X_train.shape)\n",
    "print(X_train[0, :6])\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "print(X_train.shape)\n",
    "print(X_train[0, :6])\n",
    "\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.shape)\n",
    "print(X_train[0, :6])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train <class 'numpy.ndarray'> (60000,) 5\n",
      "Y_train <class 'numpy.ndarray'> (60000, 10) [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)\n",
    "\n",
    "print(\"y_train\", type(y_train), y_train.shape, y_train[0])\n",
    "\n",
    "print(\"Y_train\", type(Y_train), Y_train.shape, Y_train[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mnist(bounds):\n",
    "    _mnist = MNIST(l1_out=bounds[0], \n",
    "                   l2_out=bounds[1], \n",
    "                   l1_drop=bounds[2], \n",
    "                   l2_drop=bounds[3], \n",
    "                   bn1=bounds[4],\n",
    "                   bn2=bounds[5],\n",
    "                   batch_size=bounds[6],\n",
    "                   epochs=bounds[7], \n",
    "                   validation_split=bounds[8])\n",
    "    mnist_evaluation = _mnist.mnist_evaluate()\n",
    "    print(mnist_evaluation)\n",
    "    return mnist_evaluation[0],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\deap\\tools\\_hypervolume\\pyhv.py:33: ImportWarning: Falling back to the python version of hypervolume module. Expect this to be very slow.\n",
      "  \"module. Expect this to be very slow.\", ImportWarning)\n"
     ]
    }
   ],
   "source": [
    "from deap import base, creator, tools, algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\deap\\creator.py:141: RuntimeWarning: A class named 'FitnessMax' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  RuntimeWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\deap\\creator.py:141: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "creator.create('FitnessMax', base.Fitness, weights = (-1.0, ))\n",
    "creator.create('Individual', list, fitness=creator.FitnessMax)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register('L1_out', random.choice, (64, 128, 256, 512, 1024))\n",
    "toolbox.register('L2_out', random.choice, (64, 128, 256, 512, 1024))\n",
    "toolbox.register(\"L1_drop\", random.uniform, 0.0, 0.3)\n",
    "toolbox.register(\"L2_drop\", random.uniform, 0.0, 0.3)\n",
    "toolbox.register(\"bn1\", random.randint, 0, 1)\n",
    "toolbox.register(\"bn2\", random.randint, 0, 1)\n",
    "toolbox.register(\"batch_size\", random.choice, (10, 100, 500))\n",
    "toolbox.register(\"epochs\", random.choice, (5, 10, 20))\n",
    "toolbox.register(\"validation_split\", random.uniform, 0.0, 0.3)\n",
    "\n",
    "toolbox.register('individual', tools.initCycle, creator.Individual,\n",
    "                 (toolbox.L1_out, toolbox.L2_out,\n",
    "                 toolbox.L1_drop, toolbox.L2_drop,\n",
    "                 toolbox.bn1, toolbox.bn2,\n",
    "                 toolbox.batch_size, toolbox.epochs, toolbox.validation_split),\n",
    "                 n=1)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "toolbox.register(\"evaluate\", run_mnist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of evolution\n",
      "\n",
      "        l1_out:\t512\n",
      "        l2_out:\t64\n",
      "        l1_drop:\t0.18906571629566554\n",
      "        l2_drop:\t0.12118829087054188\n",
      "        bn1:\t0\n",
      "        bn2:\t0\n",
      "        batch_size:\t100\n",
      "        epochs:\t20\n",
      "        validation_split:\t0.27380697683392835\n",
      "        \n",
      "Epoch 00007: early stopping\n",
      "[0.07106867912851157, 0.9772000056505203]\n",
      "\n",
      "        l1_out:\t128\n",
      "        l2_out:\t128\n",
      "        l1_drop:\t0.023943619120116687\n",
      "        l2_drop:\t0.12502013021715647\n",
      "        bn1:\t0\n",
      "        bn2:\t0\n",
      "        batch_size:\t10\n",
      "        epochs:\t10\n",
      "        validation_split:\t0.20383943374115368\n",
      "        \n",
      "[0.06667245912841327, 0.9809999964833259]\n",
      "\n",
      "        l1_out:\t64\n",
      "        l2_out:\t64\n",
      "        l1_drop:\t0.052369065073309795\n",
      "        l2_drop:\t0.17600891153302792\n",
      "        bn1:\t1\n",
      "        bn2:\t0\n",
      "        batch_size:\t500\n",
      "        epochs:\t5\n",
      "        validation_split:\t0.026646503392500687\n",
      "        \n",
      "[0.11047704452648759, 0.9665000021457673]\n",
      "\n",
      "        l1_out:\t64\n",
      "        l2_out:\t512\n",
      "        l1_drop:\t0.11910387551405677\n",
      "        l2_drop:\t0.06412721938460672\n",
      "        bn1:\t0\n",
      "        bn2:\t1\n",
      "        batch_size:\t100\n",
      "        epochs:\t20\n",
      "        validation_split:\t0.09210574048914517\n",
      "        \n",
      "Epoch 00005: early stopping\n",
      "[0.0841208848777751, 0.9732000041007995]\n",
      "\n",
      "        l1_out:\t256\n",
      "        l2_out:\t512\n",
      "        l1_drop:\t0.15575202668971602\n",
      "        l2_drop:\t0.015022987876030168\n",
      "        bn1:\t0\n",
      "        bn2:\t1\n",
      "        batch_size:\t10\n",
      "        epochs:\t5\n",
      "        validation_split:\t0.06589604628677845\n",
      "        \n",
      "Epoch 00005: early stopping\n",
      "[0.07766676420411596, 0.9773999960422516]\n",
      "  Evaluated 5 individuals\n",
      "-- Generation 0 --\n",
      "mate\n",
      "mutate\n",
      "mutate\n",
      "    Min 0.06667245912841327\n",
      "    Max 0.11047704452648759\n",
      "    Avg 0.0763126202080478\n",
      "    Std 0.017166857161285805\n",
      "-- Generation 1 --\n",
      "mutate\n",
      "    Min 0.06667245912841327\n",
      "    Max 0.07106867912851157\n",
      "    Avg 0.06755170312843292\n",
      "    Std 0.0017584880000396886\n",
      "-- Generation 2 --\n",
      "mate\n",
      "mutate\n",
      "    Min 0.06667245912841327\n",
      "    Max 0.11047704452648759\n",
      "    Avg 0.07631262020804779\n",
      "    Std 0.017166857161285857\n",
      "-- Generation 3 --\n",
      "    Min 0.06667245912841327\n",
      "    Max 0.06667245912841327\n",
      "    Avg 0.06667245912841327\n",
      "    Std 0.0\n",
      "-- Generation 4 --\n",
      "mate\n",
      "mutate\n",
      "    Min 0.06667245912841327\n",
      "    Max 0.07106867912851157\n",
      "    Avg 0.06755170312843292\n",
      "    Std 0.001758488000039442\n",
      "-- Generation 5 --\n",
      "mate\n",
      "    Min 0.06667245912841327\n",
      "    Max 0.07106867912851157\n",
      "    Avg 0.06755170312843292\n",
      "    Std 0.001758488000039442\n",
      "-- Generation 6 --\n",
      "mate\n",
      "mate\n",
      "    Min 0.06667245912841327\n",
      "    Max 0.11047704452648759\n",
      "    Avg 0.07980230535792017\n",
      "    Std 0.0166171700554875\n",
      "-- Generation 7 --\n",
      "mutate\n",
      "mutate\n",
      "    Min 0.06667245912841327\n",
      "    Max 0.07106867912851157\n",
      "    Avg 0.06755170312843292\n",
      "    Std 0.0017584880000396886\n",
      "-- Generation 8 --\n",
      "    Min 0.06667245912841327\n",
      "    Max 0.06667245912841327\n",
      "    Avg 0.06667245912841327\n",
      "    Std 0.0\n",
      "-- Generation 9 --\n",
      "mate\n",
      "mate\n",
      "mutate\n",
      "    Min 0.06667245912841327\n",
      "    Max 0.11047704452648759\n",
      "    Avg 0.07980230535792017\n",
      "    Std 0.0166171700554875\n",
      "-- End of (successful) evolution --\n",
      "Best individual is [128, 128, 0.023943619120116687, 0.12502013021715647, 0, 0, 10, 10, 0.20383943374115368], (0.06667245912841327,)\n"
     ]
    }
   ],
   "source": [
    "def genAlg(population=5, CXPB=0.5, MUTPB=0.2, NGEN=5):\n",
    "    \"\"\"Function for running hyper parameter optimization on Genetic Algorithm\"\"\"\n",
    "    random.seed(64)\n",
    "    pop = toolbox.population(n=population)\n",
    "    \n",
    "    print(\"Start of evolution\")\n",
    "    \n",
    "    fitnesses = list(map(toolbox.evaluate, pop))\n",
    "    for ind, fit in zip(pop, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "        \n",
    "    print(\"  Evaluated %i individuals\" % len(pop))\n",
    "    \n",
    "    for g in range(NGEN):\n",
    "        print(\"-- Generation %i --\" % g)\n",
    "        \n",
    "        offspring = toolbox.select(pop, len(pop))\n",
    "        offspring = list(map(toolbox.clone, offspring))\n",
    "        \n",
    "        for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
    "            if random.random() < CXPB:\n",
    "                print(\"mate\")\n",
    "                toolbox.mate(child1, child2)\n",
    "                del child1.fitness.values\n",
    "                del child2.fitness.values\n",
    "                \n",
    "        for mutant in offspring:\n",
    "            if random.random() < MUTPB:\n",
    "                print(\"mutate\")\n",
    "                toolbox.mutate(mutant)\n",
    "                del mutant.fitness.values\n",
    "        try:\n",
    "            invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "            fitness = map(toolbox.evaluate, invalid_ind)\n",
    "            for ind, fit in zip(invalid_ind, fitnesses):\n",
    "                ind.fitness.values = fit\n",
    "        except AssertionError:\n",
    "            pass\n",
    "        \n",
    "        pop[:] = offspring\n",
    "        \n",
    "        try:\n",
    "            fits = [ind.fitness.values[0] for ind in pop]\n",
    "            \n",
    "            length = len(pop)\n",
    "            mean = sum(fits)/length\n",
    "            sum2 = sum(x*x for x in fits)\n",
    "            std = abs(sum2/length - mean**2)**0.5\n",
    "\n",
    "            print(\"    Min %s\" % min(fits))\n",
    "            print(\"    Max %s\" % max(fits))\n",
    "            print(\"    Avg %s\" % mean)\n",
    "            print(\"    Std %s\" % std)\n",
    "        except IndexError:\n",
    "            pass\n",
    "    print(\"-- End of (successful) evolution --\")\n",
    "    \n",
    "    best_ind = tools.selBest(pop, 1)[0]\n",
    "    print(\"Best individual is %s, %s\" % (best_ind, best_ind.fitness.values))\n",
    "    return best_ind\n",
    "\n",
    "\n",
    "best_int = genAlg(population=5, CXPB=0.5, MUTPB=0.2, NGEN=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[128, 128, 0.023943619120116687, 0.12502013021715647, 0, 0, 10, 10, 0.20383943374115368]\n"
     ]
    }
   ],
   "source": [
    "print(best_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
